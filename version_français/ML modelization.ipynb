{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e1f8c8",
   "metadata": {},
   "source": [
    "# Le cœur de l'expérience : la modélisation ML\n",
    "------\n",
    "\n",
    "Plan :\n",
    "- 1- Introduction\n",
    "- 2- Définitions des fonctions\n",
    "- 3- Prototypage\n",
    "- 4- Expérimentation\n",
    "- 5- Log-return\n",
    "\n",
    "## 1- Introduction\n",
    "\n",
    "Après avoir identifié les phases de marché et la spécificité de Binance dans l’analyse exploratoire (**EDA.ipynb**), nous passons à l’étape décisive qui consiste à tester l’hypothèse développée dans le premier article (**Article 1 - Introduction au projet**) : le prix passé contient-il, à lui seul, un signal prédictif exploitable ?\n",
    "\n",
    "Nous entrons ainsi dans le cœur de l’expérimentation : la modélisation. Pour ce faire, nous mobilisons des réseaux de neurones récurrents (RNN), conçus précisément pour traiter les séquences temporelles. Contrairement aux implémentations courantes, qui reposent sur une prédiction single-step (corrigée en continu par les valeurs réelles), nous imposons ici une contrainte réaliste : le modèle ne peut s’appuyer que sur ses propres prédictions antérieures pour estimer le futur. Cette approche multi-step autorégressive simule les conditions opérationnelles réelles, où les valeurs futures sont inconnues au moment de la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56ff9e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Third-party imports\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "from dash.dependencies import Input as DashInput, Output, State # Rename of import to avoid conflict with plotly Input/Output\n",
    "from plotly.subplots import make_subplots\n",
    "from typing import List, Dict, Any, Optional, Union, Tuple\n",
    "from itertools import cycle\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, History\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    LSTM,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    GlobalAveragePooling1D,\n",
    "    Input,\n",
    "    SimpleRNN,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "# --- Visual Configuration ---\n",
    "\n",
    "# Standardized color palette for plotting\n",
    "# Ensures visual consistency across Plotly visualizations\n",
    "custom_colors = {\n",
    "    'Initial sequence': '#118c4f',\n",
    "    'Real values': '#2c7bb6',\n",
    "    'Predictions': '#f33333'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5179bb",
   "metadata": {},
   "source": [
    "## 2- Définitions des fonctions\n",
    "\n",
    "Cette partie du code repose sur une architecture modulaire et reproductible, où chaque composant répond à une problématique précise pour faciliter l’expérimentation.\n",
    "\n",
    "La fonction *\"split\\_and\\_generate\\_dataset\"* met en œuvre un découpage chronologique strict (entraînement, validation, test) et une normalisation, afin d’éviter toute fuite d’information.\n",
    "\n",
    "La classe *\"ModelGenerator\"* agit comme un constructeur déclaratif de modèles, permettant de spécifier des architectures via un schéma de configuration simple et sérialisable. Cette abstraction élimine la duplication de code entre expériences et standardise le processus de définition des modèles.\n",
    "\n",
    "Enfin, les fonctions *\"predict\\_future\\_from\\_sequence\"* et *\"run\\_walkforward\\_prediction\"* implémentent une validation prospective de type *\"walk-forward\"*, simulant un déploiement en conditions réelles : le modèle génère ses prédictions de manière autorégressive, chaque nouvelle estimation s’appuyant uniquement sur les observations passées et les prédictions antérieures, conformément aux contraintes opérationnelles où les valeurs futures restent inconnues, comme expliquée plus en détail dans l'**Article 1 - Introduction au projet**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "987b1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    \"\"\"\n",
    "    Set random seeds for reproducibility across Python, NumPy, and TensorFlow.\n",
    "\n",
    "    Args:\n",
    "        seed: The seed value to ensure consistent results. Defaults to 42.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize seeds for all relevant libraries\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "# Enable deterministic operations for consistent GPU results\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "\n",
    "# Apply seed at the start of the execution\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6bb08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_generate_dataset(\n",
    "    df: pd.DataFrame,\n",
    "    input_width: int = 24,\n",
    "    batch_size: int = 32,\n",
    "    train_ratio: float = 0.7,\n",
    "    val_ratio: float = 0.25,\n",
    "    scaler_type: str = 'minmax'\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, tf.data.Dataset, tf.data.Dataset, tf.data.Dataset, Union[MinMaxScaler, StandardScaler]]:\n",
    "    \"\"\"\n",
    "    Split time series data and create scaled training, validation, and test generators.\n",
    "\n",
    "    Args:\n",
    "        df: Single-column DataFrame containing the time series.\n",
    "        input_width: Number of historical steps per input sequence. Defaults to 24.\n",
    "        batch_size: Number of samples per training batch. Defaults to 32.\n",
    "        train_ratio: Fraction of data used for training. Defaults to 0.7.\n",
    "        val_ratio: Fraction of data used for validation. Defaults to 0.25.\n",
    "        scaler_type: Scaling method ('minmax' or 'standard'). Defaults to 'minmax'.\n",
    "\n",
    "    Returns:\n",
    "        DataFrames for each split, their corresponding TF generators, and the fitted scaler.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(df)\n",
    "    train_size = int(n * train_ratio)\n",
    "    val_size = int(n * val_ratio)\n",
    "    \n",
    "    # Chronological split to respect time-series order\n",
    "    df_train = df.iloc[:train_size]\n",
    "    df_val = df.iloc[train_size: train_size + val_size]\n",
    "    df_test = df.iloc[train_size + val_size:]\n",
    "    \n",
    "    # Feature scaling: fit only on training data to avoid data leakage\n",
    "    if scaler_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaler_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        raise ValueError(\"scaler_type must be either 'minmax' or 'standard'\")\n",
    "    \n",
    "    scaled_train = scaler.fit_transform(df_train) \n",
    "    scaled_val = scaler.transform(df_val)\n",
    "    scaled_test = scaler.transform(df_test)\n",
    "    \n",
    "    # Generate TF datasets for model consumption\n",
    "    # Note: Targets (y) are identical to inputs (X) for windowed forecasting\n",
    "    train_gen = timeseries_dataset_from_array(\n",
    "        scaled_train, scaled_train,\n",
    "        sequence_length=input_width,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    val_gen = timeseries_dataset_from_array(\n",
    "        scaled_val, scaled_val,\n",
    "        sequence_length=input_width,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    test_gen = timeseries_dataset_from_array(\n",
    "        scaled_test, scaled_test,\n",
    "        sequence_length=input_width,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    return df_train, df_val, df_test, train_gen, val_gen, test_gen, scaler\n",
    "\n",
    "class ModelGenerator:\n",
    "    \"\"\"\n",
    "    A flexible neural network model generator for time series forecasting.\n",
    "\n",
    "    Attributes:\n",
    "        input_shape: Shape of the input data (steps, features).\n",
    "        model: The compiled Keras Sequential model instance.\n",
    "        layer_types: Mapping of identifiers to Keras layer classes.\n",
    "        optimizer_map: Mapping of names to Keras optimizer classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape: Tuple[int, ...]) -> None:\n",
    "        \"\"\"Initializes the generator with input dimensions and component maps.\"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        self.model = None\n",
    "        \n",
    "        self.layer_types = {\n",
    "            'lstm': LSTM,\n",
    "            'gru': GRU,\n",
    "            'simplernn': SimpleRNN,\n",
    "            'dense': Dense,\n",
    "            'dropout': Dropout,\n",
    "            'global_average_pooling1d': GlobalAveragePooling1D,\n",
    "        }\n",
    "        \n",
    "        self.optimizer_map = {\n",
    "            'adam': Adam,\n",
    "            'sgd': SGD,\n",
    "            'rmsprop': RMSprop\n",
    "        }\n",
    "    \n",
    "    def build_model(\n",
    "        self,\n",
    "        layers_config: List[Dict[str, Any]],\n",
    "        optimizer_name: str = 'adam',\n",
    "        optimizer_config: Optional[Dict[str, Any]] = None,\n",
    "        loss: str = 'mse',\n",
    "        metrics: Optional[List[Union[str, tf.keras.metrics.Metric]]] = None\n",
    "    ) -> Sequential:\n",
    "        \"\"\"\n",
    "        Builds and compiles a sequential model based on configuration.\n",
    "\n",
    "        Args:\n",
    "            layers_config: List of dicts specifying 'type' and layer parameters.\n",
    "            optimizer_name: Name of the optimizer to use. Defaults to 'adam'.\n",
    "            optimizer_config: Optional parameters for the optimizer.\n",
    "            loss: Loss function identifier or object. Defaults to 'mse'.\n",
    "            metrics: List of metrics for evaluation. Defaults to ['mae'].\n",
    "\n",
    "        Returns:\n",
    "            The compiled Keras Sequential model.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an unsupported layer type or optimizer is provided.\n",
    "        \"\"\"\n",
    "        if metrics is None:\n",
    "            metrics = ['mae'] \n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=self.input_shape))\n",
    "        \n",
    "        for layer in layers_config:\n",
    "            layer_type_name = layer['type']\n",
    "            layer_class = self.layer_types.get(layer_type_name)\n",
    "            \n",
    "            if layer_class is None:\n",
    "                raise ValueError(f\"Unknown layer type: {layer_type_name}\")\n",
    "            \n",
    "            # Filter out 'type' to pass only valid Keras layer arguments\n",
    "            layer_args = {k: v for k, v in layer.items() if k != 'type'}\n",
    "            model.add(layer_class(**layer_args))\n",
    "        \n",
    "        # Optimizer setup\n",
    "        optimizer_class = self.optimizer_map.get(optimizer_name.lower())\n",
    "        if optimizer_class is None:\n",
    "            raise ValueError(\n",
    "                f\"Unknown optimizer: {optimizer_name}. \"\n",
    "                f\"Available: {list(self.optimizer_map.keys())}\"\n",
    "            )\n",
    "        \n",
    "        opt_config = optimizer_config or {'learning_rate': 0.001}\n",
    "        optimizer = optimizer_class(**opt_config)\n",
    "        \n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def train(\n",
    "        self,\n",
    "        train_gen: tf.data.Dataset,\n",
    "        val_gen: Optional[tf.data.Dataset] = None,\n",
    "        epochs: int = 10,\n",
    "        verbose: int = 1,\n",
    "        **kwargs: Any\n",
    "    ) -> History:\n",
    "        \"\"\"\n",
    "        Trains the compiled model using data generators.\n",
    "\n",
    "        Args:\n",
    "            train_gen: Training data generator or dataset.\n",
    "            val_gen: Validation data generator or dataset.\n",
    "            epochs: Number of training cycles. Defaults to 10.\n",
    "            verbose: Verbosity level (0, 1, or 2). Defaults to 1.\n",
    "            **kwargs: Additional arguments passed to model.fit.\n",
    "\n",
    "        Returns:\n",
    "            The training history object.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"No model has been built. Call build_model first.\")\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=epochs,\n",
    "            verbose=verbose,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def predict(self, test_gen: tf.data.Dataset) -> np.ndarray:\n",
    "        \"\"\"Generates predictions from the test generator.\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"No model has been built. Call build_model first.\")\n",
    "        \n",
    "        return self.model.predict(test_gen)\n",
    "    \n",
    "    def get_model_summary(self) -> None:\n",
    "        \"\"\"Prints the model architecture summary to the console.\"\"\"\n",
    "        if self.model is not None:\n",
    "            self.model.summary()\n",
    "        else:\n",
    "            print(\"No model available. Build the model before requesting a summary.\")\n",
    "\n",
    "def predict_future_from_sequence(model: Any, \n",
    "    initial_sequence_scaled: np.ndarray, \n",
    "    steps: int\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Predict future time steps using autoregressive forecasting.\n",
    "\n",
    "    Generates multi-step predictions by iteratively using the model's \n",
    "    previous output as input for the next prediction step.\n",
    "\n",
    "    Args:\n",
    "        model: The trained Keras/TensorFlow model.\n",
    "        initial_sequence_scaled: Starting sequence of shape (1, input_width, n_features).\n",
    "        steps: Total number of future time steps to forecast.\n",
    "\n",
    "    Returns:\n",
    "        A (steps, 1) array of scaled predictions.\n",
    "\n",
    "    Example:\n",
    "        >>> pred_scaled = predict_future_from_sequence(model, last_seq, steps=12)\n",
    "        >>> pred_original = scaler.inverse_transform(pred_scaled)\n",
    "    \"\"\"\n",
    "    # Work on a copy to prevent side effects on the input data\n",
    "    current_sequence = initial_sequence_scaled.copy()\n",
    "    predictions_scaled = []\n",
    "    \n",
    "    for _ in range(steps):\n",
    "        # Predict the next step (verbose=0 reduces console noise)\n",
    "        next_pred_scaled = model.predict(current_sequence, verbose=0)  \n",
    "        # Store the first feature of the prediction\n",
    "        predictions_scaled.append(next_pred_scaled[0, 0]) \n",
    "        \n",
    "        # Update the sequence for the next prediction\n",
    "        # Shift the sequence one step to the left and append the new prediction at the end\n",
    "        current_sequence = np.roll(current_sequence, -1, axis=1)\n",
    "        current_sequence[0, -1, 0] = next_pred_scaled[0, 0]\n",
    "    \n",
    "    return np.array(predictions_scaled).reshape(-1, 1)  # Shape: (steps, 1)\n",
    "\n",
    "def run_walkforward_prediction(\n",
    "    df_test: pd.DataFrame, \n",
    "    model: Any, \n",
    "    scaler: Any, \n",
    "    input_width: int\n",
    ") -> Tuple[Optional[np.ndarray], Optional[np.ndarray], pd.DataFrame, Optional[pd.DatetimeIndex]]:\n",
    "    \"\"\"\n",
    "    Perform walk-forward prediction on a test dataset.\n",
    "\n",
    "    Splits the test data into an initial sequence and a future period, \n",
    "    then generates predictions iteratively using an autoregressive approach.\n",
    "\n",
    "    Args:\n",
    "        df_test: Test dataset with a univariate time series.\n",
    "        model: Trained Keras/TensorFlow model.\n",
    "        scaler: Scaler used for data normalization (e.g., MinMaxScaler).\n",
    "        input_width: Number of time steps required as input for the model.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - Unscaled predictions (1D array).\n",
    "            - True unscaled values (1D array).\n",
    "            - The initial sequence DataFrame used as context.\n",
    "            - The temporal index for the future predictions.\n",
    "    \"\"\"\n",
    "    # Split data into initial context and future target period\n",
    "    initial_points_for_prediction = input_width\n",
    "    \n",
    "    assert len(df_test) > initial_points_for_prediction, \\\n",
    "        \"df_test length must be greater than input_width.\"\n",
    "    \n",
    "    df_test_initial = df_test.iloc[:initial_points_for_prediction]\n",
    "    df_test_future = df_test.iloc[initial_points_for_prediction:]\n",
    "    \n",
    "    if len(df_test_future) == 0:\n",
    "        print(\"Error: df_test_future is empty. Adjust input_width.\")\n",
    "        # Return 4 elements with None for predictions/true values\n",
    "        return None, None, df_test_initial, None\n",
    "    \n",
    "    # Prepare the initial sequence for the model\n",
    "    initial_seq_values = df_test_initial.values  \n",
    "    initial_seq_scaled = scaler.transform(initial_seq_values)  \n",
    "    \n",
    "    # Reshape to (1, steps, features) for Keras\n",
    "    actual_initial_seq_scaled = initial_seq_scaled[-input_width:].reshape(1, input_width, 1)\n",
    "    \n",
    "    # Generate autoregressive predictions\n",
    "    steps_to_predict = len(df_test_future) \n",
    "    predictions_walkforward_scaled = predict_future_from_sequence(\n",
    "        model=model,\n",
    "        initial_sequence_scaled=actual_initial_seq_scaled,\n",
    "        steps=steps_to_predict\n",
    "    )\n",
    "    \n",
    "    # Inverse transform to original scale\n",
    "    predictions_walkforward_unscaled = scaler.inverse_transform(predictions_walkforward_scaled).flatten()\n",
    "    y_true_future_unscaled = df_test_future.values.flatten()\n",
    "    \n",
    "    # Reconstruct temporal index\n",
    "    # Attempt to infer frequency or fallback to 'h' (Hourly)\n",
    "    freq = (\n",
    "        df_test_initial.index.freq \n",
    "        or pd.infer_freq(df_test_initial.index) \n",
    "        or 'h'\n",
    "    )\n",
    "    \n",
    "    future_index = pd.date_range(\n",
    "        start=df_test_initial.index[-1],\n",
    "        periods=len(predictions_walkforward_unscaled) +1 ,\n",
    "        freq=freq\n",
    "    )[1:] # Start from the first point after the initial sequence\n",
    "    \n",
    "    return (predictions_walkforward_unscaled, \n",
    "            y_true_future_unscaled, \n",
    "            df_test_initial, \n",
    "            future_index)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc1a48",
   "metadata": {},
   "source": [
    "## 3- Prototypage\n",
    "\n",
    "Le développement de ce script est le fruit d’un processus itératif conçu pour servir de banc d’essai rapide à diverse configurations de modèles. L’évolution de ce code a traversé trois phases critiques :\n",
    "\n",
    "Le premier défi a porté sur la gestion de la mémoire des données destinées aux modèles RNN. Face au choix entre une solution maison ou utilisation de librairie, C’est donc cette voie qui a été retenue, conduisant à l’intégration de la fonction *\"timeseries\\_dataset\\_from\\_array\"* a été intégrée à *\"split\\_and\\_generate\\_dataset\"*. Cette approche offre une gestion du chargement des données dans la mémoire standard attendue par les frameworks modernes, et amène, théoriquement, à des gains de performances.\n",
    "\n",
    "La deuxième étape, centrée sur la construction des modèles, a motivé l’adoption d’une approche orientée objet via la classe *ModelGenerator*. Celle-ci isole la logique de construction du modèle, permettant de définir et comparer facilement différentes architectures neuronales (LSTM, GRU, etc.) ou jeux d’hyperparamètres, sans dupliquer le code ni compromettre la lisibilité du pipeline expérimental.\n",
    "\n",
    "Enfin la dernière phase a émergé de la réflexion initiée dans le premier article (**Article 1 - Introduction au projet**) sur la différence entre une approche single-step ou multi-step. Question qui immédiatement soulève celle du choix des métriques d’évaluation. En effet, celle utilisée habituellement comme la **MAE**, ou **RMSE** sont adaptée à une prédiction ponctuelle, elles se révèlent insuffisante dans un contexte multi-step, car leur nature agrégée (moyenne) masque la dynamique temporelle, notamment la dérive progressive du modèle au fil des prédictions. C’est pourquoi le concept d’erreur absolue en pourcentage (*Absolute Percentage Error, APE*) a été introduit, elle permet à chaque pas de temps de visualiser l’erreur.\n",
    "\n",
    "Toutefois, cette approche soulève elle-même une difficulté : comment distinguer une véritable capacité prédictive d’une simple coïncidence ? Comme le montre le graphique *\"Walk-forward with initial context\"* ci-après, un modèle peut sembler performant à certains instants non pas parce qu’il capture la dynamique sous-jacente, mais parce qu’il reproduit une tendance générale et « retombe par hasard » sur les valeurs réelles.\n",
    "\n",
    "En l’absence de métrique robuste pour le multi-step, nous nous appuyons ici sur une analyse visuelle qualitative, conscient de ses limites.\n",
    "L’ensemble de ces défis feront l’objet d’un article dédié, où nous rentrerons plus en détail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf225071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0803 - mae: 0.0803 - root_mean_squared_error: 0.1219 - val_loss: 0.0934 - val_mae: 0.0934 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 2/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0606 - mae: 0.0606 - root_mean_squared_error: 0.0779 - val_loss: 0.0799 - val_mae: 0.0799 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 3/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0631 - mae: 0.0631 - root_mean_squared_error: 0.0805 - val_loss: 0.0535 - val_mae: 0.0535 - val_root_mean_squared_error: 0.0640\n",
      "Epoch 4/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0732 - mae: 0.0732 - root_mean_squared_error: 0.0941 - val_loss: 0.0849 - val_mae: 0.0849 - val_root_mean_squared_error: 0.0991\n",
      "Epoch 5/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0712 - mae: 0.0712 - root_mean_squared_error: 0.0915 - val_loss: 0.0786 - val_mae: 0.0786 - val_root_mean_squared_error: 0.0923\n",
      "Epoch 6/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0682 - mae: 0.0682 - root_mean_squared_error: 0.0883 - val_loss: 0.0752 - val_mae: 0.0752 - val_root_mean_squared_error: 0.0887\n",
      "Epoch 7/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0679 - mae: 0.0679 - root_mean_squared_error: 0.0880 - val_loss: 0.0764 - val_mae: 0.0764 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 8/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0694 - mae: 0.0694 - root_mean_squared_error: 0.0897 - val_loss: 0.0679 - val_mae: 0.0679 - val_root_mean_squared_error: 0.0804\n",
      "Epoch 9/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0672 - mae: 0.0672 - root_mean_squared_error: 0.0872 - val_loss: 0.1052 - val_mae: 0.1052 - val_root_mean_squared_error: 0.1189\n",
      "Epoch 10/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0641 - mae: 0.0641 - root_mean_squared_error: 0.0825 - val_loss: 0.0907 - val_mae: 0.0907 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 11/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0648 - mae: 0.0648 - root_mean_squared_error: 0.0835 - val_loss: 0.0782 - val_mae: 0.0782 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 12/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0624 - mae: 0.0624 - root_mean_squared_error: 0.0805 - val_loss: 0.0909 - val_mae: 0.0909 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 13/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0613 - mae: 0.0613 - root_mean_squared_error: 0.0788 - val_loss: 0.0746 - val_mae: 0.0746 - val_root_mean_squared_error: 0.0880\n",
      "Epoch 14/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0603 - mae: 0.0603 - root_mean_squared_error: 0.0783 - val_loss: 0.0844 - val_mae: 0.0844 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 15/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0579 - mae: 0.0579 - root_mean_squared_error: 0.0745 - val_loss: 0.0732 - val_mae: 0.0732 - val_root_mean_squared_error: 0.0862\n",
      "Epoch 16/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0552 - mae: 0.0552 - root_mean_squared_error: 0.0715 - val_loss: 0.0698 - val_mae: 0.0698 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 17/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0532 - mae: 0.0532 - root_mean_squared_error: 0.0687 - val_loss: 0.0929 - val_mae: 0.0929 - val_root_mean_squared_error: 0.1049\n",
      "Epoch 18/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0496 - mae: 0.0496 - root_mean_squared_error: 0.0645 - val_loss: 0.0662 - val_mae: 0.0662 - val_root_mean_squared_error: 0.0786\n",
      "Epoch 19/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0480 - mae: 0.0480 - root_mean_squared_error: 0.0628 - val_loss: 0.0741 - val_mae: 0.0741 - val_root_mean_squared_error: 0.0865\n",
      "Epoch 20/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0446 - mae: 0.0446 - root_mean_squared_error: 0.0585 - val_loss: 0.0710 - val_mae: 0.0710 - val_root_mean_squared_error: 0.0834\n",
      "Epoch 21/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0502 - mae: 0.0502 - root_mean_squared_error: 0.0671 - val_loss: 0.0940 - val_mae: 0.0940 - val_root_mean_squared_error: 0.1072\n",
      "Epoch 22/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0474 - mae: 0.0474 - root_mean_squared_error: 0.0624 - val_loss: 0.0602 - val_mae: 0.0602 - val_root_mean_squared_error: 0.0721\n",
      "Epoch 23/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0441 - mae: 0.0441 - root_mean_squared_error: 0.0575 - val_loss: 0.0630 - val_mae: 0.0630 - val_root_mean_squared_error: 0.0752\n",
      "Epoch 24/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0405 - mae: 0.0405 - root_mean_squared_error: 0.0534 - val_loss: 0.0629 - val_mae: 0.0629 - val_root_mean_squared_error: 0.0752\n",
      "Epoch 25/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0377 - mae: 0.0377 - root_mean_squared_error: 0.0507 - val_loss: 0.0598 - val_mae: 0.0598 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 26/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0366 - mae: 0.0366 - root_mean_squared_error: 0.0486 - val_loss: 0.0709 - val_mae: 0.0709 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 27/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0473 - val_loss: 0.0798 - val_mae: 0.0798 - val_root_mean_squared_error: 0.0934\n",
      "Epoch 28/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0480 - val_loss: 0.0831 - val_mae: 0.0831 - val_root_mean_squared_error: 0.0984\n",
      "Epoch 29/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0468 - val_loss: 0.0667 - val_mae: 0.0667 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 30/30\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0479 - val_loss: 0.0689 - val_mae: 0.0689 - val_root_mean_squared_error: 0.0826\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Main execution script for BTC/USDT price forecasting.\n",
    "\n",
    "This script handles data loading, preprocessing, model architecture definition,\n",
    "training with error tracking (MAE/RMSE), and evaluation using a walk-forward \n",
    "compatible generator approach.\n",
    "\"\"\"\n",
    "# --- Data Preparation ---\n",
    "\n",
    "# Load and format the dataset\n",
    "# Note: Assuming 'timestamp' is in milliseconds as per Binance/standard crypto exports\n",
    "df = pd.read_csv('../data/dataset/BTCUSDT_1h.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Filter for the year 2025 and focus on the 'close' price\n",
    "df_2025 = df[df.index.year == 2025][['close']].sort_index()\n",
    "\n",
    "# Generate split datasets and TensorFlow generators\n",
    "df_train, df_val, df_test, train_gen, val_gen, test_gen, scaler = split_and_generate_dataset(\n",
    "    df_2025,\n",
    "    input_width=24,\n",
    "    batch_size=32,\n",
    "    scaler_type='minmax'\n",
    "    )\n",
    "\n",
    "# --- Model Configuration ---\n",
    "\n",
    "input_shape = (24, 1) # (timesteps, features)\n",
    "\n",
    "# Initialize generator and build a Recurrent Neural Network (LSTM)\n",
    "mg = ModelGenerator(input_shape=input_shape)\n",
    "model = mg.build_model(\n",
    "    layers_config=[\n",
    "        {'type': 'lstm', 'units': 50, 'return_sequences': True},\n",
    "        {'type': 'lstm', 'units': 50, 'return_sequences': False},  \n",
    "        {'type': 'dropout', 'rate': 0.2},\n",
    "        {'type': 'dense', 'units': 1}\n",
    "    ],\n",
    "    optimizer_name='adam',\n",
    "    optimizer_config={'learning_rate': 0.001},\n",
    "    loss= 'mae',\n",
    "    metrics=['mae', RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "# --- Training & Inference ---\n",
    "\n",
    "# Train the model and capture performance metrics over time\n",
    "history = mg.train(\n",
    "    train_gen,\n",
    "    val_gen,\n",
    "    epochs=30\n",
    "    )\n",
    "\n",
    "# Perform inference on the test set\n",
    "predictions = mg.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "268d0456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=loss<br>Epoch=%{x}<br>Metric Value=%{y}<extra></extra>",
         "legendgroup": "loss",
         "line": {
          "color": "#1F77B4",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwd",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAoAiMtD8AAACgewyvPwAAAGA6JLA/AAAAYO66sj8AAAAAxTiyPwAAAOA5dLE/AAAAoMxfsT8AAABAa8WxPwAAAIDSM7E/AAAAAC9rsD8AAADAl5SwPwAAAKCN+K8/AAAAIEZcrz8AAAAAjdmuPwAAAGC1o60/AAAAIKVErD8AAACApDyrPwAAAMAvYak/AAAA4KONqD8AAACAzdemPwAAAGDAuak/AAAAAJlBqD8AAACABZqmPwAAACAhvKQ/AAAAwLNSoz8AAACAJLqiPwAAACCP/6E/AAAAwEjGoj8AAABAxhqiPwAAAIDfTKI/",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=val_loss<br>Epoch=%{x}<br>Metric Value=%{y}<extra></extra>",
         "legendgroup": "val_loss",
         "line": {
          "color": "#FF7F0E",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "val_loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwd",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAICLptz8AAADAu3K0PwAAACAdXqs/AAAA4Ou9tT8AAAAgER20PwAAAKCeQbM/AAAAwJaQsz8AAABAOWCxPwAAAEDR7Lo/AAAAgDA1tz8AAABgBwa0PwAAAMDaQrc/AAAAwAsbsz8AAADgG5i1PwAAAMBGvLI/AAAAYD/dsT8AAAAg0ci3PwAAAEAp9bA/AAAAoMX3sj8AAADA6ymyPwAAACCYE7g/AAAA4HHUrj8AAABAAyKwPwAAACBdGbA/AAAAgLSirj8AAACA+SWyPwAAAMDZbrQ/AAAAADdDtT8AAACg1ROxPwAAAAARprE/",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=root_mean_squared_error<br>Epoch=%{x}<br>Metric Value=%{y}<extra></extra>",
         "legendgroup": "root_mean_squared_error",
         "line": {
          "color": "#2CA02C",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "root_mean_squared_error",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwd",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAQAk0vz8AAABA2++zPwAAAKCGmbQ/AAAAYE4VuD8AAABA1G63PwAAAADDmLY/AAAAIM+Htj8AAAAAMvm2PwAAAGD6UrY/AAAAgL8etT8AAADg3F61PwAAAODHnbQ/AAAAALUstD8AAABAzQu0PwAAAODdD7M/AAAAIGJLsj8AAAAgPpixPwAAAACthLA/AAAAoKIQsD8AAADgmfCtPwAAAKB2LrE/AAAA4IX1rz8AAADAPG2tPwAAAIBrVas/AAAAYMr5qT8AAADgdOSoPwAAAMAeO6g/AAAAoCmXqD8AAACgY/unPwAAAGAyhKg/",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=val_root_mean_squared_error<br>Epoch=%{x}<br>Metric Value=%{y}<extra></extra>",
         "legendgroup": "val_root_mean_squared_error",
         "line": {
          "color": "#D62728",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "val_root_mean_squared_error",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwd",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAQKo2uj8AAAAgrkS3PwAAAGBqYrA/AAAAoAdcuT8AAADAFKK3PwAAAAAtsrY/AAAAQMcNtz8AAADgM5K0PwAAAEDtcb4/AAAAID3buj8AAAAAI5C3PwAAAOAU1bo/AAAAwDyJtj8AAABAGCe5PwAAAICXE7Y/AAAA4CUatT8AAADA0di6PwAAAEDeHLQ/AAAA4Mwktj8AAAAglle1PwAAAIACcrs/AAAAwDx0sj8AAACgTD2zPwAAACBYQLM/AAAAQBRhsj8AAACAk5a1PwAAAECo5rc/AAAAYNIuuT8AAABgi2a0PwAAAAD0I7U/",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=mae<br>Epoch=%{x}<br>Metric Value=%{y}<extra></extra>",
         "legendgroup": "mae",
         "line": {
          "color": "#9467BD",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "mae",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwd",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAoAiMtD8AAACgewyvPwAAAGA6JLA/AAAAYO66sj8AAAAAxTiyPwAAAOA5dLE/AAAAoMxfsT8AAABAa8WxPwAAAIDSM7E/AAAAAC9rsD8AAADAl5SwPwAAAKCN+K8/AAAAIEZcrz8AAAAAjdmuPwAAAGC1o60/AAAAIKVErD8AAACApDyrPwAAAMAvYak/AAAA4KONqD8AAACAzdemPwAAAGDAuak/AAAAAJlBqD8AAACABZqmPwAAACAhvKQ/AAAAwLNSoz8AAACAJLqiPwAAACCP/6E/AAAAwEjGoj8AAABAxhqiPwAAAIDfTKI/",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=val_mae<br>Epoch=%{x}<br>Metric Value=%{y}<extra></extra>",
         "legendgroup": "val_mae",
         "line": {
          "color": "#8C564B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "val_mae",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwd",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAICLptz8AAADAu3K0PwAAACAdXqs/AAAA4Ou9tT8AAAAgER20PwAAAKCeQbM/AAAAwJaQsz8AAABAOWCxPwAAAEDR7Lo/AAAAgDA1tz8AAABgBwa0PwAAAMDaQrc/AAAAwAsbsz8AAADgG5i1PwAAAMBGvLI/AAAAYD/dsT8AAAAg0ci3PwAAAEAp9bA/AAAAoMX3sj8AAADA6ymyPwAAACCYE7g/AAAA4HHUrj8AAABAAyKwPwAAACBdGbA/AAAAgLSirj8AAACA+SWyPwAAAMDZbrQ/AAAAADdDtT8AAACg1ROxPwAAAAARprE/",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "text": "Model Training History"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Metric Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Training History Visualization ---\n",
    "\n",
    "# Plot training and validation metrics to monitor model convergence and overfitting\n",
    "\n",
    "fig_history = px.line(history.history,\n",
    "        y=[\n",
    "            'loss',\n",
    "            'val_loss',\n",
    "            'root_mean_squared_error',\n",
    "            'val_root_mean_squared_error',\n",
    "            'mae', 'val_mae'\n",
    "            ],\n",
    "        labels={'index': 'Epoch', 'value': 'Metric Value'},\n",
    "        title='Model Training History',\n",
    "        template='simple_white')\n",
    "\n",
    "# Display the plot\n",
    "fig_history.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "396c2ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Walk-Forward Prediction Execution ---\n",
    "\n",
    "# Generate autoregressive predictions on the test set\n",
    "# This returns unscaled predictions, true values, and the associated temporal index\n",
    "\n",
    "predictions_wf, y_true_wf, df_init, future_index = run_walkforward_prediction(\n",
    "    df_test=df_test,\n",
    "    model=mg.model,\n",
    "    scaler=scaler,\n",
    "    input_width=24\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e2b61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Walk-Forward Period Metrics (Test Suite):\n",
      "MAE: 2879.1005\n",
      "RMSE: 3385.6972\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Type=Initial sequence<br>Date=%{x}<br>Value=%{y}<extra></extra>",
         "legendgroup": "Initial sequence",
         "line": {
          "color": "#118c4f",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Initial sequence",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2025-09-15T23:00:00",
          "2025-09-16T00:00:00",
          "2025-09-16T01:00:00",
          "2025-09-16T02:00:00",
          "2025-09-16T03:00:00",
          "2025-09-16T04:00:00",
          "2025-09-16T05:00:00",
          "2025-09-16T06:00:00",
          "2025-09-16T07:00:00",
          "2025-09-16T08:00:00",
          "2025-09-16T09:00:00",
          "2025-09-16T10:00:00",
          "2025-09-16T11:00:00",
          "2025-09-16T12:00:00",
          "2025-09-16T13:00:00",
          "2025-09-16T14:00:00",
          "2025-09-16T15:00:00",
          "2025-09-16T16:00:00",
          "2025-09-16T17:00:00",
          "2025-09-16T18:00:00",
          "2025-09-16T19:00:00",
          "2025-09-16T20:00:00",
          "2025-09-16T21:00:00",
          "2025-09-16T22:00:00"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "w/UoXFsp/ED2KFyPChn8QHE9CtcDFfxAUrgehacV/EAAAAAAtCb8QI/C9SjwMvxAZmZmZgpO/ECamZmZpUP8QAAAAAAASPxAj8L1KKw8/EAfhetRVDH8QMP1KFzHKvxAexSuR30l/EApXI/C9S78QAAAAAAAIPxAKVyPwg0m/EBI4XoUHkz8QFyPwvVAVvxAPQrXo9hu/EApXI/CLWz8QLgehesBhPxAUrgehXeG/ECPwvUoCIT8QHsUrkd5h/xA",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "Type=Real values<br>Date=%{x}<br>Value=%{y}<extra></extra>",
         "legendgroup": "Real values",
         "line": {
          "color": "#2c7bb6",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Real values",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2025-09-16T23:00:00",
          "2025-09-17T00:00:00",
          "2025-09-17T01:00:00",
          "2025-09-17T02:00:00",
          "2025-09-17T03:00:00",
          "2025-09-17T04:00:00",
          "2025-09-17T05:00:00",
          "2025-09-17T06:00:00",
          "2025-09-17T07:00:00",
          "2025-09-17T08:00:00",
          "2025-09-17T09:00:00",
          "2025-09-17T10:00:00",
          "2025-09-17T11:00:00",
          "2025-09-17T12:00:00",
          "2025-09-17T13:00:00",
          "2025-09-17T14:00:00",
          "2025-09-17T15:00:00",
          "2025-09-17T16:00:00",
          "2025-09-17T17:00:00",
          "2025-09-17T18:00:00",
          "2025-09-17T19:00:00",
          "2025-09-17T20:00:00",
          "2025-09-17T21:00:00",
          "2025-09-17T22:00:00",
          "2025-09-17T23:00:00",
          "2025-09-18T00:00:00",
          "2025-09-18T01:00:00",
          "2025-09-18T02:00:00",
          "2025-09-18T03:00:00",
          "2025-09-18T04:00:00",
          "2025-09-18T05:00:00",
          "2025-09-18T06:00:00",
          "2025-09-18T07:00:00",
          "2025-09-18T08:00:00",
          "2025-09-18T09:00:00",
          "2025-09-18T10:00:00",
          "2025-09-18T11:00:00",
          "2025-09-18T12:00:00",
          "2025-09-18T13:00:00",
          "2025-09-18T14:00:00",
          "2025-09-18T15:00:00",
          "2025-09-18T16:00:00",
          "2025-09-18T17:00:00",
          "2025-09-18T18:00:00",
          "2025-09-18T19:00:00",
          "2025-09-18T20:00:00",
          "2025-09-18T21:00:00",
          "2025-09-18T22:00:00",
          "2025-09-18T23:00:00",
          "2025-09-19T00:00:00",
          "2025-09-19T01:00:00",
          "2025-09-19T02:00:00",
          "2025-09-19T03:00:00",
          "2025-09-19T04:00:00",
          "2025-09-19T05:00:00",
          "2025-09-19T06:00:00",
          "2025-09-19T07:00:00",
          "2025-09-19T08:00:00",
          "2025-09-19T09:00:00",
          "2025-09-19T10:00:00",
          "2025-09-19T11:00:00",
          "2025-09-19T12:00:00",
          "2025-09-19T13:00:00",
          "2025-09-19T14:00:00",
          "2025-09-19T15:00:00",
          "2025-09-19T16:00:00",
          "2025-09-19T17:00:00",
          "2025-09-19T18:00:00",
          "2025-09-19T19:00:00",
          "2025-09-19T20:00:00",
          "2025-09-19T21:00:00",
          "2025-09-19T22:00:00",
          "2025-09-19T23:00:00",
          "2025-09-20T00:00:00",
          "2025-09-20T01:00:00",
          "2025-09-20T02:00:00",
          "2025-09-20T03:00:00",
          "2025-09-20T04:00:00",
          "2025-09-20T05:00:00",
          "2025-09-20T06:00:00",
          "2025-09-20T07:00:00",
          "2025-09-20T08:00:00",
          "2025-09-20T09:00:00",
          "2025-09-20T10:00:00",
          "2025-09-20T11:00:00",
          "2025-09-20T12:00:00",
          "2025-09-20T13:00:00",
          "2025-09-20T14:00:00",
          "2025-09-20T15:00:00",
          "2025-09-20T16:00:00",
          "2025-09-20T17:00:00",
          "2025-09-20T18:00:00",
          "2025-09-20T19:00:00",
          "2025-09-20T20:00:00",
          "2025-09-20T21:00:00",
          "2025-09-20T22:00:00",
          "2025-09-20T23:00:00",
          "2025-09-21T00:00:00",
          "2025-09-21T01:00:00",
          "2025-09-21T02:00:00",
          "2025-09-21T03:00:00",
          "2025-09-21T04:00:00",
          "2025-09-21T05:00:00",
          "2025-09-21T06:00:00",
          "2025-09-21T07:00:00",
          "2025-09-21T08:00:00",
          "2025-09-21T09:00:00",
          "2025-09-21T10:00:00",
          "2025-09-21T11:00:00",
          "2025-09-21T12:00:00",
          "2025-09-21T13:00:00",
          "2025-09-21T14:00:00",
          "2025-09-21T15:00:00",
          "2025-09-21T16:00:00",
          "2025-09-21T17:00:00",
          "2025-09-21T18:00:00",
          "2025-09-21T19:00:00",
          "2025-09-21T20:00:00",
          "2025-09-21T21:00:00",
          "2025-09-21T22:00:00",
          "2025-09-21T23:00:00",
          "2025-09-22T00:00:00",
          "2025-09-22T01:00:00",
          "2025-09-22T02:00:00",
          "2025-09-22T03:00:00",
          "2025-09-22T04:00:00",
          "2025-09-22T05:00:00",
          "2025-09-22T06:00:00",
          "2025-09-22T07:00:00",
          "2025-09-22T08:00:00",
          "2025-09-22T09:00:00",
          "2025-09-22T10:00:00",
          "2025-09-22T11:00:00",
          "2025-09-22T12:00:00",
          "2025-09-22T13:00:00",
          "2025-09-22T14:00:00",
          "2025-09-22T15:00:00",
          "2025-09-22T16:00:00",
          "2025-09-22T17:00:00",
          "2025-09-22T18:00:00",
          "2025-09-22T19:00:00",
          "2025-09-22T20:00:00",
          "2025-09-22T21:00:00",
          "2025-09-22T22:00:00",
          "2025-09-22T23:00:00",
          "2025-09-23T00:00:00",
          "2025-09-23T01:00:00",
          "2025-09-23T02:00:00",
          "2025-09-23T03:00:00",
          "2025-09-23T04:00:00",
          "2025-09-23T05:00:00",
          "2025-09-23T06:00:00",
          "2025-09-23T07:00:00",
          "2025-09-23T08:00:00",
          "2025-09-23T09:00:00",
          "2025-09-23T10:00:00",
          "2025-09-23T11:00:00",
          "2025-09-23T12:00:00",
          "2025-09-23T13:00:00",
          "2025-09-23T14:00:00",
          "2025-09-23T15:00:00",
          "2025-09-23T16:00:00",
          "2025-09-23T17:00:00",
          "2025-09-23T18:00:00",
          "2025-09-23T19:00:00",
          "2025-09-23T20:00:00",
          "2025-09-23T21:00:00",
          "2025-09-23T22:00:00",
          "2025-09-23T23:00:00",
          "2025-09-24T00:00:00",
          "2025-09-24T01:00:00",
          "2025-09-24T02:00:00",
          "2025-09-24T03:00:00",
          "2025-09-24T04:00:00",
          "2025-09-24T05:00:00",
          "2025-09-24T06:00:00",
          "2025-09-24T07:00:00",
          "2025-09-24T08:00:00",
          "2025-09-24T09:00:00",
          "2025-09-24T10:00:00",
          "2025-09-24T11:00:00",
          "2025-09-24T12:00:00",
          "2025-09-24T13:00:00",
          "2025-09-24T14:00:00",
          "2025-09-24T15:00:00",
          "2025-09-24T16:00:00",
          "2025-09-24T17:00:00",
          "2025-09-24T18:00:00",
          "2025-09-24T19:00:00",
          "2025-09-24T20:00:00",
          "2025-09-24T21:00:00",
          "2025-09-24T22:00:00",
          "2025-09-24T23:00:00",
          "2025-09-25T00:00:00",
          "2025-09-25T01:00:00",
          "2025-09-25T02:00:00",
          "2025-09-25T03:00:00",
          "2025-09-25T04:00:00",
          "2025-09-25T05:00:00",
          "2025-09-25T06:00:00",
          "2025-09-25T07:00:00",
          "2025-09-25T08:00:00",
          "2025-09-25T09:00:00",
          "2025-09-25T10:00:00",
          "2025-09-25T11:00:00",
          "2025-09-25T12:00:00",
          "2025-09-25T13:00:00",
          "2025-09-25T14:00:00",
          "2025-09-25T15:00:00",
          "2025-09-25T16:00:00",
          "2025-09-25T17:00:00",
          "2025-09-25T18:00:00",
          "2025-09-25T19:00:00",
          "2025-09-25T20:00:00",
          "2025-09-25T21:00:00",
          "2025-09-25T22:00:00",
          "2025-09-25T23:00:00",
          "2025-09-26T00:00:00",
          "2025-09-26T01:00:00",
          "2025-09-26T02:00:00",
          "2025-09-26T03:00:00",
          "2025-09-26T04:00:00",
          "2025-09-26T05:00:00",
          "2025-09-26T06:00:00",
          "2025-09-26T07:00:00",
          "2025-09-26T08:00:00",
          "2025-09-26T09:00:00",
          "2025-09-26T10:00:00",
          "2025-09-26T11:00:00",
          "2025-09-26T12:00:00",
          "2025-09-26T13:00:00",
          "2025-09-26T14:00:00",
          "2025-09-26T15:00:00",
          "2025-09-26T16:00:00",
          "2025-09-26T17:00:00",
          "2025-09-26T18:00:00",
          "2025-09-26T19:00:00",
          "2025-09-26T20:00:00",
          "2025-09-26T21:00:00",
          "2025-09-26T22:00:00",
          "2025-09-26T23:00:00",
          "2025-09-27T00:00:00",
          "2025-09-27T01:00:00",
          "2025-09-27T02:00:00",
          "2025-09-27T03:00:00",
          "2025-09-27T04:00:00",
          "2025-09-27T05:00:00",
          "2025-09-27T06:00:00",
          "2025-09-27T07:00:00",
          "2025-09-27T08:00:00",
          "2025-09-27T09:00:00",
          "2025-09-27T10:00:00",
          "2025-09-27T11:00:00",
          "2025-09-27T12:00:00",
          "2025-09-27T13:00:00",
          "2025-09-27T14:00:00",
          "2025-09-27T15:00:00",
          "2025-09-27T16:00:00",
          "2025-09-27T17:00:00",
          "2025-09-27T18:00:00",
          "2025-09-27T19:00:00",
          "2025-09-27T20:00:00",
          "2025-09-27T21:00:00",
          "2025-09-27T22:00:00",
          "2025-09-27T23:00:00",
          "2025-09-28T00:00:00",
          "2025-09-28T01:00:00",
          "2025-09-28T02:00:00",
          "2025-09-28T03:00:00",
          "2025-09-28T04:00:00",
          "2025-09-28T05:00:00",
          "2025-09-28T06:00:00",
          "2025-09-28T07:00:00",
          "2025-09-28T08:00:00",
          "2025-09-28T09:00:00",
          "2025-09-28T10:00:00",
          "2025-09-28T11:00:00",
          "2025-09-28T12:00:00",
          "2025-09-28T13:00:00",
          "2025-09-28T14:00:00",
          "2025-09-28T15:00:00",
          "2025-09-28T16:00:00",
          "2025-09-28T17:00:00",
          "2025-09-28T18:00:00",
          "2025-09-28T19:00:00",
          "2025-09-28T20:00:00",
          "2025-09-28T21:00:00",
          "2025-09-28T22:00:00",
          "2025-09-28T23:00:00",
          "2025-09-29T00:00:00",
          "2025-09-29T01:00:00",
          "2025-09-29T02:00:00",
          "2025-09-29T03:00:00",
          "2025-09-29T04:00:00",
          "2025-09-29T05:00:00",
          "2025-09-29T06:00:00",
          "2025-09-29T07:00:00",
          "2025-09-29T08:00:00",
          "2025-09-29T09:00:00",
          "2025-09-29T10:00:00",
          "2025-09-29T11:00:00",
          "2025-09-29T12:00:00",
          "2025-09-29T13:00:00"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "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",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "Type=Predictions<br>Date=%{x}<br>Value=%{y}<extra></extra>",
         "legendgroup": "Predictions",
         "line": {
          "color": "#f33333",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Predictions",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2025-09-16T23:00:00",
          "2025-09-17T00:00:00",
          "2025-09-17T01:00:00",
          "2025-09-17T02:00:00",
          "2025-09-17T03:00:00",
          "2025-09-17T04:00:00",
          "2025-09-17T05:00:00",
          "2025-09-17T06:00:00",
          "2025-09-17T07:00:00",
          "2025-09-17T08:00:00",
          "2025-09-17T09:00:00",
          "2025-09-17T10:00:00",
          "2025-09-17T11:00:00",
          "2025-09-17T12:00:00",
          "2025-09-17T13:00:00",
          "2025-09-17T14:00:00",
          "2025-09-17T15:00:00",
          "2025-09-17T16:00:00",
          "2025-09-17T17:00:00",
          "2025-09-17T18:00:00",
          "2025-09-17T19:00:00",
          "2025-09-17T20:00:00",
          "2025-09-17T21:00:00",
          "2025-09-17T22:00:00",
          "2025-09-17T23:00:00",
          "2025-09-18T00:00:00",
          "2025-09-18T01:00:00",
          "2025-09-18T02:00:00",
          "2025-09-18T03:00:00",
          "2025-09-18T04:00:00",
          "2025-09-18T05:00:00",
          "2025-09-18T06:00:00",
          "2025-09-18T07:00:00",
          "2025-09-18T08:00:00",
          "2025-09-18T09:00:00",
          "2025-09-18T10:00:00",
          "2025-09-18T11:00:00",
          "2025-09-18T12:00:00",
          "2025-09-18T13:00:00",
          "2025-09-18T14:00:00",
          "2025-09-18T15:00:00",
          "2025-09-18T16:00:00",
          "2025-09-18T17:00:00",
          "2025-09-18T18:00:00",
          "2025-09-18T19:00:00",
          "2025-09-18T20:00:00",
          "2025-09-18T21:00:00",
          "2025-09-18T22:00:00",
          "2025-09-18T23:00:00",
          "2025-09-19T00:00:00",
          "2025-09-19T01:00:00",
          "2025-09-19T02:00:00",
          "2025-09-19T03:00:00",
          "2025-09-19T04:00:00",
          "2025-09-19T05:00:00",
          "2025-09-19T06:00:00",
          "2025-09-19T07:00:00",
          "2025-09-19T08:00:00",
          "2025-09-19T09:00:00",
          "2025-09-19T10:00:00",
          "2025-09-19T11:00:00",
          "2025-09-19T12:00:00",
          "2025-09-19T13:00:00",
          "2025-09-19T14:00:00",
          "2025-09-19T15:00:00",
          "2025-09-19T16:00:00",
          "2025-09-19T17:00:00",
          "2025-09-19T18:00:00",
          "2025-09-19T19:00:00",
          "2025-09-19T20:00:00",
          "2025-09-19T21:00:00",
          "2025-09-19T22:00:00",
          "2025-09-19T23:00:00",
          "2025-09-20T00:00:00",
          "2025-09-20T01:00:00",
          "2025-09-20T02:00:00",
          "2025-09-20T03:00:00",
          "2025-09-20T04:00:00",
          "2025-09-20T05:00:00",
          "2025-09-20T06:00:00",
          "2025-09-20T07:00:00",
          "2025-09-20T08:00:00",
          "2025-09-20T09:00:00",
          "2025-09-20T10:00:00",
          "2025-09-20T11:00:00",
          "2025-09-20T12:00:00",
          "2025-09-20T13:00:00",
          "2025-09-20T14:00:00",
          "2025-09-20T15:00:00",
          "2025-09-20T16:00:00",
          "2025-09-20T17:00:00",
          "2025-09-20T18:00:00",
          "2025-09-20T19:00:00",
          "2025-09-20T20:00:00",
          "2025-09-20T21:00:00",
          "2025-09-20T22:00:00",
          "2025-09-20T23:00:00",
          "2025-09-21T00:00:00",
          "2025-09-21T01:00:00",
          "2025-09-21T02:00:00",
          "2025-09-21T03:00:00",
          "2025-09-21T04:00:00",
          "2025-09-21T05:00:00",
          "2025-09-21T06:00:00",
          "2025-09-21T07:00:00",
          "2025-09-21T08:00:00",
          "2025-09-21T09:00:00",
          "2025-09-21T10:00:00",
          "2025-09-21T11:00:00",
          "2025-09-21T12:00:00",
          "2025-09-21T13:00:00",
          "2025-09-21T14:00:00",
          "2025-09-21T15:00:00",
          "2025-09-21T16:00:00",
          "2025-09-21T17:00:00",
          "2025-09-21T18:00:00",
          "2025-09-21T19:00:00",
          "2025-09-21T20:00:00",
          "2025-09-21T21:00:00",
          "2025-09-21T22:00:00",
          "2025-09-21T23:00:00",
          "2025-09-22T00:00:00",
          "2025-09-22T01:00:00",
          "2025-09-22T02:00:00",
          "2025-09-22T03:00:00",
          "2025-09-22T04:00:00",
          "2025-09-22T05:00:00",
          "2025-09-22T06:00:00",
          "2025-09-22T07:00:00",
          "2025-09-22T08:00:00",
          "2025-09-22T09:00:00",
          "2025-09-22T10:00:00",
          "2025-09-22T11:00:00",
          "2025-09-22T12:00:00",
          "2025-09-22T13:00:00",
          "2025-09-22T14:00:00",
          "2025-09-22T15:00:00",
          "2025-09-22T16:00:00",
          "2025-09-22T17:00:00",
          "2025-09-22T18:00:00",
          "2025-09-22T19:00:00",
          "2025-09-22T20:00:00",
          "2025-09-22T21:00:00",
          "2025-09-22T22:00:00",
          "2025-09-22T23:00:00",
          "2025-09-23T00:00:00",
          "2025-09-23T01:00:00",
          "2025-09-23T02:00:00",
          "2025-09-23T03:00:00",
          "2025-09-23T04:00:00",
          "2025-09-23T05:00:00",
          "2025-09-23T06:00:00",
          "2025-09-23T07:00:00",
          "2025-09-23T08:00:00",
          "2025-09-23T09:00:00",
          "2025-09-23T10:00:00",
          "2025-09-23T11:00:00",
          "2025-09-23T12:00:00",
          "2025-09-23T13:00:00",
          "2025-09-23T14:00:00",
          "2025-09-23T15:00:00",
          "2025-09-23T16:00:00",
          "2025-09-23T17:00:00",
          "2025-09-23T18:00:00",
          "2025-09-23T19:00:00",
          "2025-09-23T20:00:00",
          "2025-09-23T21:00:00",
          "2025-09-23T22:00:00",
          "2025-09-23T23:00:00",
          "2025-09-24T00:00:00",
          "2025-09-24T01:00:00",
          "2025-09-24T02:00:00",
          "2025-09-24T03:00:00",
          "2025-09-24T04:00:00",
          "2025-09-24T05:00:00",
          "2025-09-24T06:00:00",
          "2025-09-24T07:00:00",
          "2025-09-24T08:00:00",
          "2025-09-24T09:00:00",
          "2025-09-24T10:00:00",
          "2025-09-24T11:00:00",
          "2025-09-24T12:00:00",
          "2025-09-24T13:00:00",
          "2025-09-24T14:00:00",
          "2025-09-24T15:00:00",
          "2025-09-24T16:00:00",
          "2025-09-24T17:00:00",
          "2025-09-24T18:00:00",
          "2025-09-24T19:00:00",
          "2025-09-24T20:00:00",
          "2025-09-24T21:00:00",
          "2025-09-24T22:00:00",
          "2025-09-24T23:00:00",
          "2025-09-25T00:00:00",
          "2025-09-25T01:00:00",
          "2025-09-25T02:00:00",
          "2025-09-25T03:00:00",
          "2025-09-25T04:00:00",
          "2025-09-25T05:00:00",
          "2025-09-25T06:00:00",
          "2025-09-25T07:00:00",
          "2025-09-25T08:00:00",
          "2025-09-25T09:00:00",
          "2025-09-25T10:00:00",
          "2025-09-25T11:00:00",
          "2025-09-25T12:00:00",
          "2025-09-25T13:00:00",
          "2025-09-25T14:00:00",
          "2025-09-25T15:00:00",
          "2025-09-25T16:00:00",
          "2025-09-25T17:00:00",
          "2025-09-25T18:00:00",
          "2025-09-25T19:00:00",
          "2025-09-25T20:00:00",
          "2025-09-25T21:00:00",
          "2025-09-25T22:00:00",
          "2025-09-25T23:00:00",
          "2025-09-26T00:00:00",
          "2025-09-26T01:00:00",
          "2025-09-26T02:00:00",
          "2025-09-26T03:00:00",
          "2025-09-26T04:00:00",
          "2025-09-26T05:00:00",
          "2025-09-26T06:00:00",
          "2025-09-26T07:00:00",
          "2025-09-26T08:00:00",
          "2025-09-26T09:00:00",
          "2025-09-26T10:00:00",
          "2025-09-26T11:00:00",
          "2025-09-26T12:00:00",
          "2025-09-26T13:00:00",
          "2025-09-26T14:00:00",
          "2025-09-26T15:00:00",
          "2025-09-26T16:00:00",
          "2025-09-26T17:00:00",
          "2025-09-26T18:00:00",
          "2025-09-26T19:00:00",
          "2025-09-26T20:00:00",
          "2025-09-26T21:00:00",
          "2025-09-26T22:00:00",
          "2025-09-26T23:00:00",
          "2025-09-27T00:00:00",
          "2025-09-27T01:00:00",
          "2025-09-27T02:00:00",
          "2025-09-27T03:00:00",
          "2025-09-27T04:00:00",
          "2025-09-27T05:00:00",
          "2025-09-27T06:00:00",
          "2025-09-27T07:00:00",
          "2025-09-27T08:00:00",
          "2025-09-27T09:00:00",
          "2025-09-27T10:00:00",
          "2025-09-27T11:00:00",
          "2025-09-27T12:00:00",
          "2025-09-27T13:00:00",
          "2025-09-27T14:00:00",
          "2025-09-27T15:00:00",
          "2025-09-27T16:00:00",
          "2025-09-27T17:00:00",
          "2025-09-27T18:00:00",
          "2025-09-27T19:00:00",
          "2025-09-27T20:00:00",
          "2025-09-27T21:00:00",
          "2025-09-27T22:00:00",
          "2025-09-27T23:00:00",
          "2025-09-28T00:00:00",
          "2025-09-28T01:00:00",
          "2025-09-28T02:00:00",
          "2025-09-28T03:00:00",
          "2025-09-28T04:00:00",
          "2025-09-28T05:00:00",
          "2025-09-28T06:00:00",
          "2025-09-28T07:00:00",
          "2025-09-28T08:00:00",
          "2025-09-28T09:00:00",
          "2025-09-28T10:00:00",
          "2025-09-28T11:00:00",
          "2025-09-28T12:00:00",
          "2025-09-28T13:00:00",
          "2025-09-28T14:00:00",
          "2025-09-28T15:00:00",
          "2025-09-28T16:00:00",
          "2025-09-28T17:00:00",
          "2025-09-28T18:00:00",
          "2025-09-28T19:00:00",
          "2025-09-28T20:00:00",
          "2025-09-28T21:00:00",
          "2025-09-28T22:00:00",
          "2025-09-28T23:00:00",
          "2025-09-29T00:00:00",
          "2025-09-29T01:00:00",
          "2025-09-29T02:00:00",
          "2025-09-29T03:00:00",
          "2025-09-29T04:00:00",
          "2025-09-29T05:00:00",
          "2025-09-29T06:00:00",
          "2025-09-29T07:00:00",
          "2025-09-29T08:00:00",
          "2025-09-29T09:00:00",
          "2025-09-29T10:00:00",
          "2025-09-29T11:00:00",
          "2025-09-29T12:00:00",
          "2025-09-29T13:00:00"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "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",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Type"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "text": "Walk-Forward Prediction with Initial Context"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if predictions_wf is not None:\n",
    "    # Compute performance metrics for the walk-forward validation period\n",
    "    mae = mean_absolute_error(y_true_wf, predictions_wf)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_wf, predictions_wf))\n",
    "    \n",
    "    print(f\"\\nWalk-Forward Period Metrics (Test Suite):\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "    # Visualization with Plotly Express\n",
    "    # Prepare data for future values (Real vs Predicted)\n",
    "    plot_df = pd.DataFrame({\n",
    "        'Date': future_index,\n",
    "        'Real values': y_true_wf,\n",
    "        'Predictions': predictions_wf\n",
    "    }).melt(\n",
    "        id_vars='Date',\n",
    "        value_vars=['Real values', 'Predictions'],\n",
    "        var_name='Type',\n",
    "        value_name='Value'\n",
    "        )\n",
    "\n",
    "    # Prepare the historical context (Initial sequence)\n",
    "    initial_df = pd.DataFrame({\n",
    "        'Date': df_init.index,\n",
    "        'Value': df_init['close'].values, # Dynamically select the close price\n",
    "        'Type': 'Initial sequence'\n",
    "    })\n",
    "\n",
    "    # Combine historical context and future predictions for a complete view\n",
    "    full_plot_df = pd.concat([initial_df, plot_df], ignore_index=True)\n",
    "\n",
    "    # Generate the interactive line chart\n",
    "    fig2 = px.line(\n",
    "        full_plot_df,\n",
    "        x='Date',\n",
    "        y='Value',\n",
    "        color='Type',\n",
    "        title='Walk-Forward Prediction with Initial Context',\n",
    "        template='simple_white',\n",
    "        color_discrete_map=custom_colors\n",
    "    )\n",
    "    \n",
    "    fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3543b75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Absolute Percentage Error (APE) over Time'}, xlabel='Date', ylabel='Error (%)'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Detailed Error Analysis ---\n",
    "\n",
    "# Consolidate results into a structured DataFrame for point-wise analysis\n",
    "r = pd.DataFrame({\n",
    "    'Date': future_index,\n",
    "    'Real values': y_true_wf,\n",
    "    'Predictions': predictions_wf\n",
    "})\n",
    "r.set_index('Date', inplace=True)\n",
    "\n",
    "# Calculate the Absolute Error (AE) for each step\n",
    "# Formula: $AE = |y_{true} - y_{pred}|$\n",
    "r['AE'] = abs(r['Real values'] - r['Predictions'])\n",
    "\n",
    "# Calculate the Absolute Percentage Error (APE) for each step\n",
    "# Formula: $APE = |\\frac{y_{true} - y_{pred}}{y_{true}}| \\times 100$\n",
    "r['APE'] = (\n",
    "    abs(r['AE'] / r['Real values']) \n",
    "    * 100\n",
    ")\n",
    "\n",
    "# Visualize the error trend over the prediction horizon\n",
    "# Using the default backend (Matplotlib) for a quick diagnostic plot\n",
    "r['APE'].plot(\n",
    "    title='Absolute Percentage Error (APE) over Time',\n",
    "    ylabel='Error (%)',\n",
    "    xlabel='Date',\n",
    "    grid=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb39045",
   "metadata": {},
   "source": [
    "## 4- Expérimentation\n",
    "\n",
    "À ce stade de la démarche, tous les outils nécessaires ont été mis en place : le pipeline de préparation des données, l’architecture modulaire du modèle, la stratégie d’évaluation (*walk-forward*), ainsi que les métriques pertinentes. Il ne reste plus qu’à lancer l’expérimentation.\n",
    "\n",
    "Puisqu’il s’agit d’une optimisation systématique de modèles, il est essentiel de définir précisément quels hyperparamètres seront explorés et pourquoi. Les choix retenus visent à couvrir les dimensions critiques de la modélisation temporelle dans un contexte de marché bruité comme celui des cryptomonnaies :\n",
    "\n",
    "- *Input_width* : Définit la mémoire temporelle du modèle, c’est-à-dire le nombre de pas passés utilisés pour prédire le futur. Une fenêtre trop courte prive le modèle de contexte nécessaire (ex. tendance, cycle), une fenêtre trop longue introduit du bruit ancien ou des régimes de marché obsolètes, ce qui nuit à la généralisation.\n",
    "\n",
    "- *Batch_size* : Correspond à la taille des mini-lots utilisés lors de la descente de gradient. C’est un compromis entre stabilité et exploration : des lots plus petits introduisent du bruit dans les mises à jour, ce qui peut aider à échapper aux minima locaux, mais augmente le coût computationnel et la variance de l’apprentissage. Des lots plus grands offrent des gradients plus stables, au risque de converger vers des solutions sous-optimales.\n",
    "\n",
    "- *Learning_rate* : C’est le pas de mise à jour des poids à chaque itération. Il contrôle à la fois la vitesse de convergence et la qualité du minimum atteint. Un taux trop faible ralentit l’apprentissage ; un taux trop élevé provoque des oscillations ou une divergence, car les mises à jour « dépassent » les zones optimales.\n",
    "\n",
    "- *Model_units* : Définit la richesse des représentations internes du modèle. Trop peu d’unités entraînent un sous-apprentissage (le modèle ne peut pas capturer les dynamiques temporelles complexes) ; trop d’unités favorisent le surapprentissage, surtout sur des données bruitées comme les prix de cryptomonnaies, où le modèle mémorise le hasard plutôt qu’un signal véritable.\n",
    "\n",
    "- *Drop_out* : Mécanisme de régularisation qui désactive aléatoirement une fraction des neurones pendant l’entraînement. Cela force le réseau à ne pas dépendre de chemins spécifiques et à distribuer l’information, ce qui limite fortement le surapprentissage. Un taux trop élevé peut toutefois empêcher l’apprentissage utile (sous-apprentissage).\n",
    "\n",
    "- *Number_of_layer* : Profondeur du réseau. Plus il y a de couches, plus le modèle peut extraire des motifs temporels hiérarchiques (ex. : variations locales → tendances → régimes). Cependant, dans les architectures récurrentes, une profondeur excessive aggrave les problèmes de gradients (disparition ou explosion), surtout sur des séquences longues, rendant l’entraînement instable ou inefficace.\n",
    "\n",
    "- *loss_function* : La fonction de perte définit ce que le modèle cherche à minimiser, donc ce qu’il considère comme une « bonne » prédiction :\n",
    "\n",
    "    - *MSE* pénalise fortement les grandes erreurs, ce qui la rend sensible aux outliers.\n",
    "\n",
    "    - *MAE* traite toutes les erreurs de façon linéaire, offrant plus de robustesse, mais moins de sensibilité aux écarts extrêmes.\n",
    "\n",
    "    - *Huber* combine les deux : robuste aux outliers, tout en restant sensible aux petites erreurs.\n",
    "\n",
    "L’exploration de ces hyperparamètres, combinée à l’étude de trois architectures de réseaux de neurones différentes (LSTM, GRU et SimpleRNN), conduit à un nombre élevé d’expériences, environ une centaine, même en se limitant à des variations univariées (c’est-à-dire en faisant varier un seul hyperparamètre à la fois).  \n",
    "\n",
    "Dans ce contexte, la traçabilité manuelle devient rapidement impraticable. Pourtant, elle est indispensable : sans un suivi rigoureux, il est impossible de reproduire les résultats, de comparer objectivement les performances ou d’identifier les facteurs réellement influents sur la qualité des prédictions.\n",
    "\n",
    "C’est pourquoi MLflow a été intégré au pipeline expérimental. Cet outil permet d’enregistrer automatiquement, pour chaque exécution :\n",
    "\n",
    "- Les hyperparamètres utilisés,\n",
    "\n",
    "- Les métriques d’évaluation (MAE, RMSE, pertes d’entraînement, etc.),\n",
    "\n",
    "- Les artefacts produits (modèles sauvegardés, figures de prédictions, courbes d’apprentissage).\n",
    "\n",
    "A cela se rajoute un script qui permet d’afficher les différentes courbes pour analyser les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2950b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:11:10 INFO mlflow.tracking.fluent: Experiment with name 'lstm_input_width_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: input_width = 12 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0917 - mae: 0.0917 - root_mean_squared_error: 0.1436 - val_loss: 0.0753 - val_mae: 0.0753 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 2/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0544 - mae: 0.0544 - root_mean_squared_error: 0.0694 - val_loss: 0.0375 - val_mae: 0.0375 - val_root_mean_squared_error: 0.0455\n",
      "Epoch 3/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0526 - mae: 0.0526 - root_mean_squared_error: 0.0681 - val_loss: 0.0567 - val_mae: 0.0567 - val_root_mean_squared_error: 0.0658\n",
      "Epoch 4/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0556 - mae: 0.0556 - root_mean_squared_error: 0.0715 - val_loss: 0.0733 - val_mae: 0.0733 - val_root_mean_squared_error: 0.0819\n",
      "Epoch 5/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0528 - mae: 0.0528 - root_mean_squared_error: 0.0689 - val_loss: 0.0331 - val_mae: 0.0331 - val_root_mean_squared_error: 0.0407\n",
      "Epoch 6/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0541 - mae: 0.0541 - root_mean_squared_error: 0.0702 - val_loss: 0.0411 - val_mae: 0.0411 - val_root_mean_squared_error: 0.0497\n",
      "Epoch 7/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0526 - mae: 0.0526 - root_mean_squared_error: 0.0687 - val_loss: 0.0413 - val_mae: 0.0413 - val_root_mean_squared_error: 0.0499\n",
      "Epoch 8/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0467 - mae: 0.0467 - root_mean_squared_error: 0.0611 - val_loss: 0.0458 - val_mae: 0.0458 - val_root_mean_squared_error: 0.0544\n",
      "Epoch 9/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0446 - mae: 0.0446 - root_mean_squared_error: 0.0582 - val_loss: 0.0408 - val_mae: 0.0408 - val_root_mean_squared_error: 0.0492\n",
      "Epoch 10/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0414 - mae: 0.0414 - root_mean_squared_error: 0.0547 - val_loss: 0.0381 - val_mae: 0.0381 - val_root_mean_squared_error: 0.0463\n",
      "Epoch 11/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0405 - mae: 0.0405 - root_mean_squared_error: 0.0534 - val_loss: 0.0265 - val_mae: 0.0265 - val_root_mean_squared_error: 0.0337\n",
      "Epoch 12/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0529 - val_loss: 0.0584 - val_mae: 0.0584 - val_root_mean_squared_error: 0.0673\n",
      "Epoch 13/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0391 - mae: 0.0391 - root_mean_squared_error: 0.0514 - val_loss: 0.0461 - val_mae: 0.0461 - val_root_mean_squared_error: 0.0552\n",
      "Epoch 14/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0395 - mae: 0.0395 - root_mean_squared_error: 0.0522 - val_loss: 0.0521 - val_mae: 0.0521 - val_root_mean_squared_error: 0.0615\n",
      "Epoch 15/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0508 - val_loss: 0.0451 - val_mae: 0.0451 - val_root_mean_squared_error: 0.0541\n",
      "Epoch 16/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0398 - mae: 0.0398 - root_mean_squared_error: 0.0526 - val_loss: 0.0600 - val_mae: 0.0600 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 17/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0503 - val_loss: 0.0488 - val_mae: 0.0488 - val_root_mean_squared_error: 0.0583\n",
      "Epoch 18/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0374 - mae: 0.0374 - root_mean_squared_error: 0.0495 - val_loss: 0.0411 - val_mae: 0.0411 - val_root_mean_squared_error: 0.0496\n",
      "Epoch 19/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0493 - val_loss: 0.0615 - val_mae: 0.0615 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 20/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0472 - val_loss: 0.0543 - val_mae: 0.0543 - val_root_mean_squared_error: 0.0639\n",
      "Epoch 21/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0464 - val_loss: 0.0551 - val_mae: 0.0551 - val_root_mean_squared_error: 0.0650\n",
      "Epoch 22/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0386 - mae: 0.0386 - root_mean_squared_error: 0.0508 - val_loss: 0.0509 - val_mae: 0.0509 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 23/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0473 - val_loss: 0.0424 - val_mae: 0.0424 - val_root_mean_squared_error: 0.0511\n",
      "Epoch 24/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0317 - mae: 0.0317 - root_mean_squared_error: 0.0426 - val_loss: 0.0453 - val_mae: 0.0453 - val_root_mean_squared_error: 0.0541\n",
      "Epoch 25/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0313 - mae: 0.0313 - root_mean_squared_error: 0.0420 - val_loss: 0.0411 - val_mae: 0.0411 - val_root_mean_squared_error: 0.0496\n",
      "Epoch 26/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0311 - mae: 0.0311 - root_mean_squared_error: 0.0416 - val_loss: 0.0570 - val_mae: 0.0570 - val_root_mean_squared_error: 0.0668\n",
      "Epoch 27/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0318 - mae: 0.0318 - root_mean_squared_error: 0.0423 - val_loss: 0.0537 - val_mae: 0.0537 - val_root_mean_squared_error: 0.0639\n",
      "Epoch 28/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0455 - val_loss: 0.0507 - val_mae: 0.0507 - val_root_mean_squared_error: 0.0599\n",
      "Epoch 29/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0311 - mae: 0.0311 - root_mean_squared_error: 0.0415 - val_loss: 0.0435 - val_mae: 0.0435 - val_root_mean_squared_error: 0.0524\n",
      "Epoch 30/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0308 - mae: 0.0308 - root_mean_squared_error: 0.0413 - val_loss: 0.0396 - val_mae: 0.0396 - val_root_mean_squared_error: 0.0479\n",
      "Epoch 31/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0293 - mae: 0.0293 - root_mean_squared_error: 0.0388 - val_loss: 0.0658 - val_mae: 0.0658 - val_root_mean_squared_error: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:11:30 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:11:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:11:41 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:11:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: input_width = 24 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0939 - mae: 0.0939 - root_mean_squared_error: 0.1429 - val_loss: 0.0597 - val_mae: 0.0597 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0663 - mae: 0.0663 - root_mean_squared_error: 0.0858 - val_loss: 0.0466 - val_mae: 0.0466 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0674 - mae: 0.0674 - root_mean_squared_error: 0.0866 - val_loss: 0.0569 - val_mae: 0.0569 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0662 - mae: 0.0662 - root_mean_squared_error: 0.0843 - val_loss: 0.0620 - val_mae: 0.0620 - val_root_mean_squared_error: 0.0740\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0647 - mae: 0.0647 - root_mean_squared_error: 0.0830 - val_loss: 0.0659 - val_mae: 0.0659 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0656 - mae: 0.0656 - root_mean_squared_error: 0.0833 - val_loss: 0.0851 - val_mae: 0.0851 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0632 - mae: 0.0632 - root_mean_squared_error: 0.0810 - val_loss: 0.0588 - val_mae: 0.0588 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0660 - mae: 0.0660 - root_mean_squared_error: 0.0839 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0642 - mae: 0.0642 - root_mean_squared_error: 0.0813 - val_loss: 0.0718 - val_mae: 0.0718 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0831 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0661 - mae: 0.0661 - root_mean_squared_error: 0.0834 - val_loss: 0.0678 - val_mae: 0.0678 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0651 - mae: 0.0651 - root_mean_squared_error: 0.0819 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0644 - mae: 0.0644 - root_mean_squared_error: 0.0809 - val_loss: 0.0639 - val_mae: 0.0639 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0645 - mae: 0.0645 - root_mean_squared_error: 0.0811 - val_loss: 0.0570 - val_mae: 0.0570 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0630 - mae: 0.0630 - root_mean_squared_error: 0.0795 - val_loss: 0.0691 - val_mae: 0.0691 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0622 - mae: 0.0622 - root_mean_squared_error: 0.0784 - val_loss: 0.0594 - val_mae: 0.0594 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0606 - mae: 0.0606 - root_mean_squared_error: 0.0765 - val_loss: 0.0660 - val_mae: 0.0660 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0600 - mae: 0.0600 - root_mean_squared_error: 0.0760 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0596 - mae: 0.0596 - root_mean_squared_error: 0.0757 - val_loss: 0.0666 - val_mae: 0.0666 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0744 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0746 - val_mae: 0.0746 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0629 - val_mae: 0.0629 - val_root_mean_squared_error: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:12:23 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:12:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:12:31 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:12:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: input_width = 48 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1027 - mae: 0.1027 - root_mean_squared_error: 0.1499 - val_loss: 0.0738 - val_mae: 0.0738 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0815 - mae: 0.0815 - root_mean_squared_error: 0.1022 - val_loss: 0.0879 - val_mae: 0.0879 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0800 - mae: 0.0800 - root_mean_squared_error: 0.1001 - val_loss: 0.0863 - val_mae: 0.0863 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0790 - mae: 0.0790 - root_mean_squared_error: 0.0983 - val_loss: 0.0955 - val_mae: 0.0955 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0792 - mae: 0.0792 - root_mean_squared_error: 0.0994 - val_loss: 0.0986 - val_mae: 0.0986 - val_root_mean_squared_error: 0.1131\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0818 - mae: 0.0818 - root_mean_squared_error: 0.1014 - val_loss: 0.0906 - val_mae: 0.0906 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0801 - mae: 0.0801 - root_mean_squared_error: 0.1001 - val_loss: 0.0792 - val_mae: 0.0792 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0826 - mae: 0.0826 - root_mean_squared_error: 0.1032 - val_loss: 0.0710 - val_mae: 0.0710 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0787 - mae: 0.0787 - root_mean_squared_error: 0.0980 - val_loss: 0.0881 - val_mae: 0.0881 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0765 - mae: 0.0765 - root_mean_squared_error: 0.0952 - val_loss: 0.0710 - val_mae: 0.0710 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0775 - mae: 0.0775 - root_mean_squared_error: 0.0963 - val_loss: 0.0827 - val_mae: 0.0827 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0748 - mae: 0.0748 - root_mean_squared_error: 0.0930 - val_loss: 0.0810 - val_mae: 0.0810 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0741 - mae: 0.0741 - root_mean_squared_error: 0.0916 - val_loss: 0.0810 - val_mae: 0.0810 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0734 - mae: 0.0734 - root_mean_squared_error: 0.0914 - val_loss: 0.0776 - val_mae: 0.0776 - val_root_mean_squared_error: 0.0927\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0720 - mae: 0.0720 - root_mean_squared_error: 0.0901 - val_loss: 0.0939 - val_mae: 0.0939 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0706 - mae: 0.0706 - root_mean_squared_error: 0.0876 - val_loss: 0.0784 - val_mae: 0.0784 - val_root_mean_squared_error: 0.0934\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0713 - mae: 0.0713 - root_mean_squared_error: 0.0885 - val_loss: 0.0810 - val_mae: 0.0810 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0719 - mae: 0.0719 - root_mean_squared_error: 0.0898 - val_loss: 0.0719 - val_mae: 0.0719 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0691 - mae: 0.0691 - root_mean_squared_error: 0.0869 - val_loss: 0.0784 - val_mae: 0.0784 - val_root_mean_squared_error: 0.0935\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0679 - mae: 0.0679 - root_mean_squared_error: 0.0857 - val_loss: 0.0822 - val_mae: 0.0822 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0679 - mae: 0.0679 - root_mean_squared_error: 0.0855 - val_loss: 0.0794 - val_mae: 0.0794 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0688 - mae: 0.0688 - root_mean_squared_error: 0.0867 - val_loss: 0.0873 - val_mae: 0.0873 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0680 - mae: 0.0680 - root_mean_squared_error: 0.0859 - val_loss: 0.0782 - val_mae: 0.0782 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0685 - mae: 0.0685 - root_mean_squared_error: 0.0861 - val_loss: 0.0813 - val_mae: 0.0813 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0671 - mae: 0.0671 - root_mean_squared_error: 0.0851 - val_loss: 0.0872 - val_mae: 0.0872 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0838 - val_loss: 0.0742 - val_mae: 0.0742 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0678 - mae: 0.0678 - root_mean_squared_error: 0.0859 - val_loss: 0.0893 - val_mae: 0.0893 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0667 - mae: 0.0667 - root_mean_squared_error: 0.0846 - val_loss: 0.0844 - val_mae: 0.0844 - val_root_mean_squared_error: 0.0993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:13:31 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:13:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:13:38 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:13:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: input_width = 72 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.1110 - mae: 0.1110 - root_mean_squared_error: 0.1565 - val_loss: 0.1211 - val_mae: 0.1211 - val_root_mean_squared_error: 0.1362\n",
      "Epoch 2/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0921 - mae: 0.0921 - root_mean_squared_error: 0.1142 - val_loss: 0.1173 - val_mae: 0.1173 - val_root_mean_squared_error: 0.1330\n",
      "Epoch 3/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0906 - mae: 0.0906 - root_mean_squared_error: 0.1122 - val_loss: 0.0945 - val_mae: 0.0945 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 4/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0938 - mae: 0.0938 - root_mean_squared_error: 0.1148 - val_loss: 0.0823 - val_mae: 0.0823 - val_root_mean_squared_error: 0.0991\n",
      "Epoch 5/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0923 - mae: 0.0923 - root_mean_squared_error: 0.1137 - val_loss: 0.0831 - val_mae: 0.0831 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 6/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0916 - mae: 0.0916 - root_mean_squared_error: 0.1130 - val_loss: 0.0826 - val_mae: 0.0826 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 7/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0919 - mae: 0.0919 - root_mean_squared_error: 0.1137 - val_loss: 0.0829 - val_mae: 0.0829 - val_root_mean_squared_error: 0.0999\n",
      "Epoch 8/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0899 - mae: 0.0899 - root_mean_squared_error: 0.1114 - val_loss: 0.0783 - val_mae: 0.0783 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 9/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0891 - mae: 0.0891 - root_mean_squared_error: 0.1098 - val_loss: 0.0857 - val_mae: 0.0857 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 10/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0871 - mae: 0.0871 - root_mean_squared_error: 0.1086 - val_loss: 0.0867 - val_mae: 0.0867 - val_root_mean_squared_error: 0.1038\n",
      "Epoch 11/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0859 - mae: 0.0859 - root_mean_squared_error: 0.1074 - val_loss: 0.1030 - val_mae: 0.1030 - val_root_mean_squared_error: 0.1193\n",
      "Epoch 12/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0848 - mae: 0.0848 - root_mean_squared_error: 0.1055 - val_loss: 0.0900 - val_mae: 0.0900 - val_root_mean_squared_error: 0.1071\n",
      "Epoch 13/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0829 - mae: 0.0829 - root_mean_squared_error: 0.1034 - val_loss: 0.0876 - val_mae: 0.0876 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 14/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0830 - mae: 0.0830 - root_mean_squared_error: 0.1033 - val_loss: 0.1060 - val_mae: 0.1060 - val_root_mean_squared_error: 0.1220\n",
      "Epoch 15/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0835 - mae: 0.0835 - root_mean_squared_error: 0.1041 - val_loss: 0.0959 - val_mae: 0.0959 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 16/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0823 - mae: 0.0823 - root_mean_squared_error: 0.1020 - val_loss: 0.0896 - val_mae: 0.0896 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 17/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0813 - mae: 0.0813 - root_mean_squared_error: 0.1006 - val_loss: 0.0927 - val_mae: 0.0927 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 18/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0801 - mae: 0.0801 - root_mean_squared_error: 0.1001 - val_loss: 0.0955 - val_mae: 0.0955 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 19/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0791 - mae: 0.0791 - root_mean_squared_error: 0.0990 - val_loss: 0.0927 - val_mae: 0.0927 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 20/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0809 - mae: 0.0809 - root_mean_squared_error: 0.1007 - val_loss: 0.0948 - val_mae: 0.0948 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 21/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0794 - mae: 0.0794 - root_mean_squared_error: 0.0985 - val_loss: 0.0917 - val_mae: 0.0917 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 22/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0793 - mae: 0.0793 - root_mean_squared_error: 0.0995 - val_loss: 0.0928 - val_mae: 0.0928 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 23/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0785 - mae: 0.0785 - root_mean_squared_error: 0.0984 - val_loss: 0.0896 - val_mae: 0.0896 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 24/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0785 - mae: 0.0785 - root_mean_squared_error: 0.0988 - val_loss: 0.0865 - val_mae: 0.0865 - val_root_mean_squared_error: 0.1037\n",
      "Epoch 25/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0781 - mae: 0.0781 - root_mean_squared_error: 0.0978 - val_loss: 0.0834 - val_mae: 0.0834 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 26/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0780 - mae: 0.0780 - root_mean_squared_error: 0.0981 - val_loss: 0.0887 - val_mae: 0.0887 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 27/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0775 - mae: 0.0775 - root_mean_squared_error: 0.0974 - val_loss: 0.0803 - val_mae: 0.0803 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 28/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0789 - mae: 0.0789 - root_mean_squared_error: 0.0991 - val_loss: 0.0911 - val_mae: 0.0911 - val_root_mean_squared_error: 0.1081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:14:54 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:15:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:15:01 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:15:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: input_width = 96 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1171 - mae: 0.1171 - root_mean_squared_error: 0.1613 - val_loss: 0.1335 - val_mae: 0.1335 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 2/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0981 - mae: 0.0981 - root_mean_squared_error: 0.1209 - val_loss: 0.1227 - val_mae: 0.1227 - val_root_mean_squared_error: 0.1398\n",
      "Epoch 3/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0994 - mae: 0.0994 - root_mean_squared_error: 0.1224 - val_loss: 0.1166 - val_mae: 0.1166 - val_root_mean_squared_error: 0.1339\n",
      "Epoch 4/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.1021 - mae: 0.1021 - root_mean_squared_error: 0.1251 - val_loss: 0.1117 - val_mae: 0.1117 - val_root_mean_squared_error: 0.1291\n",
      "Epoch 5/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.1000 - mae: 0.1000 - root_mean_squared_error: 0.1225 - val_loss: 0.1010 - val_mae: 0.1010 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 6/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.1016 - mae: 0.1016 - root_mean_squared_error: 0.1246 - val_loss: 0.1132 - val_mae: 0.1132 - val_root_mean_squared_error: 0.1307\n",
      "Epoch 7/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.1004 - mae: 0.1004 - root_mean_squared_error: 0.1234 - val_loss: 0.1298 - val_mae: 0.1298 - val_root_mean_squared_error: 0.1463\n",
      "Epoch 8/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0987 - mae: 0.0987 - root_mean_squared_error: 0.1212 - val_loss: 0.1302 - val_mae: 0.1302 - val_root_mean_squared_error: 0.1466\n",
      "Epoch 9/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0944 - mae: 0.0944 - root_mean_squared_error: 0.1161 - val_loss: 0.1142 - val_mae: 0.1142 - val_root_mean_squared_error: 0.1316\n",
      "Epoch 10/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0948 - mae: 0.0948 - root_mean_squared_error: 0.1173 - val_loss: 0.1296 - val_mae: 0.1296 - val_root_mean_squared_error: 0.1460\n",
      "Epoch 11/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0931 - mae: 0.0931 - root_mean_squared_error: 0.1151 - val_loss: 0.1259 - val_mae: 0.1259 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 12/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0939 - mae: 0.0939 - root_mean_squared_error: 0.1153 - val_loss: 0.1142 - val_mae: 0.1142 - val_root_mean_squared_error: 0.1316\n",
      "Epoch 13/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0919 - mae: 0.0919 - root_mean_squared_error: 0.1133 - val_loss: 0.1221 - val_mae: 0.1221 - val_root_mean_squared_error: 0.1391\n",
      "Epoch 14/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0914 - mae: 0.0914 - root_mean_squared_error: 0.1128 - val_loss: 0.1126 - val_mae: 0.1126 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 15/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0912 - mae: 0.0912 - root_mean_squared_error: 0.1128 - val_loss: 0.1178 - val_mae: 0.1178 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 16/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0903 - mae: 0.0903 - root_mean_squared_error: 0.1120 - val_loss: 0.1212 - val_mae: 0.1212 - val_root_mean_squared_error: 0.1382\n",
      "Epoch 17/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0897 - mae: 0.0897 - root_mean_squared_error: 0.1106 - val_loss: 0.1121 - val_mae: 0.1121 - val_root_mean_squared_error: 0.1296\n",
      "Epoch 18/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0904 - mae: 0.0904 - root_mean_squared_error: 0.1117 - val_loss: 0.1191 - val_mae: 0.1191 - val_root_mean_squared_error: 0.1363\n",
      "Epoch 19/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0878 - mae: 0.0878 - root_mean_squared_error: 0.1089 - val_loss: 0.1142 - val_mae: 0.1142 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 20/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0890 - mae: 0.0890 - root_mean_squared_error: 0.1101 - val_loss: 0.1126 - val_mae: 0.1126 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 21/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0892 - mae: 0.0892 - root_mean_squared_error: 0.1103 - val_loss: 0.1118 - val_mae: 0.1118 - val_root_mean_squared_error: 0.1293\n",
      "Epoch 22/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0885 - mae: 0.0885 - root_mean_squared_error: 0.1096 - val_loss: 0.1070 - val_mae: 0.1070 - val_root_mean_squared_error: 0.1247\n",
      "Epoch 23/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0866 - mae: 0.0866 - root_mean_squared_error: 0.1083 - val_loss: 0.1091 - val_mae: 0.1091 - val_root_mean_squared_error: 0.1267\n",
      "Epoch 24/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0879 - mae: 0.0879 - root_mean_squared_error: 0.1091 - val_loss: 0.1120 - val_mae: 0.1120 - val_root_mean_squared_error: 0.1295\n",
      "Epoch 25/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0880 - mae: 0.0880 - root_mean_squared_error: 0.1095 - val_loss: 0.1101 - val_mae: 0.1101 - val_root_mean_squared_error: 0.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:16:23 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:16:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:16:30 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:16:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 19:16:48 INFO mlflow.tracking.fluent: Experiment with name 'lstm_batch_size_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: batch_size = 16 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0805 - mae: 0.0805 - root_mean_squared_error: 0.1178 - val_loss: 0.0547 - val_mae: 0.0547 - val_root_mean_squared_error: 0.0662\n",
      "Epoch 2/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0608 - mae: 0.0608 - root_mean_squared_error: 0.0787 - val_loss: 0.1008 - val_mae: 0.1008 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 3/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0589 - mae: 0.0589 - root_mean_squared_error: 0.0757 - val_loss: 0.0714 - val_mae: 0.0714 - val_root_mean_squared_error: 0.0836\n",
      "Epoch 4/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0581 - mae: 0.0581 - root_mean_squared_error: 0.0750 - val_loss: 0.0866 - val_mae: 0.0866 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 5/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0588 - mae: 0.0588 - root_mean_squared_error: 0.0758 - val_loss: 0.1032 - val_mae: 0.1032 - val_root_mean_squared_error: 0.1146\n",
      "Epoch 6/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0572 - mae: 0.0572 - root_mean_squared_error: 0.0746 - val_loss: 0.1028 - val_mae: 0.1028 - val_root_mean_squared_error: 0.1145\n",
      "Epoch 7/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0590 - mae: 0.0590 - root_mean_squared_error: 0.0766 - val_loss: 0.0832 - val_mae: 0.0832 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 8/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0601 - mae: 0.0601 - root_mean_squared_error: 0.0783 - val_loss: 0.0816 - val_mae: 0.0816 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 9/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0593 - mae: 0.0593 - root_mean_squared_error: 0.0772 - val_loss: 0.0765 - val_mae: 0.0765 - val_root_mean_squared_error: 0.0896\n",
      "Epoch 10/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0605 - mae: 0.0605 - root_mean_squared_error: 0.0793 - val_loss: 0.0734 - val_mae: 0.0734 - val_root_mean_squared_error: 0.0863\n",
      "Epoch 11/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0584 - mae: 0.0584 - root_mean_squared_error: 0.0757 - val_loss: 0.0751 - val_mae: 0.0751 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 12/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0591 - mae: 0.0591 - root_mean_squared_error: 0.0768 - val_loss: 0.0785 - val_mae: 0.0785 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 13/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0573 - mae: 0.0573 - root_mean_squared_error: 0.0751 - val_loss: 0.0673 - val_mae: 0.0673 - val_root_mean_squared_error: 0.0800\n",
      "Epoch 14/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0568 - mae: 0.0568 - root_mean_squared_error: 0.0745 - val_loss: 0.0671 - val_mae: 0.0671 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 15/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0566 - mae: 0.0566 - root_mean_squared_error: 0.0739 - val_loss: 0.0532 - val_mae: 0.0532 - val_root_mean_squared_error: 0.0648\n",
      "Epoch 16/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0555 - mae: 0.0555 - root_mean_squared_error: 0.0727 - val_loss: 0.0585 - val_mae: 0.0585 - val_root_mean_squared_error: 0.0706\n",
      "Epoch 17/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0545 - mae: 0.0545 - root_mean_squared_error: 0.0712 - val_loss: 0.0733 - val_mae: 0.0733 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 18/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0537 - mae: 0.0537 - root_mean_squared_error: 0.0701 - val_loss: 0.0744 - val_mae: 0.0744 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 19/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0527 - mae: 0.0527 - root_mean_squared_error: 0.0697 - val_loss: 0.0654 - val_mae: 0.0654 - val_root_mean_squared_error: 0.0778\n",
      "Epoch 20/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0518 - mae: 0.0518 - root_mean_squared_error: 0.0681 - val_loss: 0.0696 - val_mae: 0.0696 - val_root_mean_squared_error: 0.0821\n",
      "Epoch 21/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0516 - mae: 0.0516 - root_mean_squared_error: 0.0682 - val_loss: 0.0524 - val_mae: 0.0524 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 22/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0521 - mae: 0.0521 - root_mean_squared_error: 0.0684 - val_loss: 0.0618 - val_mae: 0.0618 - val_root_mean_squared_error: 0.0741\n",
      "Epoch 23/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0512 - mae: 0.0512 - root_mean_squared_error: 0.0671 - val_loss: 0.0624 - val_mae: 0.0624 - val_root_mean_squared_error: 0.0747\n",
      "Epoch 24/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0507 - mae: 0.0507 - root_mean_squared_error: 0.0665 - val_loss: 0.0554 - val_mae: 0.0554 - val_root_mean_squared_error: 0.0676\n",
      "Epoch 25/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0510 - mae: 0.0510 - root_mean_squared_error: 0.0675 - val_loss: 0.0551 - val_mae: 0.0551 - val_root_mean_squared_error: 0.0672\n",
      "Epoch 26/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0519 - mae: 0.0519 - root_mean_squared_error: 0.0672 - val_loss: 0.0456 - val_mae: 0.0456 - val_root_mean_squared_error: 0.0573\n",
      "Epoch 27/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0497 - mae: 0.0497 - root_mean_squared_error: 0.0652 - val_loss: 0.0556 - val_mae: 0.0556 - val_root_mean_squared_error: 0.0679\n",
      "Epoch 28/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0493 - mae: 0.0493 - root_mean_squared_error: 0.0649 - val_loss: 0.0617 - val_mae: 0.0617 - val_root_mean_squared_error: 0.0739\n",
      "Epoch 29/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0490 - mae: 0.0490 - root_mean_squared_error: 0.0644 - val_loss: 0.0652 - val_mae: 0.0652 - val_root_mean_squared_error: 0.0774\n",
      "Epoch 30/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0647 - val_loss: 0.0575 - val_mae: 0.0575 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 31/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0649 - val_loss: 0.0480 - val_mae: 0.0480 - val_root_mean_squared_error: 0.0601\n",
      "Epoch 32/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0487 - mae: 0.0487 - root_mean_squared_error: 0.0643 - val_loss: 0.0595 - val_mae: 0.0595 - val_root_mean_squared_error: 0.0717\n",
      "Epoch 33/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0479 - mae: 0.0479 - root_mean_squared_error: 0.0632 - val_loss: 0.0415 - val_mae: 0.0415 - val_root_mean_squared_error: 0.0529\n",
      "Epoch 34/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0475 - mae: 0.0475 - root_mean_squared_error: 0.0623 - val_loss: 0.0523 - val_mae: 0.0523 - val_root_mean_squared_error: 0.0644\n",
      "Epoch 35/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0461 - mae: 0.0461 - root_mean_squared_error: 0.0609 - val_loss: 0.0580 - val_mae: 0.0580 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 36/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0447 - mae: 0.0447 - root_mean_squared_error: 0.0587 - val_loss: 0.0578 - val_mae: 0.0578 - val_root_mean_squared_error: 0.0696\n",
      "Epoch 37/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0443 - mae: 0.0443 - root_mean_squared_error: 0.0578 - val_loss: 0.0565 - val_mae: 0.0565 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 38/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0431 - mae: 0.0431 - root_mean_squared_error: 0.0561 - val_loss: 0.0627 - val_mae: 0.0627 - val_root_mean_squared_error: 0.0735\n",
      "Epoch 39/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0401 - mae: 0.0401 - root_mean_squared_error: 0.0527 - val_loss: 0.0653 - val_mae: 0.0653 - val_root_mean_squared_error: 0.0760\n",
      "Epoch 40/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0482 - val_loss: 0.0905 - val_mae: 0.0905 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 41/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0452 - val_loss: 0.0500 - val_mae: 0.0500 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 42/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0437 - val_loss: 0.0597 - val_mae: 0.0597 - val_root_mean_squared_error: 0.0714\n",
      "Epoch 43/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0332 - mae: 0.0332 - root_mean_squared_error: 0.0424 - val_loss: 0.0779 - val_mae: 0.0779 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 44/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0312 - mae: 0.0312 - root_mean_squared_error: 0.0403 - val_loss: 0.0978 - val_mae: 0.0978 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 45/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0304 - mae: 0.0304 - root_mean_squared_error: 0.0396 - val_loss: 0.1192 - val_mae: 0.1192 - val_root_mean_squared_error: 0.1340\n",
      "Epoch 46/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0381 - val_loss: 0.1148 - val_mae: 0.1148 - val_root_mean_squared_error: 0.1284\n",
      "Epoch 47/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0282 - mae: 0.0282 - root_mean_squared_error: 0.0375 - val_loss: 0.1163 - val_mae: 0.1163 - val_root_mean_squared_error: 0.1319\n",
      "Epoch 48/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0290 - mae: 0.0290 - root_mean_squared_error: 0.0382 - val_loss: 0.1180 - val_mae: 0.1180 - val_root_mean_squared_error: 0.1324\n",
      "Epoch 49/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0277 - mae: 0.0277 - root_mean_squared_error: 0.0362 - val_loss: 0.1077 - val_mae: 0.1077 - val_root_mean_squared_error: 0.1236\n",
      "Epoch 50/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - mae: 0.0268 - root_mean_squared_error: 0.0352 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:17:55 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:18:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:18:03 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:18:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: batch_size = 32 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0939 - mae: 0.0939 - root_mean_squared_error: 0.1429 - val_loss: 0.0597 - val_mae: 0.0597 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0663 - mae: 0.0663 - root_mean_squared_error: 0.0858 - val_loss: 0.0466 - val_mae: 0.0466 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0674 - mae: 0.0674 - root_mean_squared_error: 0.0866 - val_loss: 0.0569 - val_mae: 0.0569 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0662 - mae: 0.0662 - root_mean_squared_error: 0.0843 - val_loss: 0.0620 - val_mae: 0.0620 - val_root_mean_squared_error: 0.0740\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0647 - mae: 0.0647 - root_mean_squared_error: 0.0830 - val_loss: 0.0659 - val_mae: 0.0659 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0656 - mae: 0.0656 - root_mean_squared_error: 0.0833 - val_loss: 0.0851 - val_mae: 0.0851 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0632 - mae: 0.0632 - root_mean_squared_error: 0.0810 - val_loss: 0.0588 - val_mae: 0.0588 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0660 - mae: 0.0660 - root_mean_squared_error: 0.0839 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0642 - mae: 0.0642 - root_mean_squared_error: 0.0813 - val_loss: 0.0718 - val_mae: 0.0718 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0831 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0661 - mae: 0.0661 - root_mean_squared_error: 0.0834 - val_loss: 0.0678 - val_mae: 0.0678 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0651 - mae: 0.0651 - root_mean_squared_error: 0.0819 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0644 - mae: 0.0644 - root_mean_squared_error: 0.0809 - val_loss: 0.0639 - val_mae: 0.0639 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0645 - mae: 0.0645 - root_mean_squared_error: 0.0811 - val_loss: 0.0570 - val_mae: 0.0570 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0630 - mae: 0.0630 - root_mean_squared_error: 0.0795 - val_loss: 0.0691 - val_mae: 0.0691 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0622 - mae: 0.0622 - root_mean_squared_error: 0.0784 - val_loss: 0.0594 - val_mae: 0.0594 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0606 - mae: 0.0606 - root_mean_squared_error: 0.0765 - val_loss: 0.0660 - val_mae: 0.0660 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0600 - mae: 0.0600 - root_mean_squared_error: 0.0760 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0596 - mae: 0.0596 - root_mean_squared_error: 0.0757 - val_loss: 0.0666 - val_mae: 0.0666 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0744 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0746 - val_mae: 0.0746 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0629 - val_mae: 0.0629 - val_root_mean_squared_error: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:18:44 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:18:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:18:52 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:18:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: batch_size = 64 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1395 - mae: 0.1395 - root_mean_squared_error: 0.2023 - val_loss: 0.1196 - val_mae: 0.1196 - val_root_mean_squared_error: 0.1291\n",
      "Epoch 2/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0850 - mae: 0.0850 - root_mean_squared_error: 0.1078 - val_loss: 0.1547 - val_mae: 0.1547 - val_root_mean_squared_error: 0.1623\n",
      "Epoch 3/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0825 - mae: 0.0825 - root_mean_squared_error: 0.1049 - val_loss: 0.1577 - val_mae: 0.1577 - val_root_mean_squared_error: 0.1652\n",
      "Epoch 4/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0808 - mae: 0.0808 - root_mean_squared_error: 0.1017 - val_loss: 0.1525 - val_mae: 0.1525 - val_root_mean_squared_error: 0.1601\n",
      "Epoch 5/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0791 - mae: 0.0791 - root_mean_squared_error: 0.1003 - val_loss: 0.1579 - val_mae: 0.1579 - val_root_mean_squared_error: 0.1653\n",
      "Epoch 6/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0780 - mae: 0.0780 - root_mean_squared_error: 0.0989 - val_loss: 0.1281 - val_mae: 0.1281 - val_root_mean_squared_error: 0.1365\n",
      "Epoch 7/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0739 - mae: 0.0739 - root_mean_squared_error: 0.0934 - val_loss: 0.1265 - val_mae: 0.1265 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 8/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0755 - mae: 0.0755 - root_mean_squared_error: 0.0952 - val_loss: 0.1224 - val_mae: 0.1224 - val_root_mean_squared_error: 0.1309\n",
      "Epoch 9/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0727 - mae: 0.0727 - root_mean_squared_error: 0.0914 - val_loss: 0.1177 - val_mae: 0.1177 - val_root_mean_squared_error: 0.1263\n",
      "Epoch 10/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0702 - mae: 0.0702 - root_mean_squared_error: 0.0891 - val_loss: 0.1247 - val_mae: 0.1247 - val_root_mean_squared_error: 0.1330\n",
      "Epoch 11/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0663 - mae: 0.0663 - root_mean_squared_error: 0.0850 - val_loss: 0.1060 - val_mae: 0.1060 - val_root_mean_squared_error: 0.1153\n",
      "Epoch 12/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0652 - mae: 0.0652 - root_mean_squared_error: 0.0830 - val_loss: 0.1161 - val_mae: 0.1161 - val_root_mean_squared_error: 0.1247\n",
      "Epoch 13/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0639 - mae: 0.0639 - root_mean_squared_error: 0.0813 - val_loss: 0.1136 - val_mae: 0.1136 - val_root_mean_squared_error: 0.1224\n",
      "Epoch 14/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0609 - mae: 0.0609 - root_mean_squared_error: 0.0779 - val_loss: 0.0999 - val_mae: 0.0999 - val_root_mean_squared_error: 0.1093\n",
      "Epoch 15/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0768 - val_loss: 0.1120 - val_mae: 0.1120 - val_root_mean_squared_error: 0.1209\n",
      "Epoch 16/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0596 - mae: 0.0596 - root_mean_squared_error: 0.0763 - val_loss: 0.0887 - val_mae: 0.0887 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 17/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0584 - mae: 0.0584 - root_mean_squared_error: 0.0749 - val_loss: 0.0946 - val_mae: 0.0946 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 18/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0569 - mae: 0.0569 - root_mean_squared_error: 0.0732 - val_loss: 0.0933 - val_mae: 0.0933 - val_root_mean_squared_error: 0.1031\n",
      "Epoch 19/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0565 - mae: 0.0565 - root_mean_squared_error: 0.0724 - val_loss: 0.0917 - val_mae: 0.0917 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 20/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0568 - mae: 0.0568 - root_mean_squared_error: 0.0728 - val_loss: 0.0929 - val_mae: 0.0929 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 21/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0550 - mae: 0.0550 - root_mean_squared_error: 0.0705 - val_loss: 0.0905 - val_mae: 0.0905 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 22/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0550 - mae: 0.0550 - root_mean_squared_error: 0.0711 - val_loss: 0.0891 - val_mae: 0.0891 - val_root_mean_squared_error: 0.0994\n",
      "Epoch 23/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0569 - mae: 0.0569 - root_mean_squared_error: 0.0728 - val_loss: 0.0979 - val_mae: 0.0979 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 24/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0545 - mae: 0.0545 - root_mean_squared_error: 0.0702 - val_loss: 0.1031 - val_mae: 0.1031 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 25/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0565 - mae: 0.0565 - root_mean_squared_error: 0.0724 - val_loss: 0.1030 - val_mae: 0.1030 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 26/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0553 - mae: 0.0553 - root_mean_squared_error: 0.0710 - val_loss: 0.0922 - val_mae: 0.0922 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 27/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0555 - mae: 0.0555 - root_mean_squared_error: 0.0711 - val_loss: 0.0982 - val_mae: 0.0982 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 28/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0528 - mae: 0.0528 - root_mean_squared_error: 0.0685 - val_loss: 0.0795 - val_mae: 0.0795 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 29/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0540 - mae: 0.0540 - root_mean_squared_error: 0.0698 - val_loss: 0.0982 - val_mae: 0.0982 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 30/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0536 - mae: 0.0536 - root_mean_squared_error: 0.0691 - val_loss: 0.0896 - val_mae: 0.0896 - val_root_mean_squared_error: 0.0999\n",
      "Epoch 31/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0535 - mae: 0.0535 - root_mean_squared_error: 0.0693 - val_loss: 0.0771 - val_mae: 0.0771 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 32/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0523 - mae: 0.0523 - root_mean_squared_error: 0.0676 - val_loss: 0.0894 - val_mae: 0.0894 - val_root_mean_squared_error: 0.0997\n",
      "Epoch 33/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0520 - mae: 0.0520 - root_mean_squared_error: 0.0671 - val_loss: 0.0909 - val_mae: 0.0909 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 34/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0512 - mae: 0.0512 - root_mean_squared_error: 0.0663 - val_loss: 0.0833 - val_mae: 0.0833 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 35/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0505 - mae: 0.0505 - root_mean_squared_error: 0.0657 - val_loss: 0.0873 - val_mae: 0.0873 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 36/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0513 - mae: 0.0513 - root_mean_squared_error: 0.0663 - val_loss: 0.0818 - val_mae: 0.0818 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 37/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0507 - mae: 0.0507 - root_mean_squared_error: 0.0663 - val_loss: 0.0741 - val_mae: 0.0741 - val_root_mean_squared_error: 0.0850\n",
      "Epoch 38/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0507 - mae: 0.0507 - root_mean_squared_error: 0.0659 - val_loss: 0.0628 - val_mae: 0.0628 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 39/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0505 - mae: 0.0505 - root_mean_squared_error: 0.0662 - val_loss: 0.0810 - val_mae: 0.0810 - val_root_mean_squared_error: 0.0913\n",
      "Epoch 40/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0490 - mae: 0.0490 - root_mean_squared_error: 0.0640 - val_loss: 0.0663 - val_mae: 0.0663 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 41/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0488 - mae: 0.0488 - root_mean_squared_error: 0.0638 - val_loss: 0.0547 - val_mae: 0.0547 - val_root_mean_squared_error: 0.0663\n",
      "Epoch 42/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0493 - mae: 0.0493 - root_mean_squared_error: 0.0641 - val_loss: 0.0562 - val_mae: 0.0562 - val_root_mean_squared_error: 0.0675\n",
      "Epoch 43/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0479 - mae: 0.0479 - root_mean_squared_error: 0.0627 - val_loss: 0.0538 - val_mae: 0.0538 - val_root_mean_squared_error: 0.0653\n",
      "Epoch 44/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0475 - mae: 0.0475 - root_mean_squared_error: 0.0619 - val_loss: 0.0430 - val_mae: 0.0430 - val_root_mean_squared_error: 0.0544\n",
      "Epoch 45/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0477 - mae: 0.0477 - root_mean_squared_error: 0.0624 - val_loss: 0.0582 - val_mae: 0.0582 - val_root_mean_squared_error: 0.0690\n",
      "Epoch 46/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0464 - mae: 0.0464 - root_mean_squared_error: 0.0608 - val_loss: 0.0578 - val_mae: 0.0578 - val_root_mean_squared_error: 0.0690\n",
      "Epoch 47/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0453 - mae: 0.0453 - root_mean_squared_error: 0.0592 - val_loss: 0.0602 - val_mae: 0.0602 - val_root_mean_squared_error: 0.0716\n",
      "Epoch 48/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0455 - mae: 0.0455 - root_mean_squared_error: 0.0595 - val_loss: 0.0641 - val_mae: 0.0641 - val_root_mean_squared_error: 0.0752\n",
      "Epoch 49/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0446 - mae: 0.0446 - root_mean_squared_error: 0.0585 - val_loss: 0.0663 - val_mae: 0.0663 - val_root_mean_squared_error: 0.0780\n",
      "Epoch 50/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0448 - mae: 0.0448 - root_mean_squared_error: 0.0583 - val_loss: 0.0545 - val_mae: 0.0545 - val_root_mean_squared_error: 0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:19:43 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:19:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:19:51 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:19:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: batch_size = 128 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.1970 - mae: 0.1970 - root_mean_squared_error: 0.2719 - val_loss: 0.0770 - val_mae: 0.0770 - val_root_mean_squared_error: 0.0852\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0746 - mae: 0.0746 - root_mean_squared_error: 0.0951 - val_loss: 0.0562 - val_mae: 0.0562 - val_root_mean_squared_error: 0.0658\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0638 - mae: 0.0638 - root_mean_squared_error: 0.0833 - val_loss: 0.0644 - val_mae: 0.0644 - val_root_mean_squared_error: 0.0733\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0602 - mae: 0.0602 - root_mean_squared_error: 0.0784 - val_loss: 0.0432 - val_mae: 0.0432 - val_root_mean_squared_error: 0.0538\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0575 - mae: 0.0575 - root_mean_squared_error: 0.0747 - val_loss: 0.0400 - val_mae: 0.0400 - val_root_mean_squared_error: 0.0508\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0555 - mae: 0.0555 - root_mean_squared_error: 0.0719 - val_loss: 0.0402 - val_mae: 0.0402 - val_root_mean_squared_error: 0.0510\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0551 - mae: 0.0551 - root_mean_squared_error: 0.0713 - val_loss: 0.0420 - val_mae: 0.0420 - val_root_mean_squared_error: 0.0529\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0569 - mae: 0.0569 - root_mean_squared_error: 0.0729 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0546\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0646 - mae: 0.0646 - root_mean_squared_error: 0.0825 - val_loss: 0.1185 - val_mae: 0.1185 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0673 - mae: 0.0673 - root_mean_squared_error: 0.0866 - val_loss: 0.1484 - val_mae: 0.1484 - val_root_mean_squared_error: 0.1552\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0842 - mae: 0.0842 - root_mean_squared_error: 0.1062 - val_loss: 0.0407 - val_mae: 0.0407 - val_root_mean_squared_error: 0.0519\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0684 - mae: 0.0684 - root_mean_squared_error: 0.0859 - val_loss: 0.0490 - val_mae: 0.0490 - val_root_mean_squared_error: 0.0603\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0592 - mae: 0.0592 - root_mean_squared_error: 0.0754 - val_loss: 0.0474 - val_mae: 0.0474 - val_root_mean_squared_error: 0.0585\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0565 - mae: 0.0565 - root_mean_squared_error: 0.0734 - val_loss: 0.0300 - val_mae: 0.0300 - val_root_mean_squared_error: 0.0406\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0599 - mae: 0.0599 - root_mean_squared_error: 0.0777 - val_loss: 0.0304 - val_mae: 0.0304 - val_root_mean_squared_error: 0.0400\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0647 - mae: 0.0647 - root_mean_squared_error: 0.0825 - val_loss: 0.0513 - val_mae: 0.0513 - val_root_mean_squared_error: 0.0598\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0835 - val_loss: 0.0476 - val_mae: 0.0476 - val_root_mean_squared_error: 0.0561\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0599 - mae: 0.0599 - root_mean_squared_error: 0.0762 - val_loss: 0.0315 - val_mae: 0.0315 - val_root_mean_squared_error: 0.0408\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0582 - mae: 0.0582 - root_mean_squared_error: 0.0745 - val_loss: 0.0369 - val_mae: 0.0369 - val_root_mean_squared_error: 0.0455\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0575 - mae: 0.0575 - root_mean_squared_error: 0.0739 - val_loss: 0.0370 - val_mae: 0.0370 - val_root_mean_squared_error: 0.0454\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0649 - mae: 0.0649 - root_mean_squared_error: 0.0829 - val_loss: 0.0568 - val_mae: 0.0568 - val_root_mean_squared_error: 0.0652\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0634 - mae: 0.0634 - root_mean_squared_error: 0.0807 - val_loss: 0.0352 - val_mae: 0.0352 - val_root_mean_squared_error: 0.0439\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0543 - mae: 0.0543 - root_mean_squared_error: 0.0702 - val_loss: 0.0319 - val_mae: 0.0319 - val_root_mean_squared_error: 0.0409\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0532 - mae: 0.0532 - root_mean_squared_error: 0.0686 - val_loss: 0.0346 - val_mae: 0.0346 - val_root_mean_squared_error: 0.0431\n",
      "Epoch 25/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0608 - mae: 0.0608 - root_mean_squared_error: 0.0779 - val_loss: 0.0580 - val_mae: 0.0580 - val_root_mean_squared_error: 0.0661\n",
      "Epoch 26/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0598 - mae: 0.0598 - root_mean_squared_error: 0.0760 - val_loss: 0.0453 - val_mae: 0.0453 - val_root_mean_squared_error: 0.0536\n",
      "Epoch 27/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0567 - mae: 0.0567 - root_mean_squared_error: 0.0732 - val_loss: 0.0424 - val_mae: 0.0424 - val_root_mean_squared_error: 0.0507\n",
      "Epoch 28/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0586 - mae: 0.0586 - root_mean_squared_error: 0.0750 - val_loss: 0.0454 - val_mae: 0.0454 - val_root_mean_squared_error: 0.0536\n",
      "Epoch 29/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0581 - mae: 0.0581 - root_mean_squared_error: 0.0747 - val_loss: 0.0406 - val_mae: 0.0406 - val_root_mean_squared_error: 0.0488\n",
      "Epoch 30/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0543 - mae: 0.0543 - root_mean_squared_error: 0.0697 - val_loss: 0.0469 - val_mae: 0.0469 - val_root_mean_squared_error: 0.0551\n",
      "Epoch 31/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0581 - mae: 0.0581 - root_mean_squared_error: 0.0745 - val_loss: 0.0557 - val_mae: 0.0557 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 32/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0602 - mae: 0.0602 - root_mean_squared_error: 0.0763 - val_loss: 0.0500 - val_mae: 0.0500 - val_root_mean_squared_error: 0.0581\n",
      "Epoch 33/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0551 - mae: 0.0551 - root_mean_squared_error: 0.0703 - val_loss: 0.0300 - val_mae: 0.0300 - val_root_mean_squared_error: 0.0390\n",
      "Epoch 34/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0542 - mae: 0.0542 - root_mean_squared_error: 0.0693 - val_loss: 0.0327 - val_mae: 0.0327 - val_root_mean_squared_error: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:20:29 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:20:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:20:36 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:20:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 19:20:57 INFO mlflow.tracking.fluent: Experiment with name 'lstm_learning_rate_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: learning_rate = 0.0001 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2513 - mae: 0.2513 - root_mean_squared_error: 0.3303 - val_loss: 0.1173 - val_mae: 0.1173 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0791 - mae: 0.0791 - root_mean_squared_error: 0.1013 - val_loss: 0.0952 - val_mae: 0.0952 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0728 - mae: 0.0728 - root_mean_squared_error: 0.0927 - val_loss: 0.0708 - val_mae: 0.0708 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0666 - mae: 0.0666 - root_mean_squared_error: 0.0847 - val_loss: 0.0542 - val_mae: 0.0542 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0633 - mae: 0.0633 - root_mean_squared_error: 0.0821 - val_loss: 0.0610 - val_mae: 0.0610 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0609 - mae: 0.0609 - root_mean_squared_error: 0.0786 - val_loss: 0.0493 - val_mae: 0.0493 - val_root_mean_squared_error: 0.0590\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0586 - mae: 0.0586 - root_mean_squared_error: 0.0761 - val_loss: 0.0369 - val_mae: 0.0369 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0586 - mae: 0.0586 - root_mean_squared_error: 0.0759 - val_loss: 0.0360 - val_mae: 0.0360 - val_root_mean_squared_error: 0.0463\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0557 - mae: 0.0557 - root_mean_squared_error: 0.0723 - val_loss: 0.0447 - val_mae: 0.0447 - val_root_mean_squared_error: 0.0546\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0555 - mae: 0.0555 - root_mean_squared_error: 0.0719 - val_loss: 0.0346 - val_mae: 0.0346 - val_root_mean_squared_error: 0.0448\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0538 - mae: 0.0538 - root_mean_squared_error: 0.0702 - val_loss: 0.0383 - val_mae: 0.0383 - val_root_mean_squared_error: 0.0483\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0530 - mae: 0.0530 - root_mean_squared_error: 0.0684 - val_loss: 0.0410 - val_mae: 0.0410 - val_root_mean_squared_error: 0.0509\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0530 - mae: 0.0530 - root_mean_squared_error: 0.0686 - val_loss: 0.0374 - val_mae: 0.0374 - val_root_mean_squared_error: 0.0474\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0522 - mae: 0.0522 - root_mean_squared_error: 0.0676 - val_loss: 0.0278 - val_mae: 0.0278 - val_root_mean_squared_error: 0.0375\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0526 - mae: 0.0526 - root_mean_squared_error: 0.0683 - val_loss: 0.0373 - val_mae: 0.0373 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0519 - mae: 0.0519 - root_mean_squared_error: 0.0672 - val_loss: 0.0389 - val_mae: 0.0389 - val_root_mean_squared_error: 0.0486\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0510 - mae: 0.0510 - root_mean_squared_error: 0.0661 - val_loss: 0.0426 - val_mae: 0.0426 - val_root_mean_squared_error: 0.0520\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0508 - mae: 0.0508 - root_mean_squared_error: 0.0664 - val_loss: 0.0303 - val_mae: 0.0303 - val_root_mean_squared_error: 0.0400\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0500 - mae: 0.0500 - root_mean_squared_error: 0.0654 - val_loss: 0.0408 - val_mae: 0.0408 - val_root_mean_squared_error: 0.0501\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0503 - mae: 0.0503 - root_mean_squared_error: 0.0652 - val_loss: 0.0355 - val_mae: 0.0355 - val_root_mean_squared_error: 0.0450\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0495 - mae: 0.0495 - root_mean_squared_error: 0.0637 - val_loss: 0.0523 - val_mae: 0.0523 - val_root_mean_squared_error: 0.0605\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0487 - mae: 0.0487 - root_mean_squared_error: 0.0633 - val_loss: 0.0429 - val_mae: 0.0429 - val_root_mean_squared_error: 0.0518\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0487 - mae: 0.0487 - root_mean_squared_error: 0.0632 - val_loss: 0.0317 - val_mae: 0.0317 - val_root_mean_squared_error: 0.0410\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0485 - mae: 0.0485 - root_mean_squared_error: 0.0629 - val_loss: 0.0512 - val_mae: 0.0512 - val_root_mean_squared_error: 0.0594\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0482 - mae: 0.0482 - root_mean_squared_error: 0.0632 - val_loss: 0.0303 - val_mae: 0.0303 - val_root_mean_squared_error: 0.0393\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0475 - mae: 0.0475 - root_mean_squared_error: 0.0617 - val_loss: 0.0498 - val_mae: 0.0498 - val_root_mean_squared_error: 0.0578\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0459 - mae: 0.0459 - root_mean_squared_error: 0.0597 - val_loss: 0.0423 - val_mae: 0.0423 - val_root_mean_squared_error: 0.0507\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0466 - mae: 0.0466 - root_mean_squared_error: 0.0607 - val_loss: 0.0267 - val_mae: 0.0267 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0461 - mae: 0.0461 - root_mean_squared_error: 0.0604 - val_loss: 0.0336 - val_mae: 0.0336 - val_root_mean_squared_error: 0.0420\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0461 - mae: 0.0461 - root_mean_squared_error: 0.0602 - val_loss: 0.0339 - val_mae: 0.0339 - val_root_mean_squared_error: 0.0419\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0441 - mae: 0.0441 - root_mean_squared_error: 0.0574 - val_loss: 0.0322 - val_mae: 0.0322 - val_root_mean_squared_error: 0.0403\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0458 - mae: 0.0458 - root_mean_squared_error: 0.0600 - val_loss: 0.0224 - val_mae: 0.0224 - val_root_mean_squared_error: 0.0300\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0445 - mae: 0.0445 - root_mean_squared_error: 0.0577 - val_loss: 0.0354 - val_mae: 0.0354 - val_root_mean_squared_error: 0.0426\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0441 - mae: 0.0441 - root_mean_squared_error: 0.0573 - val_loss: 0.0535 - val_mae: 0.0535 - val_root_mean_squared_error: 0.0597\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0439 - mae: 0.0439 - root_mean_squared_error: 0.0572 - val_loss: 0.0447 - val_mae: 0.0447 - val_root_mean_squared_error: 0.0518\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0429 - mae: 0.0429 - root_mean_squared_error: 0.0562 - val_loss: 0.0626 - val_mae: 0.0626 - val_root_mean_squared_error: 0.0683\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0435 - mae: 0.0435 - root_mean_squared_error: 0.0562 - val_loss: 0.0434 - val_mae: 0.0434 - val_root_mean_squared_error: 0.0499\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0565 - val_loss: 0.0214 - val_mae: 0.0214 - val_root_mean_squared_error: 0.0281\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0426 - mae: 0.0426 - root_mean_squared_error: 0.0558 - val_loss: 0.0333 - val_mae: 0.0333 - val_root_mean_squared_error: 0.0402\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0429 - mae: 0.0429 - root_mean_squared_error: 0.0560 - val_loss: 0.0268 - val_mae: 0.0268 - val_root_mean_squared_error: 0.0338\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0552 - val_loss: 0.0466 - val_mae: 0.0466 - val_root_mean_squared_error: 0.0530\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0426 - mae: 0.0426 - root_mean_squared_error: 0.0557 - val_loss: 0.0397 - val_mae: 0.0397 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0553 - val_loss: 0.0228 - val_mae: 0.0228 - val_root_mean_squared_error: 0.0292\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0412 - mae: 0.0412 - root_mean_squared_error: 0.0538 - val_loss: 0.0281 - val_mae: 0.0281 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0412 - mae: 0.0412 - root_mean_squared_error: 0.0538 - val_loss: 0.0415 - val_mae: 0.0415 - val_root_mean_squared_error: 0.0480\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0408 - mae: 0.0408 - root_mean_squared_error: 0.0536 - val_loss: 0.0282 - val_mae: 0.0282 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0529 - val_loss: 0.0204 - val_mae: 0.0204 - val_root_mean_squared_error: 0.0263\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0521 - val_loss: 0.0286 - val_mae: 0.0286 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0405 - mae: 0.0405 - root_mean_squared_error: 0.0528 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0316\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0512 - val_loss: 0.0424 - val_mae: 0.0424 - val_root_mean_squared_error: 0.0493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:21:41 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:21:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:21:49 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:21:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: learning_rate = 0.001 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0939 - mae: 0.0939 - root_mean_squared_error: 0.1429 - val_loss: 0.0597 - val_mae: 0.0597 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0663 - mae: 0.0663 - root_mean_squared_error: 0.0858 - val_loss: 0.0466 - val_mae: 0.0466 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0674 - mae: 0.0674 - root_mean_squared_error: 0.0866 - val_loss: 0.0569 - val_mae: 0.0569 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0662 - mae: 0.0662 - root_mean_squared_error: 0.0843 - val_loss: 0.0620 - val_mae: 0.0620 - val_root_mean_squared_error: 0.0740\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0647 - mae: 0.0647 - root_mean_squared_error: 0.0830 - val_loss: 0.0659 - val_mae: 0.0659 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0656 - mae: 0.0656 - root_mean_squared_error: 0.0833 - val_loss: 0.0851 - val_mae: 0.0851 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0632 - mae: 0.0632 - root_mean_squared_error: 0.0810 - val_loss: 0.0588 - val_mae: 0.0588 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0660 - mae: 0.0660 - root_mean_squared_error: 0.0839 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0642 - mae: 0.0642 - root_mean_squared_error: 0.0813 - val_loss: 0.0718 - val_mae: 0.0718 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0831 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0661 - mae: 0.0661 - root_mean_squared_error: 0.0834 - val_loss: 0.0678 - val_mae: 0.0678 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0651 - mae: 0.0651 - root_mean_squared_error: 0.0819 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0644 - mae: 0.0644 - root_mean_squared_error: 0.0809 - val_loss: 0.0639 - val_mae: 0.0639 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0645 - mae: 0.0645 - root_mean_squared_error: 0.0811 - val_loss: 0.0570 - val_mae: 0.0570 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0630 - mae: 0.0630 - root_mean_squared_error: 0.0795 - val_loss: 0.0691 - val_mae: 0.0691 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0622 - mae: 0.0622 - root_mean_squared_error: 0.0784 - val_loss: 0.0594 - val_mae: 0.0594 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0606 - mae: 0.0606 - root_mean_squared_error: 0.0765 - val_loss: 0.0660 - val_mae: 0.0660 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0600 - mae: 0.0600 - root_mean_squared_error: 0.0760 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0596 - mae: 0.0596 - root_mean_squared_error: 0.0757 - val_loss: 0.0666 - val_mae: 0.0666 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0744 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0746 - val_mae: 0.0746 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0629 - val_mae: 0.0629 - val_root_mean_squared_error: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:22:30 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:22:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:22:38 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:22:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: learning_rate = 0.01 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0893 - mae: 0.0893 - root_mean_squared_error: 0.1194 - val_loss: 0.0803 - val_mae: 0.0803 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1004 - mae: 0.1004 - root_mean_squared_error: 0.1287 - val_loss: 0.1320 - val_mae: 0.1320 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1023 - mae: 0.1023 - root_mean_squared_error: 0.1278 - val_loss: 0.1125 - val_mae: 0.1125 - val_root_mean_squared_error: 0.1306\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1073 - mae: 0.1073 - root_mean_squared_error: 0.1323 - val_loss: 0.1271 - val_mae: 0.1271 - val_root_mean_squared_error: 0.1454\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1157 - mae: 0.1157 - root_mean_squared_error: 0.1425 - val_loss: 0.1168 - val_mae: 0.1168 - val_root_mean_squared_error: 0.1353\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1108 - mae: 0.1108 - root_mean_squared_error: 0.1372 - val_loss: 0.1395 - val_mae: 0.1395 - val_root_mean_squared_error: 0.1577\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1123 - mae: 0.1123 - root_mean_squared_error: 0.1391 - val_loss: 0.1627 - val_mae: 0.1627 - val_root_mean_squared_error: 0.1791\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1056 - mae: 0.1056 - root_mean_squared_error: 0.1298 - val_loss: 0.1712 - val_mae: 0.1712 - val_root_mean_squared_error: 0.1869\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1027 - mae: 0.1027 - root_mean_squared_error: 0.1266 - val_loss: 0.1767 - val_mae: 0.1767 - val_root_mean_squared_error: 0.1917\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0998 - mae: 0.0998 - root_mean_squared_error: 0.1233 - val_loss: 0.1715 - val_mae: 0.1715 - val_root_mean_squared_error: 0.1866\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0966 - mae: 0.0966 - root_mean_squared_error: 0.1199 - val_loss: 0.1695 - val_mae: 0.1695 - val_root_mean_squared_error: 0.1845\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0919 - mae: 0.0919 - root_mean_squared_error: 0.1147 - val_loss: 0.1391 - val_mae: 0.1391 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0890 - mae: 0.0890 - root_mean_squared_error: 0.1118 - val_loss: 0.1608 - val_mae: 0.1608 - val_root_mean_squared_error: 0.1759\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0887 - mae: 0.0887 - root_mean_squared_error: 0.1102 - val_loss: 0.1668 - val_mae: 0.1668 - val_root_mean_squared_error: 0.1817\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0876 - mae: 0.0876 - root_mean_squared_error: 0.1087 - val_loss: 0.1855 - val_mae: 0.1855 - val_root_mean_squared_error: 0.1992\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0816 - mae: 0.0816 - root_mean_squared_error: 0.1026 - val_loss: 0.1222 - val_mae: 0.1222 - val_root_mean_squared_error: 0.1389\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0861 - mae: 0.0861 - root_mean_squared_error: 0.1082 - val_loss: 0.1350 - val_mae: 0.1350 - val_root_mean_squared_error: 0.1509\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0797 - mae: 0.0797 - root_mean_squared_error: 0.1019 - val_loss: 0.1167 - val_mae: 0.1167 - val_root_mean_squared_error: 0.1330\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0743 - mae: 0.0743 - root_mean_squared_error: 0.0963 - val_loss: 0.1116 - val_mae: 0.1116 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0752 - mae: 0.0752 - root_mean_squared_error: 0.0974 - val_loss: 0.1093 - val_mae: 0.1093 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0713 - mae: 0.0713 - root_mean_squared_error: 0.0923 - val_loss: 0.1135 - val_mae: 0.1135 - val_root_mean_squared_error: 0.1297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:23:18 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:23:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:23:26 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:23:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: learning_rate = 0.1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1384 - mae: 0.1384 - root_mean_squared_error: 0.4292 - val_loss: 0.1799 - val_mae: 0.1799 - val_root_mean_squared_error: 0.2010\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1320 - mae: 0.1320 - root_mean_squared_error: 0.1711 - val_loss: 0.1417 - val_mae: 0.1417 - val_root_mean_squared_error: 0.1639\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1337 - mae: 0.1337 - root_mean_squared_error: 0.1713 - val_loss: 0.1468 - val_mae: 0.1468 - val_root_mean_squared_error: 0.1689\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1305 - mae: 0.1305 - root_mean_squared_error: 0.1687 - val_loss: 0.1740 - val_mae: 0.1740 - val_root_mean_squared_error: 0.1954\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1300 - mae: 0.1300 - root_mean_squared_error: 0.1670 - val_loss: 0.1541 - val_mae: 0.1541 - val_root_mean_squared_error: 0.1760\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1318 - mae: 0.1318 - root_mean_squared_error: 0.1701 - val_loss: 0.1632 - val_mae: 0.1632 - val_root_mean_squared_error: 0.1849\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1329 - mae: 0.1329 - root_mean_squared_error: 0.1722 - val_loss: 0.1547 - val_mae: 0.1547 - val_root_mean_squared_error: 0.1766\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1324 - mae: 0.1324 - root_mean_squared_error: 0.1706 - val_loss: 0.1548 - val_mae: 0.1548 - val_root_mean_squared_error: 0.1767\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1317 - mae: 0.1317 - root_mean_squared_error: 0.1699 - val_loss: 0.1635 - val_mae: 0.1635 - val_root_mean_squared_error: 0.1852\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1323 - mae: 0.1323 - root_mean_squared_error: 0.1716 - val_loss: 0.1551 - val_mae: 0.1551 - val_root_mean_squared_error: 0.1770\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1337 - mae: 0.1337 - root_mean_squared_error: 0.1713 - val_loss: 0.1466 - val_mae: 0.1466 - val_root_mean_squared_error: 0.1687\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1320 - mae: 0.1320 - root_mean_squared_error: 0.1696 - val_loss: 0.1541 - val_mae: 0.1541 - val_root_mean_squared_error: 0.1761\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1340 - mae: 0.1340 - root_mean_squared_error: 0.1714 - val_loss: 0.1407 - val_mae: 0.1407 - val_root_mean_squared_error: 0.1629\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1289 - mae: 0.1289 - root_mean_squared_error: 0.1673 - val_loss: 0.1774 - val_mae: 0.1774 - val_root_mean_squared_error: 0.1986\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1306 - mae: 0.1306 - root_mean_squared_error: 0.1675 - val_loss: 0.1430 - val_mae: 0.1430 - val_root_mean_squared_error: 0.1652\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1334 - mae: 0.1334 - root_mean_squared_error: 0.1715 - val_loss: 0.1467 - val_mae: 0.1467 - val_root_mean_squared_error: 0.1688\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1317 - mae: 0.1317 - root_mean_squared_error: 0.1693 - val_loss: 0.1514 - val_mae: 0.1514 - val_root_mean_squared_error: 0.1734\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1326 - mae: 0.1326 - root_mean_squared_error: 0.1699 - val_loss: 0.1437 - val_mae: 0.1437 - val_root_mean_squared_error: 0.1659\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1322 - mae: 0.1322 - root_mean_squared_error: 0.1699 - val_loss: 0.1484 - val_mae: 0.1484 - val_root_mean_squared_error: 0.1705\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1311 - mae: 0.1311 - root_mean_squared_error: 0.1684 - val_loss: 0.1639 - val_mae: 0.1639 - val_root_mean_squared_error: 0.1855\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1327 - mae: 0.1327 - root_mean_squared_error: 0.1719 - val_loss: 0.1557 - val_mae: 0.1557 - val_root_mean_squared_error: 0.1776\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1313 - mae: 0.1313 - root_mean_squared_error: 0.1695 - val_loss: 0.1619 - val_mae: 0.1619 - val_root_mean_squared_error: 0.1836\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1337 - mae: 0.1337 - root_mean_squared_error: 0.1723 - val_loss: 0.1452 - val_mae: 0.1452 - val_root_mean_squared_error: 0.1673\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1324 - mae: 0.1324 - root_mean_squared_error: 0.1699 - val_loss: 0.1551 - val_mae: 0.1551 - val_root_mean_squared_error: 0.1770\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1322 - mae: 0.1322 - root_mean_squared_error: 0.1701 - val_loss: 0.1593 - val_mae: 0.1593 - val_root_mean_squared_error: 0.1811\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1320 - mae: 0.1320 - root_mean_squared_error: 0.1705 - val_loss: 0.1550 - val_mae: 0.1550 - val_root_mean_squared_error: 0.1769\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1337 - mae: 0.1337 - root_mean_squared_error: 0.1712 - val_loss: 0.1467 - val_mae: 0.1467 - val_root_mean_squared_error: 0.1689\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1299 - mae: 0.1299 - root_mean_squared_error: 0.1685 - val_loss: 0.1916 - val_mae: 0.1916 - val_root_mean_squared_error: 0.2119\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1301 - mae: 0.1301 - root_mean_squared_error: 0.1670 - val_loss: 0.1448 - val_mae: 0.1448 - val_root_mean_squared_error: 0.1669\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1316 - mae: 0.1316 - root_mean_squared_error: 0.1696 - val_loss: 0.1621 - val_mae: 0.1621 - val_root_mean_squared_error: 0.1838\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1337 - mae: 0.1337 - root_mean_squared_error: 0.1723 - val_loss: 0.1492 - val_mae: 0.1492 - val_root_mean_squared_error: 0.1713\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1314 - mae: 0.1314 - root_mean_squared_error: 0.1689 - val_loss: 0.1623 - val_mae: 0.1623 - val_root_mean_squared_error: 0.1840\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1338 - mae: 0.1338 - root_mean_squared_error: 0.1723 - val_loss: 0.1449 - val_mae: 0.1449 - val_root_mean_squared_error: 0.1670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:24:16 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:24:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:24:24 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:24:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 19:24:46 INFO mlflow.tracking.fluent: Experiment with name 'lstm_model_units_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: model_units = 10 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1192 - mae: 0.1192 - root_mean_squared_error: 0.1582 - val_loss: 0.1126 - val_mae: 0.1126 - val_root_mean_squared_error: 0.1241\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0929 - mae: 0.0929 - root_mean_squared_error: 0.1215 - val_loss: 0.1071 - val_mae: 0.1071 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0854 - mae: 0.0854 - root_mean_squared_error: 0.1114 - val_loss: 0.1251 - val_mae: 0.1251 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0818 - mae: 0.0818 - root_mean_squared_error: 0.1078 - val_loss: 0.1030 - val_mae: 0.1030 - val_root_mean_squared_error: 0.1140\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0802 - mae: 0.0802 - root_mean_squared_error: 0.1041 - val_loss: 0.1165 - val_mae: 0.1165 - val_root_mean_squared_error: 0.1266\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0767 - mae: 0.0767 - root_mean_squared_error: 0.0998 - val_loss: 0.1136 - val_mae: 0.1136 - val_root_mean_squared_error: 0.1238\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0767 - mae: 0.0767 - root_mean_squared_error: 0.0994 - val_loss: 0.1059 - val_mae: 0.1059 - val_root_mean_squared_error: 0.1163\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0743 - mae: 0.0743 - root_mean_squared_error: 0.0961 - val_loss: 0.0911 - val_mae: 0.0911 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0707 - mae: 0.0707 - root_mean_squared_error: 0.0918 - val_loss: 0.1046 - val_mae: 0.1046 - val_root_mean_squared_error: 0.1146\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0709 - mae: 0.0709 - root_mean_squared_error: 0.0922 - val_loss: 0.0861 - val_mae: 0.0861 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0686 - mae: 0.0686 - root_mean_squared_error: 0.0895 - val_loss: 0.1056 - val_mae: 0.1056 - val_root_mean_squared_error: 0.1155\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0673 - mae: 0.0673 - root_mean_squared_error: 0.0866 - val_loss: 0.0994 - val_mae: 0.0994 - val_root_mean_squared_error: 0.1097\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0665 - mae: 0.0665 - root_mean_squared_error: 0.0861 - val_loss: 0.0842 - val_mae: 0.0842 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0641 - mae: 0.0641 - root_mean_squared_error: 0.0831 - val_loss: 0.0897 - val_mae: 0.0897 - val_root_mean_squared_error: 0.1003\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0624 - mae: 0.0624 - root_mean_squared_error: 0.0808 - val_loss: 0.0885 - val_mae: 0.0885 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0611 - mae: 0.0611 - root_mean_squared_error: 0.0793 - val_loss: 0.0842 - val_mae: 0.0842 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0610 - mae: 0.0610 - root_mean_squared_error: 0.0793 - val_loss: 0.0685 - val_mae: 0.0685 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0593 - mae: 0.0593 - root_mean_squared_error: 0.0772 - val_loss: 0.0905 - val_mae: 0.0905 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0593 - mae: 0.0593 - root_mean_squared_error: 0.0774 - val_loss: 0.0883 - val_mae: 0.0883 - val_root_mean_squared_error: 0.0982\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0563 - mae: 0.0563 - root_mean_squared_error: 0.0737 - val_loss: 0.0793 - val_mae: 0.0793 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0561 - mae: 0.0561 - root_mean_squared_error: 0.0738 - val_loss: 0.0755 - val_mae: 0.0755 - val_root_mean_squared_error: 0.0862\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0554 - mae: 0.0554 - root_mean_squared_error: 0.0720 - val_loss: 0.0609 - val_mae: 0.0609 - val_root_mean_squared_error: 0.0721\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0542 - mae: 0.0542 - root_mean_squared_error: 0.0706 - val_loss: 0.0711 - val_mae: 0.0711 - val_root_mean_squared_error: 0.0819\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0542 - mae: 0.0542 - root_mean_squared_error: 0.0707 - val_loss: 0.0903 - val_mae: 0.0903 - val_root_mean_squared_error: 0.1002\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0525 - mae: 0.0525 - root_mean_squared_error: 0.0686 - val_loss: 0.0762 - val_mae: 0.0762 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0520 - mae: 0.0520 - root_mean_squared_error: 0.0680 - val_loss: 0.0670 - val_mae: 0.0670 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0517 - mae: 0.0517 - root_mean_squared_error: 0.0669 - val_loss: 0.0733 - val_mae: 0.0733 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0507 - mae: 0.0507 - root_mean_squared_error: 0.0666 - val_loss: 0.0613 - val_mae: 0.0613 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0494 - mae: 0.0494 - root_mean_squared_error: 0.0649 - val_loss: 0.0778 - val_mae: 0.0778 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0494 - mae: 0.0494 - root_mean_squared_error: 0.0647 - val_loss: 0.0606 - val_mae: 0.0606 - val_root_mean_squared_error: 0.0719\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0474 - mae: 0.0474 - root_mean_squared_error: 0.0623 - val_loss: 0.0747 - val_mae: 0.0747 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0468 - mae: 0.0468 - root_mean_squared_error: 0.0616 - val_loss: 0.0764 - val_mae: 0.0764 - val_root_mean_squared_error: 0.0885\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0458 - mae: 0.0458 - root_mean_squared_error: 0.0592 - val_loss: 0.1055 - val_mae: 0.1055 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0457 - mae: 0.0457 - root_mean_squared_error: 0.0598 - val_loss: 0.0941 - val_mae: 0.0941 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0447 - mae: 0.0447 - root_mean_squared_error: 0.0590 - val_loss: 0.0780 - val_mae: 0.0780 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0449 - mae: 0.0449 - root_mean_squared_error: 0.0588 - val_loss: 0.1137 - val_mae: 0.1137 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0446 - mae: 0.0446 - root_mean_squared_error: 0.0584 - val_loss: 0.1007 - val_mae: 0.1007 - val_root_mean_squared_error: 0.1139\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0559 - val_loss: 0.1188 - val_mae: 0.1188 - val_root_mean_squared_error: 0.1323\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0560 - val_loss: 0.1006 - val_mae: 0.1006 - val_root_mean_squared_error: 0.1158\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0423 - mae: 0.0423 - root_mean_squared_error: 0.0554 - val_loss: 0.1035 - val_mae: 0.1035 - val_root_mean_squared_error: 0.1186\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0426 - mae: 0.0426 - root_mean_squared_error: 0.0554 - val_loss: 0.0954 - val_mae: 0.0954 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0425 - mae: 0.0425 - root_mean_squared_error: 0.0565 - val_loss: 0.1155 - val_mae: 0.1155 - val_root_mean_squared_error: 0.1300\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0560 - val_loss: 0.1063 - val_mae: 0.1063 - val_root_mean_squared_error: 0.1203\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0415 - mae: 0.0415 - root_mean_squared_error: 0.0552 - val_loss: 0.1257 - val_mae: 0.1257 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0416 - mae: 0.0416 - root_mean_squared_error: 0.0554 - val_loss: 0.1259 - val_mae: 0.1259 - val_root_mean_squared_error: 0.1395\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0409 - mae: 0.0409 - root_mean_squared_error: 0.0548 - val_loss: 0.1249 - val_mae: 0.1249 - val_root_mean_squared_error: 0.1399\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0408 - mae: 0.0408 - root_mean_squared_error: 0.0544 - val_loss: 0.1044 - val_mae: 0.1044 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0531 - val_loss: 0.1080 - val_mae: 0.1080 - val_root_mean_squared_error: 0.1228\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0515 - val_loss: 0.1169 - val_mae: 0.1169 - val_root_mean_squared_error: 0.1325\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0512 - val_loss: 0.1065 - val_mae: 0.1065 - val_root_mean_squared_error: 0.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:25:19 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:25:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:25:27 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:25:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: model_units = 50 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0939 - mae: 0.0939 - root_mean_squared_error: 0.1429 - val_loss: 0.0597 - val_mae: 0.0597 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0663 - mae: 0.0663 - root_mean_squared_error: 0.0858 - val_loss: 0.0466 - val_mae: 0.0466 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0674 - mae: 0.0674 - root_mean_squared_error: 0.0866 - val_loss: 0.0569 - val_mae: 0.0569 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0662 - mae: 0.0662 - root_mean_squared_error: 0.0843 - val_loss: 0.0620 - val_mae: 0.0620 - val_root_mean_squared_error: 0.0740\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0647 - mae: 0.0647 - root_mean_squared_error: 0.0830 - val_loss: 0.0659 - val_mae: 0.0659 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0656 - mae: 0.0656 - root_mean_squared_error: 0.0833 - val_loss: 0.0851 - val_mae: 0.0851 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0632 - mae: 0.0632 - root_mean_squared_error: 0.0810 - val_loss: 0.0588 - val_mae: 0.0588 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0660 - mae: 0.0660 - root_mean_squared_error: 0.0839 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0642 - mae: 0.0642 - root_mean_squared_error: 0.0813 - val_loss: 0.0718 - val_mae: 0.0718 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0831 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0661 - mae: 0.0661 - root_mean_squared_error: 0.0834 - val_loss: 0.0678 - val_mae: 0.0678 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0651 - mae: 0.0651 - root_mean_squared_error: 0.0819 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0644 - mae: 0.0644 - root_mean_squared_error: 0.0809 - val_loss: 0.0639 - val_mae: 0.0639 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0645 - mae: 0.0645 - root_mean_squared_error: 0.0811 - val_loss: 0.0570 - val_mae: 0.0570 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0630 - mae: 0.0630 - root_mean_squared_error: 0.0795 - val_loss: 0.0691 - val_mae: 0.0691 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0622 - mae: 0.0622 - root_mean_squared_error: 0.0784 - val_loss: 0.0594 - val_mae: 0.0594 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0606 - mae: 0.0606 - root_mean_squared_error: 0.0765 - val_loss: 0.0660 - val_mae: 0.0660 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0600 - mae: 0.0600 - root_mean_squared_error: 0.0760 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0596 - mae: 0.0596 - root_mean_squared_error: 0.0757 - val_loss: 0.0666 - val_mae: 0.0666 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0744 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0746 - val_mae: 0.0746 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0629 - val_mae: 0.0629 - val_root_mean_squared_error: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:26:09 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:26:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:26:16 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:26:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: model_units = 100 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0808 - mae: 0.0808 - root_mean_squared_error: 0.1275 - val_loss: 0.0659 - val_mae: 0.0659 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0559 - mae: 0.0559 - root_mean_squared_error: 0.0716 - val_loss: 0.0698 - val_mae: 0.0698 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0601 - mae: 0.0601 - root_mean_squared_error: 0.0778 - val_loss: 0.0403 - val_mae: 0.0403 - val_root_mean_squared_error: 0.0507\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0662 - mae: 0.0662 - root_mean_squared_error: 0.0856 - val_loss: 0.0572 - val_mae: 0.0572 - val_root_mean_squared_error: 0.0691\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0629 - mae: 0.0629 - root_mean_squared_error: 0.0810 - val_loss: 0.0520 - val_mae: 0.0520 - val_root_mean_squared_error: 0.0635\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0839 - val_loss: 0.0570 - val_mae: 0.0570 - val_root_mean_squared_error: 0.0689\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0630 - mae: 0.0630 - root_mean_squared_error: 0.0805 - val_loss: 0.0612 - val_mae: 0.0612 - val_root_mean_squared_error: 0.0734\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0632 - mae: 0.0632 - root_mean_squared_error: 0.0808 - val_loss: 0.0713 - val_mae: 0.0713 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0645 - mae: 0.0645 - root_mean_squared_error: 0.0818 - val_loss: 0.0639 - val_mae: 0.0639 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0654 - mae: 0.0654 - root_mean_squared_error: 0.0828 - val_loss: 0.0782 - val_mae: 0.0782 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0639 - mae: 0.0639 - root_mean_squared_error: 0.0806 - val_loss: 0.0682 - val_mae: 0.0682 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0660 - mae: 0.0660 - root_mean_squared_error: 0.0830 - val_loss: 0.0798 - val_mae: 0.0798 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0644 - mae: 0.0644 - root_mean_squared_error: 0.0809 - val_loss: 0.0784 - val_mae: 0.0784 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0672 - mae: 0.0672 - root_mean_squared_error: 0.0841 - val_loss: 0.0714 - val_mae: 0.0714 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0643 - mae: 0.0643 - root_mean_squared_error: 0.0810 - val_loss: 0.0756 - val_mae: 0.0756 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0638 - mae: 0.0638 - root_mean_squared_error: 0.0800 - val_loss: 0.0681 - val_mae: 0.0681 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0627 - mae: 0.0627 - root_mean_squared_error: 0.0790 - val_loss: 0.0653 - val_mae: 0.0653 - val_root_mean_squared_error: 0.0778\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0631 - mae: 0.0631 - root_mean_squared_error: 0.0792 - val_loss: 0.0616 - val_mae: 0.0616 - val_root_mean_squared_error: 0.0739\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0631 - mae: 0.0631 - root_mean_squared_error: 0.0796 - val_loss: 0.0713 - val_mae: 0.0713 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0589 - mae: 0.0589 - root_mean_squared_error: 0.0747 - val_loss: 0.0620 - val_mae: 0.0620 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0594 - mae: 0.0594 - root_mean_squared_error: 0.0749 - val_loss: 0.0609 - val_mae: 0.0609 - val_root_mean_squared_error: 0.0732\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0586 - mae: 0.0586 - root_mean_squared_error: 0.0741 - val_loss: 0.0640 - val_mae: 0.0640 - val_root_mean_squared_error: 0.0764\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0737 - val_loss: 0.0621 - val_mae: 0.0621 - val_root_mean_squared_error: 0.0744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:27:07 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:27:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:27:14 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:27:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: model_units = 200 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0780 - mae: 0.0780 - root_mean_squared_error: 0.1168 - val_loss: 0.1165 - val_mae: 0.1165 - val_root_mean_squared_error: 0.1247\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0520 - mae: 0.0520 - root_mean_squared_error: 0.0674 - val_loss: 0.1026 - val_mae: 0.1026 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0546 - mae: 0.0546 - root_mean_squared_error: 0.0709 - val_loss: 0.1118 - val_mae: 0.1118 - val_root_mean_squared_error: 0.1222\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0589 - mae: 0.0589 - root_mean_squared_error: 0.0768 - val_loss: 0.0425 - val_mae: 0.0425 - val_root_mean_squared_error: 0.0529\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0709 - mae: 0.0709 - root_mean_squared_error: 0.0912 - val_loss: 0.0672 - val_mae: 0.0672 - val_root_mean_squared_error: 0.0798\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0690 - mae: 0.0690 - root_mean_squared_error: 0.0880 - val_loss: 0.0750 - val_mae: 0.0750 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0651 - mae: 0.0651 - root_mean_squared_error: 0.0827 - val_loss: 0.0655 - val_mae: 0.0655 - val_root_mean_squared_error: 0.0779\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0660 - mae: 0.0660 - root_mean_squared_error: 0.0847 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0830\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0660 - mae: 0.0660 - root_mean_squared_error: 0.0839 - val_loss: 0.0627 - val_mae: 0.0627 - val_root_mean_squared_error: 0.0748\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0656 - mae: 0.0656 - root_mean_squared_error: 0.0834 - val_loss: 0.0735 - val_mae: 0.0735 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0828 - val_loss: 0.0793 - val_mae: 0.0793 - val_root_mean_squared_error: 0.0927\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0665 - mae: 0.0665 - root_mean_squared_error: 0.0843 - val_loss: 0.0847 - val_mae: 0.0847 - val_root_mean_squared_error: 0.0981\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0667 - mae: 0.0667 - root_mean_squared_error: 0.0840 - val_loss: 0.0827 - val_mae: 0.0827 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0663 - mae: 0.0663 - root_mean_squared_error: 0.0834 - val_loss: 0.0807 - val_mae: 0.0807 - val_root_mean_squared_error: 0.0942\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0671 - mae: 0.0671 - root_mean_squared_error: 0.0843 - val_loss: 0.0821 - val_mae: 0.0821 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0659 - mae: 0.0659 - root_mean_squared_error: 0.0826 - val_loss: 0.0788 - val_mae: 0.0788 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0651 - mae: 0.0651 - root_mean_squared_error: 0.0814 - val_loss: 0.0831 - val_mae: 0.0831 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0641 - mae: 0.0641 - root_mean_squared_error: 0.0806 - val_loss: 0.0753 - val_mae: 0.0753 - val_root_mean_squared_error: 0.0885\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0625 - mae: 0.0625 - root_mean_squared_error: 0.0789 - val_loss: 0.0798 - val_mae: 0.0798 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0608 - mae: 0.0608 - root_mean_squared_error: 0.0765 - val_loss: 0.0725 - val_mae: 0.0725 - val_root_mean_squared_error: 0.0855\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0618 - mae: 0.0618 - root_mean_squared_error: 0.0779 - val_loss: 0.0777 - val_mae: 0.0777 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0604 - mae: 0.0604 - root_mean_squared_error: 0.0765 - val_loss: 0.0758 - val_mae: 0.0758 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0600 - mae: 0.0600 - root_mean_squared_error: 0.0756 - val_loss: 0.0797 - val_mae: 0.0797 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0582 - mae: 0.0582 - root_mean_squared_error: 0.0737 - val_loss: 0.0716 - val_mae: 0.0716 - val_root_mean_squared_error: 0.0845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:28:28 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:28:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:28:36 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:28:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 19:28:58 INFO mlflow.tracking.fluent: Experiment with name 'lstm_dropout_rate_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: dropout_rate = 0 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0733 - mae: 0.0733 - root_mean_squared_error: 0.1302 - val_loss: 0.0881 - val_mae: 0.0881 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0458 - mae: 0.0458 - root_mean_squared_error: 0.0608 - val_loss: 0.0638 - val_mae: 0.0638 - val_root_mean_squared_error: 0.0758\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0519 - mae: 0.0519 - root_mean_squared_error: 0.0678 - val_loss: 0.0597 - val_mae: 0.0597 - val_root_mean_squared_error: 0.0714\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0524 - mae: 0.0524 - root_mean_squared_error: 0.0677 - val_loss: 0.0590 - val_mae: 0.0590 - val_root_mean_squared_error: 0.0706\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0508 - mae: 0.0508 - root_mean_squared_error: 0.0657 - val_loss: 0.0622 - val_mae: 0.0622 - val_root_mean_squared_error: 0.0741\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0501 - mae: 0.0501 - root_mean_squared_error: 0.0646 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0738\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0493 - mae: 0.0493 - root_mean_squared_error: 0.0637 - val_loss: 0.0618 - val_mae: 0.0618 - val_root_mean_squared_error: 0.0737\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0486 - mae: 0.0486 - root_mean_squared_error: 0.0629 - val_loss: 0.0642 - val_mae: 0.0642 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0476 - mae: 0.0476 - root_mean_squared_error: 0.0617 - val_loss: 0.0621 - val_mae: 0.0621 - val_root_mean_squared_error: 0.0740\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0468 - mae: 0.0468 - root_mean_squared_error: 0.0608 - val_loss: 0.0615 - val_mae: 0.0615 - val_root_mean_squared_error: 0.0733\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0460 - mae: 0.0460 - root_mean_squared_error: 0.0600 - val_loss: 0.0637 - val_mae: 0.0637 - val_root_mean_squared_error: 0.0757\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0451 - mae: 0.0451 - root_mean_squared_error: 0.0590 - val_loss: 0.0632 - val_mae: 0.0632 - val_root_mean_squared_error: 0.0751\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0445 - mae: 0.0445 - root_mean_squared_error: 0.0582 - val_loss: 0.0596 - val_mae: 0.0596 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0571 - val_loss: 0.0640 - val_mae: 0.0640 - val_root_mean_squared_error: 0.0759\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0417 - mae: 0.0417 - root_mean_squared_error: 0.0551 - val_loss: 0.0620 - val_mae: 0.0620 - val_root_mean_squared_error: 0.0737\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0410 - mae: 0.0410 - root_mean_squared_error: 0.0537 - val_loss: 0.0618 - val_mae: 0.0618 - val_root_mean_squared_error: 0.0735\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0422 - mae: 0.0422 - root_mean_squared_error: 0.0553 - val_loss: 0.0599 - val_mae: 0.0599 - val_root_mean_squared_error: 0.0715\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0393 - mae: 0.0393 - root_mean_squared_error: 0.0524 - val_loss: 0.0661 - val_mae: 0.0661 - val_root_mean_squared_error: 0.0777\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0405 - mae: 0.0405 - root_mean_squared_error: 0.0534 - val_loss: 0.0644 - val_mae: 0.0644 - val_root_mean_squared_error: 0.0761\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0533 - val_loss: 0.0659 - val_mae: 0.0659 - val_root_mean_squared_error: 0.0778\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0511 - val_loss: 0.0726 - val_mae: 0.0726 - val_root_mean_squared_error: 0.0848\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0495 - val_loss: 0.0674 - val_mae: 0.0674 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0467 - val_loss: 0.0737 - val_mae: 0.0737 - val_root_mean_squared_error: 0.0862\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0462 - val_loss: 0.0669 - val_mae: 0.0669 - val_root_mean_squared_error: 0.0794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:29:19 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:29:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:29:27 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:29:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: dropout_rate = 0.2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0939 - mae: 0.0939 - root_mean_squared_error: 0.1429 - val_loss: 0.0597 - val_mae: 0.0597 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0663 - mae: 0.0663 - root_mean_squared_error: 0.0858 - val_loss: 0.0466 - val_mae: 0.0466 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0674 - mae: 0.0674 - root_mean_squared_error: 0.0866 - val_loss: 0.0569 - val_mae: 0.0569 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0662 - mae: 0.0662 - root_mean_squared_error: 0.0843 - val_loss: 0.0620 - val_mae: 0.0620 - val_root_mean_squared_error: 0.0740\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0647 - mae: 0.0647 - root_mean_squared_error: 0.0830 - val_loss: 0.0659 - val_mae: 0.0659 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0656 - mae: 0.0656 - root_mean_squared_error: 0.0833 - val_loss: 0.0851 - val_mae: 0.0851 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0632 - mae: 0.0632 - root_mean_squared_error: 0.0810 - val_loss: 0.0588 - val_mae: 0.0588 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0660 - mae: 0.0660 - root_mean_squared_error: 0.0839 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0642 - mae: 0.0642 - root_mean_squared_error: 0.0813 - val_loss: 0.0718 - val_mae: 0.0718 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0831 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0661 - mae: 0.0661 - root_mean_squared_error: 0.0834 - val_loss: 0.0678 - val_mae: 0.0678 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0651 - mae: 0.0651 - root_mean_squared_error: 0.0819 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0644 - mae: 0.0644 - root_mean_squared_error: 0.0809 - val_loss: 0.0639 - val_mae: 0.0639 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0645 - mae: 0.0645 - root_mean_squared_error: 0.0811 - val_loss: 0.0570 - val_mae: 0.0570 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0630 - mae: 0.0630 - root_mean_squared_error: 0.0795 - val_loss: 0.0691 - val_mae: 0.0691 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0622 - mae: 0.0622 - root_mean_squared_error: 0.0784 - val_loss: 0.0594 - val_mae: 0.0594 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0606 - mae: 0.0606 - root_mean_squared_error: 0.0765 - val_loss: 0.0660 - val_mae: 0.0660 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0600 - mae: 0.0600 - root_mean_squared_error: 0.0760 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0596 - mae: 0.0596 - root_mean_squared_error: 0.0757 - val_loss: 0.0666 - val_mae: 0.0666 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0744 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0746 - val_mae: 0.0746 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0629 - val_mae: 0.0629 - val_root_mean_squared_error: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:30:09 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:30:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:30:17 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:30:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: dropout_rate = 0.5 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1245 - mae: 0.1245 - root_mean_squared_error: 0.1759 - val_loss: 0.1019 - val_mae: 0.1019 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0888 - mae: 0.0888 - root_mean_squared_error: 0.1152 - val_loss: 0.0821 - val_mae: 0.0821 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0860 - mae: 0.0860 - root_mean_squared_error: 0.1116 - val_loss: 0.0525 - val_mae: 0.0525 - val_root_mean_squared_error: 0.0641\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0849 - mae: 0.0849 - root_mean_squared_error: 0.1097 - val_loss: 0.0993 - val_mae: 0.0993 - val_root_mean_squared_error: 0.1103\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0797 - mae: 0.0797 - root_mean_squared_error: 0.1024 - val_loss: 0.0961 - val_mae: 0.0961 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0830 - mae: 0.0830 - root_mean_squared_error: 0.1061 - val_loss: 0.0919 - val_mae: 0.0919 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0826 - mae: 0.0826 - root_mean_squared_error: 0.1046 - val_loss: 0.0696 - val_mae: 0.0696 - val_root_mean_squared_error: 0.0822\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0847 - mae: 0.0847 - root_mean_squared_error: 0.1069 - val_loss: 0.0685 - val_mae: 0.0685 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0815 - mae: 0.0815 - root_mean_squared_error: 0.1025 - val_loss: 0.0747 - val_mae: 0.0747 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0794 - mae: 0.0794 - root_mean_squared_error: 0.0997 - val_loss: 0.0614 - val_mae: 0.0614 - val_root_mean_squared_error: 0.0739\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0764 - mae: 0.0764 - root_mean_squared_error: 0.0967 - val_loss: 0.0613 - val_mae: 0.0613 - val_root_mean_squared_error: 0.0738\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0736 - mae: 0.0736 - root_mean_squared_error: 0.0941 - val_loss: 0.0676 - val_mae: 0.0676 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0716 - mae: 0.0716 - root_mean_squared_error: 0.0910 - val_loss: 0.0621 - val_mae: 0.0621 - val_root_mean_squared_error: 0.0746\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0687 - mae: 0.0687 - root_mean_squared_error: 0.0881 - val_loss: 0.0694 - val_mae: 0.0694 - val_root_mean_squared_error: 0.0819\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0676 - mae: 0.0676 - root_mean_squared_error: 0.0864 - val_loss: 0.0716 - val_mae: 0.0716 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0657 - mae: 0.0657 - root_mean_squared_error: 0.0847 - val_loss: 0.0724 - val_mae: 0.0724 - val_root_mean_squared_error: 0.0848\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0654 - mae: 0.0654 - root_mean_squared_error: 0.0835 - val_loss: 0.0713 - val_mae: 0.0713 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0630 - mae: 0.0630 - root_mean_squared_error: 0.0812 - val_loss: 0.0676 - val_mae: 0.0676 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0630 - mae: 0.0630 - root_mean_squared_error: 0.0816 - val_loss: 0.0739 - val_mae: 0.0739 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0605 - mae: 0.0605 - root_mean_squared_error: 0.0783 - val_loss: 0.0768 - val_mae: 0.0768 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0613 - mae: 0.0613 - root_mean_squared_error: 0.0792 - val_loss: 0.0713 - val_mae: 0.0713 - val_root_mean_squared_error: 0.0835\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0617 - mae: 0.0617 - root_mean_squared_error: 0.0794 - val_loss: 0.0669 - val_mae: 0.0669 - val_root_mean_squared_error: 0.0794\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0610 - mae: 0.0610 - root_mean_squared_error: 0.0784 - val_loss: 0.0697 - val_mae: 0.0697 - val_root_mean_squared_error: 0.0819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:31:01 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:31:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:31:11 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:31:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: dropout_rate = 0.8 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1836 - mae: 0.1836 - root_mean_squared_error: 0.2485 - val_loss: 0.1669 - val_mae: 0.1669 - val_root_mean_squared_error: 0.1747\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1316 - mae: 0.1316 - root_mean_squared_error: 0.1735 - val_loss: 0.1253 - val_mae: 0.1253 - val_root_mean_squared_error: 0.1356\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1215 - mae: 0.1215 - root_mean_squared_error: 0.1597 - val_loss: 0.1612 - val_mae: 0.1612 - val_root_mean_squared_error: 0.1700\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1193 - mae: 0.1193 - root_mean_squared_error: 0.1554 - val_loss: 0.1083 - val_mae: 0.1083 - val_root_mean_squared_error: 0.1197\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1150 - mae: 0.1150 - root_mean_squared_error: 0.1481 - val_loss: 0.1317 - val_mae: 0.1317 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1116 - mae: 0.1116 - root_mean_squared_error: 0.1426 - val_loss: 0.1155 - val_mae: 0.1155 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1030 - mae: 0.1030 - root_mean_squared_error: 0.1326 - val_loss: 0.1157 - val_mae: 0.1157 - val_root_mean_squared_error: 0.1261\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0978 - mae: 0.0978 - root_mean_squared_error: 0.1254 - val_loss: 0.1497 - val_mae: 0.1497 - val_root_mean_squared_error: 0.1586\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0895 - mae: 0.0895 - root_mean_squared_error: 0.1156 - val_loss: 0.1060 - val_mae: 0.1060 - val_root_mean_squared_error: 0.1172\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0854 - mae: 0.0854 - root_mean_squared_error: 0.1100 - val_loss: 0.1202 - val_mae: 0.1202 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0791 - mae: 0.0791 - root_mean_squared_error: 0.1036 - val_loss: 0.0755 - val_mae: 0.0755 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0770 - mae: 0.0770 - root_mean_squared_error: 0.1017 - val_loss: 0.1230 - val_mae: 0.1230 - val_root_mean_squared_error: 0.1339\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0728 - mae: 0.0728 - root_mean_squared_error: 0.0961 - val_loss: 0.0680 - val_mae: 0.0680 - val_root_mean_squared_error: 0.0782\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0700 - mae: 0.0700 - root_mean_squared_error: 0.0925 - val_loss: 0.0744 - val_mae: 0.0744 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0695 - mae: 0.0695 - root_mean_squared_error: 0.0916 - val_loss: 0.0405 - val_mae: 0.0405 - val_root_mean_squared_error: 0.0499\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0652 - mae: 0.0652 - root_mean_squared_error: 0.0860 - val_loss: 0.0791 - val_mae: 0.0791 - val_root_mean_squared_error: 0.0882\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0622 - mae: 0.0622 - root_mean_squared_error: 0.0817 - val_loss: 0.0916 - val_mae: 0.0916 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0604 - mae: 0.0604 - root_mean_squared_error: 0.0800 - val_loss: 0.0715 - val_mae: 0.0715 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0593 - mae: 0.0593 - root_mean_squared_error: 0.0793 - val_loss: 0.0571 - val_mae: 0.0571 - val_root_mean_squared_error: 0.0663\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0599 - mae: 0.0599 - root_mean_squared_error: 0.0798 - val_loss: 0.0610 - val_mae: 0.0610 - val_root_mean_squared_error: 0.0688\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0561 - mae: 0.0561 - root_mean_squared_error: 0.0760 - val_loss: 0.0659 - val_mae: 0.0659 - val_root_mean_squared_error: 0.0730\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0606 - mae: 0.0606 - root_mean_squared_error: 0.0810 - val_loss: 0.0527 - val_mae: 0.0527 - val_root_mean_squared_error: 0.0620\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0565 - mae: 0.0565 - root_mean_squared_error: 0.0766 - val_loss: 0.0491 - val_mae: 0.0491 - val_root_mean_squared_error: 0.0587\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0791 - val_loss: 0.0639 - val_mae: 0.0639 - val_root_mean_squared_error: 0.0735\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0575 - mae: 0.0575 - root_mean_squared_error: 0.0780 - val_loss: 0.0501 - val_mae: 0.0501 - val_root_mean_squared_error: 0.0591\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0569 - mae: 0.0569 - root_mean_squared_error: 0.0771 - val_loss: 0.0675 - val_mae: 0.0675 - val_root_mean_squared_error: 0.0757\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0565 - mae: 0.0565 - root_mean_squared_error: 0.0772 - val_loss: 0.0222 - val_mae: 0.0222 - val_root_mean_squared_error: 0.0286\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0561 - mae: 0.0561 - root_mean_squared_error: 0.0771 - val_loss: 0.1118 - val_mae: 0.1118 - val_root_mean_squared_error: 0.1193\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0542 - mae: 0.0542 - root_mean_squared_error: 0.0749 - val_loss: 0.0472 - val_mae: 0.0472 - val_root_mean_squared_error: 0.0564\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0618 - mae: 0.0618 - root_mean_squared_error: 0.0835 - val_loss: 0.1224 - val_mae: 0.1224 - val_root_mean_squared_error: 0.1338\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0852 - val_loss: 0.0493 - val_mae: 0.0493 - val_root_mean_squared_error: 0.0584\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0566 - mae: 0.0566 - root_mean_squared_error: 0.0781 - val_loss: 0.0450 - val_mae: 0.0450 - val_root_mean_squared_error: 0.0545\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0576 - mae: 0.0576 - root_mean_squared_error: 0.0785 - val_loss: 0.0695 - val_mae: 0.0695 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0547 - mae: 0.0547 - root_mean_squared_error: 0.0749 - val_loss: 0.0701 - val_mae: 0.0701 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0544 - mae: 0.0544 - root_mean_squared_error: 0.0750 - val_loss: 0.0647 - val_mae: 0.0647 - val_root_mean_squared_error: 0.0731\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0557 - mae: 0.0557 - root_mean_squared_error: 0.0759 - val_loss: 0.0952 - val_mae: 0.0952 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0542 - mae: 0.0542 - root_mean_squared_error: 0.0746 - val_loss: 0.0493 - val_mae: 0.0493 - val_root_mean_squared_error: 0.0596\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0563 - mae: 0.0563 - root_mean_squared_error: 0.0770 - val_loss: 0.0379 - val_mae: 0.0379 - val_root_mean_squared_error: 0.0465\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0602 - mae: 0.0602 - root_mean_squared_error: 0.0818 - val_loss: 0.0497 - val_mae: 0.0497 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0592 - mae: 0.0592 - root_mean_squared_error: 0.0805 - val_loss: 0.0488 - val_mae: 0.0488 - val_root_mean_squared_error: 0.0580\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0560 - mae: 0.0560 - root_mean_squared_error: 0.0774 - val_loss: 0.0775 - val_mae: 0.0775 - val_root_mean_squared_error: 0.0888\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0554 - mae: 0.0554 - root_mean_squared_error: 0.0773 - val_loss: 0.0800 - val_mae: 0.0800 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0558 - mae: 0.0558 - root_mean_squared_error: 0.0771 - val_loss: 0.0343 - val_mae: 0.0343 - val_root_mean_squared_error: 0.0425\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0563 - mae: 0.0563 - root_mean_squared_error: 0.0764 - val_loss: 0.0369 - val_mae: 0.0369 - val_root_mean_squared_error: 0.0448\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0567 - mae: 0.0567 - root_mean_squared_error: 0.0784 - val_loss: 0.0480 - val_mae: 0.0480 - val_root_mean_squared_error: 0.0582\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0542 - mae: 0.0542 - root_mean_squared_error: 0.0754 - val_loss: 0.0357 - val_mae: 0.0357 - val_root_mean_squared_error: 0.0452\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0564 - mae: 0.0564 - root_mean_squared_error: 0.0790 - val_loss: 0.0993 - val_mae: 0.0993 - val_root_mean_squared_error: 0.1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:32:15 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:32:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:32:24 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:32:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 19:32:46 INFO mlflow.tracking.fluent: Experiment with name 'lstm_number_of_layer_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: number_of_layer = 1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0939 - mae: 0.0939 - root_mean_squared_error: 0.1429 - val_loss: 0.0597 - val_mae: 0.0597 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0663 - mae: 0.0663 - root_mean_squared_error: 0.0858 - val_loss: 0.0466 - val_mae: 0.0466 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0674 - mae: 0.0674 - root_mean_squared_error: 0.0866 - val_loss: 0.0569 - val_mae: 0.0569 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0662 - mae: 0.0662 - root_mean_squared_error: 0.0843 - val_loss: 0.0620 - val_mae: 0.0620 - val_root_mean_squared_error: 0.0740\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0647 - mae: 0.0647 - root_mean_squared_error: 0.0830 - val_loss: 0.0659 - val_mae: 0.0659 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0656 - mae: 0.0656 - root_mean_squared_error: 0.0833 - val_loss: 0.0851 - val_mae: 0.0851 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0632 - mae: 0.0632 - root_mean_squared_error: 0.0810 - val_loss: 0.0588 - val_mae: 0.0588 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0660 - mae: 0.0660 - root_mean_squared_error: 0.0839 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0642 - mae: 0.0642 - root_mean_squared_error: 0.0813 - val_loss: 0.0718 - val_mae: 0.0718 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0831 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0661 - mae: 0.0661 - root_mean_squared_error: 0.0834 - val_loss: 0.0678 - val_mae: 0.0678 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0651 - mae: 0.0651 - root_mean_squared_error: 0.0819 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0644 - mae: 0.0644 - root_mean_squared_error: 0.0809 - val_loss: 0.0639 - val_mae: 0.0639 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0645 - mae: 0.0645 - root_mean_squared_error: 0.0811 - val_loss: 0.0570 - val_mae: 0.0570 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0630 - mae: 0.0630 - root_mean_squared_error: 0.0795 - val_loss: 0.0691 - val_mae: 0.0691 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0622 - mae: 0.0622 - root_mean_squared_error: 0.0784 - val_loss: 0.0594 - val_mae: 0.0594 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0606 - mae: 0.0606 - root_mean_squared_error: 0.0765 - val_loss: 0.0660 - val_mae: 0.0660 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0600 - mae: 0.0600 - root_mean_squared_error: 0.0760 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0596 - mae: 0.0596 - root_mean_squared_error: 0.0757 - val_loss: 0.0666 - val_mae: 0.0666 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0744 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0746 - val_mae: 0.0746 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0629 - val_mae: 0.0629 - val_root_mean_squared_error: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:33:06 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:33:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:33:14 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:33:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: number_of_layer = 2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0902 - mae: 0.0902 - root_mean_squared_error: 0.1336 - val_loss: 0.0494 - val_mae: 0.0494 - val_root_mean_squared_error: 0.0598\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0660 - mae: 0.0660 - root_mean_squared_error: 0.0841 - val_loss: 0.0782 - val_mae: 0.0782 - val_root_mean_squared_error: 0.0913\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0695 - mae: 0.0695 - root_mean_squared_error: 0.0900 - val_loss: 0.0816 - val_mae: 0.0816 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0755 - mae: 0.0755 - root_mean_squared_error: 0.0963 - val_loss: 0.0839 - val_mae: 0.0839 - val_root_mean_squared_error: 0.0988\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0779 - mae: 0.0779 - root_mean_squared_error: 0.1016 - val_loss: 0.0934 - val_mae: 0.0934 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0758 - mae: 0.0758 - root_mean_squared_error: 0.0984 - val_loss: 0.1212 - val_mae: 0.1212 - val_root_mean_squared_error: 0.1372\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0767 - mae: 0.0767 - root_mean_squared_error: 0.0992 - val_loss: 0.1133 - val_mae: 0.1133 - val_root_mean_squared_error: 0.1300\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0768 - mae: 0.0768 - root_mean_squared_error: 0.0987 - val_loss: 0.1246 - val_mae: 0.1246 - val_root_mean_squared_error: 0.1411\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0759 - mae: 0.0759 - root_mean_squared_error: 0.0964 - val_loss: 0.1202 - val_mae: 0.1202 - val_root_mean_squared_error: 0.1373\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0759 - mae: 0.0759 - root_mean_squared_error: 0.0971 - val_loss: 0.1214 - val_mae: 0.1214 - val_root_mean_squared_error: 0.1389\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0770 - mae: 0.0770 - root_mean_squared_error: 0.0982 - val_loss: 0.1309 - val_mae: 0.1309 - val_root_mean_squared_error: 0.1483\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0763 - mae: 0.0763 - root_mean_squared_error: 0.0966 - val_loss: 0.1239 - val_mae: 0.1239 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0736 - mae: 0.0736 - root_mean_squared_error: 0.0940 - val_loss: 0.1367 - val_mae: 0.1367 - val_root_mean_squared_error: 0.1538\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0718 - mae: 0.0718 - root_mean_squared_error: 0.0917 - val_loss: 0.1305 - val_mae: 0.1305 - val_root_mean_squared_error: 0.1477\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0691 - mae: 0.0691 - root_mean_squared_error: 0.0887 - val_loss: 0.1254 - val_mae: 0.1254 - val_root_mean_squared_error: 0.1429\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0668 - mae: 0.0668 - root_mean_squared_error: 0.0862 - val_loss: 0.1212 - val_mae: 0.1212 - val_root_mean_squared_error: 0.1386\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0640 - mae: 0.0640 - root_mean_squared_error: 0.0826 - val_loss: 0.1252 - val_mae: 0.1252 - val_root_mean_squared_error: 0.1422\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0631 - mae: 0.0631 - root_mean_squared_error: 0.0813 - val_loss: 0.1161 - val_mae: 0.1161 - val_root_mean_squared_error: 0.1334\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0610 - mae: 0.0610 - root_mean_squared_error: 0.0793 - val_loss: 0.1070 - val_mae: 0.1070 - val_root_mean_squared_error: 0.1239\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0617 - mae: 0.0617 - root_mean_squared_error: 0.0793 - val_loss: 0.1083 - val_mae: 0.1083 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0594 - mae: 0.0594 - root_mean_squared_error: 0.0773 - val_loss: 0.1122 - val_mae: 0.1122 - val_root_mean_squared_error: 0.1284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:34:11 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:34:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:34:18 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:34:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: number_of_layer = 3 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - loss: 0.0921 - mae: 0.0921 - root_mean_squared_error: 0.1297 - val_loss: 0.1238 - val_mae: 0.1238 - val_root_mean_squared_error: 0.1344\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0725 - mae: 0.0725 - root_mean_squared_error: 0.0919 - val_loss: 0.0923 - val_mae: 0.0923 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0910 - mae: 0.0910 - root_mean_squared_error: 0.1159 - val_loss: 0.0982 - val_mae: 0.0982 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0955 - mae: 0.0955 - root_mean_squared_error: 0.1230 - val_loss: 0.1215 - val_mae: 0.1215 - val_root_mean_squared_error: 0.1398\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0969 - mae: 0.0969 - root_mean_squared_error: 0.1223 - val_loss: 0.1483 - val_mae: 0.1483 - val_root_mean_squared_error: 0.1669\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.1075 - mae: 0.1075 - root_mean_squared_error: 0.1339 - val_loss: 0.1338 - val_mae: 0.1338 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.1136 - mae: 0.1136 - root_mean_squared_error: 0.1416 - val_loss: 0.1672 - val_mae: 0.1672 - val_root_mean_squared_error: 0.1864\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.1091 - mae: 0.1091 - root_mean_squared_error: 0.1377 - val_loss: 0.2054 - val_mae: 0.2054 - val_root_mean_squared_error: 0.2223\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.1052 - mae: 0.1052 - root_mean_squared_error: 0.1328 - val_loss: 0.2121 - val_mae: 0.2121 - val_root_mean_squared_error: 0.2286\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.1001 - mae: 0.1001 - root_mean_squared_error: 0.1252 - val_loss: 0.2273 - val_mae: 0.2273 - val_root_mean_squared_error: 0.2431\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0918 - mae: 0.0918 - root_mean_squared_error: 0.1157 - val_loss: 0.2390 - val_mae: 0.2390 - val_root_mean_squared_error: 0.2545\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0886 - mae: 0.0886 - root_mean_squared_error: 0.1122 - val_loss: 0.2509 - val_mae: 0.2509 - val_root_mean_squared_error: 0.2658\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0844 - mae: 0.0844 - root_mean_squared_error: 0.1071 - val_loss: 0.2353 - val_mae: 0.2353 - val_root_mean_squared_error: 0.2510\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0853 - mae: 0.0853 - root_mean_squared_error: 0.1084 - val_loss: 0.2375 - val_mae: 0.2375 - val_root_mean_squared_error: 0.2531\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0827 - mae: 0.0827 - root_mean_squared_error: 0.1059 - val_loss: 0.2473 - val_mae: 0.2473 - val_root_mean_squared_error: 0.2620\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0829 - mae: 0.0829 - root_mean_squared_error: 0.1043 - val_loss: 0.2353 - val_mae: 0.2353 - val_root_mean_squared_error: 0.2508\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0830 - mae: 0.0830 - root_mean_squared_error: 0.1051 - val_loss: 0.2414 - val_mae: 0.2414 - val_root_mean_squared_error: 0.2566\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0816 - mae: 0.0816 - root_mean_squared_error: 0.1027 - val_loss: 0.2410 - val_mae: 0.2410 - val_root_mean_squared_error: 0.2562\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0774 - mae: 0.0774 - root_mean_squared_error: 0.0985 - val_loss: 0.2353 - val_mae: 0.2353 - val_root_mean_squared_error: 0.2507\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0807 - mae: 0.0807 - root_mean_squared_error: 0.1012 - val_loss: 0.2442 - val_mae: 0.2442 - val_root_mean_squared_error: 0.2593\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0785 - mae: 0.0785 - root_mean_squared_error: 0.0990 - val_loss: 0.2423 - val_mae: 0.2423 - val_root_mean_squared_error: 0.2576\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0749 - mae: 0.0749 - root_mean_squared_error: 0.0941 - val_loss: 0.2416 - val_mae: 0.2416 - val_root_mean_squared_error: 0.2568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:35:34 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:35:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:35:42 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:35:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: number_of_layer = 4 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - loss: 0.0993 - mae: 0.0993 - root_mean_squared_error: 0.1440 - val_loss: 0.1667 - val_mae: 0.1667 - val_root_mean_squared_error: 0.1800\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0806 - mae: 0.0806 - root_mean_squared_error: 0.1024 - val_loss: 0.1237 - val_mae: 0.1237 - val_root_mean_squared_error: 0.1434\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.1094 - mae: 0.1094 - root_mean_squared_error: 0.1403 - val_loss: 0.1531 - val_mae: 0.1531 - val_root_mean_squared_error: 0.1737\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.1172 - mae: 0.1172 - root_mean_squared_error: 0.1470 - val_loss: 0.1604 - val_mae: 0.1604 - val_root_mean_squared_error: 0.1816\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.1288 - mae: 0.1288 - root_mean_squared_error: 0.1633 - val_loss: 0.1774 - val_mae: 0.1774 - val_root_mean_squared_error: 0.1984\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.1326 - mae: 0.1326 - root_mean_squared_error: 0.1690 - val_loss: 0.2306 - val_mae: 0.2306 - val_root_mean_squared_error: 0.2477\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.1235 - mae: 0.1235 - root_mean_squared_error: 0.1579 - val_loss: 0.2482 - val_mae: 0.2482 - val_root_mean_squared_error: 0.2643\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.1362 - mae: 0.1362 - root_mean_squared_error: 0.1717 - val_loss: 0.2410 - val_mae: 0.2410 - val_root_mean_squared_error: 0.2576\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.1213 - mae: 0.1213 - root_mean_squared_error: 0.1538 - val_loss: 0.2369 - val_mae: 0.2369 - val_root_mean_squared_error: 0.2537\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.1293 - mae: 0.1293 - root_mean_squared_error: 0.1648 - val_loss: 0.2181 - val_mae: 0.2181 - val_root_mean_squared_error: 0.2361\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.1080 - mae: 0.1080 - root_mean_squared_error: 0.1380 - val_loss: 0.2269 - val_mae: 0.2269 - val_root_mean_squared_error: 0.2444\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.1401 - mae: 0.1401 - root_mean_squared_error: 0.1787 - val_loss: 0.1872 - val_mae: 0.1872 - val_root_mean_squared_error: 0.2078\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0973 - mae: 0.0973 - root_mean_squared_error: 0.1237 - val_loss: 0.2411 - val_mae: 0.2411 - val_root_mean_squared_error: 0.2577\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.1474 - mae: 0.1474 - root_mean_squared_error: 0.1870 - val_loss: 0.2002 - val_mae: 0.2002 - val_root_mean_squared_error: 0.2199\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.1005 - mae: 0.1005 - root_mean_squared_error: 0.1219 - val_loss: 0.2435 - val_mae: 0.2435 - val_root_mean_squared_error: 0.2599\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.1227 - mae: 0.1227 - root_mean_squared_error: 0.1590 - val_loss: 0.1968 - val_mae: 0.1968 - val_root_mean_squared_error: 0.2167\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0910 - mae: 0.0910 - root_mean_squared_error: 0.1130 - val_loss: 0.2521 - val_mae: 0.2521 - val_root_mean_squared_error: 0.2681\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.1040 - mae: 0.1040 - root_mean_squared_error: 0.1338 - val_loss: 0.2185 - val_mae: 0.2185 - val_root_mean_squared_error: 0.2368\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0875 - mae: 0.0875 - root_mean_squared_error: 0.1187 - val_loss: 0.2321 - val_mae: 0.2321 - val_root_mean_squared_error: 0.2493\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0878 - mae: 0.0878 - root_mean_squared_error: 0.1181 - val_loss: 0.2326 - val_mae: 0.2326 - val_root_mean_squared_error: 0.2497\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0877 - mae: 0.0877 - root_mean_squared_error: 0.1177 - val_loss: 0.2245 - val_mae: 0.2245 - val_root_mean_squared_error: 0.2422\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0884 - mae: 0.0884 - root_mean_squared_error: 0.1186 - val_loss: 0.2230 - val_mae: 0.2230 - val_root_mean_squared_error: 0.2408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:37:11 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:37:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:37:19 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:37:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 19:37:43 INFO mlflow.tracking.fluent: Experiment with name 'lstm_loss_function_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: loss_function = mae ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0939 - mae: 0.0939 - root_mean_squared_error: 0.1429 - val_loss: 0.0597 - val_mae: 0.0597 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0663 - mae: 0.0663 - root_mean_squared_error: 0.0858 - val_loss: 0.0466 - val_mae: 0.0466 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0674 - mae: 0.0674 - root_mean_squared_error: 0.0866 - val_loss: 0.0569 - val_mae: 0.0569 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0662 - mae: 0.0662 - root_mean_squared_error: 0.0843 - val_loss: 0.0620 - val_mae: 0.0620 - val_root_mean_squared_error: 0.0740\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0647 - mae: 0.0647 - root_mean_squared_error: 0.0830 - val_loss: 0.0659 - val_mae: 0.0659 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0656 - mae: 0.0656 - root_mean_squared_error: 0.0833 - val_loss: 0.0851 - val_mae: 0.0851 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0632 - mae: 0.0632 - root_mean_squared_error: 0.0810 - val_loss: 0.0588 - val_mae: 0.0588 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0660 - mae: 0.0660 - root_mean_squared_error: 0.0839 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0642 - mae: 0.0642 - root_mean_squared_error: 0.0813 - val_loss: 0.0718 - val_mae: 0.0718 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0831 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0661 - mae: 0.0661 - root_mean_squared_error: 0.0834 - val_loss: 0.0678 - val_mae: 0.0678 - val_root_mean_squared_error: 0.0802\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0651 - mae: 0.0651 - root_mean_squared_error: 0.0819 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0644 - mae: 0.0644 - root_mean_squared_error: 0.0809 - val_loss: 0.0639 - val_mae: 0.0639 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0645 - mae: 0.0645 - root_mean_squared_error: 0.0811 - val_loss: 0.0570 - val_mae: 0.0570 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0630 - mae: 0.0630 - root_mean_squared_error: 0.0795 - val_loss: 0.0691 - val_mae: 0.0691 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0622 - mae: 0.0622 - root_mean_squared_error: 0.0784 - val_loss: 0.0594 - val_mae: 0.0594 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0606 - mae: 0.0606 - root_mean_squared_error: 0.0765 - val_loss: 0.0660 - val_mae: 0.0660 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0600 - mae: 0.0600 - root_mean_squared_error: 0.0760 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0596 - mae: 0.0596 - root_mean_squared_error: 0.0757 - val_loss: 0.0666 - val_mae: 0.0666 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0744 - val_loss: 0.0619 - val_mae: 0.0619 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0746 - val_mae: 0.0746 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0726 - val_loss: 0.0629 - val_mae: 0.0629 - val_root_mean_squared_error: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:38:04 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:38:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:38:11 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:38:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: loss_function = mse ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0215 - mae: 0.0982 - root_mean_squared_error: 0.1467 - val_loss: 0.0049 - val_mae: 0.0584 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0073 - mae: 0.0664 - root_mean_squared_error: 0.0854 - val_loss: 0.0028 - val_mae: 0.0427 - val_root_mean_squared_error: 0.0534\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0070 - mae: 0.0654 - root_mean_squared_error: 0.0839 - val_loss: 0.0036 - val_mae: 0.0484 - val_root_mean_squared_error: 0.0597\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0067 - mae: 0.0645 - root_mean_squared_error: 0.0821 - val_loss: 0.0051 - val_mae: 0.0596 - val_root_mean_squared_error: 0.0714\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0067 - mae: 0.0637 - root_mean_squared_error: 0.0816 - val_loss: 0.0050 - val_mae: 0.0590 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0066 - mae: 0.0637 - root_mean_squared_error: 0.0814 - val_loss: 0.0059 - val_mae: 0.0652 - val_root_mean_squared_error: 0.0771\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0612 - root_mean_squared_error: 0.0785 - val_loss: 0.0044 - val_mae: 0.0548 - val_root_mean_squared_error: 0.0666\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0064 - mae: 0.0626 - root_mean_squared_error: 0.0801 - val_loss: 0.0047 - val_mae: 0.0565 - val_root_mean_squared_error: 0.0684\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0061 - mae: 0.0609 - root_mean_squared_error: 0.0783 - val_loss: 0.0051 - val_mae: 0.0594 - val_root_mean_squared_error: 0.0714\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0062 - mae: 0.0615 - root_mean_squared_error: 0.0788 - val_loss: 0.0063 - val_mae: 0.0671 - val_root_mean_squared_error: 0.0793\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0061 - mae: 0.0607 - root_mean_squared_error: 0.0778 - val_loss: 0.0066 - val_mae: 0.0689 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0060 - mae: 0.0607 - root_mean_squared_error: 0.0773 - val_loss: 0.0080 - val_mae: 0.0773 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0059 - mae: 0.0609 - root_mean_squared_error: 0.0771 - val_loss: 0.0066 - val_mae: 0.0687 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0061 - mae: 0.0614 - root_mean_squared_error: 0.0781 - val_loss: 0.0063 - val_mae: 0.0668 - val_root_mean_squared_error: 0.0792\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0061 - mae: 0.0612 - root_mean_squared_error: 0.0778 - val_loss: 0.0071 - val_mae: 0.0716 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0059 - mae: 0.0607 - root_mean_squared_error: 0.0770 - val_loss: 0.0065 - val_mae: 0.0682 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0059 - mae: 0.0611 - root_mean_squared_error: 0.0771 - val_loss: 0.0068 - val_mae: 0.0699 - val_root_mean_squared_error: 0.0823\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0060 - mae: 0.0609 - root_mean_squared_error: 0.0774 - val_loss: 0.0059 - val_mae: 0.0643 - val_root_mean_squared_error: 0.0767\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0059 - mae: 0.0606 - root_mean_squared_error: 0.0768 - val_loss: 0.0072 - val_mae: 0.0723 - val_root_mean_squared_error: 0.0847\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0056 - mae: 0.0589 - root_mean_squared_error: 0.0747 - val_loss: 0.0065 - val_mae: 0.0686 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0054 - mae: 0.0578 - root_mean_squared_error: 0.0732 - val_loss: 0.0065 - val_mae: 0.0680 - val_root_mean_squared_error: 0.0803\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0054 - mae: 0.0578 - root_mean_squared_error: 0.0735 - val_loss: 0.0068 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:38:56 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:39:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:39:03 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:39:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: loss_function = huber ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0108 - mae: 0.0982 - root_mean_squared_error: 0.1467 - val_loss: 0.0024 - val_mae: 0.0585 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0664 - root_mean_squared_error: 0.0854 - val_loss: 0.0014 - val_mae: 0.0428 - val_root_mean_squared_error: 0.0535\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035 - mae: 0.0654 - root_mean_squared_error: 0.0839 - val_loss: 0.0018 - val_mae: 0.0484 - val_root_mean_squared_error: 0.0597\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0034 - mae: 0.0645 - root_mean_squared_error: 0.0821 - val_loss: 0.0025 - val_mae: 0.0596 - val_root_mean_squared_error: 0.0714\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0637 - root_mean_squared_error: 0.0816 - val_loss: 0.0025 - val_mae: 0.0590 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0637 - root_mean_squared_error: 0.0814 - val_loss: 0.0030 - val_mae: 0.0652 - val_root_mean_squared_error: 0.0771\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0612 - root_mean_squared_error: 0.0785 - val_loss: 0.0022 - val_mae: 0.0548 - val_root_mean_squared_error: 0.0666\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0626 - root_mean_squared_error: 0.0801 - val_loss: 0.0023 - val_mae: 0.0565 - val_root_mean_squared_error: 0.0684\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0609 - root_mean_squared_error: 0.0783 - val_loss: 0.0025 - val_mae: 0.0593 - val_root_mean_squared_error: 0.0714\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0615 - root_mean_squared_error: 0.0788 - val_loss: 0.0031 - val_mae: 0.0671 - val_root_mean_squared_error: 0.0792\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0607 - root_mean_squared_error: 0.0778 - val_loss: 0.0033 - val_mae: 0.0689 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0607 - root_mean_squared_error: 0.0773 - val_loss: 0.0040 - val_mae: 0.0773 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0609 - root_mean_squared_error: 0.0771 - val_loss: 0.0033 - val_mae: 0.0687 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0614 - root_mean_squared_error: 0.0781 - val_loss: 0.0031 - val_mae: 0.0668 - val_root_mean_squared_error: 0.0792\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0612 - root_mean_squared_error: 0.0778 - val_loss: 0.0035 - val_mae: 0.0716 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0607 - root_mean_squared_error: 0.0770 - val_loss: 0.0032 - val_mae: 0.0682 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0611 - root_mean_squared_error: 0.0770 - val_loss: 0.0034 - val_mae: 0.0699 - val_root_mean_squared_error: 0.0823\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0609 - root_mean_squared_error: 0.0774 - val_loss: 0.0029 - val_mae: 0.0643 - val_root_mean_squared_error: 0.0767\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0606 - root_mean_squared_error: 0.0768 - val_loss: 0.0036 - val_mae: 0.0723 - val_root_mean_squared_error: 0.0847\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0589 - root_mean_squared_error: 0.0747 - val_loss: 0.0033 - val_mae: 0.0686 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0578 - root_mean_squared_error: 0.0732 - val_loss: 0.0032 - val_mae: 0.0680 - val_root_mean_squared_error: 0.0803\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0578 - root_mean_squared_error: 0.0735 - val_loss: 0.0034 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:39:47 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:39:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:39:55 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:39:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 19:40:18 INFO mlflow.tracking.fluent: Experiment with name 'gru_input_width_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: input_width = 12 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0993 - mae: 0.0993 - root_mean_squared_error: 0.1495 - val_loss: 0.0677 - val_mae: 0.0677 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 2/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0612 - mae: 0.0612 - root_mean_squared_error: 0.0788 - val_loss: 0.0398 - val_mae: 0.0398 - val_root_mean_squared_error: 0.0480\n",
      "Epoch 3/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0563 - mae: 0.0563 - root_mean_squared_error: 0.0733 - val_loss: 0.0413 - val_mae: 0.0413 - val_root_mean_squared_error: 0.0491\n",
      "Epoch 4/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0533 - mae: 0.0533 - root_mean_squared_error: 0.0685 - val_loss: 0.0593 - val_mae: 0.0593 - val_root_mean_squared_error: 0.0661\n",
      "Epoch 5/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0491 - mae: 0.0491 - root_mean_squared_error: 0.0644 - val_loss: 0.0302 - val_mae: 0.0302 - val_root_mean_squared_error: 0.0375\n",
      "Epoch 6/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0483 - mae: 0.0483 - root_mean_squared_error: 0.0626 - val_loss: 0.0377 - val_mae: 0.0377 - val_root_mean_squared_error: 0.0452\n",
      "Epoch 7/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0474 - mae: 0.0474 - root_mean_squared_error: 0.0614 - val_loss: 0.0491 - val_mae: 0.0491 - val_root_mean_squared_error: 0.0563\n",
      "Epoch 8/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0420 - mae: 0.0420 - root_mean_squared_error: 0.0550 - val_loss: 0.0492 - val_mae: 0.0492 - val_root_mean_squared_error: 0.0565\n",
      "Epoch 9/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0417 - mae: 0.0417 - root_mean_squared_error: 0.0544 - val_loss: 0.0480 - val_mae: 0.0480 - val_root_mean_squared_error: 0.0555\n",
      "Epoch 10/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0532 - val_loss: 0.0498 - val_mae: 0.0498 - val_root_mean_squared_error: 0.0573\n",
      "Epoch 11/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0525 - val_loss: 0.0332 - val_mae: 0.0332 - val_root_mean_squared_error: 0.0402\n",
      "Epoch 12/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0387 - mae: 0.0387 - root_mean_squared_error: 0.0507 - val_loss: 0.0407 - val_mae: 0.0407 - val_root_mean_squared_error: 0.0479\n",
      "Epoch 13/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0491 - val_loss: 0.0423 - val_mae: 0.0423 - val_root_mean_squared_error: 0.0499\n",
      "Epoch 14/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0368 - mae: 0.0368 - root_mean_squared_error: 0.0481 - val_loss: 0.0413 - val_mae: 0.0413 - val_root_mean_squared_error: 0.0487\n",
      "Epoch 15/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0473 - val_loss: 0.0402 - val_mae: 0.0402 - val_root_mean_squared_error: 0.0474\n",
      "Epoch 16/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0473 - val_loss: 0.0483 - val_mae: 0.0483 - val_root_mean_squared_error: 0.0565\n",
      "Epoch 17/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0470 - val_loss: 0.0425 - val_mae: 0.0425 - val_root_mean_squared_error: 0.0499\n",
      "Epoch 18/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0460 - val_loss: 0.0310 - val_mae: 0.0310 - val_root_mean_squared_error: 0.0370\n",
      "Epoch 19/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0474 - val_loss: 0.0560 - val_mae: 0.0560 - val_root_mean_squared_error: 0.0635\n",
      "Epoch 20/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0458 - val_loss: 0.0403 - val_mae: 0.0403 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 21/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0439 - val_loss: 0.0492 - val_mae: 0.0492 - val_root_mean_squared_error: 0.0560\n",
      "Epoch 22/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0481 - val_loss: 0.0421 - val_mae: 0.0421 - val_root_mean_squared_error: 0.0494\n",
      "Epoch 23/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0485 - val_loss: 0.0353 - val_mae: 0.0353 - val_root_mean_squared_error: 0.0411\n",
      "Epoch 24/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0314 - mae: 0.0314 - root_mean_squared_error: 0.0416 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0284\n",
      "Epoch 25/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0302 - mae: 0.0302 - root_mean_squared_error: 0.0395 - val_loss: 0.0126 - val_mae: 0.0126 - val_root_mean_squared_error: 0.0162\n",
      "Epoch 26/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0289 - mae: 0.0289 - root_mean_squared_error: 0.0378 - val_loss: 0.0349 - val_mae: 0.0349 - val_root_mean_squared_error: 0.0380\n",
      "Epoch 27/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0373 - val_loss: 0.0391 - val_mae: 0.0391 - val_root_mean_squared_error: 0.0423\n",
      "Epoch 28/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0283 - mae: 0.0283 - root_mean_squared_error: 0.0374 - val_loss: 0.0369 - val_mae: 0.0369 - val_root_mean_squared_error: 0.0400\n",
      "Epoch 29/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0366 - val_loss: 0.0163 - val_mae: 0.0163 - val_root_mean_squared_error: 0.0198\n",
      "Epoch 30/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0282 - mae: 0.0282 - root_mean_squared_error: 0.0373 - val_loss: 0.0322 - val_mae: 0.0322 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 31/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0301 - mae: 0.0301 - root_mean_squared_error: 0.0391 - val_loss: 0.0386 - val_mae: 0.0386 - val_root_mean_squared_error: 0.0435\n",
      "Epoch 32/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0321 - mae: 0.0321 - root_mean_squared_error: 0.0423 - val_loss: 0.0279 - val_mae: 0.0279 - val_root_mean_squared_error: 0.0328\n",
      "Epoch 33/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0326 - mae: 0.0326 - root_mean_squared_error: 0.0432 - val_loss: 0.0150 - val_mae: 0.0150 - val_root_mean_squared_error: 0.0182\n",
      "Epoch 34/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.0303 - root_mean_squared_error: 0.0401 - val_loss: 0.0129 - val_mae: 0.0129 - val_root_mean_squared_error: 0.0160\n",
      "Epoch 35/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0281 - mae: 0.0281 - root_mean_squared_error: 0.0370 - val_loss: 0.0113 - val_mae: 0.0113 - val_root_mean_squared_error: 0.0148\n",
      "Epoch 36/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0271 - mae: 0.0271 - root_mean_squared_error: 0.0358 - val_loss: 0.0166 - val_mae: 0.0166 - val_root_mean_squared_error: 0.0196\n",
      "Epoch 37/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0257 - mae: 0.0257 - root_mean_squared_error: 0.0337 - val_loss: 0.0106 - val_mae: 0.0106 - val_root_mean_squared_error: 0.0134\n",
      "Epoch 38/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - mae: 0.0243 - root_mean_squared_error: 0.0317 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0285\n",
      "Epoch 39/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0231 - mae: 0.0231 - root_mean_squared_error: 0.0301 - val_loss: 0.0294 - val_mae: 0.0294 - val_root_mean_squared_error: 0.0318\n",
      "Epoch 40/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0238 - mae: 0.0238 - root_mean_squared_error: 0.0313 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0271\n",
      "Epoch 41/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0237 - mae: 0.0237 - root_mean_squared_error: 0.0313 - val_loss: 0.0299 - val_mae: 0.0299 - val_root_mean_squared_error: 0.0325\n",
      "Epoch 42/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0251 - mae: 0.0251 - root_mean_squared_error: 0.0328 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0285\n",
      "Epoch 43/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0280 - mae: 0.0280 - root_mean_squared_error: 0.0371 - val_loss: 0.0270 - val_mae: 0.0270 - val_root_mean_squared_error: 0.0314\n",
      "Epoch 44/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0299 - mae: 0.0299 - root_mean_squared_error: 0.0397 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0269\n",
      "Epoch 45/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0271 - mae: 0.0271 - root_mean_squared_error: 0.0354 - val_loss: 0.0291 - val_mae: 0.0291 - val_root_mean_squared_error: 0.0331\n",
      "Epoch 46/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0273 - mae: 0.0273 - root_mean_squared_error: 0.0363 - val_loss: 0.0214 - val_mae: 0.0214 - val_root_mean_squared_error: 0.0238\n",
      "Epoch 47/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0222 - mae: 0.0222 - root_mean_squared_error: 0.0292 - val_loss: 0.0211 - val_mae: 0.0211 - val_root_mean_squared_error: 0.0238\n",
      "Epoch 48/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0236 - mae: 0.0236 - root_mean_squared_error: 0.0311 - val_loss: 0.0287 - val_mae: 0.0287 - val_root_mean_squared_error: 0.0316\n",
      "Epoch 49/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0346 - val_loss: 0.0277 - val_mae: 0.0277 - val_root_mean_squared_error: 0.0321\n",
      "Epoch 50/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0361 - val_loss: 0.0086 - val_mae: 0.0086 - val_root_mean_squared_error: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:40:53 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:41:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:41:01 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:41:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: input_width = 24 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1032 - mae: 0.1032 - root_mean_squared_error: 0.1527 - val_loss: 0.0721 - val_mae: 0.0721 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0690 - mae: 0.0690 - root_mean_squared_error: 0.0884 - val_loss: 0.0606 - val_mae: 0.0606 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0654 - mae: 0.0654 - root_mean_squared_error: 0.0840 - val_loss: 0.0494 - val_mae: 0.0494 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0627 - mae: 0.0627 - root_mean_squared_error: 0.0800 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0766 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0748 - val_loss: 0.0751 - val_mae: 0.0751 - val_root_mean_squared_error: 0.0853\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0549 - mae: 0.0549 - root_mean_squared_error: 0.0707 - val_loss: 0.0591 - val_mae: 0.0591 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0553 - mae: 0.0553 - root_mean_squared_error: 0.0714 - val_loss: 0.0575 - val_mae: 0.0575 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0523 - mae: 0.0523 - root_mean_squared_error: 0.0677 - val_loss: 0.0613 - val_mae: 0.0613 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0502 - mae: 0.0502 - root_mean_squared_error: 0.0653 - val_loss: 0.0652 - val_mae: 0.0652 - val_root_mean_squared_error: 0.0753\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0473 - mae: 0.0473 - root_mean_squared_error: 0.0612 - val_loss: 0.0603 - val_mae: 0.0603 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0463 - mae: 0.0463 - root_mean_squared_error: 0.0602 - val_loss: 0.0692 - val_mae: 0.0692 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0461 - mae: 0.0461 - root_mean_squared_error: 0.0591 - val_loss: 0.0643 - val_mae: 0.0643 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0571 - val_loss: 0.0618 - val_mae: 0.0618 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0548 - val_loss: 0.0625 - val_mae: 0.0625 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0524 - val_loss: 0.0414 - val_mae: 0.0414 - val_root_mean_squared_error: 0.0491\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0503 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0514\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0504 - val_loss: 0.0349 - val_mae: 0.0349 - val_root_mean_squared_error: 0.0416\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0523 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0432\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0458 - val_loss: 0.0422 - val_mae: 0.0422 - val_root_mean_squared_error: 0.0469\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0452 - val_loss: 0.0327 - val_mae: 0.0327 - val_root_mean_squared_error: 0.0380\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0434 - val_loss: 0.0252 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0302\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0478 - val_loss: 0.0402 - val_mae: 0.0402 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0366 - mae: 0.0366 - root_mean_squared_error: 0.0484 - val_loss: 0.0275 - val_mae: 0.0275 - val_root_mean_squared_error: 0.0326\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0449 - val_loss: 0.0151 - val_mae: 0.0151 - val_root_mean_squared_error: 0.0188\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0322 - mae: 0.0322 - root_mean_squared_error: 0.0419 - val_loss: 0.0451 - val_mae: 0.0451 - val_root_mean_squared_error: 0.0495\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0444 - val_loss: 0.0302 - val_mae: 0.0302 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0469 - val_loss: 0.0226 - val_mae: 0.0226 - val_root_mean_squared_error: 0.0270\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0426 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0422\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0323 - mae: 0.0323 - root_mean_squared_error: 0.0424 - val_loss: 0.0348 - val_mae: 0.0348 - val_root_mean_squared_error: 0.0395\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0310 - mae: 0.0310 - root_mean_squared_error: 0.0404 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0314\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0315 - mae: 0.0315 - root_mean_squared_error: 0.0418 - val_loss: 0.0111 - val_mae: 0.0111 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0291 - mae: 0.0291 - root_mean_squared_error: 0.0377 - val_loss: 0.0278 - val_mae: 0.0278 - val_root_mean_squared_error: 0.0318\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0277 - mae: 0.0277 - root_mean_squared_error: 0.0367 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0294 - mae: 0.0294 - root_mean_squared_error: 0.0380 - val_loss: 0.0256 - val_mae: 0.0256 - val_root_mean_squared_error: 0.0300\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0283 - mae: 0.0283 - root_mean_squared_error: 0.0373 - val_loss: 0.0377 - val_mae: 0.0377 - val_root_mean_squared_error: 0.0414\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0282 - mae: 0.0282 - root_mean_squared_error: 0.0371 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0278\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0369 - val_loss: 0.0124 - val_mae: 0.0124 - val_root_mean_squared_error: 0.0153\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0365 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0205\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0374 - val_loss: 0.0132 - val_mae: 0.0132 - val_root_mean_squared_error: 0.0161\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0253 - mae: 0.0253 - root_mean_squared_error: 0.0336 - val_loss: 0.0287 - val_mae: 0.0287 - val_root_mean_squared_error: 0.0321\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0378 - val_loss: 0.0163 - val_mae: 0.0163 - val_root_mean_squared_error: 0.0195\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0349 - val_loss: 0.0128 - val_mae: 0.0128 - val_root_mean_squared_error: 0.0155\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0269 - mae: 0.0269 - root_mean_squared_error: 0.0351 - val_loss: 0.0190 - val_mae: 0.0190 - val_root_mean_squared_error: 0.0221\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0250 - mae: 0.0250 - root_mean_squared_error: 0.0330 - val_loss: 0.0160 - val_mae: 0.0160 - val_root_mean_squared_error: 0.0185\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0233 - mae: 0.0233 - root_mean_squared_error: 0.0309 - val_loss: 0.0087 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0109\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0279 - mae: 0.0279 - root_mean_squared_error: 0.0366 - val_loss: 0.0109 - val_mae: 0.0109 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0354 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0225 - mae: 0.0225 - root_mean_squared_error: 0.0294 - val_loss: 0.0140 - val_mae: 0.0140 - val_root_mean_squared_error: 0.0160\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0232 - mae: 0.0232 - root_mean_squared_error: 0.0305 - val_loss: 0.0072 - val_mae: 0.0072 - val_root_mean_squared_error: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:42:13 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:42:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:42:21 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:42:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: input_width = 48 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1105 - mae: 0.1105 - root_mean_squared_error: 0.1580 - val_loss: 0.0803 - val_mae: 0.0803 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0813 - mae: 0.0813 - root_mean_squared_error: 0.1019 - val_loss: 0.0903 - val_mae: 0.0903 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0787 - mae: 0.0787 - root_mean_squared_error: 0.0983 - val_loss: 0.0760 - val_mae: 0.0760 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0771 - mae: 0.0771 - root_mean_squared_error: 0.0958 - val_loss: 0.0739 - val_mae: 0.0739 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0759 - mae: 0.0759 - root_mean_squared_error: 0.0952 - val_loss: 0.0836 - val_mae: 0.0836 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0745 - mae: 0.0745 - root_mean_squared_error: 0.0929 - val_loss: 0.0908 - val_mae: 0.0908 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0716 - mae: 0.0716 - root_mean_squared_error: 0.0897 - val_loss: 0.0879 - val_mae: 0.0879 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0725 - mae: 0.0725 - root_mean_squared_error: 0.0906 - val_loss: 0.0944 - val_mae: 0.0944 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0694 - mae: 0.0694 - root_mean_squared_error: 0.0867 - val_loss: 0.1166 - val_mae: 0.1166 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0675 - mae: 0.0675 - root_mean_squared_error: 0.0844 - val_loss: 0.1005 - val_mae: 0.1005 - val_root_mean_squared_error: 0.1151\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0664 - mae: 0.0664 - root_mean_squared_error: 0.0833 - val_loss: 0.1086 - val_mae: 0.1086 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0644 - mae: 0.0644 - root_mean_squared_error: 0.0807 - val_loss: 0.1021 - val_mae: 0.1021 - val_root_mean_squared_error: 0.1165\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0640 - mae: 0.0640 - root_mean_squared_error: 0.0800 - val_loss: 0.1027 - val_mae: 0.1027 - val_root_mean_squared_error: 0.1159\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0619 - mae: 0.0619 - root_mean_squared_error: 0.0779 - val_loss: 0.0923 - val_mae: 0.0923 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0609 - mae: 0.0609 - root_mean_squared_error: 0.0767 - val_loss: 0.0838 - val_mae: 0.0838 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0584 - mae: 0.0584 - root_mean_squared_error: 0.0743 - val_loss: 0.0758 - val_mae: 0.0758 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0550 - mae: 0.0550 - root_mean_squared_error: 0.0703 - val_loss: 0.0952 - val_mae: 0.0952 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0523 - mae: 0.0523 - root_mean_squared_error: 0.0676 - val_loss: 0.0757 - val_mae: 0.0757 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0537 - mae: 0.0537 - root_mean_squared_error: 0.0682 - val_loss: 0.0748 - val_mae: 0.0748 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0645 - val_loss: 0.0766 - val_mae: 0.0766 - val_root_mean_squared_error: 0.0852\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0458 - mae: 0.0458 - root_mean_squared_error: 0.0583 - val_loss: 0.0653 - val_mae: 0.0653 - val_root_mean_squared_error: 0.0747\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0415 - mae: 0.0415 - root_mean_squared_error: 0.0531 - val_loss: 0.0634 - val_mae: 0.0634 - val_root_mean_squared_error: 0.0731\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0528 - val_loss: 0.0811 - val_mae: 0.0811 - val_root_mean_squared_error: 0.0913\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0441 - mae: 0.0441 - root_mean_squared_error: 0.0572 - val_loss: 0.0660 - val_mae: 0.0660 - val_root_mean_squared_error: 0.0743\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0500 - val_loss: 0.0513 - val_mae: 0.0513 - val_root_mean_squared_error: 0.0597\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0505 - val_loss: 0.0604 - val_mae: 0.0604 - val_root_mean_squared_error: 0.0674\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0485 - val_loss: 0.0443 - val_mae: 0.0443 - val_root_mean_squared_error: 0.0515\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0475 - val_loss: 0.0374 - val_mae: 0.0374 - val_root_mean_squared_error: 0.0438\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0468 - val_loss: 0.0495 - val_mae: 0.0495 - val_root_mean_squared_error: 0.0565\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0466 - val_loss: 0.0410 - val_mae: 0.0410 - val_root_mean_squared_error: 0.0469\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0449 - val_loss: 0.0457 - val_mae: 0.0457 - val_root_mean_squared_error: 0.0524\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0372 - mae: 0.0372 - root_mean_squared_error: 0.0489 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0305\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0443 - val_loss: 0.0224 - val_mae: 0.0224 - val_root_mean_squared_error: 0.0275\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0308 - mae: 0.0308 - root_mean_squared_error: 0.0405 - val_loss: 0.0455 - val_mae: 0.0455 - val_root_mean_squared_error: 0.0495\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0414 - val_loss: 0.0467 - val_mae: 0.0467 - val_root_mean_squared_error: 0.0514\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0310 - mae: 0.0310 - root_mean_squared_error: 0.0405 - val_loss: 0.0489 - val_mae: 0.0489 - val_root_mean_squared_error: 0.0540\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0329 - mae: 0.0329 - root_mean_squared_error: 0.0429 - val_loss: 0.0424 - val_mae: 0.0424 - val_root_mean_squared_error: 0.0464\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0299 - mae: 0.0299 - root_mean_squared_error: 0.0388 - val_loss: 0.0207 - val_mae: 0.0207 - val_root_mean_squared_error: 0.0252\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0306 - mae: 0.0306 - root_mean_squared_error: 0.0402 - val_loss: 0.0201 - val_mae: 0.0201 - val_root_mean_squared_error: 0.0245\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0283 - mae: 0.0283 - root_mean_squared_error: 0.0372 - val_loss: 0.0179 - val_mae: 0.0179 - val_root_mean_squared_error: 0.0219\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0290 - mae: 0.0290 - root_mean_squared_error: 0.0377 - val_loss: 0.0327 - val_mae: 0.0327 - val_root_mean_squared_error: 0.0373\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0305 - mae: 0.0305 - root_mean_squared_error: 0.0399 - val_loss: 0.0181 - val_mae: 0.0181 - val_root_mean_squared_error: 0.0220\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0312 - mae: 0.0312 - root_mean_squared_error: 0.0403 - val_loss: 0.0143 - val_mae: 0.0143 - val_root_mean_squared_error: 0.0177\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0277 - mae: 0.0277 - root_mean_squared_error: 0.0361 - val_loss: 0.0190 - val_mae: 0.0190 - val_root_mean_squared_error: 0.0227\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0275 - mae: 0.0275 - root_mean_squared_error: 0.0360 - val_loss: 0.0340 - val_mae: 0.0340 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0346 - val_loss: 0.0110 - val_mae: 0.0110 - val_root_mean_squared_error: 0.0140\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0310 - mae: 0.0310 - root_mean_squared_error: 0.0409 - val_loss: 0.0195 - val_mae: 0.0195 - val_root_mean_squared_error: 0.0222\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0270 - mae: 0.0270 - root_mean_squared_error: 0.0356 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0102\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0248 - mae: 0.0248 - root_mean_squared_error: 0.0323 - val_loss: 0.0091 - val_mae: 0.0091 - val_root_mean_squared_error: 0.0117\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0262 - mae: 0.0262 - root_mean_squared_error: 0.0344 - val_loss: 0.0085 - val_mae: 0.0085 - val_root_mean_squared_error: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:44:06 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:44:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:44:13 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:44:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: input_width = 72 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 0.1181 - mae: 0.1181 - root_mean_squared_error: 0.1641 - val_loss: 0.1029 - val_mae: 0.1029 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 2/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0915 - mae: 0.0915 - root_mean_squared_error: 0.1134 - val_loss: 0.0754 - val_mae: 0.0754 - val_root_mean_squared_error: 0.0926\n",
      "Epoch 3/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0903 - mae: 0.0903 - root_mean_squared_error: 0.1118 - val_loss: 0.0760 - val_mae: 0.0760 - val_root_mean_squared_error: 0.0934\n",
      "Epoch 4/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0890 - mae: 0.0890 - root_mean_squared_error: 0.1093 - val_loss: 0.0814 - val_mae: 0.0814 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 5/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0864 - mae: 0.0864 - root_mean_squared_error: 0.1063 - val_loss: 0.0824 - val_mae: 0.0824 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 6/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0856 - mae: 0.0856 - root_mean_squared_error: 0.1055 - val_loss: 0.0660 - val_mae: 0.0660 - val_root_mean_squared_error: 0.0830\n",
      "Epoch 7/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0846 - mae: 0.0846 - root_mean_squared_error: 0.1046 - val_loss: 0.0696 - val_mae: 0.0696 - val_root_mean_squared_error: 0.0863\n",
      "Epoch 8/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0827 - mae: 0.0827 - root_mean_squared_error: 0.1022 - val_loss: 0.0820 - val_mae: 0.0820 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 9/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0803 - mae: 0.0803 - root_mean_squared_error: 0.0990 - val_loss: 0.0966 - val_mae: 0.0966 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 10/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0790 - mae: 0.0790 - root_mean_squared_error: 0.0982 - val_loss: 0.1029 - val_mae: 0.1029 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 11/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0774 - mae: 0.0774 - root_mean_squared_error: 0.0957 - val_loss: 0.1206 - val_mae: 0.1206 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 12/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0759 - mae: 0.0759 - root_mean_squared_error: 0.0941 - val_loss: 0.1186 - val_mae: 0.1186 - val_root_mean_squared_error: 0.1335\n",
      "Epoch 13/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0735 - mae: 0.0735 - root_mean_squared_error: 0.0910 - val_loss: 0.1231 - val_mae: 0.1231 - val_root_mean_squared_error: 0.1380\n",
      "Epoch 14/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0724 - mae: 0.0724 - root_mean_squared_error: 0.0900 - val_loss: 0.1261 - val_mae: 0.1261 - val_root_mean_squared_error: 0.1405\n",
      "Epoch 15/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0720 - mae: 0.0720 - root_mean_squared_error: 0.0894 - val_loss: 0.1287 - val_mae: 0.1287 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 16/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0708 - mae: 0.0708 - root_mean_squared_error: 0.0880 - val_loss: 0.1252 - val_mae: 0.1252 - val_root_mean_squared_error: 0.1397\n",
      "Epoch 17/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0685 - mae: 0.0685 - root_mean_squared_error: 0.0853 - val_loss: 0.1164 - val_mae: 0.1164 - val_root_mean_squared_error: 0.1307\n",
      "Epoch 18/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0656 - mae: 0.0656 - root_mean_squared_error: 0.0827 - val_loss: 0.1028 - val_mae: 0.1028 - val_root_mean_squared_error: 0.1176\n",
      "Epoch 19/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0621 - mae: 0.0621 - root_mean_squared_error: 0.0800 - val_loss: 0.0950 - val_mae: 0.0950 - val_root_mean_squared_error: 0.1090\n",
      "Epoch 20/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0643 - mae: 0.0643 - root_mean_squared_error: 0.0826 - val_loss: 0.0814 - val_mae: 0.0814 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 21/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0566 - mae: 0.0566 - root_mean_squared_error: 0.0732 - val_loss: 0.1005 - val_mae: 0.1005 - val_root_mean_squared_error: 0.1128\n",
      "Epoch 22/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0551 - mae: 0.0551 - root_mean_squared_error: 0.0711 - val_loss: 0.0814 - val_mae: 0.0814 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 23/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0504 - mae: 0.0504 - root_mean_squared_error: 0.0639 - val_loss: 0.0757 - val_mae: 0.0757 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 24/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0515 - mae: 0.0515 - root_mean_squared_error: 0.0655 - val_loss: 0.0793 - val_mae: 0.0793 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 25/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0481 - mae: 0.0481 - root_mean_squared_error: 0.0601 - val_loss: 0.0591 - val_mae: 0.0591 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 26/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0478 - mae: 0.0478 - root_mean_squared_error: 0.0605 - val_loss: 0.0718 - val_mae: 0.0718 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 27/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0455 - mae: 0.0455 - root_mean_squared_error: 0.0570 - val_loss: 0.0601 - val_mae: 0.0601 - val_root_mean_squared_error: 0.0691\n",
      "Epoch 28/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0405 - mae: 0.0405 - root_mean_squared_error: 0.0517 - val_loss: 0.0555 - val_mae: 0.0555 - val_root_mean_squared_error: 0.0639\n",
      "Epoch 29/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0382 - mae: 0.0382 - root_mean_squared_error: 0.0492 - val_loss: 0.0506 - val_mae: 0.0506 - val_root_mean_squared_error: 0.0583\n",
      "Epoch 30/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0454 - val_loss: 0.0406 - val_mae: 0.0406 - val_root_mean_squared_error: 0.0482\n",
      "Epoch 31/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0484 - val_loss: 0.0562 - val_mae: 0.0562 - val_root_mean_squared_error: 0.0627\n",
      "Epoch 32/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0462 - val_loss: 0.0442 - val_mae: 0.0442 - val_root_mean_squared_error: 0.0512\n",
      "Epoch 33/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0358 - mae: 0.0358 - root_mean_squared_error: 0.0471 - val_loss: 0.0417 - val_mae: 0.0417 - val_root_mean_squared_error: 0.0480\n",
      "Epoch 34/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0445 - val_loss: 0.0453 - val_mae: 0.0453 - val_root_mean_squared_error: 0.0504\n",
      "Epoch 35/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0329 - mae: 0.0329 - root_mean_squared_error: 0.0420 - val_loss: 0.0293 - val_mae: 0.0293 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 36/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0446 - val_loss: 0.0314 - val_mae: 0.0314 - val_root_mean_squared_error: 0.0370\n",
      "Epoch 37/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0427 - val_loss: 0.0333 - val_mae: 0.0333 - val_root_mean_squared_error: 0.0390\n",
      "Epoch 38/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0317 - mae: 0.0317 - root_mean_squared_error: 0.0418 - val_loss: 0.0207 - val_mae: 0.0207 - val_root_mean_squared_error: 0.0252\n",
      "Epoch 39/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0435 - val_loss: 0.0357 - val_mae: 0.0357 - val_root_mean_squared_error: 0.0403\n",
      "Epoch 40/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0315 - mae: 0.0315 - root_mean_squared_error: 0.0415 - val_loss: 0.0187 - val_mae: 0.0187 - val_root_mean_squared_error: 0.0223\n",
      "Epoch 41/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0376 - val_loss: 0.0136 - val_mae: 0.0136 - val_root_mean_squared_error: 0.0169\n",
      "Epoch 42/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0314 - mae: 0.0314 - root_mean_squared_error: 0.0413 - val_loss: 0.0158 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0194\n",
      "Epoch 43/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0310 - mae: 0.0310 - root_mean_squared_error: 0.0405 - val_loss: 0.0119 - val_mae: 0.0119 - val_root_mean_squared_error: 0.0150\n",
      "Epoch 44/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0370 - val_loss: 0.0325 - val_mae: 0.0325 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 45/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0289 - mae: 0.0289 - root_mean_squared_error: 0.0379 - val_loss: 0.0300 - val_mae: 0.0300 - val_root_mean_squared_error: 0.0328\n",
      "Epoch 46/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0295 - mae: 0.0295 - root_mean_squared_error: 0.0384 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0277\n",
      "Epoch 47/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0333 - mae: 0.0333 - root_mean_squared_error: 0.0430 - val_loss: 0.0219 - val_mae: 0.0219 - val_root_mean_squared_error: 0.0261\n",
      "Epoch 48/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0560 - val_loss: 0.0159 - val_mae: 0.0159 - val_root_mean_squared_error: 0.0182\n",
      "Epoch 49/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0483 - val_loss: 0.0090 - val_mae: 0.0090 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 50/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0280 - mae: 0.0280 - root_mean_squared_error: 0.0378 - val_loss: 0.0094 - val_mae: 0.0094 - val_root_mean_squared_error: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:46:28 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:46:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:46:36 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:46:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: input_width = 96 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.1219 - mae: 0.1219 - root_mean_squared_error: 0.1672 - val_loss: 0.1160 - val_mae: 0.1160 - val_root_mean_squared_error: 0.1334\n",
      "Epoch 2/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0976 - mae: 0.0976 - root_mean_squared_error: 0.1204 - val_loss: 0.1086 - val_mae: 0.1086 - val_root_mean_squared_error: 0.1262\n",
      "Epoch 3/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0966 - mae: 0.0966 - root_mean_squared_error: 0.1188 - val_loss: 0.1138 - val_mae: 0.1138 - val_root_mean_squared_error: 0.1312\n",
      "Epoch 4/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0954 - mae: 0.0954 - root_mean_squared_error: 0.1167 - val_loss: 0.1228 - val_mae: 0.1228 - val_root_mean_squared_error: 0.1396\n",
      "Epoch 5/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0953 - mae: 0.0953 - root_mean_squared_error: 0.1167 - val_loss: 0.0985 - val_mae: 0.0985 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 6/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0957 - mae: 0.0957 - root_mean_squared_error: 0.1174 - val_loss: 0.1053 - val_mae: 0.1053 - val_root_mean_squared_error: 0.1230\n",
      "Epoch 7/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0951 - mae: 0.0951 - root_mean_squared_error: 0.1170 - val_loss: 0.1105 - val_mae: 0.1105 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 8/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0950 - mae: 0.0950 - root_mean_squared_error: 0.1168 - val_loss: 0.1079 - val_mae: 0.1079 - val_root_mean_squared_error: 0.1255\n",
      "Epoch 9/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0905 - mae: 0.0905 - root_mean_squared_error: 0.1115 - val_loss: 0.1019 - val_mae: 0.1019 - val_root_mean_squared_error: 0.1197\n",
      "Epoch 10/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0908 - mae: 0.0908 - root_mean_squared_error: 0.1126 - val_loss: 0.1016 - val_mae: 0.1016 - val_root_mean_squared_error: 0.1194\n",
      "Epoch 11/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0899 - mae: 0.0899 - root_mean_squared_error: 0.1109 - val_loss: 0.0980 - val_mae: 0.0980 - val_root_mean_squared_error: 0.1157\n",
      "Epoch 12/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0902 - mae: 0.0902 - root_mean_squared_error: 0.1104 - val_loss: 0.0993 - val_mae: 0.0993 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 13/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0883 - mae: 0.0883 - root_mean_squared_error: 0.1087 - val_loss: 0.1151 - val_mae: 0.1151 - val_root_mean_squared_error: 0.1315\n",
      "Epoch 14/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0872 - mae: 0.0872 - root_mean_squared_error: 0.1072 - val_loss: 0.1053 - val_mae: 0.1053 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 15/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0860 - mae: 0.0860 - root_mean_squared_error: 0.1060 - val_loss: 0.1167 - val_mae: 0.1167 - val_root_mean_squared_error: 0.1330\n",
      "Epoch 16/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0853 - mae: 0.0853 - root_mean_squared_error: 0.1056 - val_loss: 0.1289 - val_mae: 0.1289 - val_root_mean_squared_error: 0.1445\n",
      "Epoch 17/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0846 - mae: 0.0846 - root_mean_squared_error: 0.1039 - val_loss: 0.1258 - val_mae: 0.1258 - val_root_mean_squared_error: 0.1419\n",
      "Epoch 18/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0840 - mae: 0.0840 - root_mean_squared_error: 0.1034 - val_loss: 0.1382 - val_mae: 0.1382 - val_root_mean_squared_error: 0.1533\n",
      "Epoch 19/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0807 - mae: 0.0807 - root_mean_squared_error: 0.0993 - val_loss: 0.1298 - val_mae: 0.1298 - val_root_mean_squared_error: 0.1455\n",
      "Epoch 20/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0820 - mae: 0.0820 - root_mean_squared_error: 0.1010 - val_loss: 0.1402 - val_mae: 0.1402 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 21/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0819 - mae: 0.0819 - root_mean_squared_error: 0.1004 - val_loss: 0.1425 - val_mae: 0.1425 - val_root_mean_squared_error: 0.1573\n",
      "Epoch 22/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0793 - mae: 0.0793 - root_mean_squared_error: 0.0980 - val_loss: 0.1378 - val_mae: 0.1378 - val_root_mean_squared_error: 0.1528\n",
      "Epoch 23/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0772 - mae: 0.0772 - root_mean_squared_error: 0.0965 - val_loss: 0.1402 - val_mae: 0.1402 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 24/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0776 - mae: 0.0776 - root_mean_squared_error: 0.0964 - val_loss: 0.1540 - val_mae: 0.1540 - val_root_mean_squared_error: 0.1678\n",
      "Epoch 25/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0764 - mae: 0.0764 - root_mean_squared_error: 0.0953 - val_loss: 0.1426 - val_mae: 0.1426 - val_root_mean_squared_error: 0.1572\n",
      "Epoch 26/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0745 - mae: 0.0745 - root_mean_squared_error: 0.0935 - val_loss: 0.1399 - val_mae: 0.1399 - val_root_mean_squared_error: 0.1541\n",
      "Epoch 27/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0715 - mae: 0.0715 - root_mean_squared_error: 0.0910 - val_loss: 0.1236 - val_mae: 0.1236 - val_root_mean_squared_error: 0.1379\n",
      "Epoch 28/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0697 - mae: 0.0697 - root_mean_squared_error: 0.0897 - val_loss: 0.1035 - val_mae: 0.1035 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 29/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0659 - mae: 0.0659 - root_mean_squared_error: 0.0862 - val_loss: 0.0783 - val_mae: 0.0783 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 30/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0520 - mae: 0.0520 - root_mean_squared_error: 0.0668 - val_loss: 0.0789 - val_mae: 0.0789 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 31/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0462 - mae: 0.0462 - root_mean_squared_error: 0.0594 - val_loss: 0.0733 - val_mae: 0.0733 - val_root_mean_squared_error: 0.0813\n",
      "Epoch 32/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0396 - mae: 0.0396 - root_mean_squared_error: 0.0508 - val_loss: 0.0552 - val_mae: 0.0552 - val_root_mean_squared_error: 0.0624\n",
      "Epoch 33/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0549 - val_loss: 0.0431 - val_mae: 0.0431 - val_root_mean_squared_error: 0.0507\n",
      "Epoch 34/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0491 - val_loss: 0.0429 - val_mae: 0.0429 - val_root_mean_squared_error: 0.0495\n",
      "Epoch 35/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0458 - val_loss: 0.0274 - val_mae: 0.0274 - val_root_mean_squared_error: 0.0333\n",
      "Epoch 36/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0465 - val_loss: 0.0318 - val_mae: 0.0318 - val_root_mean_squared_error: 0.0380\n",
      "Epoch 37/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0468 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0303\n",
      "Epoch 38/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0331 - mae: 0.0331 - root_mean_squared_error: 0.0434 - val_loss: 0.0278 - val_mae: 0.0278 - val_root_mean_squared_error: 0.0324\n",
      "Epoch 39/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0322 - mae: 0.0322 - root_mean_squared_error: 0.0421 - val_loss: 0.0184 - val_mae: 0.0184 - val_root_mean_squared_error: 0.0231\n",
      "Epoch 40/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0325 - mae: 0.0325 - root_mean_squared_error: 0.0423 - val_loss: 0.0142 - val_mae: 0.0142 - val_root_mean_squared_error: 0.0184\n",
      "Epoch 41/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0321 - mae: 0.0321 - root_mean_squared_error: 0.0421 - val_loss: 0.0150 - val_mae: 0.0150 - val_root_mean_squared_error: 0.0190\n",
      "Epoch 42/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0450 - val_loss: 0.0491 - val_mae: 0.0491 - val_root_mean_squared_error: 0.0529\n",
      "Epoch 43/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0322 - mae: 0.0322 - root_mean_squared_error: 0.0420 - val_loss: 0.0149 - val_mae: 0.0149 - val_root_mean_squared_error: 0.0189\n",
      "Epoch 44/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0306 - mae: 0.0306 - root_mean_squared_error: 0.0397 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0284\n",
      "Epoch 45/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0326 - mae: 0.0326 - root_mean_squared_error: 0.0423 - val_loss: 0.0390 - val_mae: 0.0390 - val_root_mean_squared_error: 0.0424\n",
      "Epoch 46/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0319 - mae: 0.0319 - root_mean_squared_error: 0.0418 - val_loss: 0.0222 - val_mae: 0.0222 - val_root_mean_squared_error: 0.0261\n",
      "Epoch 47/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0315 - mae: 0.0315 - root_mean_squared_error: 0.0412 - val_loss: 0.0204 - val_mae: 0.0204 - val_root_mean_squared_error: 0.0245\n",
      "Epoch 48/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0306 - mae: 0.0306 - root_mean_squared_error: 0.0401 - val_loss: 0.0183 - val_mae: 0.0183 - val_root_mean_squared_error: 0.0226\n",
      "Epoch 49/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0432 - val_loss: 0.0180 - val_mae: 0.0180 - val_root_mean_squared_error: 0.0221\n",
      "Epoch 50/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0333 - mae: 0.0333 - root_mean_squared_error: 0.0433 - val_loss: 0.0163 - val_mae: 0.0163 - val_root_mean_squared_error: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:49:22 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:49:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:49:30 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:49:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 19:49:49 INFO mlflow.tracking.fluent: Experiment with name 'gru_batch_size_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: batch_size = 16 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0822 - mae: 0.0822 - root_mean_squared_error: 0.1216 - val_loss: 0.0726 - val_mae: 0.0726 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 2/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0621 - mae: 0.0621 - root_mean_squared_error: 0.0801 - val_loss: 0.0972 - val_mae: 0.0972 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 3/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0567 - mae: 0.0567 - root_mean_squared_error: 0.0728 - val_loss: 0.0930 - val_mae: 0.0930 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 4/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0550 - mae: 0.0550 - root_mean_squared_error: 0.0711 - val_loss: 0.0868 - val_mae: 0.0868 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 5/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0543 - mae: 0.0543 - root_mean_squared_error: 0.0699 - val_loss: 0.0896 - val_mae: 0.0896 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 6/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0538 - mae: 0.0538 - root_mean_squared_error: 0.0696 - val_loss: 0.1021 - val_mae: 0.1021 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 7/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0538 - mae: 0.0538 - root_mean_squared_error: 0.0693 - val_loss: 0.0815 - val_mae: 0.0815 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 8/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0543 - mae: 0.0543 - root_mean_squared_error: 0.0705 - val_loss: 0.0818 - val_mae: 0.0818 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 9/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0525 - mae: 0.0525 - root_mean_squared_error: 0.0685 - val_loss: 0.0808 - val_mae: 0.0808 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 10/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0532 - mae: 0.0532 - root_mean_squared_error: 0.0701 - val_loss: 0.0765 - val_mae: 0.0765 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 11/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0520 - mae: 0.0520 - root_mean_squared_error: 0.0673 - val_loss: 0.0821 - val_mae: 0.0821 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 12/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0520 - mae: 0.0520 - root_mean_squared_error: 0.0679 - val_loss: 0.0872 - val_mae: 0.0872 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 13/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0497 - mae: 0.0497 - root_mean_squared_error: 0.0651 - val_loss: 0.0796 - val_mae: 0.0796 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 14/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0503 - mae: 0.0503 - root_mean_squared_error: 0.0658 - val_loss: 0.0749 - val_mae: 0.0749 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 15/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0497 - mae: 0.0497 - root_mean_squared_error: 0.0654 - val_loss: 0.0642 - val_mae: 0.0642 - val_root_mean_squared_error: 0.0759\n",
      "Epoch 16/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0489 - mae: 0.0489 - root_mean_squared_error: 0.0643 - val_loss: 0.0704 - val_mae: 0.0704 - val_root_mean_squared_error: 0.0823\n",
      "Epoch 17/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0468 - mae: 0.0468 - root_mean_squared_error: 0.0607 - val_loss: 0.0726 - val_mae: 0.0726 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 18/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0455 - mae: 0.0455 - root_mean_squared_error: 0.0589 - val_loss: 0.0772 - val_mae: 0.0772 - val_root_mean_squared_error: 0.0882\n",
      "Epoch 19/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0440 - mae: 0.0440 - root_mean_squared_error: 0.0575 - val_loss: 0.0583 - val_mae: 0.0583 - val_root_mean_squared_error: 0.0682\n",
      "Epoch 20/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0431 - mae: 0.0431 - root_mean_squared_error: 0.0560 - val_loss: 0.0658 - val_mae: 0.0658 - val_root_mean_squared_error: 0.0747\n",
      "Epoch 21/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0526 - val_loss: 0.0529 - val_mae: 0.0529 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 22/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0391 - mae: 0.0391 - root_mean_squared_error: 0.0510 - val_loss: 0.0721 - val_mae: 0.0721 - val_root_mean_squared_error: 0.0779\n",
      "Epoch 23/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0499 - val_loss: 0.0701 - val_mae: 0.0701 - val_root_mean_squared_error: 0.0747\n",
      "Epoch 24/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0452 - val_loss: 0.0577 - val_mae: 0.0577 - val_root_mean_squared_error: 0.0615\n",
      "Epoch 25/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0331 - mae: 0.0331 - root_mean_squared_error: 0.0433 - val_loss: 0.0312 - val_mae: 0.0312 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 26/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0315 - mae: 0.0315 - root_mean_squared_error: 0.0408 - val_loss: 0.0399 - val_mae: 0.0399 - val_root_mean_squared_error: 0.0418\n",
      "Epoch 27/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0294 - mae: 0.0294 - root_mean_squared_error: 0.0385 - val_loss: 0.0207 - val_mae: 0.0207 - val_root_mean_squared_error: 0.0224\n",
      "Epoch 28/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0345 - val_loss: 0.0111 - val_mae: 0.0111 - val_root_mean_squared_error: 0.0133\n",
      "Epoch 29/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0282 - mae: 0.0282 - root_mean_squared_error: 0.0364 - val_loss: 0.0193 - val_mae: 0.0193 - val_root_mean_squared_error: 0.0214\n",
      "Epoch 30/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0263 - mae: 0.0263 - root_mean_squared_error: 0.0346 - val_loss: 0.0144 - val_mae: 0.0144 - val_root_mean_squared_error: 0.0167\n",
      "Epoch 31/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0262 - mae: 0.0262 - root_mean_squared_error: 0.0339 - val_loss: 0.0072 - val_mae: 0.0072 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 32/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0257 - mae: 0.0257 - root_mean_squared_error: 0.0338 - val_loss: 0.0143 - val_mae: 0.0143 - val_root_mean_squared_error: 0.0166\n",
      "Epoch 33/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0348 - val_loss: 0.0175 - val_mae: 0.0175 - val_root_mean_squared_error: 0.0199\n",
      "Epoch 34/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0243 - mae: 0.0243 - root_mean_squared_error: 0.0317 - val_loss: 0.0219 - val_mae: 0.0219 - val_root_mean_squared_error: 0.0242\n",
      "Epoch 35/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0241 - mae: 0.0241 - root_mean_squared_error: 0.0323 - val_loss: 0.0301 - val_mae: 0.0301 - val_root_mean_squared_error: 0.0319\n",
      "Epoch 36/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0239 - mae: 0.0239 - root_mean_squared_error: 0.0320 - val_loss: 0.0260 - val_mae: 0.0260 - val_root_mean_squared_error: 0.0280\n",
      "Epoch 37/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0256 - mae: 0.0256 - root_mean_squared_error: 0.0332 - val_loss: 0.0113 - val_mae: 0.0113 - val_root_mean_squared_error: 0.0131\n",
      "Epoch 38/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0247 - mae: 0.0247 - root_mean_squared_error: 0.0326 - val_loss: 0.0138 - val_mae: 0.0138 - val_root_mean_squared_error: 0.0154\n",
      "Epoch 39/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0246 - mae: 0.0246 - root_mean_squared_error: 0.0321 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 40/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0235 - mae: 0.0235 - root_mean_squared_error: 0.0312 - val_loss: 0.0255 - val_mae: 0.0255 - val_root_mean_squared_error: 0.0262\n",
      "Epoch 41/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0244 - mae: 0.0244 - root_mean_squared_error: 0.0317 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0252\n",
      "Epoch 42/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0216 - mae: 0.0216 - root_mean_squared_error: 0.0284 - val_loss: 0.0274 - val_mae: 0.0274 - val_root_mean_squared_error: 0.0280\n",
      "Epoch 43/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0228 - mae: 0.0228 - root_mean_squared_error: 0.0301 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0244\n",
      "Epoch 44/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0200 - mae: 0.0200 - root_mean_squared_error: 0.0265 - val_loss: 0.0120 - val_mae: 0.0120 - val_root_mean_squared_error: 0.0129\n",
      "Epoch 45/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0220 - mae: 0.0220 - root_mean_squared_error: 0.0286 - val_loss: 0.0123 - val_mae: 0.0123 - val_root_mean_squared_error: 0.0135\n",
      "Epoch 46/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0224 - mae: 0.0224 - root_mean_squared_error: 0.0306 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0062\n",
      "Epoch 47/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0198 - mae: 0.0198 - root_mean_squared_error: 0.0263 - val_loss: 0.0134 - val_mae: 0.0134 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 48/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195 - mae: 0.0195 - root_mean_squared_error: 0.0255 - val_loss: 0.0062 - val_mae: 0.0062 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 49/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0199 - mae: 0.0199 - root_mean_squared_error: 0.0265 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 50/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0213 - mae: 0.0213 - root_mean_squared_error: 0.0278 - val_loss: 0.0055 - val_mae: 0.0055 - val_root_mean_squared_error: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:51:08 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:51:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:51:16 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:51:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: batch_size = 32 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1032 - mae: 0.1032 - root_mean_squared_error: 0.1527 - val_loss: 0.0721 - val_mae: 0.0721 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0690 - mae: 0.0690 - root_mean_squared_error: 0.0884 - val_loss: 0.0606 - val_mae: 0.0606 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0654 - mae: 0.0654 - root_mean_squared_error: 0.0840 - val_loss: 0.0494 - val_mae: 0.0494 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0627 - mae: 0.0627 - root_mean_squared_error: 0.0800 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0766 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0748 - val_loss: 0.0751 - val_mae: 0.0751 - val_root_mean_squared_error: 0.0853\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0549 - mae: 0.0549 - root_mean_squared_error: 0.0707 - val_loss: 0.0591 - val_mae: 0.0591 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0553 - mae: 0.0553 - root_mean_squared_error: 0.0714 - val_loss: 0.0575 - val_mae: 0.0575 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0523 - mae: 0.0523 - root_mean_squared_error: 0.0677 - val_loss: 0.0613 - val_mae: 0.0613 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0502 - mae: 0.0502 - root_mean_squared_error: 0.0653 - val_loss: 0.0652 - val_mae: 0.0652 - val_root_mean_squared_error: 0.0753\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0473 - mae: 0.0473 - root_mean_squared_error: 0.0612 - val_loss: 0.0603 - val_mae: 0.0603 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0463 - mae: 0.0463 - root_mean_squared_error: 0.0602 - val_loss: 0.0692 - val_mae: 0.0692 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0461 - mae: 0.0461 - root_mean_squared_error: 0.0591 - val_loss: 0.0643 - val_mae: 0.0643 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0571 - val_loss: 0.0618 - val_mae: 0.0618 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0548 - val_loss: 0.0625 - val_mae: 0.0625 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0524 - val_loss: 0.0414 - val_mae: 0.0414 - val_root_mean_squared_error: 0.0491\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0503 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0514\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0504 - val_loss: 0.0349 - val_mae: 0.0349 - val_root_mean_squared_error: 0.0416\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0523 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0432\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0458 - val_loss: 0.0422 - val_mae: 0.0422 - val_root_mean_squared_error: 0.0469\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0452 - val_loss: 0.0327 - val_mae: 0.0327 - val_root_mean_squared_error: 0.0380\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0434 - val_loss: 0.0252 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0302\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0478 - val_loss: 0.0402 - val_mae: 0.0402 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0366 - mae: 0.0366 - root_mean_squared_error: 0.0484 - val_loss: 0.0275 - val_mae: 0.0275 - val_root_mean_squared_error: 0.0326\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0449 - val_loss: 0.0151 - val_mae: 0.0151 - val_root_mean_squared_error: 0.0188\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0322 - mae: 0.0322 - root_mean_squared_error: 0.0419 - val_loss: 0.0451 - val_mae: 0.0451 - val_root_mean_squared_error: 0.0495\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0444 - val_loss: 0.0302 - val_mae: 0.0302 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0469 - val_loss: 0.0226 - val_mae: 0.0226 - val_root_mean_squared_error: 0.0270\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0426 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0422\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0323 - mae: 0.0323 - root_mean_squared_error: 0.0424 - val_loss: 0.0348 - val_mae: 0.0348 - val_root_mean_squared_error: 0.0395\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0310 - mae: 0.0310 - root_mean_squared_error: 0.0404 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0314\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0315 - mae: 0.0315 - root_mean_squared_error: 0.0418 - val_loss: 0.0111 - val_mae: 0.0111 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0291 - mae: 0.0291 - root_mean_squared_error: 0.0377 - val_loss: 0.0278 - val_mae: 0.0278 - val_root_mean_squared_error: 0.0318\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0277 - mae: 0.0277 - root_mean_squared_error: 0.0367 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0294 - mae: 0.0294 - root_mean_squared_error: 0.0380 - val_loss: 0.0256 - val_mae: 0.0256 - val_root_mean_squared_error: 0.0300\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0283 - mae: 0.0283 - root_mean_squared_error: 0.0373 - val_loss: 0.0377 - val_mae: 0.0377 - val_root_mean_squared_error: 0.0414\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0282 - mae: 0.0282 - root_mean_squared_error: 0.0371 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0278\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0369 - val_loss: 0.0124 - val_mae: 0.0124 - val_root_mean_squared_error: 0.0153\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0365 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0205\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0374 - val_loss: 0.0132 - val_mae: 0.0132 - val_root_mean_squared_error: 0.0161\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0253 - mae: 0.0253 - root_mean_squared_error: 0.0336 - val_loss: 0.0287 - val_mae: 0.0287 - val_root_mean_squared_error: 0.0321\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0378 - val_loss: 0.0163 - val_mae: 0.0163 - val_root_mean_squared_error: 0.0195\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0349 - val_loss: 0.0128 - val_mae: 0.0128 - val_root_mean_squared_error: 0.0155\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0269 - mae: 0.0269 - root_mean_squared_error: 0.0351 - val_loss: 0.0190 - val_mae: 0.0190 - val_root_mean_squared_error: 0.0221\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0250 - mae: 0.0250 - root_mean_squared_error: 0.0330 - val_loss: 0.0160 - val_mae: 0.0160 - val_root_mean_squared_error: 0.0185\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0233 - mae: 0.0233 - root_mean_squared_error: 0.0309 - val_loss: 0.0087 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0109\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0279 - mae: 0.0279 - root_mean_squared_error: 0.0366 - val_loss: 0.0109 - val_mae: 0.0109 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0354 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0225 - mae: 0.0225 - root_mean_squared_error: 0.0294 - val_loss: 0.0140 - val_mae: 0.0140 - val_root_mean_squared_error: 0.0160\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0232 - mae: 0.0232 - root_mean_squared_error: 0.0305 - val_loss: 0.0072 - val_mae: 0.0072 - val_root_mean_squared_error: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:52:30 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:52:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:52:37 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:52:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: batch_size = 64 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1808 - mae: 0.1808 - root_mean_squared_error: 0.2368 - val_loss: 0.0932 - val_mae: 0.0932 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 2/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0927 - mae: 0.0927 - root_mean_squared_error: 0.1164 - val_loss: 0.0963 - val_mae: 0.0963 - val_root_mean_squared_error: 0.1056\n",
      "Epoch 3/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0792 - mae: 0.0792 - root_mean_squared_error: 0.1002 - val_loss: 0.0863 - val_mae: 0.0863 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 4/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0712 - mae: 0.0712 - root_mean_squared_error: 0.0903 - val_loss: 0.0851 - val_mae: 0.0851 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 5/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0639 - mae: 0.0639 - root_mean_squared_error: 0.0824 - val_loss: 0.0875 - val_mae: 0.0875 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 6/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0618 - mae: 0.0618 - root_mean_squared_error: 0.0793 - val_loss: 0.0770 - val_mae: 0.0770 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 7/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0599 - mae: 0.0599 - root_mean_squared_error: 0.0766 - val_loss: 0.1037 - val_mae: 0.1037 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 8/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0601 - mae: 0.0601 - root_mean_squared_error: 0.0766 - val_loss: 0.1269 - val_mae: 0.1269 - val_root_mean_squared_error: 0.1349\n",
      "Epoch 9/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0588 - mae: 0.0588 - root_mean_squared_error: 0.0746 - val_loss: 0.1372 - val_mae: 0.1372 - val_root_mean_squared_error: 0.1455\n",
      "Epoch 10/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0605 - mae: 0.0605 - root_mean_squared_error: 0.0768 - val_loss: 0.1507 - val_mae: 0.1507 - val_root_mean_squared_error: 0.1588\n",
      "Epoch 11/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0587 - mae: 0.0587 - root_mean_squared_error: 0.0746 - val_loss: 0.1400 - val_mae: 0.1400 - val_root_mean_squared_error: 0.1489\n",
      "Epoch 12/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0602 - mae: 0.0602 - root_mean_squared_error: 0.0760 - val_loss: 0.1456 - val_mae: 0.1456 - val_root_mean_squared_error: 0.1542\n",
      "Epoch 13/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0600 - mae: 0.0600 - root_mean_squared_error: 0.0759 - val_loss: 0.1418 - val_mae: 0.1418 - val_root_mean_squared_error: 0.1509\n",
      "Epoch 14/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0584 - mae: 0.0584 - root_mean_squared_error: 0.0739 - val_loss: 0.1388 - val_mae: 0.1388 - val_root_mean_squared_error: 0.1481\n",
      "Epoch 15/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0574 - mae: 0.0574 - root_mean_squared_error: 0.0730 - val_loss: 0.1448 - val_mae: 0.1448 - val_root_mean_squared_error: 0.1540\n",
      "Epoch 16/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0577 - mae: 0.0577 - root_mean_squared_error: 0.0733 - val_loss: 0.1248 - val_mae: 0.1248 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 17/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0562 - mae: 0.0562 - root_mean_squared_error: 0.0718 - val_loss: 0.1331 - val_mae: 0.1331 - val_root_mean_squared_error: 0.1428\n",
      "Epoch 18/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0541 - mae: 0.0541 - root_mean_squared_error: 0.0692 - val_loss: 0.1346 - val_mae: 0.1346 - val_root_mean_squared_error: 0.1441\n",
      "Epoch 19/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0529 - mae: 0.0529 - root_mean_squared_error: 0.0676 - val_loss: 0.1304 - val_mae: 0.1304 - val_root_mean_squared_error: 0.1402\n",
      "Epoch 20/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0532 - mae: 0.0532 - root_mean_squared_error: 0.0681 - val_loss: 0.1320 - val_mae: 0.1320 - val_root_mean_squared_error: 0.1415\n",
      "Epoch 21/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0511 - mae: 0.0511 - root_mean_squared_error: 0.0652 - val_loss: 0.1344 - val_mae: 0.1344 - val_root_mean_squared_error: 0.1436\n",
      "Epoch 22/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0510 - mae: 0.0510 - root_mean_squared_error: 0.0660 - val_loss: 0.1323 - val_mae: 0.1323 - val_root_mean_squared_error: 0.1414\n",
      "Epoch 23/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0506 - mae: 0.0506 - root_mean_squared_error: 0.0649 - val_loss: 0.1277 - val_mae: 0.1277 - val_root_mean_squared_error: 0.1371\n",
      "Epoch 24/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0637 - val_loss: 0.1317 - val_mae: 0.1317 - val_root_mean_squared_error: 0.1404\n",
      "Epoch 25/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0496 - mae: 0.0496 - root_mean_squared_error: 0.0638 - val_loss: 0.1250 - val_mae: 0.1250 - val_root_mean_squared_error: 0.1337\n",
      "Epoch 26/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0480 - mae: 0.0480 - root_mean_squared_error: 0.0624 - val_loss: 0.1091 - val_mae: 0.1091 - val_root_mean_squared_error: 0.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:53:20 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:53:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:53:28 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:53:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: batch_size = 128 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.2085 - mae: 0.2085 - root_mean_squared_error: 0.2844 - val_loss: 0.0411 - val_mae: 0.0411 - val_root_mean_squared_error: 0.0517\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1084 - mae: 0.1084 - root_mean_squared_error: 0.1391 - val_loss: 0.0491 - val_mae: 0.0491 - val_root_mean_squared_error: 0.0591\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1113 - mae: 0.1113 - root_mean_squared_error: 0.1403 - val_loss: 0.0354 - val_mae: 0.0354 - val_root_mean_squared_error: 0.0460\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0909 - mae: 0.0909 - root_mean_squared_error: 0.1157 - val_loss: 0.0408 - val_mae: 0.0408 - val_root_mean_squared_error: 0.0507\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0788 - mae: 0.0788 - root_mean_squared_error: 0.1011 - val_loss: 0.0444 - val_mae: 0.0444 - val_root_mean_squared_error: 0.0539\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0726 - mae: 0.0726 - root_mean_squared_error: 0.0932 - val_loss: 0.0442 - val_mae: 0.0442 - val_root_mean_squared_error: 0.0534\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0691 - mae: 0.0691 - root_mean_squared_error: 0.0890 - val_loss: 0.0425 - val_mae: 0.0425 - val_root_mean_squared_error: 0.0514\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0666 - mae: 0.0666 - root_mean_squared_error: 0.0859 - val_loss: 0.0353 - val_mae: 0.0353 - val_root_mean_squared_error: 0.0441\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0638 - mae: 0.0638 - root_mean_squared_error: 0.0826 - val_loss: 0.0297 - val_mae: 0.0297 - val_root_mean_squared_error: 0.0388\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0620 - mae: 0.0620 - root_mean_squared_error: 0.0795 - val_loss: 0.0282 - val_mae: 0.0282 - val_root_mean_squared_error: 0.0374\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0618 - mae: 0.0618 - root_mean_squared_error: 0.0804 - val_loss: 0.0302 - val_mae: 0.0302 - val_root_mean_squared_error: 0.0390\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0598 - mae: 0.0598 - root_mean_squared_error: 0.0773 - val_loss: 0.0335 - val_mae: 0.0335 - val_root_mean_squared_error: 0.0422\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0605 - mae: 0.0605 - root_mean_squared_error: 0.0777 - val_loss: 0.0390 - val_mae: 0.0390 - val_root_mean_squared_error: 0.0479\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0606 - mae: 0.0606 - root_mean_squared_error: 0.0779 - val_loss: 0.0418 - val_mae: 0.0418 - val_root_mean_squared_error: 0.0508\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0640 - mae: 0.0640 - root_mean_squared_error: 0.0822 - val_loss: 0.0426 - val_mae: 0.0426 - val_root_mean_squared_error: 0.0516\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0664 - mae: 0.0664 - root_mean_squared_error: 0.0852 - val_loss: 0.0412 - val_mae: 0.0412 - val_root_mean_squared_error: 0.0500\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0674 - mae: 0.0674 - root_mean_squared_error: 0.0860 - val_loss: 0.0447 - val_mae: 0.0447 - val_root_mean_squared_error: 0.0538\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0711 - mae: 0.0711 - root_mean_squared_error: 0.0907 - val_loss: 0.0449 - val_mae: 0.0449 - val_root_mean_squared_error: 0.0541\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0769 - mae: 0.0769 - root_mean_squared_error: 0.0968 - val_loss: 0.0462 - val_mae: 0.0462 - val_root_mean_squared_error: 0.0555\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0745 - mae: 0.0745 - root_mean_squared_error: 0.0941 - val_loss: 0.0462 - val_mae: 0.0462 - val_root_mean_squared_error: 0.0556\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0710 - mae: 0.0710 - root_mean_squared_error: 0.0902 - val_loss: 0.0465 - val_mae: 0.0465 - val_root_mean_squared_error: 0.0559\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0685 - mae: 0.0685 - root_mean_squared_error: 0.0868 - val_loss: 0.0446 - val_mae: 0.0446 - val_root_mean_squared_error: 0.0537\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0660 - mae: 0.0660 - root_mean_squared_error: 0.0846 - val_loss: 0.0436 - val_mae: 0.0436 - val_root_mean_squared_error: 0.0526\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0646 - mae: 0.0646 - root_mean_squared_error: 0.0825 - val_loss: 0.0469 - val_mae: 0.0469 - val_root_mean_squared_error: 0.0564\n",
      "Epoch 25/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0632 - mae: 0.0632 - root_mean_squared_error: 0.0813 - val_loss: 0.0465 - val_mae: 0.0465 - val_root_mean_squared_error: 0.0559\n",
      "Epoch 26/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0639 - mae: 0.0639 - root_mean_squared_error: 0.0816 - val_loss: 0.0453 - val_mae: 0.0453 - val_root_mean_squared_error: 0.0545\n",
      "Epoch 27/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0631 - mae: 0.0631 - root_mean_squared_error: 0.0811 - val_loss: 0.0457 - val_mae: 0.0457 - val_root_mean_squared_error: 0.0550\n",
      "Epoch 28/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0623 - mae: 0.0623 - root_mean_squared_error: 0.0795 - val_loss: 0.0462 - val_mae: 0.0462 - val_root_mean_squared_error: 0.0555\n",
      "Epoch 29/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0607 - mae: 0.0607 - root_mean_squared_error: 0.0776 - val_loss: 0.0451 - val_mae: 0.0451 - val_root_mean_squared_error: 0.0542\n",
      "Epoch 30/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0615 - mae: 0.0615 - root_mean_squared_error: 0.0787 - val_loss: 0.0426 - val_mae: 0.0426 - val_root_mean_squared_error: 0.0514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:54:07 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:54:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:54:15 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:54:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 19:54:39 INFO mlflow.tracking.fluent: Experiment with name 'gru_learning_rate_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: learning_rate = 0.0001 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.3112 - mae: 0.3112 - root_mean_squared_error: 0.3716 - val_loss: 0.1348 - val_mae: 0.1348 - val_root_mean_squared_error: 0.1433\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1047 - mae: 0.1047 - root_mean_squared_error: 0.1306 - val_loss: 0.0618 - val_mae: 0.0618 - val_root_mean_squared_error: 0.0735\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0935 - mae: 0.0935 - root_mean_squared_error: 0.1173 - val_loss: 0.0577 - val_mae: 0.0577 - val_root_mean_squared_error: 0.0693\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0843 - mae: 0.0843 - root_mean_squared_error: 0.1058 - val_loss: 0.0539 - val_mae: 0.0539 - val_root_mean_squared_error: 0.0654\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0775 - mae: 0.0775 - root_mean_squared_error: 0.0992 - val_loss: 0.0447 - val_mae: 0.0447 - val_root_mean_squared_error: 0.0566\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0730 - mae: 0.0730 - root_mean_squared_error: 0.0938 - val_loss: 0.0479 - val_mae: 0.0479 - val_root_mean_squared_error: 0.0595\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0685 - mae: 0.0685 - root_mean_squared_error: 0.0885 - val_loss: 0.0366 - val_mae: 0.0366 - val_root_mean_squared_error: 0.0486\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0665 - mae: 0.0665 - root_mean_squared_error: 0.0859 - val_loss: 0.0398 - val_mae: 0.0398 - val_root_mean_squared_error: 0.0517\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0631 - mae: 0.0631 - root_mean_squared_error: 0.0818 - val_loss: 0.0417 - val_mae: 0.0417 - val_root_mean_squared_error: 0.0534\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0627 - mae: 0.0627 - root_mean_squared_error: 0.0816 - val_loss: 0.0339 - val_mae: 0.0339 - val_root_mean_squared_error: 0.0457\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0604 - mae: 0.0604 - root_mean_squared_error: 0.0789 - val_loss: 0.0465 - val_mae: 0.0465 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0592 - mae: 0.0592 - root_mean_squared_error: 0.0764 - val_loss: 0.0328 - val_mae: 0.0328 - val_root_mean_squared_error: 0.0443\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0584 - mae: 0.0584 - root_mean_squared_error: 0.0755 - val_loss: 0.0327 - val_mae: 0.0327 - val_root_mean_squared_error: 0.0441\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0579 - mae: 0.0579 - root_mean_squared_error: 0.0749 - val_loss: 0.0328 - val_mae: 0.0328 - val_root_mean_squared_error: 0.0440\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0578 - mae: 0.0578 - root_mean_squared_error: 0.0748 - val_loss: 0.0372 - val_mae: 0.0372 - val_root_mean_squared_error: 0.0480\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0570 - mae: 0.0570 - root_mean_squared_error: 0.0739 - val_loss: 0.0328 - val_mae: 0.0328 - val_root_mean_squared_error: 0.0436\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0561 - mae: 0.0561 - root_mean_squared_error: 0.0729 - val_loss: 0.0313 - val_mae: 0.0313 - val_root_mean_squared_error: 0.0420\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0559 - mae: 0.0559 - root_mean_squared_error: 0.0726 - val_loss: 0.0331 - val_mae: 0.0331 - val_root_mean_squared_error: 0.0435\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0546 - mae: 0.0546 - root_mean_squared_error: 0.0711 - val_loss: 0.0310 - val_mae: 0.0310 - val_root_mean_squared_error: 0.0412\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0543 - mae: 0.0543 - root_mean_squared_error: 0.0703 - val_loss: 0.0343 - val_mae: 0.0343 - val_root_mean_squared_error: 0.0443\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0539 - mae: 0.0539 - root_mean_squared_error: 0.0694 - val_loss: 0.0362 - val_mae: 0.0362 - val_root_mean_squared_error: 0.0460\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0534 - mae: 0.0534 - root_mean_squared_error: 0.0688 - val_loss: 0.0351 - val_mae: 0.0351 - val_root_mean_squared_error: 0.0449\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0531 - mae: 0.0531 - root_mean_squared_error: 0.0688 - val_loss: 0.0386 - val_mae: 0.0386 - val_root_mean_squared_error: 0.0481\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0527 - mae: 0.0527 - root_mean_squared_error: 0.0681 - val_loss: 0.0426 - val_mae: 0.0426 - val_root_mean_squared_error: 0.0517\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0524 - mae: 0.0524 - root_mean_squared_error: 0.0685 - val_loss: 0.0414 - val_mae: 0.0414 - val_root_mean_squared_error: 0.0505\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0518 - mae: 0.0518 - root_mean_squared_error: 0.0673 - val_loss: 0.0377 - val_mae: 0.0377 - val_root_mean_squared_error: 0.0469\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0507 - mae: 0.0507 - root_mean_squared_error: 0.0658 - val_loss: 0.0544 - val_mae: 0.0544 - val_root_mean_squared_error: 0.0624\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0511 - mae: 0.0511 - root_mean_squared_error: 0.0664 - val_loss: 0.0436 - val_mae: 0.0436 - val_root_mean_squared_error: 0.0523\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0511 - mae: 0.0511 - root_mean_squared_error: 0.0664 - val_loss: 0.0524 - val_mae: 0.0524 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0504 - mae: 0.0504 - root_mean_squared_error: 0.0655 - val_loss: 0.0537 - val_mae: 0.0537 - val_root_mean_squared_error: 0.0617\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0490 - mae: 0.0490 - root_mean_squared_error: 0.0635 - val_loss: 0.0522 - val_mae: 0.0522 - val_root_mean_squared_error: 0.0603\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0505 - mae: 0.0505 - root_mean_squared_error: 0.0659 - val_loss: 0.0407 - val_mae: 0.0407 - val_root_mean_squared_error: 0.0494\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0636 - val_loss: 0.0511 - val_mae: 0.0511 - val_root_mean_squared_error: 0.0593\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0491 - mae: 0.0491 - root_mean_squared_error: 0.0636 - val_loss: 0.0486 - val_mae: 0.0486 - val_root_mean_squared_error: 0.0570\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0635 - val_loss: 0.0547 - val_mae: 0.0547 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0482 - mae: 0.0482 - root_mean_squared_error: 0.0627 - val_loss: 0.0532 - val_mae: 0.0532 - val_root_mean_squared_error: 0.0617\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0481 - mae: 0.0481 - root_mean_squared_error: 0.0621 - val_loss: 0.0621 - val_mae: 0.0621 - val_root_mean_squared_error: 0.0701\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0475 - mae: 0.0475 - root_mean_squared_error: 0.0616 - val_loss: 0.0474 - val_mae: 0.0474 - val_root_mean_squared_error: 0.0562\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0481 - mae: 0.0481 - root_mean_squared_error: 0.0626 - val_loss: 0.0573 - val_mae: 0.0573 - val_root_mean_squared_error: 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:55:18 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:55:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:55:26 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:55:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: learning_rate = 0.001 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1032 - mae: 0.1032 - root_mean_squared_error: 0.1527 - val_loss: 0.0721 - val_mae: 0.0721 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0690 - mae: 0.0690 - root_mean_squared_error: 0.0884 - val_loss: 0.0606 - val_mae: 0.0606 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0654 - mae: 0.0654 - root_mean_squared_error: 0.0840 - val_loss: 0.0494 - val_mae: 0.0494 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0627 - mae: 0.0627 - root_mean_squared_error: 0.0800 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0766 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0748 - val_loss: 0.0751 - val_mae: 0.0751 - val_root_mean_squared_error: 0.0853\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0549 - mae: 0.0549 - root_mean_squared_error: 0.0707 - val_loss: 0.0591 - val_mae: 0.0591 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0553 - mae: 0.0553 - root_mean_squared_error: 0.0714 - val_loss: 0.0575 - val_mae: 0.0575 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0523 - mae: 0.0523 - root_mean_squared_error: 0.0677 - val_loss: 0.0613 - val_mae: 0.0613 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0502 - mae: 0.0502 - root_mean_squared_error: 0.0653 - val_loss: 0.0652 - val_mae: 0.0652 - val_root_mean_squared_error: 0.0753\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0473 - mae: 0.0473 - root_mean_squared_error: 0.0612 - val_loss: 0.0603 - val_mae: 0.0603 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0463 - mae: 0.0463 - root_mean_squared_error: 0.0602 - val_loss: 0.0692 - val_mae: 0.0692 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0461 - mae: 0.0461 - root_mean_squared_error: 0.0591 - val_loss: 0.0643 - val_mae: 0.0643 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0571 - val_loss: 0.0618 - val_mae: 0.0618 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0548 - val_loss: 0.0625 - val_mae: 0.0625 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0524 - val_loss: 0.0414 - val_mae: 0.0414 - val_root_mean_squared_error: 0.0491\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0503 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0514\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0504 - val_loss: 0.0349 - val_mae: 0.0349 - val_root_mean_squared_error: 0.0416\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0523 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0432\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0458 - val_loss: 0.0422 - val_mae: 0.0422 - val_root_mean_squared_error: 0.0469\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0452 - val_loss: 0.0327 - val_mae: 0.0327 - val_root_mean_squared_error: 0.0380\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0434 - val_loss: 0.0252 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0302\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0478 - val_loss: 0.0402 - val_mae: 0.0402 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0366 - mae: 0.0366 - root_mean_squared_error: 0.0484 - val_loss: 0.0275 - val_mae: 0.0275 - val_root_mean_squared_error: 0.0326\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0449 - val_loss: 0.0151 - val_mae: 0.0151 - val_root_mean_squared_error: 0.0188\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0322 - mae: 0.0322 - root_mean_squared_error: 0.0419 - val_loss: 0.0451 - val_mae: 0.0451 - val_root_mean_squared_error: 0.0495\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0444 - val_loss: 0.0302 - val_mae: 0.0302 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0469 - val_loss: 0.0226 - val_mae: 0.0226 - val_root_mean_squared_error: 0.0270\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0426 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0422\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0323 - mae: 0.0323 - root_mean_squared_error: 0.0424 - val_loss: 0.0348 - val_mae: 0.0348 - val_root_mean_squared_error: 0.0395\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0310 - mae: 0.0310 - root_mean_squared_error: 0.0404 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0314\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0315 - mae: 0.0315 - root_mean_squared_error: 0.0418 - val_loss: 0.0111 - val_mae: 0.0111 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0291 - mae: 0.0291 - root_mean_squared_error: 0.0377 - val_loss: 0.0278 - val_mae: 0.0278 - val_root_mean_squared_error: 0.0318\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0277 - mae: 0.0277 - root_mean_squared_error: 0.0367 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0294 - mae: 0.0294 - root_mean_squared_error: 0.0380 - val_loss: 0.0256 - val_mae: 0.0256 - val_root_mean_squared_error: 0.0300\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0283 - mae: 0.0283 - root_mean_squared_error: 0.0373 - val_loss: 0.0377 - val_mae: 0.0377 - val_root_mean_squared_error: 0.0414\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0282 - mae: 0.0282 - root_mean_squared_error: 0.0371 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0278\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0369 - val_loss: 0.0124 - val_mae: 0.0124 - val_root_mean_squared_error: 0.0153\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0365 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0205\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0374 - val_loss: 0.0132 - val_mae: 0.0132 - val_root_mean_squared_error: 0.0161\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0253 - mae: 0.0253 - root_mean_squared_error: 0.0336 - val_loss: 0.0287 - val_mae: 0.0287 - val_root_mean_squared_error: 0.0321\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0378 - val_loss: 0.0163 - val_mae: 0.0163 - val_root_mean_squared_error: 0.0195\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0349 - val_loss: 0.0128 - val_mae: 0.0128 - val_root_mean_squared_error: 0.0155\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0269 - mae: 0.0269 - root_mean_squared_error: 0.0351 - val_loss: 0.0190 - val_mae: 0.0190 - val_root_mean_squared_error: 0.0221\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0250 - mae: 0.0250 - root_mean_squared_error: 0.0330 - val_loss: 0.0160 - val_mae: 0.0160 - val_root_mean_squared_error: 0.0185\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0233 - mae: 0.0233 - root_mean_squared_error: 0.0309 - val_loss: 0.0087 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0109\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0279 - mae: 0.0279 - root_mean_squared_error: 0.0366 - val_loss: 0.0109 - val_mae: 0.0109 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0354 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0225 - mae: 0.0225 - root_mean_squared_error: 0.0294 - val_loss: 0.0140 - val_mae: 0.0140 - val_root_mean_squared_error: 0.0160\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0232 - mae: 0.0232 - root_mean_squared_error: 0.0305 - val_loss: 0.0072 - val_mae: 0.0072 - val_root_mean_squared_error: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:56:39 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:56:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:56:47 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:56:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: learning_rate = 0.01 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0851 - mae: 0.0851 - root_mean_squared_error: 0.1112 - val_loss: 0.1551 - val_mae: 0.1551 - val_root_mean_squared_error: 0.1661\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0827 - mae: 0.0827 - root_mean_squared_error: 0.1032 - val_loss: 0.0553 - val_mae: 0.0553 - val_root_mean_squared_error: 0.0658\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1005 - mae: 0.1005 - root_mean_squared_error: 0.1261 - val_loss: 0.0651 - val_mae: 0.0651 - val_root_mean_squared_error: 0.0767\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1160 - mae: 0.1160 - root_mean_squared_error: 0.1429 - val_loss: 0.0703 - val_mae: 0.0703 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1020 - mae: 0.1020 - root_mean_squared_error: 0.1267 - val_loss: 0.0990 - val_mae: 0.0990 - val_root_mean_squared_error: 0.1153\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0964 - mae: 0.0964 - root_mean_squared_error: 0.1190 - val_loss: 0.1126 - val_mae: 0.1126 - val_root_mean_squared_error: 0.1287\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0928 - mae: 0.0928 - root_mean_squared_error: 0.1127 - val_loss: 0.0849 - val_mae: 0.0849 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0928 - mae: 0.0928 - root_mean_squared_error: 0.1126 - val_loss: 0.1468 - val_mae: 0.1468 - val_root_mean_squared_error: 0.1615\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0890 - mae: 0.0890 - root_mean_squared_error: 0.1125 - val_loss: 0.0689 - val_mae: 0.0689 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0860 - mae: 0.0860 - root_mean_squared_error: 0.1069 - val_loss: 0.1930 - val_mae: 0.1930 - val_root_mean_squared_error: 0.2060\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0867 - mae: 0.0867 - root_mean_squared_error: 0.1077 - val_loss: 0.0549 - val_mae: 0.0549 - val_root_mean_squared_error: 0.0655\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0834 - mae: 0.0834 - root_mean_squared_error: 0.1029 - val_loss: 0.0773 - val_mae: 0.0773 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0856 - mae: 0.0856 - root_mean_squared_error: 0.1039 - val_loss: 0.0710 - val_mae: 0.0710 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0756 - mae: 0.0756 - root_mean_squared_error: 0.0963 - val_loss: 0.0943 - val_mae: 0.0943 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0783 - mae: 0.0783 - root_mean_squared_error: 0.0990 - val_loss: 0.1155 - val_mae: 0.1155 - val_root_mean_squared_error: 0.1329\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0832 - mae: 0.0832 - root_mean_squared_error: 0.1044 - val_loss: 0.0951 - val_mae: 0.0951 - val_root_mean_squared_error: 0.1114\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0850 - mae: 0.0850 - root_mean_squared_error: 0.1062 - val_loss: 0.1025 - val_mae: 0.1025 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0808 - mae: 0.0808 - root_mean_squared_error: 0.1009 - val_loss: 0.1110 - val_mae: 0.1110 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0822 - mae: 0.0822 - root_mean_squared_error: 0.1039 - val_loss: 0.0999 - val_mae: 0.0999 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0826 - mae: 0.0826 - root_mean_squared_error: 0.1035 - val_loss: 0.0728 - val_mae: 0.0728 - val_root_mean_squared_error: 0.0857\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0817 - mae: 0.0817 - root_mean_squared_error: 0.1027 - val_loss: 0.0888 - val_mae: 0.0888 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0827 - mae: 0.0827 - root_mean_squared_error: 0.1014 - val_loss: 0.0741 - val_mae: 0.0741 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0797 - mae: 0.0797 - root_mean_squared_error: 0.0990 - val_loss: 0.0594 - val_mae: 0.0594 - val_root_mean_squared_error: 0.0704\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0701 - mae: 0.0701 - root_mean_squared_error: 0.0893 - val_loss: 0.0334 - val_mae: 0.0334 - val_root_mean_squared_error: 0.0391\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0690 - mae: 0.0690 - root_mean_squared_error: 0.0857 - val_loss: 0.0512 - val_mae: 0.0512 - val_root_mean_squared_error: 0.0604\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0638 - mae: 0.0638 - root_mean_squared_error: 0.0827 - val_loss: 0.0758 - val_mae: 0.0758 - val_root_mean_squared_error: 0.0876\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0631 - mae: 0.0631 - root_mean_squared_error: 0.0800 - val_loss: 0.0700 - val_mae: 0.0700 - val_root_mean_squared_error: 0.0823\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0630 - mae: 0.0630 - root_mean_squared_error: 0.0787 - val_loss: 0.0703 - val_mae: 0.0703 - val_root_mean_squared_error: 0.0805\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0619 - mae: 0.0619 - root_mean_squared_error: 0.0786 - val_loss: 0.0644 - val_mae: 0.0644 - val_root_mean_squared_error: 0.0762\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0631 - mae: 0.0631 - root_mean_squared_error: 0.0795 - val_loss: 0.0756 - val_mae: 0.0756 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0635 - mae: 0.0635 - root_mean_squared_error: 0.0794 - val_loss: 0.0625 - val_mae: 0.0625 - val_root_mean_squared_error: 0.0738\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0619 - mae: 0.0619 - root_mean_squared_error: 0.0783 - val_loss: 0.0595 - val_mae: 0.0595 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0604 - mae: 0.0604 - root_mean_squared_error: 0.0778 - val_loss: 0.0529 - val_mae: 0.0529 - val_root_mean_squared_error: 0.0614\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0529 - mae: 0.0529 - root_mean_squared_error: 0.0690 - val_loss: 0.0820 - val_mae: 0.0820 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0538 - mae: 0.0538 - root_mean_squared_error: 0.0694 - val_loss: 0.0211 - val_mae: 0.0211 - val_root_mean_squared_error: 0.0281\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0506 - mae: 0.0506 - root_mean_squared_error: 0.0668 - val_loss: 0.0353 - val_mae: 0.0353 - val_root_mean_squared_error: 0.0429\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0462 - mae: 0.0462 - root_mean_squared_error: 0.0608 - val_loss: 0.0509 - val_mae: 0.0509 - val_root_mean_squared_error: 0.0588\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0471 - mae: 0.0471 - root_mean_squared_error: 0.0615 - val_loss: 0.0198 - val_mae: 0.0198 - val_root_mean_squared_error: 0.0259\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0419 - mae: 0.0419 - root_mean_squared_error: 0.0552 - val_loss: 0.0540 - val_mae: 0.0540 - val_root_mean_squared_error: 0.0580\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0410 - mae: 0.0410 - root_mean_squared_error: 0.0542 - val_loss: 0.0520 - val_mae: 0.0520 - val_root_mean_squared_error: 0.0564\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0500 - val_loss: 0.0617 - val_mae: 0.0617 - val_root_mean_squared_error: 0.0664\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0462 - val_loss: 0.0299 - val_mae: 0.0299 - val_root_mean_squared_error: 0.0336\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0487 - val_loss: 0.0149 - val_mae: 0.0149 - val_root_mean_squared_error: 0.0195\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0391 - mae: 0.0391 - root_mean_squared_error: 0.0522 - val_loss: 0.0301 - val_mae: 0.0301 - val_root_mean_squared_error: 0.0336\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0503 - val_loss: 0.0128 - val_mae: 0.0128 - val_root_mean_squared_error: 0.0164\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0439 - val_loss: 0.0564 - val_mae: 0.0564 - val_root_mean_squared_error: 0.0596\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0474 - val_loss: 0.0144 - val_mae: 0.0144 - val_root_mean_squared_error: 0.0195\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0327 - mae: 0.0327 - root_mean_squared_error: 0.0428 - val_loss: 0.0308 - val_mae: 0.0308 - val_root_mean_squared_error: 0.0333\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0445 - val_loss: 0.0117 - val_mae: 0.0117 - val_root_mean_squared_error: 0.0166\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0328 - mae: 0.0328 - root_mean_squared_error: 0.0417 - val_loss: 0.0530 - val_mae: 0.0530 - val_root_mean_squared_error: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:58:01 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:58:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:58:08 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:58:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: learning_rate = 0.1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.3535 - mae: 0.3535 - root_mean_squared_error: 0.5397 - val_loss: 0.3453 - val_mae: 0.3453 - val_root_mean_squared_error: 0.3521\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1948 - mae: 0.1948 - root_mean_squared_error: 0.2423 - val_loss: 0.0770 - val_mae: 0.0770 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2440 - mae: 0.2440 - root_mean_squared_error: 0.3005 - val_loss: 0.8923 - val_mae: 0.8923 - val_root_mean_squared_error: 0.8963\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2273 - mae: 0.2273 - root_mean_squared_error: 0.2739 - val_loss: 0.0701 - val_mae: 0.0701 - val_root_mean_squared_error: 0.0821\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2196 - mae: 0.2196 - root_mean_squared_error: 0.2790 - val_loss: 0.1962 - val_mae: 0.1962 - val_root_mean_squared_error: 0.2096\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2293 - mae: 0.2293 - root_mean_squared_error: 0.2857 - val_loss: 0.2414 - val_mae: 0.2414 - val_root_mean_squared_error: 0.2548\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1986 - mae: 0.1986 - root_mean_squared_error: 0.2688 - val_loss: 0.1854 - val_mae: 0.1854 - val_root_mean_squared_error: 0.2033\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1616 - mae: 0.1616 - root_mean_squared_error: 0.1956 - val_loss: 0.0720 - val_mae: 0.0720 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1672 - mae: 0.1672 - root_mean_squared_error: 0.2087 - val_loss: 0.0645 - val_mae: 0.0645 - val_root_mean_squared_error: 0.0804\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1583 - mae: 0.1583 - root_mean_squared_error: 0.1969 - val_loss: 0.1761 - val_mae: 0.1761 - val_root_mean_squared_error: 0.1929\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1655 - mae: 0.1655 - root_mean_squared_error: 0.2069 - val_loss: 0.1639 - val_mae: 0.1639 - val_root_mean_squared_error: 0.1835\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1821 - mae: 0.1821 - root_mean_squared_error: 0.2375 - val_loss: 0.1916 - val_mae: 0.1916 - val_root_mean_squared_error: 0.2078\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1949 - mae: 0.1949 - root_mean_squared_error: 0.2321 - val_loss: 0.1572 - val_mae: 0.1572 - val_root_mean_squared_error: 0.1769\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1584 - mae: 0.1584 - root_mean_squared_error: 0.2000 - val_loss: 0.0850 - val_mae: 0.0850 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1291 - mae: 0.1291 - root_mean_squared_error: 0.1628 - val_loss: 0.2198 - val_mae: 0.2198 - val_root_mean_squared_error: 0.2345\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1515 - mae: 0.1515 - root_mean_squared_error: 0.1826 - val_loss: 0.1873 - val_mae: 0.1873 - val_root_mean_squared_error: 0.2045\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1489 - mae: 0.1489 - root_mean_squared_error: 0.1947 - val_loss: 0.1825 - val_mae: 0.1825 - val_root_mean_squared_error: 0.2020\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1441 - mae: 0.1441 - root_mean_squared_error: 0.1831 - val_loss: 0.2474 - val_mae: 0.2474 - val_root_mean_squared_error: 0.2618\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1462 - mae: 0.1462 - root_mean_squared_error: 0.1812 - val_loss: 0.1496 - val_mae: 0.1496 - val_root_mean_squared_error: 0.1692\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1193 - mae: 0.1193 - root_mean_squared_error: 0.1513 - val_loss: 0.0743 - val_mae: 0.0743 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2681 - mae: 0.2681 - root_mean_squared_error: 0.3612 - val_loss: 0.4293 - val_mae: 0.4293 - val_root_mean_squared_error: 0.4386\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1728 - mae: 0.1728 - root_mean_squared_error: 0.2216 - val_loss: 0.1872 - val_mae: 0.1872 - val_root_mean_squared_error: 0.2064\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1740 - mae: 0.1740 - root_mean_squared_error: 0.2248 - val_loss: 0.1593 - val_mae: 0.1593 - val_root_mean_squared_error: 0.1807\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1570 - mae: 0.1570 - root_mean_squared_error: 0.1908 - val_loss: 0.0807 - val_mae: 0.0807 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1419 - mae: 0.1419 - root_mean_squared_error: 0.1830 - val_loss: 0.1824 - val_mae: 0.1824 - val_root_mean_squared_error: 0.2026\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1241 - mae: 0.1241 - root_mean_squared_error: 0.1551 - val_loss: 0.1954 - val_mae: 0.1954 - val_root_mean_squared_error: 0.2143\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1568 - mae: 0.1568 - root_mean_squared_error: 0.2012 - val_loss: 0.1298 - val_mae: 0.1298 - val_root_mean_squared_error: 0.1514\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1452 - mae: 0.1452 - root_mean_squared_error: 0.1935 - val_loss: 0.3272 - val_mae: 0.3272 - val_root_mean_squared_error: 0.3389\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1612 - mae: 0.1612 - root_mean_squared_error: 0.2084 - val_loss: 0.1047 - val_mae: 0.1047 - val_root_mean_squared_error: 0.1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 19:59:02 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 19:59:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 19:59:10 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 19:59:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 19:59:34 INFO mlflow.tracking.fluent: Experiment with name 'gru_model_units_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: model_units = 10 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1391 - mae: 0.1391 - root_mean_squared_error: 0.1840 - val_loss: 0.1139 - val_mae: 0.1139 - val_root_mean_squared_error: 0.1244\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1009 - mae: 0.1009 - root_mean_squared_error: 0.1322 - val_loss: 0.0980 - val_mae: 0.0980 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0894 - mae: 0.0894 - root_mean_squared_error: 0.1172 - val_loss: 0.1123 - val_mae: 0.1123 - val_root_mean_squared_error: 0.1216\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0841 - mae: 0.0841 - root_mean_squared_error: 0.1098 - val_loss: 0.1004 - val_mae: 0.1004 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0819 - mae: 0.0819 - root_mean_squared_error: 0.1058 - val_loss: 0.1004 - val_mae: 0.1004 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0781 - mae: 0.0781 - root_mean_squared_error: 0.1014 - val_loss: 0.1041 - val_mae: 0.1041 - val_root_mean_squared_error: 0.1131\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0765 - mae: 0.0765 - root_mean_squared_error: 0.0993 - val_loss: 0.1047 - val_mae: 0.1047 - val_root_mean_squared_error: 0.1135\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0731 - mae: 0.0731 - root_mean_squared_error: 0.0949 - val_loss: 0.0949 - val_mae: 0.0949 - val_root_mean_squared_error: 0.1041\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0698 - mae: 0.0698 - root_mean_squared_error: 0.0907 - val_loss: 0.1089 - val_mae: 0.1089 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0690 - mae: 0.0690 - root_mean_squared_error: 0.0899 - val_loss: 0.0943 - val_mae: 0.0943 - val_root_mean_squared_error: 0.1044\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0662 - mae: 0.0662 - root_mean_squared_error: 0.0867 - val_loss: 0.1178 - val_mae: 0.1178 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0646 - mae: 0.0646 - root_mean_squared_error: 0.0835 - val_loss: 0.1194 - val_mae: 0.1194 - val_root_mean_squared_error: 0.1289\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0640 - mae: 0.0640 - root_mean_squared_error: 0.0831 - val_loss: 0.1107 - val_mae: 0.1107 - val_root_mean_squared_error: 0.1207\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0617 - mae: 0.0617 - root_mean_squared_error: 0.0800 - val_loss: 0.1156 - val_mae: 0.1156 - val_root_mean_squared_error: 0.1254\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0605 - mae: 0.0605 - root_mean_squared_error: 0.0783 - val_loss: 0.1160 - val_mae: 0.1160 - val_root_mean_squared_error: 0.1258\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0592 - mae: 0.0592 - root_mean_squared_error: 0.0766 - val_loss: 0.1177 - val_mae: 0.1177 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0586 - mae: 0.0586 - root_mean_squared_error: 0.0761 - val_loss: 0.1074 - val_mae: 0.1074 - val_root_mean_squared_error: 0.1175\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0568 - mae: 0.0568 - root_mean_squared_error: 0.0742 - val_loss: 0.1164 - val_mae: 0.1164 - val_root_mean_squared_error: 0.1257\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0570 - mae: 0.0570 - root_mean_squared_error: 0.0743 - val_loss: 0.1160 - val_mae: 0.1160 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0536 - mae: 0.0536 - root_mean_squared_error: 0.0701 - val_loss: 0.1045 - val_mae: 0.1045 - val_root_mean_squared_error: 0.1144\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0536 - mae: 0.0536 - root_mean_squared_error: 0.0706 - val_loss: 0.1033 - val_mae: 0.1033 - val_root_mean_squared_error: 0.1133\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0527 - mae: 0.0527 - root_mean_squared_error: 0.0684 - val_loss: 0.0933 - val_mae: 0.0933 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0517 - mae: 0.0517 - root_mean_squared_error: 0.0673 - val_loss: 0.0919 - val_mae: 0.0919 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0512 - mae: 0.0512 - root_mean_squared_error: 0.0672 - val_loss: 0.1102 - val_mae: 0.1102 - val_root_mean_squared_error: 0.1193\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0495 - mae: 0.0495 - root_mean_squared_error: 0.0645 - val_loss: 0.1021 - val_mae: 0.1021 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0491 - mae: 0.0491 - root_mean_squared_error: 0.0645 - val_loss: 0.0864 - val_mae: 0.0864 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0488 - mae: 0.0488 - root_mean_squared_error: 0.0633 - val_loss: 0.0906 - val_mae: 0.0906 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0479 - mae: 0.0479 - root_mean_squared_error: 0.0630 - val_loss: 0.0788 - val_mae: 0.0788 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0474 - mae: 0.0474 - root_mean_squared_error: 0.0622 - val_loss: 0.0859 - val_mae: 0.0859 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0468 - mae: 0.0468 - root_mean_squared_error: 0.0613 - val_loss: 0.0682 - val_mae: 0.0682 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0459 - mae: 0.0459 - root_mean_squared_error: 0.0599 - val_loss: 0.0577 - val_mae: 0.0577 - val_root_mean_squared_error: 0.0672\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0453 - mae: 0.0453 - root_mean_squared_error: 0.0597 - val_loss: 0.0641 - val_mae: 0.0641 - val_root_mean_squared_error: 0.0733\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0443 - mae: 0.0443 - root_mean_squared_error: 0.0581 - val_loss: 0.0741 - val_mae: 0.0741 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0429 - mae: 0.0429 - root_mean_squared_error: 0.0565 - val_loss: 0.0716 - val_mae: 0.0716 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0567 - val_loss: 0.0433 - val_mae: 0.0433 - val_root_mean_squared_error: 0.0518\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0429 - mae: 0.0429 - root_mean_squared_error: 0.0565 - val_loss: 0.0513 - val_mae: 0.0513 - val_root_mean_squared_error: 0.0585\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0417 - mae: 0.0417 - root_mean_squared_error: 0.0549 - val_loss: 0.0476 - val_mae: 0.0476 - val_root_mean_squared_error: 0.0551\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0395 - mae: 0.0395 - root_mean_squared_error: 0.0523 - val_loss: 0.0699 - val_mae: 0.0699 - val_root_mean_squared_error: 0.0771\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0526 - val_loss: 0.0512 - val_mae: 0.0512 - val_root_mean_squared_error: 0.0594\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0387 - mae: 0.0387 - root_mean_squared_error: 0.0515 - val_loss: 0.0628 - val_mae: 0.0628 - val_root_mean_squared_error: 0.0707\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0508 - val_loss: 0.0516 - val_mae: 0.0516 - val_root_mean_squared_error: 0.0601\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0514 - val_loss: 0.0511 - val_mae: 0.0511 - val_root_mean_squared_error: 0.0593\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0383 - mae: 0.0383 - root_mean_squared_error: 0.0509 - val_loss: 0.0547 - val_mae: 0.0547 - val_root_mean_squared_error: 0.0624\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0374 - mae: 0.0374 - root_mean_squared_error: 0.0501 - val_loss: 0.0542 - val_mae: 0.0542 - val_root_mean_squared_error: 0.0608\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0368 - mae: 0.0368 - root_mean_squared_error: 0.0495 - val_loss: 0.0494 - val_mae: 0.0494 - val_root_mean_squared_error: 0.0561\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0359 - mae: 0.0359 - root_mean_squared_error: 0.0489 - val_loss: 0.0430 - val_mae: 0.0430 - val_root_mean_squared_error: 0.0500\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0508 - val_loss: 0.0588 - val_mae: 0.0588 - val_root_mean_squared_error: 0.0664\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0514 - val_loss: 0.0358 - val_mae: 0.0358 - val_root_mean_squared_error: 0.0425\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0485 - val_loss: 0.0608 - val_mae: 0.0608 - val_root_mean_squared_error: 0.0669\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0484 - val_loss: 0.0507 - val_mae: 0.0507 - val_root_mean_squared_error: 0.0571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:00:17 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:00:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:00:25 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:00:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: model_units = 50 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1032 - mae: 0.1032 - root_mean_squared_error: 0.1527 - val_loss: 0.0721 - val_mae: 0.0721 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0690 - mae: 0.0690 - root_mean_squared_error: 0.0884 - val_loss: 0.0606 - val_mae: 0.0606 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0654 - mae: 0.0654 - root_mean_squared_error: 0.0840 - val_loss: 0.0494 - val_mae: 0.0494 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0627 - mae: 0.0627 - root_mean_squared_error: 0.0800 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0766 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0748 - val_loss: 0.0751 - val_mae: 0.0751 - val_root_mean_squared_error: 0.0853\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0549 - mae: 0.0549 - root_mean_squared_error: 0.0707 - val_loss: 0.0591 - val_mae: 0.0591 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0553 - mae: 0.0553 - root_mean_squared_error: 0.0714 - val_loss: 0.0575 - val_mae: 0.0575 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0523 - mae: 0.0523 - root_mean_squared_error: 0.0677 - val_loss: 0.0613 - val_mae: 0.0613 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0502 - mae: 0.0502 - root_mean_squared_error: 0.0653 - val_loss: 0.0652 - val_mae: 0.0652 - val_root_mean_squared_error: 0.0753\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0473 - mae: 0.0473 - root_mean_squared_error: 0.0612 - val_loss: 0.0603 - val_mae: 0.0603 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0463 - mae: 0.0463 - root_mean_squared_error: 0.0602 - val_loss: 0.0692 - val_mae: 0.0692 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0461 - mae: 0.0461 - root_mean_squared_error: 0.0591 - val_loss: 0.0643 - val_mae: 0.0643 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0571 - val_loss: 0.0618 - val_mae: 0.0618 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0548 - val_loss: 0.0625 - val_mae: 0.0625 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0524 - val_loss: 0.0414 - val_mae: 0.0414 - val_root_mean_squared_error: 0.0491\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0503 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0514\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0504 - val_loss: 0.0349 - val_mae: 0.0349 - val_root_mean_squared_error: 0.0416\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0523 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0432\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0458 - val_loss: 0.0422 - val_mae: 0.0422 - val_root_mean_squared_error: 0.0469\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0452 - val_loss: 0.0327 - val_mae: 0.0327 - val_root_mean_squared_error: 0.0380\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0434 - val_loss: 0.0252 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0302\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0478 - val_loss: 0.0402 - val_mae: 0.0402 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0366 - mae: 0.0366 - root_mean_squared_error: 0.0484 - val_loss: 0.0275 - val_mae: 0.0275 - val_root_mean_squared_error: 0.0326\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0449 - val_loss: 0.0151 - val_mae: 0.0151 - val_root_mean_squared_error: 0.0188\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0322 - mae: 0.0322 - root_mean_squared_error: 0.0419 - val_loss: 0.0451 - val_mae: 0.0451 - val_root_mean_squared_error: 0.0495\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0444 - val_loss: 0.0302 - val_mae: 0.0302 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0469 - val_loss: 0.0226 - val_mae: 0.0226 - val_root_mean_squared_error: 0.0270\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0426 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0422\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0323 - mae: 0.0323 - root_mean_squared_error: 0.0424 - val_loss: 0.0348 - val_mae: 0.0348 - val_root_mean_squared_error: 0.0395\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0310 - mae: 0.0310 - root_mean_squared_error: 0.0404 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0314\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0315 - mae: 0.0315 - root_mean_squared_error: 0.0418 - val_loss: 0.0111 - val_mae: 0.0111 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0291 - mae: 0.0291 - root_mean_squared_error: 0.0377 - val_loss: 0.0278 - val_mae: 0.0278 - val_root_mean_squared_error: 0.0318\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0277 - mae: 0.0277 - root_mean_squared_error: 0.0367 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0294 - mae: 0.0294 - root_mean_squared_error: 0.0380 - val_loss: 0.0256 - val_mae: 0.0256 - val_root_mean_squared_error: 0.0300\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0283 - mae: 0.0283 - root_mean_squared_error: 0.0373 - val_loss: 0.0377 - val_mae: 0.0377 - val_root_mean_squared_error: 0.0414\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0282 - mae: 0.0282 - root_mean_squared_error: 0.0371 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0278\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0369 - val_loss: 0.0124 - val_mae: 0.0124 - val_root_mean_squared_error: 0.0153\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0365 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0205\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0374 - val_loss: 0.0132 - val_mae: 0.0132 - val_root_mean_squared_error: 0.0161\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0253 - mae: 0.0253 - root_mean_squared_error: 0.0336 - val_loss: 0.0287 - val_mae: 0.0287 - val_root_mean_squared_error: 0.0321\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0378 - val_loss: 0.0163 - val_mae: 0.0163 - val_root_mean_squared_error: 0.0195\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0349 - val_loss: 0.0128 - val_mae: 0.0128 - val_root_mean_squared_error: 0.0155\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0269 - mae: 0.0269 - root_mean_squared_error: 0.0351 - val_loss: 0.0190 - val_mae: 0.0190 - val_root_mean_squared_error: 0.0221\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0250 - mae: 0.0250 - root_mean_squared_error: 0.0330 - val_loss: 0.0160 - val_mae: 0.0160 - val_root_mean_squared_error: 0.0185\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0233 - mae: 0.0233 - root_mean_squared_error: 0.0309 - val_loss: 0.0087 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0109\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0279 - mae: 0.0279 - root_mean_squared_error: 0.0366 - val_loss: 0.0109 - val_mae: 0.0109 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0354 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0225 - mae: 0.0225 - root_mean_squared_error: 0.0294 - val_loss: 0.0140 - val_mae: 0.0140 - val_root_mean_squared_error: 0.0160\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0232 - mae: 0.0232 - root_mean_squared_error: 0.0305 - val_loss: 0.0072 - val_mae: 0.0072 - val_root_mean_squared_error: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:01:40 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:01:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:01:48 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:01:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: model_units = 100 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0867 - mae: 0.0867 - root_mean_squared_error: 0.1363 - val_loss: 0.0540 - val_mae: 0.0540 - val_root_mean_squared_error: 0.0660\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0848 - val_loss: 0.0421 - val_mae: 0.0421 - val_root_mean_squared_error: 0.0534\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0612 - mae: 0.0612 - root_mean_squared_error: 0.0786 - val_loss: 0.0524 - val_mae: 0.0524 - val_root_mean_squared_error: 0.0634\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0576 - mae: 0.0576 - root_mean_squared_error: 0.0744 - val_loss: 0.0630 - val_mae: 0.0630 - val_root_mean_squared_error: 0.0730\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0551 - mae: 0.0551 - root_mean_squared_error: 0.0716 - val_loss: 0.0559 - val_mae: 0.0559 - val_root_mean_squared_error: 0.0662\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0549 - mae: 0.0549 - root_mean_squared_error: 0.0709 - val_loss: 0.0527 - val_mae: 0.0527 - val_root_mean_squared_error: 0.0625\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0487 - mae: 0.0487 - root_mean_squared_error: 0.0634 - val_loss: 0.0729 - val_mae: 0.0729 - val_root_mean_squared_error: 0.0834\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0476 - mae: 0.0476 - root_mean_squared_error: 0.0621 - val_loss: 0.0706 - val_mae: 0.0706 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0440 - mae: 0.0440 - root_mean_squared_error: 0.0569 - val_loss: 0.0465 - val_mae: 0.0465 - val_root_mean_squared_error: 0.0553\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0435 - mae: 0.0435 - root_mean_squared_error: 0.0561 - val_loss: 0.0498 - val_mae: 0.0498 - val_root_mean_squared_error: 0.0590\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0427 - mae: 0.0427 - root_mean_squared_error: 0.0560 - val_loss: 0.0592 - val_mae: 0.0592 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0405 - mae: 0.0405 - root_mean_squared_error: 0.0525 - val_loss: 0.0597 - val_mae: 0.0597 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0429 - mae: 0.0429 - root_mean_squared_error: 0.0564 - val_loss: 0.0377 - val_mae: 0.0377 - val_root_mean_squared_error: 0.0445\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0418 - mae: 0.0418 - root_mean_squared_error: 0.0534 - val_loss: 0.0327 - val_mae: 0.0327 - val_root_mean_squared_error: 0.0393\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0462 - val_loss: 0.0228 - val_mae: 0.0228 - val_root_mean_squared_error: 0.0278\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0416 - mae: 0.0416 - root_mean_squared_error: 0.0534 - val_loss: 0.0474 - val_mae: 0.0474 - val_root_mean_squared_error: 0.0551\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0526 - val_loss: 0.0392 - val_mae: 0.0392 - val_root_mean_squared_error: 0.0449\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0469 - val_loss: 0.0219 - val_mae: 0.0219 - val_root_mean_squared_error: 0.0267\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0466 - val_loss: 0.0166 - val_mae: 0.0166 - val_root_mean_squared_error: 0.0207\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0309 - mae: 0.0309 - root_mean_squared_error: 0.0398 - val_loss: 0.0175 - val_mae: 0.0175 - val_root_mean_squared_error: 0.0212\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0320 - mae: 0.0320 - root_mean_squared_error: 0.0412 - val_loss: 0.0149 - val_mae: 0.0149 - val_root_mean_squared_error: 0.0186\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0315 - mae: 0.0315 - root_mean_squared_error: 0.0408 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0292\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0327 - mae: 0.0327 - root_mean_squared_error: 0.0426 - val_loss: 0.0379 - val_mae: 0.0379 - val_root_mean_squared_error: 0.0431\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0325 - mae: 0.0325 - root_mean_squared_error: 0.0423 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0279\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0326 - mae: 0.0326 - root_mean_squared_error: 0.0419 - val_loss: 0.0253 - val_mae: 0.0253 - val_root_mean_squared_error: 0.0299\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0325 - mae: 0.0325 - root_mean_squared_error: 0.0423 - val_loss: 0.0209 - val_mae: 0.0209 - val_root_mean_squared_error: 0.0248\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0313 - mae: 0.0313 - root_mean_squared_error: 0.0407 - val_loss: 0.0198 - val_mae: 0.0198 - val_root_mean_squared_error: 0.0236\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0309 - mae: 0.0309 - root_mean_squared_error: 0.0398 - val_loss: 0.0106 - val_mae: 0.0106 - val_root_mean_squared_error: 0.0133\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0297 - mae: 0.0297 - root_mean_squared_error: 0.0386 - val_loss: 0.0169 - val_mae: 0.0169 - val_root_mean_squared_error: 0.0201\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0290 - mae: 0.0290 - root_mean_squared_error: 0.0380 - val_loss: 0.0169 - val_mae: 0.0169 - val_root_mean_squared_error: 0.0201\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0275 - mae: 0.0275 - root_mean_squared_error: 0.0354 - val_loss: 0.0159 - val_mae: 0.0159 - val_root_mean_squared_error: 0.0189\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0276 - mae: 0.0276 - root_mean_squared_error: 0.0355 - val_loss: 0.0073 - val_mae: 0.0073 - val_root_mean_squared_error: 0.0097\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0276 - mae: 0.0276 - root_mean_squared_error: 0.0356 - val_loss: 0.0126 - val_mae: 0.0126 - val_root_mean_squared_error: 0.0149\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0267 - mae: 0.0267 - root_mean_squared_error: 0.0345 - val_loss: 0.0342 - val_mae: 0.0342 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0283 - mae: 0.0283 - root_mean_squared_error: 0.0363 - val_loss: 0.0096 - val_mae: 0.0096 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0272 - mae: 0.0272 - root_mean_squared_error: 0.0357 - val_loss: 0.0323 - val_mae: 0.0323 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0262 - mae: 0.0262 - root_mean_squared_error: 0.0338 - val_loss: 0.0083 - val_mae: 0.0083 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0372 - val_loss: 0.0058 - val_mae: 0.0058 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0253 - mae: 0.0253 - root_mean_squared_error: 0.0328 - val_loss: 0.0127 - val_mae: 0.0127 - val_root_mean_squared_error: 0.0147\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0277 - mae: 0.0277 - root_mean_squared_error: 0.0362 - val_loss: 0.0197 - val_mae: 0.0197 - val_root_mean_squared_error: 0.0227\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0286 - mae: 0.0286 - root_mean_squared_error: 0.0376 - val_loss: 0.0097 - val_mae: 0.0097 - val_root_mean_squared_error: 0.0112\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0213 - mae: 0.0213 - root_mean_squared_error: 0.0282 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0210 - mae: 0.0210 - root_mean_squared_error: 0.0276 - val_loss: 0.0066 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0262 - mae: 0.0262 - root_mean_squared_error: 0.0343 - val_loss: 0.0101 - val_mae: 0.0101 - val_root_mean_squared_error: 0.0119\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0247 - mae: 0.0247 - root_mean_squared_error: 0.0318 - val_loss: 0.0098 - val_mae: 0.0098 - val_root_mean_squared_error: 0.0111\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0238 - mae: 0.0238 - root_mean_squared_error: 0.0306 - val_loss: 0.0044 - val_mae: 0.0044 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0235 - mae: 0.0235 - root_mean_squared_error: 0.0301 - val_loss: 0.0153 - val_mae: 0.0153 - val_root_mean_squared_error: 0.0161\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0347 - val_loss: 0.0066 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0233 - mae: 0.0233 - root_mean_squared_error: 0.0301 - val_loss: 0.0081 - val_mae: 0.0081 - val_root_mean_squared_error: 0.0093\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0221 - mae: 0.0221 - root_mean_squared_error: 0.0288 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:03:15 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:03:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:03:24 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:03:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: model_units = 200 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 0.0748 - mae: 0.0748 - root_mean_squared_error: 0.1176 - val_loss: 0.0656 - val_mae: 0.0656 - val_root_mean_squared_error: 0.0770\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0530 - mae: 0.0530 - root_mean_squared_error: 0.0692 - val_loss: 0.0488 - val_mae: 0.0488 - val_root_mean_squared_error: 0.0599\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0568 - mae: 0.0568 - root_mean_squared_error: 0.0741 - val_loss: 0.0488 - val_mae: 0.0488 - val_root_mean_squared_error: 0.0590\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0617 - mae: 0.0617 - root_mean_squared_error: 0.0805 - val_loss: 0.0487 - val_mae: 0.0487 - val_root_mean_squared_error: 0.0585\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0609 - mae: 0.0609 - root_mean_squared_error: 0.0787 - val_loss: 0.0658 - val_mae: 0.0658 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0576 - mae: 0.0576 - root_mean_squared_error: 0.0745 - val_loss: 0.0624 - val_mae: 0.0624 - val_root_mean_squared_error: 0.0735\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0530 - mae: 0.0530 - root_mean_squared_error: 0.0689 - val_loss: 0.0623 - val_mae: 0.0623 - val_root_mean_squared_error: 0.0734\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0508 - mae: 0.0508 - root_mean_squared_error: 0.0667 - val_loss: 0.0709 - val_mae: 0.0709 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0470 - mae: 0.0470 - root_mean_squared_error: 0.0618 - val_loss: 0.0557 - val_mae: 0.0557 - val_root_mean_squared_error: 0.0661\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0443 - mae: 0.0443 - root_mean_squared_error: 0.0584 - val_loss: 0.0704 - val_mae: 0.0704 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0413 - mae: 0.0413 - root_mean_squared_error: 0.0545 - val_loss: 0.0541 - val_mae: 0.0541 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0413 - mae: 0.0413 - root_mean_squared_error: 0.0542 - val_loss: 0.0601 - val_mae: 0.0601 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0450 - mae: 0.0450 - root_mean_squared_error: 0.0598 - val_loss: 0.0554 - val_mae: 0.0554 - val_root_mean_squared_error: 0.0653\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0536 - val_loss: 0.0505 - val_mae: 0.0505 - val_root_mean_squared_error: 0.0595\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0501 - val_loss: 0.0319 - val_mae: 0.0319 - val_root_mean_squared_error: 0.0382\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0396 - mae: 0.0396 - root_mean_squared_error: 0.0519 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0295\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0382 - mae: 0.0382 - root_mean_squared_error: 0.0494 - val_loss: 0.0296 - val_mae: 0.0296 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0461 - val_loss: 0.0155 - val_mae: 0.0155 - val_root_mean_squared_error: 0.0204\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0418 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0213\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0438 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0299\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0464 - val_loss: 0.0192 - val_mae: 0.0192 - val_root_mean_squared_error: 0.0235\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0322 - mae: 0.0322 - root_mean_squared_error: 0.0423 - val_loss: 0.0150 - val_mae: 0.0150 - val_root_mean_squared_error: 0.0188\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0321 - mae: 0.0321 - root_mean_squared_error: 0.0422 - val_loss: 0.0229 - val_mae: 0.0229 - val_root_mean_squared_error: 0.0272\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0307 - mae: 0.0307 - root_mean_squared_error: 0.0402 - val_loss: 0.0268 - val_mae: 0.0268 - val_root_mean_squared_error: 0.0311\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0309 - mae: 0.0309 - root_mean_squared_error: 0.0400 - val_loss: 0.0140 - val_mae: 0.0140 - val_root_mean_squared_error: 0.0170\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0307 - mae: 0.0307 - root_mean_squared_error: 0.0401 - val_loss: 0.0165 - val_mae: 0.0165 - val_root_mean_squared_error: 0.0193\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0305 - mae: 0.0305 - root_mean_squared_error: 0.0400 - val_loss: 0.0177 - val_mae: 0.0177 - val_root_mean_squared_error: 0.0209\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0310 - mae: 0.0310 - root_mean_squared_error: 0.0404 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0275 - mae: 0.0275 - root_mean_squared_error: 0.0349 - val_loss: 0.0080 - val_mae: 0.0080 - val_root_mean_squared_error: 0.0106\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0291 - mae: 0.0291 - root_mean_squared_error: 0.0378 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0282 - mae: 0.0282 - root_mean_squared_error: 0.0367 - val_loss: 0.0080 - val_mae: 0.0080 - val_root_mean_squared_error: 0.0096\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0280 - mae: 0.0280 - root_mean_squared_error: 0.0370 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0285 - mae: 0.0285 - root_mean_squared_error: 0.0379 - val_loss: 0.0044 - val_mae: 0.0044 - val_root_mean_squared_error: 0.0062\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0257 - mae: 0.0257 - root_mean_squared_error: 0.0328 - val_loss: 0.0112 - val_mae: 0.0112 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0287 - mae: 0.0287 - root_mean_squared_error: 0.0377 - val_loss: 0.0056 - val_mae: 0.0056 - val_root_mean_squared_error: 0.0070\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0271 - mae: 0.0271 - root_mean_squared_error: 0.0350 - val_loss: 0.0044 - val_mae: 0.0044 - val_root_mean_squared_error: 0.0059\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0262 - mae: 0.0262 - root_mean_squared_error: 0.0344 - val_loss: 0.0041 - val_mae: 0.0041 - val_root_mean_squared_error: 0.0058\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0247 - mae: 0.0247 - root_mean_squared_error: 0.0317 - val_loss: 0.0124 - val_mae: 0.0124 - val_root_mean_squared_error: 0.0136\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0339 - val_loss: 0.0113 - val_mae: 0.0113 - val_root_mean_squared_error: 0.0124\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0273 - mae: 0.0273 - root_mean_squared_error: 0.0357 - val_loss: 0.0046 - val_mae: 0.0046 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0242 - mae: 0.0242 - root_mean_squared_error: 0.0317 - val_loss: 0.0056 - val_mae: 0.0056 - val_root_mean_squared_error: 0.0069\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0259 - mae: 0.0259 - root_mean_squared_error: 0.0331 - val_loss: 0.0081 - val_mae: 0.0081 - val_root_mean_squared_error: 0.0098\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0276 - mae: 0.0276 - root_mean_squared_error: 0.0364 - val_loss: 0.0225 - val_mae: 0.0225 - val_root_mean_squared_error: 0.0249\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0225 - mae: 0.0225 - root_mean_squared_error: 0.0295 - val_loss: 0.0090 - val_mae: 0.0090 - val_root_mean_squared_error: 0.0107\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0211 - mae: 0.0211 - root_mean_squared_error: 0.0272 - val_loss: 0.0131 - val_mae: 0.0131 - val_root_mean_squared_error: 0.0168\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0195 - mae: 0.0195 - root_mean_squared_error: 0.0253 - val_loss: 0.0213 - val_mae: 0.0213 - val_root_mean_squared_error: 0.0266\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0197 - mae: 0.0197 - root_mean_squared_error: 0.0254 - val_loss: 0.0224 - val_mae: 0.0224 - val_root_mean_squared_error: 0.0272\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0204 - mae: 0.0204 - root_mean_squared_error: 0.0261 - val_loss: 0.0101 - val_mae: 0.0101 - val_root_mean_squared_error: 0.0121\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0205 - mae: 0.0205 - root_mean_squared_error: 0.0271 - val_loss: 0.0414 - val_mae: 0.0414 - val_root_mean_squared_error: 0.0452\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0183 - mae: 0.0183 - root_mean_squared_error: 0.0236 - val_loss: 0.0188 - val_mae: 0.0188 - val_root_mean_squared_error: 0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:05:42 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:05:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:05:50 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:05:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 20:06:15 INFO mlflow.tracking.fluent: Experiment with name 'gru_dropout_rate_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: dropout_rate = 0 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0884 - mae: 0.0884 - root_mean_squared_error: 0.1472 - val_loss: 0.0512 - val_mae: 0.0512 - val_root_mean_squared_error: 0.0629\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0555 - mae: 0.0555 - root_mean_squared_error: 0.0715 - val_loss: 0.0492 - val_mae: 0.0492 - val_root_mean_squared_error: 0.0605\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0500 - mae: 0.0500 - root_mean_squared_error: 0.0643 - val_loss: 0.0533 - val_mae: 0.0533 - val_root_mean_squared_error: 0.0639\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0476 - mae: 0.0476 - root_mean_squared_error: 0.0614 - val_loss: 0.0570 - val_mae: 0.0570 - val_root_mean_squared_error: 0.0675\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0453 - mae: 0.0453 - root_mean_squared_error: 0.0589 - val_loss: 0.0578 - val_mae: 0.0578 - val_root_mean_squared_error: 0.0683\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0440 - mae: 0.0440 - root_mean_squared_error: 0.0576 - val_loss: 0.0571 - val_mae: 0.0571 - val_root_mean_squared_error: 0.0675\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0567 - val_loss: 0.0608 - val_mae: 0.0608 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0420 - mae: 0.0420 - root_mean_squared_error: 0.0555 - val_loss: 0.0623 - val_mae: 0.0623 - val_root_mean_squared_error: 0.0727\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0541 - val_loss: 0.0587 - val_mae: 0.0587 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0391 - mae: 0.0391 - root_mean_squared_error: 0.0522 - val_loss: 0.0407 - val_mae: 0.0407 - val_root_mean_squared_error: 0.0490\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0328 - mae: 0.0328 - root_mean_squared_error: 0.0451 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0324\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0287 - mae: 0.0287 - root_mean_squared_error: 0.0389 - val_loss: 0.0387 - val_mae: 0.0387 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0318 - mae: 0.0318 - root_mean_squared_error: 0.0433 - val_loss: 0.0424 - val_mae: 0.0424 - val_root_mean_squared_error: 0.0506\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0286 - mae: 0.0286 - root_mean_squared_error: 0.0393 - val_loss: 0.0397 - val_mae: 0.0397 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0245 - mae: 0.0245 - root_mean_squared_error: 0.0332 - val_loss: 0.0372 - val_mae: 0.0372 - val_root_mean_squared_error: 0.0446\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0260 - mae: 0.0260 - root_mean_squared_error: 0.0353 - val_loss: 0.0325 - val_mae: 0.0325 - val_root_mean_squared_error: 0.0391\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0246 - mae: 0.0246 - root_mean_squared_error: 0.0341 - val_loss: 0.0358 - val_mae: 0.0358 - val_root_mean_squared_error: 0.0429\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0379 - val_loss: 0.0350 - val_mae: 0.0350 - val_root_mean_squared_error: 0.0422\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0243 - mae: 0.0243 - root_mean_squared_error: 0.0332 - val_loss: 0.0397 - val_mae: 0.0397 - val_root_mean_squared_error: 0.0470\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0258 - mae: 0.0258 - root_mean_squared_error: 0.0348 - val_loss: 0.0357 - val_mae: 0.0357 - val_root_mean_squared_error: 0.0427\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0252 - mae: 0.0252 - root_mean_squared_error: 0.0344 - val_loss: 0.0373 - val_mae: 0.0373 - val_root_mean_squared_error: 0.0438\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0262 - mae: 0.0262 - root_mean_squared_error: 0.0350 - val_loss: 0.0374 - val_mae: 0.0374 - val_root_mean_squared_error: 0.0443\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0252 - mae: 0.0252 - root_mean_squared_error: 0.0338 - val_loss: 0.0376 - val_mae: 0.0376 - val_root_mean_squared_error: 0.0446\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0241 - mae: 0.0241 - root_mean_squared_error: 0.0324 - val_loss: 0.0337 - val_mae: 0.0337 - val_root_mean_squared_error: 0.0404\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0229 - mae: 0.0229 - root_mean_squared_error: 0.0313 - val_loss: 0.0341 - val_mae: 0.0341 - val_root_mean_squared_error: 0.0402\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0244 - mae: 0.0244 - root_mean_squared_error: 0.0329 - val_loss: 0.0329 - val_mae: 0.0329 - val_root_mean_squared_error: 0.0397\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0261 - mae: 0.0261 - root_mean_squared_error: 0.0354 - val_loss: 0.0371 - val_mae: 0.0371 - val_root_mean_squared_error: 0.0433\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0239 - mae: 0.0239 - root_mean_squared_error: 0.0315 - val_loss: 0.0358 - val_mae: 0.0358 - val_root_mean_squared_error: 0.0426\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0226 - mae: 0.0226 - root_mean_squared_error: 0.0307 - val_loss: 0.0320 - val_mae: 0.0320 - val_root_mean_squared_error: 0.0383\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0216 - mae: 0.0216 - root_mean_squared_error: 0.0289 - val_loss: 0.0318 - val_mae: 0.0318 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0231 - mae: 0.0231 - root_mean_squared_error: 0.0304 - val_loss: 0.0308 - val_mae: 0.0308 - val_root_mean_squared_error: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:06:47 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:06:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:06:54 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:06:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: dropout_rate = 0.2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1032 - mae: 0.1032 - root_mean_squared_error: 0.1527 - val_loss: 0.0721 - val_mae: 0.0721 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0690 - mae: 0.0690 - root_mean_squared_error: 0.0884 - val_loss: 0.0606 - val_mae: 0.0606 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0654 - mae: 0.0654 - root_mean_squared_error: 0.0840 - val_loss: 0.0494 - val_mae: 0.0494 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0627 - mae: 0.0627 - root_mean_squared_error: 0.0800 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0766 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0748 - val_loss: 0.0751 - val_mae: 0.0751 - val_root_mean_squared_error: 0.0853\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0549 - mae: 0.0549 - root_mean_squared_error: 0.0707 - val_loss: 0.0591 - val_mae: 0.0591 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0553 - mae: 0.0553 - root_mean_squared_error: 0.0714 - val_loss: 0.0575 - val_mae: 0.0575 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0523 - mae: 0.0523 - root_mean_squared_error: 0.0677 - val_loss: 0.0613 - val_mae: 0.0613 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0502 - mae: 0.0502 - root_mean_squared_error: 0.0653 - val_loss: 0.0652 - val_mae: 0.0652 - val_root_mean_squared_error: 0.0753\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0473 - mae: 0.0473 - root_mean_squared_error: 0.0612 - val_loss: 0.0603 - val_mae: 0.0603 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0463 - mae: 0.0463 - root_mean_squared_error: 0.0602 - val_loss: 0.0692 - val_mae: 0.0692 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0461 - mae: 0.0461 - root_mean_squared_error: 0.0591 - val_loss: 0.0643 - val_mae: 0.0643 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0571 - val_loss: 0.0618 - val_mae: 0.0618 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0548 - val_loss: 0.0625 - val_mae: 0.0625 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0524 - val_loss: 0.0414 - val_mae: 0.0414 - val_root_mean_squared_error: 0.0491\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0503 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0514\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0504 - val_loss: 0.0349 - val_mae: 0.0349 - val_root_mean_squared_error: 0.0416\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0523 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0432\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0458 - val_loss: 0.0422 - val_mae: 0.0422 - val_root_mean_squared_error: 0.0469\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0452 - val_loss: 0.0327 - val_mae: 0.0327 - val_root_mean_squared_error: 0.0380\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0434 - val_loss: 0.0252 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0302\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0478 - val_loss: 0.0402 - val_mae: 0.0402 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0366 - mae: 0.0366 - root_mean_squared_error: 0.0484 - val_loss: 0.0275 - val_mae: 0.0275 - val_root_mean_squared_error: 0.0326\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0449 - val_loss: 0.0151 - val_mae: 0.0151 - val_root_mean_squared_error: 0.0188\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0322 - mae: 0.0322 - root_mean_squared_error: 0.0419 - val_loss: 0.0451 - val_mae: 0.0451 - val_root_mean_squared_error: 0.0495\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0444 - val_loss: 0.0302 - val_mae: 0.0302 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0469 - val_loss: 0.0226 - val_mae: 0.0226 - val_root_mean_squared_error: 0.0270\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0426 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0422\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0323 - mae: 0.0323 - root_mean_squared_error: 0.0424 - val_loss: 0.0348 - val_mae: 0.0348 - val_root_mean_squared_error: 0.0395\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0310 - mae: 0.0310 - root_mean_squared_error: 0.0404 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0314\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0315 - mae: 0.0315 - root_mean_squared_error: 0.0418 - val_loss: 0.0111 - val_mae: 0.0111 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0291 - mae: 0.0291 - root_mean_squared_error: 0.0377 - val_loss: 0.0278 - val_mae: 0.0278 - val_root_mean_squared_error: 0.0318\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0277 - mae: 0.0277 - root_mean_squared_error: 0.0367 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0294 - mae: 0.0294 - root_mean_squared_error: 0.0380 - val_loss: 0.0256 - val_mae: 0.0256 - val_root_mean_squared_error: 0.0300\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0283 - mae: 0.0283 - root_mean_squared_error: 0.0373 - val_loss: 0.0377 - val_mae: 0.0377 - val_root_mean_squared_error: 0.0414\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0282 - mae: 0.0282 - root_mean_squared_error: 0.0371 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0278\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0369 - val_loss: 0.0124 - val_mae: 0.0124 - val_root_mean_squared_error: 0.0153\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0365 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0205\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0374 - val_loss: 0.0132 - val_mae: 0.0132 - val_root_mean_squared_error: 0.0161\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0253 - mae: 0.0253 - root_mean_squared_error: 0.0336 - val_loss: 0.0287 - val_mae: 0.0287 - val_root_mean_squared_error: 0.0321\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0378 - val_loss: 0.0163 - val_mae: 0.0163 - val_root_mean_squared_error: 0.0195\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0349 - val_loss: 0.0128 - val_mae: 0.0128 - val_root_mean_squared_error: 0.0155\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0269 - mae: 0.0269 - root_mean_squared_error: 0.0351 - val_loss: 0.0190 - val_mae: 0.0190 - val_root_mean_squared_error: 0.0221\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0250 - mae: 0.0250 - root_mean_squared_error: 0.0330 - val_loss: 0.0160 - val_mae: 0.0160 - val_root_mean_squared_error: 0.0185\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0233 - mae: 0.0233 - root_mean_squared_error: 0.0309 - val_loss: 0.0087 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0109\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0279 - mae: 0.0279 - root_mean_squared_error: 0.0366 - val_loss: 0.0109 - val_mae: 0.0109 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0354 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0225 - mae: 0.0225 - root_mean_squared_error: 0.0294 - val_loss: 0.0140 - val_mae: 0.0140 - val_root_mean_squared_error: 0.0160\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0232 - mae: 0.0232 - root_mean_squared_error: 0.0305 - val_loss: 0.0072 - val_mae: 0.0072 - val_root_mean_squared_error: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:08:11 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:08:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:08:19 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:08:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: dropout_rate = 0.5 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1335 - mae: 0.1335 - root_mean_squared_error: 0.1852 - val_loss: 0.0752 - val_mae: 0.0752 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0899 - mae: 0.0899 - root_mean_squared_error: 0.1169 - val_loss: 0.0856 - val_mae: 0.0856 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0865 - mae: 0.0865 - root_mean_squared_error: 0.1120 - val_loss: 0.0595 - val_mae: 0.0595 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0833 - mae: 0.0833 - root_mean_squared_error: 0.1074 - val_loss: 0.0757 - val_mae: 0.0757 - val_root_mean_squared_error: 0.0863\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0766 - mae: 0.0766 - root_mean_squared_error: 0.0989 - val_loss: 0.0850 - val_mae: 0.0850 - val_root_mean_squared_error: 0.0950\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0782 - mae: 0.0782 - root_mean_squared_error: 0.1006 - val_loss: 0.0762 - val_mae: 0.0762 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0752 - mae: 0.0752 - root_mean_squared_error: 0.0961 - val_loss: 0.0760 - val_mae: 0.0760 - val_root_mean_squared_error: 0.0874\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0755 - mae: 0.0755 - root_mean_squared_error: 0.0964 - val_loss: 0.0737 - val_mae: 0.0737 - val_root_mean_squared_error: 0.0857\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0738 - mae: 0.0738 - root_mean_squared_error: 0.0937 - val_loss: 0.0861 - val_mae: 0.0861 - val_root_mean_squared_error: 0.0978\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0736 - mae: 0.0736 - root_mean_squared_error: 0.0932 - val_loss: 0.0769 - val_mae: 0.0769 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0726 - mae: 0.0726 - root_mean_squared_error: 0.0925 - val_loss: 0.0792 - val_mae: 0.0792 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0714 - mae: 0.0714 - root_mean_squared_error: 0.0912 - val_loss: 0.0868 - val_mae: 0.0868 - val_root_mean_squared_error: 0.0984\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0702 - mae: 0.0702 - root_mean_squared_error: 0.0888 - val_loss: 0.0774 - val_mae: 0.0774 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0688 - mae: 0.0688 - root_mean_squared_error: 0.0877 - val_loss: 0.0860 - val_mae: 0.0860 - val_root_mean_squared_error: 0.0978\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0671 - mae: 0.0671 - root_mean_squared_error: 0.0853 - val_loss: 0.0857 - val_mae: 0.0857 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0646 - mae: 0.0646 - root_mean_squared_error: 0.0827 - val_loss: 0.0983 - val_mae: 0.0983 - val_root_mean_squared_error: 0.1092\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0646 - mae: 0.0646 - root_mean_squared_error: 0.0820 - val_loss: 0.0804 - val_mae: 0.0804 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0620 - mae: 0.0620 - root_mean_squared_error: 0.0788 - val_loss: 0.0876 - val_mae: 0.0876 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0617 - mae: 0.0617 - root_mean_squared_error: 0.0788 - val_loss: 0.0919 - val_mae: 0.0919 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0602 - mae: 0.0602 - root_mean_squared_error: 0.0763 - val_loss: 0.0898 - val_mae: 0.0898 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0586 - mae: 0.0586 - root_mean_squared_error: 0.0750 - val_loss: 0.0821 - val_mae: 0.0821 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0578 - mae: 0.0578 - root_mean_squared_error: 0.0740 - val_loss: 0.0748 - val_mae: 0.0748 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0572 - mae: 0.0572 - root_mean_squared_error: 0.0731 - val_loss: 0.0676 - val_mae: 0.0676 - val_root_mean_squared_error: 0.0786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:09:08 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:09:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:09:16 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:09:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: dropout_rate = 0.8 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1895 - mae: 0.1895 - root_mean_squared_error: 0.2583 - val_loss: 0.1474 - val_mae: 0.1474 - val_root_mean_squared_error: 0.1556\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1345 - mae: 0.1345 - root_mean_squared_error: 0.1767 - val_loss: 0.1166 - val_mae: 0.1166 - val_root_mean_squared_error: 0.1263\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1234 - mae: 0.1234 - root_mean_squared_error: 0.1618 - val_loss: 0.1577 - val_mae: 0.1577 - val_root_mean_squared_error: 0.1658\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1162 - mae: 0.1162 - root_mean_squared_error: 0.1516 - val_loss: 0.1063 - val_mae: 0.1063 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1091 - mae: 0.1091 - root_mean_squared_error: 0.1418 - val_loss: 0.1328 - val_mae: 0.1328 - val_root_mean_squared_error: 0.1421\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1067 - mae: 0.1067 - root_mean_squared_error: 0.1375 - val_loss: 0.1096 - val_mae: 0.1096 - val_root_mean_squared_error: 0.1199\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1038 - mae: 0.1038 - root_mean_squared_error: 0.1331 - val_loss: 0.1246 - val_mae: 0.1246 - val_root_mean_squared_error: 0.1341\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0990 - mae: 0.0990 - root_mean_squared_error: 0.1259 - val_loss: 0.1435 - val_mae: 0.1435 - val_root_mean_squared_error: 0.1520\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0938 - mae: 0.0938 - root_mean_squared_error: 0.1192 - val_loss: 0.1041 - val_mae: 0.1041 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0892 - mae: 0.0892 - root_mean_squared_error: 0.1134 - val_loss: 0.1064 - val_mae: 0.1064 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0858 - mae: 0.0858 - root_mean_squared_error: 0.1091 - val_loss: 0.1129 - val_mae: 0.1129 - val_root_mean_squared_error: 0.1222\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0821 - mae: 0.0821 - root_mean_squared_error: 0.1051 - val_loss: 0.0853 - val_mae: 0.0853 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0813 - mae: 0.0813 - root_mean_squared_error: 0.1034 - val_loss: 0.1061 - val_mae: 0.1061 - val_root_mean_squared_error: 0.1157\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0780 - mae: 0.0780 - root_mean_squared_error: 0.0993 - val_loss: 0.0944 - val_mae: 0.0944 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0765 - mae: 0.0765 - root_mean_squared_error: 0.0985 - val_loss: 0.1108 - val_mae: 0.1108 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0749 - mae: 0.0749 - root_mean_squared_error: 0.0955 - val_loss: 0.1141 - val_mae: 0.1141 - val_root_mean_squared_error: 0.1238\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0736 - mae: 0.0736 - root_mean_squared_error: 0.0935 - val_loss: 0.1077 - val_mae: 0.1077 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0714 - mae: 0.0714 - root_mean_squared_error: 0.0913 - val_loss: 0.1152 - val_mae: 0.1152 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0719 - mae: 0.0719 - root_mean_squared_error: 0.0916 - val_loss: 0.1094 - val_mae: 0.1094 - val_root_mean_squared_error: 0.1196\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0712 - mae: 0.0712 - root_mean_squared_error: 0.0909 - val_loss: 0.0989 - val_mae: 0.0989 - val_root_mean_squared_error: 0.1095\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0692 - mae: 0.0692 - root_mean_squared_error: 0.0892 - val_loss: 0.1063 - val_mae: 0.1063 - val_root_mean_squared_error: 0.1166\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0695 - mae: 0.0695 - root_mean_squared_error: 0.0899 - val_loss: 0.1033 - val_mae: 0.1033 - val_root_mean_squared_error: 0.1140\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0685 - mae: 0.0685 - root_mean_squared_error: 0.0876 - val_loss: 0.1088 - val_mae: 0.1088 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0696 - mae: 0.0696 - root_mean_squared_error: 0.0892 - val_loss: 0.1233 - val_mae: 0.1233 - val_root_mean_squared_error: 0.1334\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0681 - mae: 0.0681 - root_mean_squared_error: 0.0872 - val_loss: 0.1139 - val_mae: 0.1139 - val_root_mean_squared_error: 0.1243\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0676 - mae: 0.0676 - root_mean_squared_error: 0.0877 - val_loss: 0.1075 - val_mae: 0.1075 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0673 - mae: 0.0673 - root_mean_squared_error: 0.0875 - val_loss: 0.1092 - val_mae: 0.1092 - val_root_mean_squared_error: 0.1193\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0650 - mae: 0.0650 - root_mean_squared_error: 0.0858 - val_loss: 0.0979 - val_mae: 0.0979 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0649 - mae: 0.0649 - root_mean_squared_error: 0.0860 - val_loss: 0.1084 - val_mae: 0.1084 - val_root_mean_squared_error: 0.1186\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0661 - mae: 0.0661 - root_mean_squared_error: 0.0871 - val_loss: 0.1085 - val_mae: 0.1085 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0631 - mae: 0.0631 - root_mean_squared_error: 0.0848 - val_loss: 0.0796 - val_mae: 0.0796 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0639 - mae: 0.0639 - root_mean_squared_error: 0.0849 - val_loss: 0.0759 - val_mae: 0.0759 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0616 - mae: 0.0616 - root_mean_squared_error: 0.0827 - val_loss: 0.0928 - val_mae: 0.0928 - val_root_mean_squared_error: 0.1026\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0622 - mae: 0.0622 - root_mean_squared_error: 0.0830 - val_loss: 0.0993 - val_mae: 0.0993 - val_root_mean_squared_error: 0.1089\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0610 - mae: 0.0610 - root_mean_squared_error: 0.0814 - val_loss: 0.1034 - val_mae: 0.1034 - val_root_mean_squared_error: 0.1138\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0608 - mae: 0.0608 - root_mean_squared_error: 0.0812 - val_loss: 0.0986 - val_mae: 0.0986 - val_root_mean_squared_error: 0.1088\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0782 - val_loss: 0.0910 - val_mae: 0.0910 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0612 - mae: 0.0612 - root_mean_squared_error: 0.0817 - val_loss: 0.0858 - val_mae: 0.0858 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0599 - mae: 0.0599 - root_mean_squared_error: 0.0820 - val_loss: 0.0701 - val_mae: 0.0701 - val_root_mean_squared_error: 0.0812\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0589 - mae: 0.0589 - root_mean_squared_error: 0.0794 - val_loss: 0.0668 - val_mae: 0.0668 - val_root_mean_squared_error: 0.0779\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0793 - val_loss: 0.0675 - val_mae: 0.0675 - val_root_mean_squared_error: 0.0789\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0588 - mae: 0.0588 - root_mean_squared_error: 0.0797 - val_loss: 0.0992 - val_mae: 0.0992 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0579 - mae: 0.0579 - root_mean_squared_error: 0.0791 - val_loss: 0.0832 - val_mae: 0.0832 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0554 - mae: 0.0554 - root_mean_squared_error: 0.0748 - val_loss: 0.0849 - val_mae: 0.0849 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0568 - mae: 0.0568 - root_mean_squared_error: 0.0785 - val_loss: 0.0735 - val_mae: 0.0735 - val_root_mean_squared_error: 0.0817\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0554 - mae: 0.0554 - root_mean_squared_error: 0.0764 - val_loss: 0.0425 - val_mae: 0.0425 - val_root_mean_squared_error: 0.0502\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0580 - mae: 0.0580 - root_mean_squared_error: 0.0797 - val_loss: 0.0742 - val_mae: 0.0742 - val_root_mean_squared_error: 0.0820\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0552 - mae: 0.0552 - root_mean_squared_error: 0.0751 - val_loss: 0.0824 - val_mae: 0.0824 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0551 - mae: 0.0551 - root_mean_squared_error: 0.0761 - val_loss: 0.0520 - val_mae: 0.0520 - val_root_mean_squared_error: 0.0618\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0554 - mae: 0.0554 - root_mean_squared_error: 0.0765 - val_loss: 0.0870 - val_mae: 0.0870 - val_root_mean_squared_error: 0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:10:31 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:10:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:10:39 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:10:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 20:11:03 INFO mlflow.tracking.fluent: Experiment with name 'gru_number_of_layer_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: number_of_layer = 1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1032 - mae: 0.1032 - root_mean_squared_error: 0.1527 - val_loss: 0.0721 - val_mae: 0.0721 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0690 - mae: 0.0690 - root_mean_squared_error: 0.0884 - val_loss: 0.0606 - val_mae: 0.0606 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0654 - mae: 0.0654 - root_mean_squared_error: 0.0840 - val_loss: 0.0494 - val_mae: 0.0494 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0627 - mae: 0.0627 - root_mean_squared_error: 0.0800 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0766 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0748 - val_loss: 0.0751 - val_mae: 0.0751 - val_root_mean_squared_error: 0.0853\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0549 - mae: 0.0549 - root_mean_squared_error: 0.0707 - val_loss: 0.0591 - val_mae: 0.0591 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0553 - mae: 0.0553 - root_mean_squared_error: 0.0714 - val_loss: 0.0575 - val_mae: 0.0575 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0523 - mae: 0.0523 - root_mean_squared_error: 0.0677 - val_loss: 0.0613 - val_mae: 0.0613 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0502 - mae: 0.0502 - root_mean_squared_error: 0.0653 - val_loss: 0.0652 - val_mae: 0.0652 - val_root_mean_squared_error: 0.0753\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0473 - mae: 0.0473 - root_mean_squared_error: 0.0612 - val_loss: 0.0603 - val_mae: 0.0603 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0463 - mae: 0.0463 - root_mean_squared_error: 0.0602 - val_loss: 0.0692 - val_mae: 0.0692 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0461 - mae: 0.0461 - root_mean_squared_error: 0.0591 - val_loss: 0.0643 - val_mae: 0.0643 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0571 - val_loss: 0.0618 - val_mae: 0.0618 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0548 - val_loss: 0.0625 - val_mae: 0.0625 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0524 - val_loss: 0.0414 - val_mae: 0.0414 - val_root_mean_squared_error: 0.0491\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0503 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0514\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0504 - val_loss: 0.0349 - val_mae: 0.0349 - val_root_mean_squared_error: 0.0416\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0523 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0432\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0458 - val_loss: 0.0422 - val_mae: 0.0422 - val_root_mean_squared_error: 0.0469\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0452 - val_loss: 0.0327 - val_mae: 0.0327 - val_root_mean_squared_error: 0.0380\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0434 - val_loss: 0.0252 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0302\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0478 - val_loss: 0.0402 - val_mae: 0.0402 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0366 - mae: 0.0366 - root_mean_squared_error: 0.0484 - val_loss: 0.0275 - val_mae: 0.0275 - val_root_mean_squared_error: 0.0326\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0449 - val_loss: 0.0151 - val_mae: 0.0151 - val_root_mean_squared_error: 0.0188\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0322 - mae: 0.0322 - root_mean_squared_error: 0.0419 - val_loss: 0.0451 - val_mae: 0.0451 - val_root_mean_squared_error: 0.0495\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0444 - val_loss: 0.0302 - val_mae: 0.0302 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0469 - val_loss: 0.0226 - val_mae: 0.0226 - val_root_mean_squared_error: 0.0270\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0426 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0422\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0323 - mae: 0.0323 - root_mean_squared_error: 0.0424 - val_loss: 0.0348 - val_mae: 0.0348 - val_root_mean_squared_error: 0.0395\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0310 - mae: 0.0310 - root_mean_squared_error: 0.0404 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0314\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0315 - mae: 0.0315 - root_mean_squared_error: 0.0418 - val_loss: 0.0111 - val_mae: 0.0111 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0291 - mae: 0.0291 - root_mean_squared_error: 0.0377 - val_loss: 0.0278 - val_mae: 0.0278 - val_root_mean_squared_error: 0.0318\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0277 - mae: 0.0277 - root_mean_squared_error: 0.0367 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0294 - mae: 0.0294 - root_mean_squared_error: 0.0380 - val_loss: 0.0256 - val_mae: 0.0256 - val_root_mean_squared_error: 0.0300\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0283 - mae: 0.0283 - root_mean_squared_error: 0.0373 - val_loss: 0.0377 - val_mae: 0.0377 - val_root_mean_squared_error: 0.0414\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0282 - mae: 0.0282 - root_mean_squared_error: 0.0371 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0278\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0369 - val_loss: 0.0124 - val_mae: 0.0124 - val_root_mean_squared_error: 0.0153\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0365 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0205\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0374 - val_loss: 0.0132 - val_mae: 0.0132 - val_root_mean_squared_error: 0.0161\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0253 - mae: 0.0253 - root_mean_squared_error: 0.0336 - val_loss: 0.0287 - val_mae: 0.0287 - val_root_mean_squared_error: 0.0321\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0378 - val_loss: 0.0163 - val_mae: 0.0163 - val_root_mean_squared_error: 0.0195\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0349 - val_loss: 0.0128 - val_mae: 0.0128 - val_root_mean_squared_error: 0.0155\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0269 - mae: 0.0269 - root_mean_squared_error: 0.0351 - val_loss: 0.0190 - val_mae: 0.0190 - val_root_mean_squared_error: 0.0221\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0250 - mae: 0.0250 - root_mean_squared_error: 0.0330 - val_loss: 0.0160 - val_mae: 0.0160 - val_root_mean_squared_error: 0.0185\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0233 - mae: 0.0233 - root_mean_squared_error: 0.0309 - val_loss: 0.0087 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0109\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0279 - mae: 0.0279 - root_mean_squared_error: 0.0366 - val_loss: 0.0109 - val_mae: 0.0109 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0354 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0225 - mae: 0.0225 - root_mean_squared_error: 0.0294 - val_loss: 0.0140 - val_mae: 0.0140 - val_root_mean_squared_error: 0.0160\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0232 - mae: 0.0232 - root_mean_squared_error: 0.0305 - val_loss: 0.0072 - val_mae: 0.0072 - val_root_mean_squared_error: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:11:54 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:12:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:12:02 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:12:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: number_of_layer = 2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0817 - mae: 0.0817 - root_mean_squared_error: 0.1077 - val_loss: 0.0319 - val_mae: 0.0319 - val_root_mean_squared_error: 0.0426\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0649 - mae: 0.0649 - root_mean_squared_error: 0.0836 - val_loss: 0.0338 - val_mae: 0.0338 - val_root_mean_squared_error: 0.0439\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0632 - mae: 0.0632 - root_mean_squared_error: 0.0819 - val_loss: 0.0800 - val_mae: 0.0800 - val_root_mean_squared_error: 0.0905\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0638 - mae: 0.0638 - root_mean_squared_error: 0.0819 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0531\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0733 - mae: 0.0733 - root_mean_squared_error: 0.0940 - val_loss: 0.0583 - val_mae: 0.0583 - val_root_mean_squared_error: 0.0694\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0650 - mae: 0.0650 - root_mean_squared_error: 0.0845 - val_loss: 0.0942 - val_mae: 0.0942 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0615 - mae: 0.0615 - root_mean_squared_error: 0.0797 - val_loss: 0.0771 - val_mae: 0.0771 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0639 - mae: 0.0639 - root_mean_squared_error: 0.0823 - val_loss: 0.0838 - val_mae: 0.0838 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0587 - mae: 0.0587 - root_mean_squared_error: 0.0758 - val_loss: 0.0761 - val_mae: 0.0761 - val_root_mean_squared_error: 0.0888\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0550 - mae: 0.0550 - root_mean_squared_error: 0.0714 - val_loss: 0.0735 - val_mae: 0.0735 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0555 - mae: 0.0555 - root_mean_squared_error: 0.0727 - val_loss: 0.0931 - val_mae: 0.0931 - val_root_mean_squared_error: 0.1057\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0529 - mae: 0.0529 - root_mean_squared_error: 0.0686 - val_loss: 0.0951 - val_mae: 0.0951 - val_root_mean_squared_error: 0.1084\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0539 - mae: 0.0539 - root_mean_squared_error: 0.0694 - val_loss: 0.0872 - val_mae: 0.0872 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0507 - mae: 0.0507 - root_mean_squared_error: 0.0661 - val_loss: 0.0890 - val_mae: 0.0890 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0499 - mae: 0.0499 - root_mean_squared_error: 0.0649 - val_loss: 0.0740 - val_mae: 0.0740 - val_root_mean_squared_error: 0.0875\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0664 - val_loss: 0.0744 - val_mae: 0.0744 - val_root_mean_squared_error: 0.0877\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0497 - mae: 0.0497 - root_mean_squared_error: 0.0642 - val_loss: 0.0880 - val_mae: 0.0880 - val_root_mean_squared_error: 0.1018\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0498 - mae: 0.0498 - root_mean_squared_error: 0.0651 - val_loss: 0.0900 - val_mae: 0.0900 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0483 - mae: 0.0483 - root_mean_squared_error: 0.0631 - val_loss: 0.0814 - val_mae: 0.0814 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0497 - mae: 0.0497 - root_mean_squared_error: 0.0650 - val_loss: 0.0759 - val_mae: 0.0759 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0483 - mae: 0.0483 - root_mean_squared_error: 0.0634 - val_loss: 0.0840 - val_mae: 0.0840 - val_root_mean_squared_error: 0.0965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:13:05 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:13:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:13:13 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:13:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: number_of_layer = 3 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.0877 - mae: 0.0877 - root_mean_squared_error: 0.1214 - val_loss: 0.1044 - val_mae: 0.1044 - val_root_mean_squared_error: 0.1145\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0748 - mae: 0.0748 - root_mean_squared_error: 0.0941 - val_loss: 0.0947 - val_mae: 0.0947 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0846 - mae: 0.0846 - root_mean_squared_error: 0.1078 - val_loss: 0.0691 - val_mae: 0.0691 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0986 - mae: 0.0986 - root_mean_squared_error: 0.1245 - val_loss: 0.0792 - val_mae: 0.0792 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0929 - mae: 0.0929 - root_mean_squared_error: 0.1160 - val_loss: 0.0785 - val_mae: 0.0785 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0934 - mae: 0.0934 - root_mean_squared_error: 0.1175 - val_loss: 0.0784 - val_mae: 0.0784 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0939 - mae: 0.0939 - root_mean_squared_error: 0.1172 - val_loss: 0.0925 - val_mae: 0.0925 - val_root_mean_squared_error: 0.1070\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0887 - mae: 0.0887 - root_mean_squared_error: 0.1110 - val_loss: 0.0836 - val_mae: 0.0836 - val_root_mean_squared_error: 0.0978\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0940 - mae: 0.0940 - root_mean_squared_error: 0.1171 - val_loss: 0.1234 - val_mae: 0.1234 - val_root_mean_squared_error: 0.1374\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0891 - mae: 0.0891 - root_mean_squared_error: 0.1104 - val_loss: 0.1244 - val_mae: 0.1244 - val_root_mean_squared_error: 0.1389\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0846 - mae: 0.0846 - root_mean_squared_error: 0.1056 - val_loss: 0.1012 - val_mae: 0.1012 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0803 - mae: 0.0803 - root_mean_squared_error: 0.1006 - val_loss: 0.1021 - val_mae: 0.1021 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0793 - mae: 0.0793 - root_mean_squared_error: 0.0992 - val_loss: 0.1362 - val_mae: 0.1362 - val_root_mean_squared_error: 0.1513\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0737 - mae: 0.0737 - root_mean_squared_error: 0.0928 - val_loss: 0.1316 - val_mae: 0.1316 - val_root_mean_squared_error: 0.1473\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0718 - mae: 0.0718 - root_mean_squared_error: 0.0903 - val_loss: 0.1240 - val_mae: 0.1240 - val_root_mean_squared_error: 0.1404\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0701 - mae: 0.0701 - root_mean_squared_error: 0.0887 - val_loss: 0.1173 - val_mae: 0.1173 - val_root_mean_squared_error: 0.1334\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0646 - mae: 0.0646 - root_mean_squared_error: 0.0826 - val_loss: 0.1034 - val_mae: 0.1034 - val_root_mean_squared_error: 0.1189\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0602 - mae: 0.0602 - root_mean_squared_error: 0.0772 - val_loss: 0.0851 - val_mae: 0.0851 - val_root_mean_squared_error: 0.0997\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0581 - mae: 0.0581 - root_mean_squared_error: 0.0754 - val_loss: 0.0879 - val_mae: 0.0879 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0556 - mae: 0.0556 - root_mean_squared_error: 0.0724 - val_loss: 0.0914 - val_mae: 0.0914 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0517 - mae: 0.0517 - root_mean_squared_error: 0.0671 - val_loss: 0.0964 - val_mae: 0.0964 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0479 - mae: 0.0479 - root_mean_squared_error: 0.0623 - val_loss: 0.0986 - val_mae: 0.0986 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0474 - mae: 0.0474 - root_mean_squared_error: 0.0618 - val_loss: 0.0862 - val_mae: 0.0862 - val_root_mean_squared_error: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:14:37 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:14:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:14:45 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:14:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: number_of_layer = 4 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.0981 - mae: 0.0981 - root_mean_squared_error: 0.1361 - val_loss: 0.0972 - val_mae: 0.0972 - val_root_mean_squared_error: 0.1098\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0813 - mae: 0.0813 - root_mean_squared_error: 0.1021 - val_loss: 0.0829 - val_mae: 0.0829 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.1083 - mae: 0.1083 - root_mean_squared_error: 0.1370 - val_loss: 0.1070 - val_mae: 0.1070 - val_root_mean_squared_error: 0.1233\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.1079 - mae: 0.1079 - root_mean_squared_error: 0.1345 - val_loss: 0.0813 - val_mae: 0.0813 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.1187 - mae: 0.1187 - root_mean_squared_error: 0.1469 - val_loss: 0.1121 - val_mae: 0.1121 - val_root_mean_squared_error: 0.1288\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.1163 - mae: 0.1163 - root_mean_squared_error: 0.1431 - val_loss: 0.1376 - val_mae: 0.1376 - val_root_mean_squared_error: 0.1533\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.1113 - mae: 0.1113 - root_mean_squared_error: 0.1375 - val_loss: 0.1486 - val_mae: 0.1486 - val_root_mean_squared_error: 0.1638\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.1082 - mae: 0.1082 - root_mean_squared_error: 0.1331 - val_loss: 0.1267 - val_mae: 0.1267 - val_root_mean_squared_error: 0.1425\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.1063 - mae: 0.1063 - root_mean_squared_error: 0.1307 - val_loss: 0.1275 - val_mae: 0.1275 - val_root_mean_squared_error: 0.1435\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.1031 - mae: 0.1031 - root_mean_squared_error: 0.1273 - val_loss: 0.1247 - val_mae: 0.1247 - val_root_mean_squared_error: 0.1411\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.1001 - mae: 0.1001 - root_mean_squared_error: 0.1230 - val_loss: 0.1070 - val_mae: 0.1070 - val_root_mean_squared_error: 0.1242\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0985 - mae: 0.0985 - root_mean_squared_error: 0.1202 - val_loss: 0.1198 - val_mae: 0.1198 - val_root_mean_squared_error: 0.1374\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0942 - mae: 0.0942 - root_mean_squared_error: 0.1159 - val_loss: 0.1305 - val_mae: 0.1305 - val_root_mean_squared_error: 0.1480\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0851 - mae: 0.0851 - root_mean_squared_error: 0.1058 - val_loss: 0.1191 - val_mae: 0.1191 - val_root_mean_squared_error: 0.1377\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0826 - mae: 0.0826 - root_mean_squared_error: 0.1033 - val_loss: 0.1189 - val_mae: 0.1189 - val_root_mean_squared_error: 0.1373\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0767 - mae: 0.0767 - root_mean_squared_error: 0.0967 - val_loss: 0.1299 - val_mae: 0.1299 - val_root_mean_squared_error: 0.1481\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0737 - mae: 0.0737 - root_mean_squared_error: 0.0933 - val_loss: 0.1197 - val_mae: 0.1197 - val_root_mean_squared_error: 0.1378\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0715 - mae: 0.0715 - root_mean_squared_error: 0.0914 - val_loss: 0.1026 - val_mae: 0.1026 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0680 - mae: 0.0680 - root_mean_squared_error: 0.0875 - val_loss: 0.1112 - val_mae: 0.1112 - val_root_mean_squared_error: 0.1286\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0673 - mae: 0.0673 - root_mean_squared_error: 0.0860 - val_loss: 0.1184 - val_mae: 0.1184 - val_root_mean_squared_error: 0.1354\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0610 - mae: 0.0610 - root_mean_squared_error: 0.0788 - val_loss: 0.1000 - val_mae: 0.1000 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0591 - mae: 0.0591 - root_mean_squared_error: 0.0768 - val_loss: 0.1034 - val_mae: 0.1034 - val_root_mean_squared_error: 0.1189\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0522 - mae: 0.0522 - root_mean_squared_error: 0.0680 - val_loss: 0.0821 - val_mae: 0.0821 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0474 - mae: 0.0474 - root_mean_squared_error: 0.0616 - val_loss: 0.0857 - val_mae: 0.0857 - val_root_mean_squared_error: 0.1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:16:32 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:16:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:16:40 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:16:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 20:17:06 INFO mlflow.tracking.fluent: Experiment with name 'gru_loss_function_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: loss_function = mae ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1032 - mae: 0.1032 - root_mean_squared_error: 0.1527 - val_loss: 0.0721 - val_mae: 0.0721 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0690 - mae: 0.0690 - root_mean_squared_error: 0.0884 - val_loss: 0.0606 - val_mae: 0.0606 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0654 - mae: 0.0654 - root_mean_squared_error: 0.0840 - val_loss: 0.0494 - val_mae: 0.0494 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0627 - mae: 0.0627 - root_mean_squared_error: 0.0800 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0766 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0806\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0748 - val_loss: 0.0751 - val_mae: 0.0751 - val_root_mean_squared_error: 0.0853\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0549 - mae: 0.0549 - root_mean_squared_error: 0.0707 - val_loss: 0.0591 - val_mae: 0.0591 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0553 - mae: 0.0553 - root_mean_squared_error: 0.0714 - val_loss: 0.0575 - val_mae: 0.0575 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0523 - mae: 0.0523 - root_mean_squared_error: 0.0677 - val_loss: 0.0613 - val_mae: 0.0613 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0502 - mae: 0.0502 - root_mean_squared_error: 0.0653 - val_loss: 0.0652 - val_mae: 0.0652 - val_root_mean_squared_error: 0.0753\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0473 - mae: 0.0473 - root_mean_squared_error: 0.0612 - val_loss: 0.0603 - val_mae: 0.0603 - val_root_mean_squared_error: 0.0709\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0463 - mae: 0.0463 - root_mean_squared_error: 0.0602 - val_loss: 0.0692 - val_mae: 0.0692 - val_root_mean_squared_error: 0.0799\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0461 - mae: 0.0461 - root_mean_squared_error: 0.0591 - val_loss: 0.0643 - val_mae: 0.0643 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0571 - val_loss: 0.0618 - val_mae: 0.0618 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0548 - val_loss: 0.0625 - val_mae: 0.0625 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0524 - val_loss: 0.0414 - val_mae: 0.0414 - val_root_mean_squared_error: 0.0491\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0503 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0514\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0504 - val_loss: 0.0349 - val_mae: 0.0349 - val_root_mean_squared_error: 0.0416\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0523 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0432\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0458 - val_loss: 0.0422 - val_mae: 0.0422 - val_root_mean_squared_error: 0.0469\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0452 - val_loss: 0.0327 - val_mae: 0.0327 - val_root_mean_squared_error: 0.0380\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0434 - val_loss: 0.0252 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0302\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0478 - val_loss: 0.0402 - val_mae: 0.0402 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0366 - mae: 0.0366 - root_mean_squared_error: 0.0484 - val_loss: 0.0275 - val_mae: 0.0275 - val_root_mean_squared_error: 0.0326\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0449 - val_loss: 0.0151 - val_mae: 0.0151 - val_root_mean_squared_error: 0.0188\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0322 - mae: 0.0322 - root_mean_squared_error: 0.0419 - val_loss: 0.0451 - val_mae: 0.0451 - val_root_mean_squared_error: 0.0495\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0444 - val_loss: 0.0302 - val_mae: 0.0302 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0469 - val_loss: 0.0226 - val_mae: 0.0226 - val_root_mean_squared_error: 0.0270\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0426 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0422\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0323 - mae: 0.0323 - root_mean_squared_error: 0.0424 - val_loss: 0.0348 - val_mae: 0.0348 - val_root_mean_squared_error: 0.0395\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0310 - mae: 0.0310 - root_mean_squared_error: 0.0404 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0314\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0315 - mae: 0.0315 - root_mean_squared_error: 0.0418 - val_loss: 0.0111 - val_mae: 0.0111 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0291 - mae: 0.0291 - root_mean_squared_error: 0.0377 - val_loss: 0.0278 - val_mae: 0.0278 - val_root_mean_squared_error: 0.0318\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0277 - mae: 0.0277 - root_mean_squared_error: 0.0367 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0294 - mae: 0.0294 - root_mean_squared_error: 0.0380 - val_loss: 0.0256 - val_mae: 0.0256 - val_root_mean_squared_error: 0.0300\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0283 - mae: 0.0283 - root_mean_squared_error: 0.0373 - val_loss: 0.0377 - val_mae: 0.0377 - val_root_mean_squared_error: 0.0414\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0282 - mae: 0.0282 - root_mean_squared_error: 0.0371 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0278\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0369 - val_loss: 0.0124 - val_mae: 0.0124 - val_root_mean_squared_error: 0.0153\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0365 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0205\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0374 - val_loss: 0.0132 - val_mae: 0.0132 - val_root_mean_squared_error: 0.0161\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0253 - mae: 0.0253 - root_mean_squared_error: 0.0336 - val_loss: 0.0287 - val_mae: 0.0287 - val_root_mean_squared_error: 0.0321\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0378 - val_loss: 0.0163 - val_mae: 0.0163 - val_root_mean_squared_error: 0.0195\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0349 - val_loss: 0.0128 - val_mae: 0.0128 - val_root_mean_squared_error: 0.0155\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0269 - mae: 0.0269 - root_mean_squared_error: 0.0351 - val_loss: 0.0190 - val_mae: 0.0190 - val_root_mean_squared_error: 0.0221\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0250 - mae: 0.0250 - root_mean_squared_error: 0.0330 - val_loss: 0.0160 - val_mae: 0.0160 - val_root_mean_squared_error: 0.0185\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0233 - mae: 0.0233 - root_mean_squared_error: 0.0309 - val_loss: 0.0087 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0109\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0279 - mae: 0.0279 - root_mean_squared_error: 0.0366 - val_loss: 0.0109 - val_mae: 0.0109 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0266 - mae: 0.0266 - root_mean_squared_error: 0.0354 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0225 - mae: 0.0225 - root_mean_squared_error: 0.0294 - val_loss: 0.0140 - val_mae: 0.0140 - val_root_mean_squared_error: 0.0160\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0232 - mae: 0.0232 - root_mean_squared_error: 0.0305 - val_loss: 0.0072 - val_mae: 0.0072 - val_root_mean_squared_error: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:17:57 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:18:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:18:05 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:18:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: loss_function = mse ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0259 - mae: 0.1120 - root_mean_squared_error: 0.1610 - val_loss: 0.0083 - val_mae: 0.0792 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0087 - mae: 0.0737 - root_mean_squared_error: 0.0934 - val_loss: 0.0068 - val_mae: 0.0706 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - mae: 0.0693 - root_mean_squared_error: 0.0879 - val_loss: 0.0051 - val_mae: 0.0596 - val_root_mean_squared_error: 0.0715\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0071 - mae: 0.0663 - root_mean_squared_error: 0.0840 - val_loss: 0.0058 - val_mae: 0.0652 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0065 - mae: 0.0632 - root_mean_squared_error: 0.0809 - val_loss: 0.0071 - val_mae: 0.0738 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0061 - mae: 0.0612 - root_mean_squared_error: 0.0778 - val_loss: 0.0067 - val_mae: 0.0711 - val_root_mean_squared_error: 0.0818\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0056 - mae: 0.0582 - root_mean_squared_error: 0.0745 - val_loss: 0.0065 - val_mae: 0.0689 - val_root_mean_squared_error: 0.0804\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0056 - mae: 0.0580 - root_mean_squared_error: 0.0747 - val_loss: 0.0057 - val_mae: 0.0641 - val_root_mean_squared_error: 0.0753\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0051 - mae: 0.0556 - root_mean_squared_error: 0.0716 - val_loss: 0.0069 - val_mae: 0.0717 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0548 - root_mean_squared_error: 0.0703 - val_loss: 0.0067 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0815\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0046 - mae: 0.0527 - root_mean_squared_error: 0.0678 - val_loss: 0.0071 - val_mae: 0.0729 - val_root_mean_squared_error: 0.0842\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0043 - mae: 0.0510 - root_mean_squared_error: 0.0659 - val_loss: 0.0078 - val_mae: 0.0771 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0507 - root_mean_squared_error: 0.0649 - val_loss: 0.0064 - val_mae: 0.0690 - val_root_mean_squared_error: 0.0801\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0040 - mae: 0.0490 - root_mean_squared_error: 0.0633 - val_loss: 0.0060 - val_mae: 0.0667 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0037 - mae: 0.0472 - root_mean_squared_error: 0.0611 - val_loss: 0.0060 - val_mae: 0.0669 - val_root_mean_squared_error: 0.0776\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0459 - root_mean_squared_error: 0.0596 - val_loss: 0.0054 - val_mae: 0.0634 - val_root_mean_squared_error: 0.0733\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0445 - root_mean_squared_error: 0.0575 - val_loss: 0.0069 - val_mae: 0.0745 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0031 - mae: 0.0426 - root_mean_squared_error: 0.0553 - val_loss: 0.0037 - val_mae: 0.0521 - val_root_mean_squared_error: 0.0611\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0420 - root_mean_squared_error: 0.0539 - val_loss: 0.0031 - val_mae: 0.0482 - val_root_mean_squared_error: 0.0556\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0400 - root_mean_squared_error: 0.0511 - val_loss: 0.0017 - val_mae: 0.0356 - val_root_mean_squared_error: 0.0411\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0022 - mae: 0.0364 - root_mean_squared_error: 0.0469 - val_loss: 9.4732e-04 - val_mae: 0.0256 - val_root_mean_squared_error: 0.0308\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0020 - mae: 0.0348 - root_mean_squared_error: 0.0448 - val_loss: 6.6515e-04 - val_mae: 0.0210 - val_root_mean_squared_error: 0.0258\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0349 - root_mean_squared_error: 0.0449 - val_loss: 0.0020 - val_mae: 0.0391 - val_root_mean_squared_error: 0.0445\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0022 - mae: 0.0364 - root_mean_squared_error: 0.0471 - val_loss: 0.0015 - val_mae: 0.0323 - val_root_mean_squared_error: 0.0384\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0383 - root_mean_squared_error: 0.0494 - val_loss: 0.0013 - val_mae: 0.0302 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0023 - mae: 0.0365 - root_mean_squared_error: 0.0475 - val_loss: 0.0014 - val_mae: 0.0322 - val_root_mean_squared_error: 0.0377\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0023 - mae: 0.0367 - root_mean_squared_error: 0.0475 - val_loss: 5.3144e-04 - val_mae: 0.0187 - val_root_mean_squared_error: 0.0231\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0023 - mae: 0.0369 - root_mean_squared_error: 0.0483 - val_loss: 7.2092e-04 - val_mae: 0.0222 - val_root_mean_squared_error: 0.0268\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0022 - mae: 0.0358 - root_mean_squared_error: 0.0466 - val_loss: 8.6959e-04 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0295\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0340 - root_mean_squared_error: 0.0445 - val_loss: 7.5233e-04 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0274\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0019 - mae: 0.0338 - root_mean_squared_error: 0.0438 - val_loss: 6.5908e-04 - val_mae: 0.0214 - val_root_mean_squared_error: 0.0257\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0340 - root_mean_squared_error: 0.0443 - val_loss: 2.3309e-04 - val_mae: 0.0118 - val_root_mean_squared_error: 0.0153\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0018 - mae: 0.0328 - root_mean_squared_error: 0.0425 - val_loss: 4.1190e-04 - val_mae: 0.0167 - val_root_mean_squared_error: 0.0203\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0019 - mae: 0.0338 - root_mean_squared_error: 0.0439 - val_loss: 0.0013 - val_mae: 0.0326 - val_root_mean_squared_error: 0.0366\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0340 - root_mean_squared_error: 0.0436 - val_loss: 6.0653e-04 - val_mae: 0.0206 - val_root_mean_squared_error: 0.0246\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0018 - mae: 0.0327 - root_mean_squared_error: 0.0423 - val_loss: 7.5444e-04 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0275\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0310 - root_mean_squared_error: 0.0404 - val_loss: 3.3158e-04 - val_mae: 0.0150 - val_root_mean_squared_error: 0.0182\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0318 - root_mean_squared_error: 0.0409 - val_loss: 1.8736e-04 - val_mae: 0.0104 - val_root_mean_squared_error: 0.0137\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0016 - mae: 0.0312 - root_mean_squared_error: 0.0406 - val_loss: 1.6801e-04 - val_mae: 0.0100 - val_root_mean_squared_error: 0.0130\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0316 - root_mean_squared_error: 0.0409 - val_loss: 2.4443e-04 - val_mae: 0.0126 - val_root_mean_squared_error: 0.0156\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0315 - root_mean_squared_error: 0.0408 - val_loss: 3.3665e-04 - val_mae: 0.0152 - val_root_mean_squared_error: 0.0183\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0019 - mae: 0.0337 - root_mean_squared_error: 0.0434 - val_loss: 2.7027e-04 - val_mae: 0.0134 - val_root_mean_squared_error: 0.0164\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0018 - mae: 0.0327 - root_mean_squared_error: 0.0424 - val_loss: 1.9352e-04 - val_mae: 0.0110 - val_root_mean_squared_error: 0.0139\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0314 - root_mean_squared_error: 0.0407 - val_loss: 2.4759e-04 - val_mae: 0.0129 - val_root_mean_squared_error: 0.0157\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0285 - root_mean_squared_error: 0.0371 - val_loss: 1.9740e-04 - val_mae: 0.0116 - val_root_mean_squared_error: 0.0140\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0276 - root_mean_squared_error: 0.0359 - val_loss: 9.7667e-05 - val_mae: 0.0073 - val_root_mean_squared_error: 0.0099\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0293 - root_mean_squared_error: 0.0380 - val_loss: 5.4056e-04 - val_mae: 0.0215 - val_root_mean_squared_error: 0.0232\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0314 - root_mean_squared_error: 0.0406 - val_loss: 1.2790e-04 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0113\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0016 - mae: 0.0307 - root_mean_squared_error: 0.0396 - val_loss: 1.0836e-04 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0104\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0282 - root_mean_squared_error: 0.0371 - val_loss: 8.3199e-05 - val_mae: 0.0069 - val_root_mean_squared_error: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:19:22 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:19:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:19:30 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:19:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: loss_function = huber ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0130 - mae: 0.1121 - root_mean_squared_error: 0.1611 - val_loss: 0.0041 - val_mae: 0.0792 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0044 - mae: 0.0737 - root_mean_squared_error: 0.0934 - val_loss: 0.0034 - val_mae: 0.0707 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0693 - root_mean_squared_error: 0.0879 - val_loss: 0.0026 - val_mae: 0.0598 - val_root_mean_squared_error: 0.0717\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0664 - root_mean_squared_error: 0.0841 - val_loss: 0.0029 - val_mae: 0.0651 - val_root_mean_squared_error: 0.0762\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0634 - root_mean_squared_error: 0.0811 - val_loss: 0.0034 - val_mae: 0.0721 - val_root_mean_squared_error: 0.0827\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0614 - root_mean_squared_error: 0.0781 - val_loss: 0.0032 - val_mae: 0.0696 - val_root_mean_squared_error: 0.0804\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0585 - root_mean_squared_error: 0.0748 - val_loss: 0.0032 - val_mae: 0.0680 - val_root_mean_squared_error: 0.0794\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0583 - root_mean_squared_error: 0.0749 - val_loss: 0.0028 - val_mae: 0.0635 - val_root_mean_squared_error: 0.0748\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0559 - root_mean_squared_error: 0.0719 - val_loss: 0.0035 - val_mae: 0.0716 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0552 - root_mean_squared_error: 0.0708 - val_loss: 0.0033 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0816\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0023 - mae: 0.0531 - root_mean_squared_error: 0.0683 - val_loss: 0.0036 - val_mae: 0.0731 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0022 - mae: 0.0514 - root_mean_squared_error: 0.0664 - val_loss: 0.0040 - val_mae: 0.0776 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0021 - mae: 0.0511 - root_mean_squared_error: 0.0655 - val_loss: 0.0032 - val_mae: 0.0693 - val_root_mean_squared_error: 0.0805\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0496 - root_mean_squared_error: 0.0640 - val_loss: 0.0030 - val_mae: 0.0671 - val_root_mean_squared_error: 0.0780\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0019 - mae: 0.0478 - root_mean_squared_error: 0.0618 - val_loss: 0.0031 - val_mae: 0.0676 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0018 - mae: 0.0466 - root_mean_squared_error: 0.0605 - val_loss: 0.0028 - val_mae: 0.0644 - val_root_mean_squared_error: 0.0746\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0453 - root_mean_squared_error: 0.0587 - val_loss: 0.0037 - val_mae: 0.0771 - val_root_mean_squared_error: 0.0863\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0016 - mae: 0.0437 - root_mean_squared_error: 0.0567 - val_loss: 0.0023 - val_mae: 0.0585 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0432 - root_mean_squared_error: 0.0553 - val_loss: 0.0021 - val_mae: 0.0563 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0412 - root_mean_squared_error: 0.0526 - val_loss: 0.0012 - val_mae: 0.0432 - val_root_mean_squared_error: 0.0491\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0375 - root_mean_squared_error: 0.0483 - val_loss: 5.2080e-04 - val_mae: 0.0268 - val_root_mean_squared_error: 0.0323\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0359 - root_mean_squared_error: 0.0462 - val_loss: 3.3538e-04 - val_mae: 0.0210 - val_root_mean_squared_error: 0.0259\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0355 - root_mean_squared_error: 0.0456 - val_loss: 9.0207e-04 - val_mae: 0.0370 - val_root_mean_squared_error: 0.0425\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0364 - root_mean_squared_error: 0.0471 - val_loss: 7.4307e-04 - val_mae: 0.0325 - val_root_mean_squared_error: 0.0386\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0380 - root_mean_squared_error: 0.0491 - val_loss: 5.8897e-04 - val_mae: 0.0286 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0361 - root_mean_squared_error: 0.0469 - val_loss: 6.7860e-04 - val_mae: 0.0314 - val_root_mean_squared_error: 0.0368\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0365 - root_mean_squared_error: 0.0473 - val_loss: 2.5126e-04 - val_mae: 0.0181 - val_root_mean_squared_error: 0.0224\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0372 - root_mean_squared_error: 0.0486 - val_loss: 3.8330e-04 - val_mae: 0.0229 - val_root_mean_squared_error: 0.0277\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0362 - root_mean_squared_error: 0.0471 - val_loss: 4.5785e-04 - val_mae: 0.0253 - val_root_mean_squared_error: 0.0303\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0342 - root_mean_squared_error: 0.0448 - val_loss: 3.9054e-04 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0279\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 9.6460e-04 - mae: 0.0340 - root_mean_squared_error: 0.0439 - val_loss: 3.3719e-04 - val_mae: 0.0216 - val_root_mean_squared_error: 0.0260\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.8477e-04 - mae: 0.0341 - root_mean_squared_error: 0.0444 - val_loss: 1.2303e-04 - val_mae: 0.0121 - val_root_mean_squared_error: 0.0157\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 9.0725e-04 - mae: 0.0329 - root_mean_squared_error: 0.0426 - val_loss: 2.1416e-04 - val_mae: 0.0170 - val_root_mean_squared_error: 0.0207\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.6622e-04 - mae: 0.0339 - root_mean_squared_error: 0.0440 - val_loss: 6.9148e-04 - val_mae: 0.0330 - val_root_mean_squared_error: 0.0372\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 9.5149e-04 - mae: 0.0340 - root_mean_squared_error: 0.0436 - val_loss: 3.0330e-04 - val_mae: 0.0205 - val_root_mean_squared_error: 0.0246\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.9590e-04 - mae: 0.0328 - root_mean_squared_error: 0.0423 - val_loss: 3.8146e-04 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0276\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.1942e-04 - mae: 0.0310 - root_mean_squared_error: 0.0405 - val_loss: 1.8182e-04 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0191\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.4510e-04 - mae: 0.0319 - root_mean_squared_error: 0.0411 - val_loss: 1.0041e-04 - val_mae: 0.0108 - val_root_mean_squared_error: 0.0142\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.2920e-04 - mae: 0.0313 - root_mean_squared_error: 0.0407 - val_loss: 9.1767e-05 - val_mae: 0.0105 - val_root_mean_squared_error: 0.0135\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.4238e-04 - mae: 0.0317 - root_mean_squared_error: 0.0410 - val_loss: 1.3358e-04 - val_mae: 0.0132 - val_root_mean_squared_error: 0.0163\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.3173e-04 - mae: 0.0314 - root_mean_squared_error: 0.0408 - val_loss: 1.8738e-04 - val_mae: 0.0161 - val_root_mean_squared_error: 0.0194\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.4228e-04 - mae: 0.0337 - root_mean_squared_error: 0.0434 - val_loss: 1.5207e-04 - val_mae: 0.0142 - val_root_mean_squared_error: 0.0174\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 9.0117e-04 - mae: 0.0327 - root_mean_squared_error: 0.0425 - val_loss: 1.0920e-04 - val_mae: 0.0118 - val_root_mean_squared_error: 0.0148\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.3077e-04 - mae: 0.0315 - root_mean_squared_error: 0.0408 - val_loss: 1.3497e-04 - val_mae: 0.0135 - val_root_mean_squared_error: 0.0164\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.8779e-04 - mae: 0.0285 - root_mean_squared_error: 0.0371 - val_loss: 1.1085e-04 - val_mae: 0.0123 - val_root_mean_squared_error: 0.0149\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.4742e-04 - mae: 0.0276 - root_mean_squared_error: 0.0360 - val_loss: 5.3800e-05 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0104\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7.2770e-04 - mae: 0.0294 - root_mean_squared_error: 0.0381 - val_loss: 2.6090e-04 - val_mae: 0.0208 - val_root_mean_squared_error: 0.0228\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.3191e-04 - mae: 0.0316 - root_mean_squared_error: 0.0408 - val_loss: 7.3281e-05 - val_mae: 0.0094 - val_root_mean_squared_error: 0.0121\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.8863e-04 - mae: 0.0308 - root_mean_squared_error: 0.0397 - val_loss: 5.9050e-05 - val_mae: 0.0081 - val_root_mean_squared_error: 0.0109\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.8709e-04 - mae: 0.0282 - root_mean_squared_error: 0.0371 - val_loss: 4.9805e-05 - val_mae: 0.0076 - val_root_mean_squared_error: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:20:47 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:20:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:20:54 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:20:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 20:21:20 INFO mlflow.tracking.fluent: Experiment with name 'simplernn_input_width_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: input_width = 12 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0656 - mae: 0.0656 - root_mean_squared_error: 0.0901 - val_loss: 0.0779 - val_mae: 0.0779 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 2/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0505 - mae: 0.0505 - root_mean_squared_error: 0.0679 - val_loss: 0.0911 - val_mae: 0.0911 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 3/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0451 - mae: 0.0451 - root_mean_squared_error: 0.0608 - val_loss: 0.0844 - val_mae: 0.0844 - val_root_mean_squared_error: 0.0947\n",
      "Epoch 4/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0426 - mae: 0.0426 - root_mean_squared_error: 0.0582 - val_loss: 0.0916 - val_mae: 0.0916 - val_root_mean_squared_error: 0.1011\n",
      "Epoch 5/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0395 - mae: 0.0395 - root_mean_squared_error: 0.0536 - val_loss: 0.0686 - val_mae: 0.0686 - val_root_mean_squared_error: 0.0798\n",
      "Epoch 6/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0524 - val_loss: 0.0577 - val_mae: 0.0577 - val_root_mean_squared_error: 0.0688\n",
      "Epoch 7/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.0364 - root_mean_squared_error: 0.0496 - val_loss: 0.0749 - val_mae: 0.0749 - val_root_mean_squared_error: 0.0858\n",
      "Epoch 8/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0492 - val_loss: 0.0798 - val_mae: 0.0798 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 9/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0481 - val_loss: 0.0633 - val_mae: 0.0633 - val_root_mean_squared_error: 0.0744\n",
      "Epoch 10/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0484 - val_loss: 0.1070 - val_mae: 0.1070 - val_root_mean_squared_error: 0.1146\n",
      "Epoch 11/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0295 - mae: 0.0295 - root_mean_squared_error: 0.0408 - val_loss: 0.0438 - val_mae: 0.0438 - val_root_mean_squared_error: 0.0531\n",
      "Epoch 12/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0308 - mae: 0.0308 - root_mean_squared_error: 0.0425 - val_loss: 0.0839 - val_mae: 0.0839 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 13/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0305 - mae: 0.0305 - root_mean_squared_error: 0.0429 - val_loss: 0.0414 - val_mae: 0.0414 - val_root_mean_squared_error: 0.0502\n",
      "Epoch 14/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0328 - mae: 0.0328 - root_mean_squared_error: 0.0465 - val_loss: 0.0986 - val_mae: 0.0986 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 15/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0286 - mae: 0.0286 - root_mean_squared_error: 0.0399 - val_loss: 0.0804 - val_mae: 0.0804 - val_root_mean_squared_error: 0.0882\n",
      "Epoch 16/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0274 - mae: 0.0274 - root_mean_squared_error: 0.0391 - val_loss: 0.0658 - val_mae: 0.0658 - val_root_mean_squared_error: 0.0751\n",
      "Epoch 17/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0289 - mae: 0.0289 - root_mean_squared_error: 0.0394 - val_loss: 0.0706 - val_mae: 0.0706 - val_root_mean_squared_error: 0.0785\n",
      "Epoch 18/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0239 - mae: 0.0239 - root_mean_squared_error: 0.0342 - val_loss: 0.0777 - val_mae: 0.0777 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 19/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0251 - mae: 0.0251 - root_mean_squared_error: 0.0365 - val_loss: 0.0609 - val_mae: 0.0609 - val_root_mean_squared_error: 0.0700\n",
      "Epoch 20/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0232 - mae: 0.0232 - root_mean_squared_error: 0.0322 - val_loss: 0.0388 - val_mae: 0.0388 - val_root_mean_squared_error: 0.0475\n",
      "Epoch 21/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0237 - mae: 0.0237 - root_mean_squared_error: 0.0338 - val_loss: 0.0817 - val_mae: 0.0817 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 22/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0222 - mae: 0.0222 - root_mean_squared_error: 0.0314 - val_loss: 0.0601 - val_mae: 0.0601 - val_root_mean_squared_error: 0.0673\n",
      "Epoch 23/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0230 - mae: 0.0230 - root_mean_squared_error: 0.0325 - val_loss: 0.0293 - val_mae: 0.0293 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 24/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0255 - mae: 0.0255 - root_mean_squared_error: 0.0351 - val_loss: 0.0393 - val_mae: 0.0393 - val_root_mean_squared_error: 0.0478\n",
      "Epoch 25/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0243 - mae: 0.0243 - root_mean_squared_error: 0.0341 - val_loss: 0.0253 - val_mae: 0.0253 - val_root_mean_squared_error: 0.0299\n",
      "Epoch 26/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0224 - mae: 0.0224 - root_mean_squared_error: 0.0306 - val_loss: 0.0481 - val_mae: 0.0481 - val_root_mean_squared_error: 0.0561\n",
      "Epoch 27/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0221 - mae: 0.0221 - root_mean_squared_error: 0.0309 - val_loss: 0.0551 - val_mae: 0.0551 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 28/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0194 - mae: 0.0194 - root_mean_squared_error: 0.0275 - val_loss: 0.0463 - val_mae: 0.0463 - val_root_mean_squared_error: 0.0545\n",
      "Epoch 29/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0212 - mae: 0.0212 - root_mean_squared_error: 0.0299 - val_loss: 0.0390 - val_mae: 0.0390 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 30/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0203 - mae: 0.0203 - root_mean_squared_error: 0.0283 - val_loss: 0.0208 - val_mae: 0.0208 - val_root_mean_squared_error: 0.0245\n",
      "Epoch 31/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0203 - mae: 0.0203 - root_mean_squared_error: 0.0284 - val_loss: 0.0429 - val_mae: 0.0429 - val_root_mean_squared_error: 0.0501\n",
      "Epoch 32/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0201 - mae: 0.0201 - root_mean_squared_error: 0.0285 - val_loss: 0.0755 - val_mae: 0.0755 - val_root_mean_squared_error: 0.0813\n",
      "Epoch 33/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0195 - mae: 0.0195 - root_mean_squared_error: 0.0279 - val_loss: 0.0768 - val_mae: 0.0768 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 34/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0203 - mae: 0.0203 - root_mean_squared_error: 0.0282 - val_loss: 0.0775 - val_mae: 0.0775 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 35/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0189 - mae: 0.0189 - root_mean_squared_error: 0.0259 - val_loss: 0.0431 - val_mae: 0.0431 - val_root_mean_squared_error: 0.0488\n",
      "Epoch 36/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0195 - mae: 0.0195 - root_mean_squared_error: 0.0270 - val_loss: 0.0728 - val_mae: 0.0728 - val_root_mean_squared_error: 0.0770\n",
      "Epoch 37/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0206 - mae: 0.0206 - root_mean_squared_error: 0.0281 - val_loss: 0.0646 - val_mae: 0.0646 - val_root_mean_squared_error: 0.0708\n",
      "Epoch 38/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0185 - mae: 0.0185 - root_mean_squared_error: 0.0251 - val_loss: 0.0544 - val_mae: 0.0544 - val_root_mean_squared_error: 0.0601\n",
      "Epoch 39/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0174 - mae: 0.0174 - root_mean_squared_error: 0.0240 - val_loss: 0.0575 - val_mae: 0.0575 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 40/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0170 - mae: 0.0170 - root_mean_squared_error: 0.0235 - val_loss: 0.0290 - val_mae: 0.0290 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 41/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0177 - mae: 0.0177 - root_mean_squared_error: 0.0240 - val_loss: 0.0463 - val_mae: 0.0463 - val_root_mean_squared_error: 0.0535\n",
      "Epoch 42/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0172 - mae: 0.0172 - root_mean_squared_error: 0.0237 - val_loss: 0.0330 - val_mae: 0.0330 - val_root_mean_squared_error: 0.0386\n",
      "Epoch 43/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - mae: 0.0173 - root_mean_squared_error: 0.0234 - val_loss: 0.0448 - val_mae: 0.0448 - val_root_mean_squared_error: 0.0502\n",
      "Epoch 44/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0168 - mae: 0.0168 - root_mean_squared_error: 0.0234 - val_loss: 0.0635 - val_mae: 0.0635 - val_root_mean_squared_error: 0.0676\n",
      "Epoch 45/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0160 - root_mean_squared_error: 0.0219 - val_loss: 0.0350 - val_mae: 0.0350 - val_root_mean_squared_error: 0.0412\n",
      "Epoch 46/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0167 - mae: 0.0167 - root_mean_squared_error: 0.0228 - val_loss: 0.0496 - val_mae: 0.0496 - val_root_mean_squared_error: 0.0554\n",
      "Epoch 47/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0153 - mae: 0.0153 - root_mean_squared_error: 0.0210 - val_loss: 0.0359 - val_mae: 0.0359 - val_root_mean_squared_error: 0.0420\n",
      "Epoch 48/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0168 - mae: 0.0168 - root_mean_squared_error: 0.0229 - val_loss: 0.0348 - val_mae: 0.0348 - val_root_mean_squared_error: 0.0388\n",
      "Epoch 49/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0193 - mae: 0.0193 - root_mean_squared_error: 0.0253 - val_loss: 0.0209 - val_mae: 0.0209 - val_root_mean_squared_error: 0.0258\n",
      "Epoch 50/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0187 - mae: 0.0187 - root_mean_squared_error: 0.0244 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:21:45 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:21:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:21:52 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:21:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: input_width = 24 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0749 - mae: 0.0749 - root_mean_squared_error: 0.1017 - val_loss: 0.1441 - val_mae: 0.1441 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0810 - val_loss: 0.0711 - val_mae: 0.0711 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0562 - mae: 0.0562 - root_mean_squared_error: 0.0746 - val_loss: 0.1185 - val_mae: 0.1185 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0545 - mae: 0.0545 - root_mean_squared_error: 0.0736 - val_loss: 0.0657 - val_mae: 0.0657 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0515 - mae: 0.0515 - root_mean_squared_error: 0.0689 - val_loss: 0.0747 - val_mae: 0.0747 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0679 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0508 - mae: 0.0508 - root_mean_squared_error: 0.0683 - val_loss: 0.0709 - val_mae: 0.0709 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0481 - mae: 0.0481 - root_mean_squared_error: 0.0647 - val_loss: 0.1175 - val_mae: 0.1175 - val_root_mean_squared_error: 0.1314\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0436 - mae: 0.0436 - root_mean_squared_error: 0.0591 - val_loss: 0.1147 - val_mae: 0.1147 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0603 - val_loss: 0.1371 - val_mae: 0.1371 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0587 - val_loss: 0.1653 - val_mae: 0.1653 - val_root_mean_squared_error: 0.1762\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0546 - val_loss: 0.1428 - val_mae: 0.1428 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0544 - val_loss: 0.1299 - val_mae: 0.1299 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0555 - val_loss: 0.1610 - val_mae: 0.1610 - val_root_mean_squared_error: 0.1716\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0512 - val_loss: 0.1413 - val_mae: 0.1413 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0379 - mae: 0.0379 - root_mean_squared_error: 0.0533 - val_loss: 0.1370 - val_mae: 0.1370 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0545 - val_loss: 0.1199 - val_mae: 0.1199 - val_root_mean_squared_error: 0.1346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0542 - val_loss: 0.0910 - val_mae: 0.0910 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0584 - val_loss: 0.0774 - val_mae: 0.0774 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0504 - val_loss: 0.0934 - val_mae: 0.0934 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0494 - val_loss: 0.0843 - val_mae: 0.0843 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0502 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0516 - val_loss: 0.0803 - val_mae: 0.0803 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0529 - val_loss: 0.0759 - val_mae: 0.0759 - val_root_mean_squared_error: 0.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:22:35 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:22:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:22:43 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:22:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: input_width = 48 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0924 - mae: 0.0924 - root_mean_squared_error: 0.1218 - val_loss: 0.1384 - val_mae: 0.1384 - val_root_mean_squared_error: 0.1539\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0768 - mae: 0.0768 - root_mean_squared_error: 0.1017 - val_loss: 0.0566 - val_mae: 0.0566 - val_root_mean_squared_error: 0.0679\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0822 - mae: 0.0822 - root_mean_squared_error: 0.1073 - val_loss: 0.0636 - val_mae: 0.0636 - val_root_mean_squared_error: 0.0782\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0791 - mae: 0.0791 - root_mean_squared_error: 0.0998 - val_loss: 0.0798 - val_mae: 0.0798 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0768 - mae: 0.0768 - root_mean_squared_error: 0.0977 - val_loss: 0.1044 - val_mae: 0.1044 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0755 - mae: 0.0755 - root_mean_squared_error: 0.0958 - val_loss: 0.0932 - val_mae: 0.0932 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0732 - mae: 0.0732 - root_mean_squared_error: 0.0943 - val_loss: 0.0980 - val_mae: 0.0980 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0719 - mae: 0.0719 - root_mean_squared_error: 0.0922 - val_loss: 0.0528 - val_mae: 0.0528 - val_root_mean_squared_error: 0.0665\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0716 - mae: 0.0716 - root_mean_squared_error: 0.0911 - val_loss: 0.0643 - val_mae: 0.0643 - val_root_mean_squared_error: 0.0795\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0721 - mae: 0.0721 - root_mean_squared_error: 0.0926 - val_loss: 0.0557 - val_mae: 0.0557 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0732 - mae: 0.0732 - root_mean_squared_error: 0.0931 - val_loss: 0.0815 - val_mae: 0.0815 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0700 - mae: 0.0700 - root_mean_squared_error: 0.0886 - val_loss: 0.0828 - val_mae: 0.0828 - val_root_mean_squared_error: 0.0978\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0702 - mae: 0.0702 - root_mean_squared_error: 0.0902 - val_loss: 0.0805 - val_mae: 0.0805 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0677 - mae: 0.0677 - root_mean_squared_error: 0.0871 - val_loss: 0.0532 - val_mae: 0.0532 - val_root_mean_squared_error: 0.0665\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0693 - mae: 0.0693 - root_mean_squared_error: 0.0908 - val_loss: 0.0489 - val_mae: 0.0489 - val_root_mean_squared_error: 0.0610\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0714 - mae: 0.0714 - root_mean_squared_error: 0.0903 - val_loss: 0.0640 - val_mae: 0.0640 - val_root_mean_squared_error: 0.0792\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0699 - mae: 0.0699 - root_mean_squared_error: 0.0876 - val_loss: 0.0598 - val_mae: 0.0598 - val_root_mean_squared_error: 0.0750\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0696 - mae: 0.0696 - root_mean_squared_error: 0.0886 - val_loss: 0.0618 - val_mae: 0.0618 - val_root_mean_squared_error: 0.0770\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0660 - mae: 0.0660 - root_mean_squared_error: 0.0849 - val_loss: 0.0563 - val_mae: 0.0563 - val_root_mean_squared_error: 0.0705\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0659 - mae: 0.0659 - root_mean_squared_error: 0.0847 - val_loss: 0.0697 - val_mae: 0.0697 - val_root_mean_squared_error: 0.0847\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0665 - mae: 0.0665 - root_mean_squared_error: 0.0856 - val_loss: 0.0970 - val_mae: 0.0970 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0675 - mae: 0.0675 - root_mean_squared_error: 0.0868 - val_loss: 0.0598 - val_mae: 0.0598 - val_root_mean_squared_error: 0.0744\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0673 - mae: 0.0673 - root_mean_squared_error: 0.0864 - val_loss: 0.0832 - val_mae: 0.0832 - val_root_mean_squared_error: 0.0980\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0683 - mae: 0.0683 - root_mean_squared_error: 0.0894 - val_loss: 0.0657 - val_mae: 0.0657 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0674 - mae: 0.0674 - root_mean_squared_error: 0.0855 - val_loss: 0.0757 - val_mae: 0.0757 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0657 - mae: 0.0657 - root_mean_squared_error: 0.0844 - val_loss: 0.0581 - val_mae: 0.0581 - val_root_mean_squared_error: 0.0729\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0634 - mae: 0.0634 - root_mean_squared_error: 0.0808 - val_loss: 0.0829 - val_mae: 0.0829 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0645 - mae: 0.0645 - root_mean_squared_error: 0.0826 - val_loss: 0.0777 - val_mae: 0.0777 - val_root_mean_squared_error: 0.0926\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0655 - mae: 0.0655 - root_mean_squared_error: 0.0827 - val_loss: 0.0669 - val_mae: 0.0669 - val_root_mean_squared_error: 0.0822\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0644 - mae: 0.0644 - root_mean_squared_error: 0.0822 - val_loss: 0.0638 - val_mae: 0.0638 - val_root_mean_squared_error: 0.0791\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0832 - val_loss: 0.0635 - val_mae: 0.0635 - val_root_mean_squared_error: 0.0786\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0662 - mae: 0.0662 - root_mean_squared_error: 0.0842 - val_loss: 0.0675 - val_mae: 0.0675 - val_root_mean_squared_error: 0.0828\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0645 - mae: 0.0645 - root_mean_squared_error: 0.0828 - val_loss: 0.0534 - val_mae: 0.0534 - val_root_mean_squared_error: 0.0676\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0662 - mae: 0.0662 - root_mean_squared_error: 0.0839 - val_loss: 0.0566 - val_mae: 0.0566 - val_root_mean_squared_error: 0.0714\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0642 - mae: 0.0642 - root_mean_squared_error: 0.0836 - val_loss: 0.0561 - val_mae: 0.0561 - val_root_mean_squared_error: 0.0707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:23:36 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:23:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:23:43 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:23:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: input_width = 72 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1242 - mae: 0.1242 - root_mean_squared_error: 0.1589 - val_loss: 0.1088 - val_mae: 0.1088 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 2/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0994 - mae: 0.0994 - root_mean_squared_error: 0.1254 - val_loss: 0.1121 - val_mae: 0.1121 - val_root_mean_squared_error: 0.1285\n",
      "Epoch 3/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0935 - mae: 0.0935 - root_mean_squared_error: 0.1181 - val_loss: 0.0841 - val_mae: 0.0841 - val_root_mean_squared_error: 0.1021\n",
      "Epoch 4/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0945 - mae: 0.0945 - root_mean_squared_error: 0.1195 - val_loss: 0.0881 - val_mae: 0.0881 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 5/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0880 - mae: 0.0880 - root_mean_squared_error: 0.1102 - val_loss: 0.0862 - val_mae: 0.0862 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 6/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0871 - mae: 0.0871 - root_mean_squared_error: 0.1085 - val_loss: 0.0763 - val_mae: 0.0763 - val_root_mean_squared_error: 0.0942\n",
      "Epoch 7/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0861 - mae: 0.0861 - root_mean_squared_error: 0.1074 - val_loss: 0.0832 - val_mae: 0.0832 - val_root_mean_squared_error: 0.1010\n",
      "Epoch 8/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0855 - mae: 0.0855 - root_mean_squared_error: 0.1067 - val_loss: 0.0730 - val_mae: 0.0730 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 9/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0859 - mae: 0.0859 - root_mean_squared_error: 0.1064 - val_loss: 0.0731 - val_mae: 0.0731 - val_root_mean_squared_error: 0.0910\n",
      "Epoch 10/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0838 - mae: 0.0838 - root_mean_squared_error: 0.1048 - val_loss: 0.0651 - val_mae: 0.0651 - val_root_mean_squared_error: 0.0823\n",
      "Epoch 11/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0840 - mae: 0.0840 - root_mean_squared_error: 0.1045 - val_loss: 0.0852 - val_mae: 0.0852 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 12/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0850 - mae: 0.0850 - root_mean_squared_error: 0.1059 - val_loss: 0.0689 - val_mae: 0.0689 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 13/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0839 - mae: 0.0839 - root_mean_squared_error: 0.1044 - val_loss: 0.0816 - val_mae: 0.0816 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 14/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0824 - mae: 0.0824 - root_mean_squared_error: 0.1022 - val_loss: 0.0770 - val_mae: 0.0770 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 15/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0844 - mae: 0.0844 - root_mean_squared_error: 0.1052 - val_loss: 0.0734 - val_mae: 0.0734 - val_root_mean_squared_error: 0.0915\n",
      "Epoch 16/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0831 - mae: 0.0831 - root_mean_squared_error: 0.1032 - val_loss: 0.0703 - val_mae: 0.0703 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 17/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0829 - mae: 0.0829 - root_mean_squared_error: 0.1028 - val_loss: 0.0823 - val_mae: 0.0823 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 18/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0807 - mae: 0.0807 - root_mean_squared_error: 0.1011 - val_loss: 0.0799 - val_mae: 0.0799 - val_root_mean_squared_error: 0.0982\n",
      "Epoch 19/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0802 - mae: 0.0802 - root_mean_squared_error: 0.1002 - val_loss: 0.0696 - val_mae: 0.0696 - val_root_mean_squared_error: 0.0877\n",
      "Epoch 20/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0805 - mae: 0.0805 - root_mean_squared_error: 0.1007 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 21/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0802 - mae: 0.0802 - root_mean_squared_error: 0.1000 - val_loss: 0.0689 - val_mae: 0.0689 - val_root_mean_squared_error: 0.0870\n",
      "Epoch 22/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0807 - mae: 0.0807 - root_mean_squared_error: 0.1009 - val_loss: 0.0753 - val_mae: 0.0753 - val_root_mean_squared_error: 0.0937\n",
      "Epoch 23/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0795 - mae: 0.0795 - root_mean_squared_error: 0.1001 - val_loss: 0.0685 - val_mae: 0.0685 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 24/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0796 - mae: 0.0796 - root_mean_squared_error: 0.1002 - val_loss: 0.0678 - val_mae: 0.0678 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 25/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0794 - mae: 0.0794 - root_mean_squared_error: 0.0996 - val_loss: 0.0621 - val_mae: 0.0621 - val_root_mean_squared_error: 0.0793\n",
      "Epoch 26/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0791 - mae: 0.0791 - root_mean_squared_error: 0.0997 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 27/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0785 - mae: 0.0785 - root_mean_squared_error: 0.0991 - val_loss: 0.0693 - val_mae: 0.0693 - val_root_mean_squared_error: 0.0876\n",
      "Epoch 28/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0799 - mae: 0.0799 - root_mean_squared_error: 0.1006 - val_loss: 0.0651 - val_mae: 0.0651 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 29/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0789 - mae: 0.0789 - root_mean_squared_error: 0.0998 - val_loss: 0.0652 - val_mae: 0.0652 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 30/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0792 - mae: 0.0792 - root_mean_squared_error: 0.1002 - val_loss: 0.0713 - val_mae: 0.0713 - val_root_mean_squared_error: 0.0897\n",
      "Epoch 31/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0796 - mae: 0.0796 - root_mean_squared_error: 0.1011 - val_loss: 0.0691 - val_mae: 0.0691 - val_root_mean_squared_error: 0.0876\n",
      "Epoch 32/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0790 - mae: 0.0790 - root_mean_squared_error: 0.0999 - val_loss: 0.0712 - val_mae: 0.0712 - val_root_mean_squared_error: 0.0897\n",
      "Epoch 33/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0774 - mae: 0.0774 - root_mean_squared_error: 0.0980 - val_loss: 0.0758 - val_mae: 0.0758 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 34/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0773 - mae: 0.0773 - root_mean_squared_error: 0.0980 - val_loss: 0.0681 - val_mae: 0.0681 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 35/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0781 - mae: 0.0781 - root_mean_squared_error: 0.0987 - val_loss: 0.0668 - val_mae: 0.0668 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 36/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0777 - mae: 0.0777 - root_mean_squared_error: 0.0986 - val_loss: 0.0603 - val_mae: 0.0603 - val_root_mean_squared_error: 0.0772\n",
      "Epoch 37/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0786 - mae: 0.0786 - root_mean_squared_error: 0.0998 - val_loss: 0.0683 - val_mae: 0.0683 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 38/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0780 - mae: 0.0780 - root_mean_squared_error: 0.0987 - val_loss: 0.0720 - val_mae: 0.0720 - val_root_mean_squared_error: 0.0906\n",
      "Epoch 39/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0781 - mae: 0.0781 - root_mean_squared_error: 0.0991 - val_loss: 0.0709 - val_mae: 0.0709 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 40/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0787 - mae: 0.0787 - root_mean_squared_error: 0.0998 - val_loss: 0.0682 - val_mae: 0.0682 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 41/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0768 - mae: 0.0768 - root_mean_squared_error: 0.0974 - val_loss: 0.0647 - val_mae: 0.0647 - val_root_mean_squared_error: 0.0827\n",
      "Epoch 42/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0777 - mae: 0.0777 - root_mean_squared_error: 0.0993 - val_loss: 0.0642 - val_mae: 0.0642 - val_root_mean_squared_error: 0.0822\n",
      "Epoch 43/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0775 - mae: 0.0775 - root_mean_squared_error: 0.0989 - val_loss: 0.0706 - val_mae: 0.0706 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 44/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0774 - mae: 0.0774 - root_mean_squared_error: 0.0984 - val_loss: 0.0663 - val_mae: 0.0663 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 45/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0768 - mae: 0.0768 - root_mean_squared_error: 0.0981 - val_loss: 0.0656 - val_mae: 0.0656 - val_root_mean_squared_error: 0.0838\n",
      "Epoch 46/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0769 - mae: 0.0769 - root_mean_squared_error: 0.0979 - val_loss: 0.0632 - val_mae: 0.0632 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 47/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0900 - mae: 0.0900 - root_mean_squared_error: 0.1265 - val_loss: 0.1056 - val_mae: 0.1056 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 48/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0770 - mae: 0.0770 - root_mean_squared_error: 0.0978 - val_loss: 0.0643 - val_mae: 0.0643 - val_root_mean_squared_error: 0.0822\n",
      "Epoch 49/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0772 - mae: 0.0772 - root_mean_squared_error: 0.0981 - val_loss: 0.0623 - val_mae: 0.0623 - val_root_mean_squared_error: 0.0798\n",
      "Epoch 50/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0771 - mae: 0.0771 - root_mean_squared_error: 0.0985 - val_loss: 0.0646 - val_mae: 0.0646 - val_root_mean_squared_error: 0.0826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:24:51 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:24:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:24:59 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:25:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: input_width = 96 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1322 - mae: 0.1322 - root_mean_squared_error: 0.1699 - val_loss: 0.1048 - val_mae: 0.1048 - val_root_mean_squared_error: 0.1231\n",
      "Epoch 2/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1057 - mae: 0.1057 - root_mean_squared_error: 0.1327 - val_loss: 0.1098 - val_mae: 0.1098 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 3/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1012 - mae: 0.1012 - root_mean_squared_error: 0.1257 - val_loss: 0.1195 - val_mae: 0.1195 - val_root_mean_squared_error: 0.1371\n",
      "Epoch 4/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0975 - mae: 0.0975 - root_mean_squared_error: 0.1213 - val_loss: 0.1018 - val_mae: 0.1018 - val_root_mean_squared_error: 0.1200\n",
      "Epoch 5/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0958 - mae: 0.0958 - root_mean_squared_error: 0.1190 - val_loss: 0.0961 - val_mae: 0.0961 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 6/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0956 - mae: 0.0956 - root_mean_squared_error: 0.1177 - val_loss: 0.1127 - val_mae: 0.1127 - val_root_mean_squared_error: 0.1306\n",
      "Epoch 7/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0954 - mae: 0.0954 - root_mean_squared_error: 0.1175 - val_loss: 0.0824 - val_mae: 0.0824 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 8/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0963 - mae: 0.0963 - root_mean_squared_error: 0.1186 - val_loss: 0.1029 - val_mae: 0.1029 - val_root_mean_squared_error: 0.1211\n",
      "Epoch 9/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0929 - mae: 0.0929 - root_mean_squared_error: 0.1149 - val_loss: 0.1001 - val_mae: 0.1001 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 10/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0911 - mae: 0.0911 - root_mean_squared_error: 0.1133 - val_loss: 0.0975 - val_mae: 0.0975 - val_root_mean_squared_error: 0.1158\n",
      "Epoch 11/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0927 - mae: 0.0927 - root_mean_squared_error: 0.1147 - val_loss: 0.0943 - val_mae: 0.0943 - val_root_mean_squared_error: 0.1126\n",
      "Epoch 12/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0928 - mae: 0.0928 - root_mean_squared_error: 0.1147 - val_loss: 0.0986 - val_mae: 0.0986 - val_root_mean_squared_error: 0.1170\n",
      "Epoch 13/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0917 - mae: 0.0917 - root_mean_squared_error: 0.1138 - val_loss: 0.1017 - val_mae: 0.1017 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 14/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0899 - mae: 0.0899 - root_mean_squared_error: 0.1116 - val_loss: 0.0917 - val_mae: 0.0917 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 15/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0884 - mae: 0.0884 - root_mean_squared_error: 0.1103 - val_loss: 0.0991 - val_mae: 0.0991 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 16/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0898 - mae: 0.0898 - root_mean_squared_error: 0.1117 - val_loss: 0.0999 - val_mae: 0.0999 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 17/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0890 - mae: 0.0890 - root_mean_squared_error: 0.1106 - val_loss: 0.0922 - val_mae: 0.0922 - val_root_mean_squared_error: 0.1106\n",
      "Epoch 18/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0905 - mae: 0.0905 - root_mean_squared_error: 0.1120 - val_loss: 0.0951 - val_mae: 0.0951 - val_root_mean_squared_error: 0.1136\n",
      "Epoch 19/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0901 - mae: 0.0901 - root_mean_squared_error: 0.1112 - val_loss: 0.0932 - val_mae: 0.0932 - val_root_mean_squared_error: 0.1118\n",
      "Epoch 20/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0901 - mae: 0.0901 - root_mean_squared_error: 0.1120 - val_loss: 0.0882 - val_mae: 0.0882 - val_root_mean_squared_error: 0.1066\n",
      "Epoch 21/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0887 - mae: 0.0887 - root_mean_squared_error: 0.1106 - val_loss: 0.0988 - val_mae: 0.0988 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 22/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0889 - mae: 0.0889 - root_mean_squared_error: 0.1107 - val_loss: 0.0908 - val_mae: 0.0908 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 23/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0874 - mae: 0.0874 - root_mean_squared_error: 0.1095 - val_loss: 0.0925 - val_mae: 0.0925 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 24/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0885 - mae: 0.0885 - root_mean_squared_error: 0.1104 - val_loss: 0.0923 - val_mae: 0.0923 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 25/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0891 - mae: 0.0891 - root_mean_squared_error: 0.1108 - val_loss: 0.0853 - val_mae: 0.0853 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 26/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0876 - mae: 0.0876 - root_mean_squared_error: 0.1093 - val_loss: 0.0934 - val_mae: 0.0934 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 27/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0864 - mae: 0.0864 - root_mean_squared_error: 0.1077 - val_loss: 0.0921 - val_mae: 0.0921 - val_root_mean_squared_error: 0.1107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:25:51 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:25:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:25:59 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:26:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 20:26:20 INFO mlflow.tracking.fluent: Experiment with name 'simplernn_batch_size_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: batch_size = 16 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0734 - mae: 0.0734 - root_mean_squared_error: 0.0970 - val_loss: 0.0521 - val_mae: 0.0521 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 2/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0786 - val_loss: 0.0939 - val_mae: 0.0939 - val_root_mean_squared_error: 0.1062\n",
      "Epoch 3/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0510 - mae: 0.0510 - root_mean_squared_error: 0.0672 - val_loss: 0.0672 - val_mae: 0.0672 - val_root_mean_squared_error: 0.0798\n",
      "Epoch 4/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0500 - mae: 0.0500 - root_mean_squared_error: 0.0660 - val_loss: 0.0765 - val_mae: 0.0765 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 5/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0457 - mae: 0.0457 - root_mean_squared_error: 0.0596 - val_loss: 0.0652 - val_mae: 0.0652 - val_root_mean_squared_error: 0.0774\n",
      "Epoch 6/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0467 - mae: 0.0467 - root_mean_squared_error: 0.0613 - val_loss: 0.0724 - val_mae: 0.0724 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 7/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0418 - mae: 0.0418 - root_mean_squared_error: 0.0557 - val_loss: 0.0536 - val_mae: 0.0536 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 8/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0524 - val_loss: 0.1003 - val_mae: 0.1003 - val_root_mean_squared_error: 0.1105\n",
      "Epoch 9/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0514 - val_loss: 0.0972 - val_mae: 0.0972 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 10/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0489 - val_loss: 0.1250 - val_mae: 0.1250 - val_root_mean_squared_error: 0.1333\n",
      "Epoch 11/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0498 - val_loss: 0.0791 - val_mae: 0.0791 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 12/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0452 - val_loss: 0.1148 - val_mae: 0.1148 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 13/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0311 - mae: 0.0311 - root_mean_squared_error: 0.0420 - val_loss: 0.1083 - val_mae: 0.1083 - val_root_mean_squared_error: 0.1157\n",
      "Epoch 14/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0306 - mae: 0.0306 - root_mean_squared_error: 0.0413 - val_loss: 0.1023 - val_mae: 0.1023 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 15/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0301 - mae: 0.0301 - root_mean_squared_error: 0.0410 - val_loss: 0.1058 - val_mae: 0.1058 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 16/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0293 - mae: 0.0293 - root_mean_squared_error: 0.0395 - val_loss: 0.0778 - val_mae: 0.0778 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 17/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0277 - mae: 0.0277 - root_mean_squared_error: 0.0383 - val_loss: 0.1222 - val_mae: 0.1222 - val_root_mean_squared_error: 0.1290\n",
      "Epoch 18/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0379 - val_loss: 0.1237 - val_mae: 0.1237 - val_root_mean_squared_error: 0.1308\n",
      "Epoch 19/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0290 - mae: 0.0290 - root_mean_squared_error: 0.0400 - val_loss: 0.0441 - val_mae: 0.0441 - val_root_mean_squared_error: 0.0537\n",
      "Epoch 20/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0285 - mae: 0.0285 - root_mean_squared_error: 0.0381 - val_loss: 0.0606 - val_mae: 0.0606 - val_root_mean_squared_error: 0.0706\n",
      "Epoch 21/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0259 - mae: 0.0259 - root_mean_squared_error: 0.0345 - val_loss: 0.1187 - val_mae: 0.1187 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 22/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0260 - mae: 0.0260 - root_mean_squared_error: 0.0351 - val_loss: 0.0670 - val_mae: 0.0670 - val_root_mean_squared_error: 0.0739\n",
      "Epoch 23/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0230 - mae: 0.0230 - root_mean_squared_error: 0.0301 - val_loss: 0.1030 - val_mae: 0.1030 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 24/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0217 - mae: 0.0217 - root_mean_squared_error: 0.0288 - val_loss: 0.0527 - val_mae: 0.0527 - val_root_mean_squared_error: 0.0629\n",
      "Epoch 25/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0223 - mae: 0.0223 - root_mean_squared_error: 0.0296 - val_loss: 0.1083 - val_mae: 0.1083 - val_root_mean_squared_error: 0.1152\n",
      "Epoch 26/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0209 - mae: 0.0209 - root_mean_squared_error: 0.0277 - val_loss: 0.0640 - val_mae: 0.0640 - val_root_mean_squared_error: 0.0723\n",
      "Epoch 27/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0224 - mae: 0.0224 - root_mean_squared_error: 0.0306 - val_loss: 0.0460 - val_mae: 0.0460 - val_root_mean_squared_error: 0.0546\n",
      "Epoch 28/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0272 - mae: 0.0272 - root_mean_squared_error: 0.0354 - val_loss: 0.0865 - val_mae: 0.0865 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 29/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0253 - mae: 0.0253 - root_mean_squared_error: 0.0331 - val_loss: 0.0503 - val_mae: 0.0503 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 30/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0228 - mae: 0.0228 - root_mean_squared_error: 0.0303 - val_loss: 0.0956 - val_mae: 0.0956 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 31/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0226 - mae: 0.0226 - root_mean_squared_error: 0.0297 - val_loss: 0.0662 - val_mae: 0.0662 - val_root_mean_squared_error: 0.0729\n",
      "Epoch 32/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0214 - mae: 0.0214 - root_mean_squared_error: 0.0282 - val_loss: 0.0630 - val_mae: 0.0630 - val_root_mean_squared_error: 0.0704\n",
      "Epoch 33/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0199 - mae: 0.0199 - root_mean_squared_error: 0.0268 - val_loss: 0.0579 - val_mae: 0.0579 - val_root_mean_squared_error: 0.0646\n",
      "Epoch 34/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0211 - mae: 0.0211 - root_mean_squared_error: 0.0286 - val_loss: 0.0567 - val_mae: 0.0567 - val_root_mean_squared_error: 0.0628\n",
      "Epoch 35/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0220 - mae: 0.0220 - root_mean_squared_error: 0.0289 - val_loss: 0.0354 - val_mae: 0.0354 - val_root_mean_squared_error: 0.0417\n",
      "Epoch 36/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0184 - mae: 0.0184 - root_mean_squared_error: 0.0244 - val_loss: 0.0515 - val_mae: 0.0515 - val_root_mean_squared_error: 0.0586\n",
      "Epoch 37/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0197 - mae: 0.0197 - root_mean_squared_error: 0.0274 - val_loss: 0.0733 - val_mae: 0.0733 - val_root_mean_squared_error: 0.0793\n",
      "Epoch 38/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0219 - mae: 0.0219 - root_mean_squared_error: 0.0282 - val_loss: 0.0484 - val_mae: 0.0484 - val_root_mean_squared_error: 0.0537\n",
      "Epoch 39/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0186 - mae: 0.0186 - root_mean_squared_error: 0.0250 - val_loss: 0.0672 - val_mae: 0.0672 - val_root_mean_squared_error: 0.0721\n",
      "Epoch 40/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0208 - mae: 0.0208 - root_mean_squared_error: 0.0272 - val_loss: 0.0628 - val_mae: 0.0628 - val_root_mean_squared_error: 0.0689\n",
      "Epoch 41/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0188 - mae: 0.0188 - root_mean_squared_error: 0.0254 - val_loss: 0.0740 - val_mae: 0.0740 - val_root_mean_squared_error: 0.0793\n",
      "Epoch 42/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0203 - mae: 0.0203 - root_mean_squared_error: 0.0268 - val_loss: 0.0346 - val_mae: 0.0346 - val_root_mean_squared_error: 0.0411\n",
      "Epoch 43/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0187 - mae: 0.0187 - root_mean_squared_error: 0.0251 - val_loss: 0.0847 - val_mae: 0.0847 - val_root_mean_squared_error: 0.0900\n",
      "Epoch 44/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0200 - mae: 0.0200 - root_mean_squared_error: 0.0262 - val_loss: 0.0388 - val_mae: 0.0388 - val_root_mean_squared_error: 0.0440\n",
      "Epoch 45/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0196 - mae: 0.0196 - root_mean_squared_error: 0.0259 - val_loss: 0.0626 - val_mae: 0.0626 - val_root_mean_squared_error: 0.0686\n",
      "Epoch 46/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0189 - mae: 0.0189 - root_mean_squared_error: 0.0251 - val_loss: 0.0279 - val_mae: 0.0279 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 47/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0195 - mae: 0.0195 - root_mean_squared_error: 0.0256 - val_loss: 0.0722 - val_mae: 0.0722 - val_root_mean_squared_error: 0.0769\n",
      "Epoch 48/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0189 - mae: 0.0189 - root_mean_squared_error: 0.0252 - val_loss: 0.0161 - val_mae: 0.0161 - val_root_mean_squared_error: 0.0197\n",
      "Epoch 49/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0181 - mae: 0.0181 - root_mean_squared_error: 0.0242 - val_loss: 0.0389 - val_mae: 0.0389 - val_root_mean_squared_error: 0.0460\n",
      "Epoch 50/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0169 - mae: 0.0169 - root_mean_squared_error: 0.0233 - val_loss: 0.0501 - val_mae: 0.0501 - val_root_mean_squared_error: 0.0575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:27:04 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:27:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:27:12 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:27:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: batch_size = 32 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0749 - mae: 0.0749 - root_mean_squared_error: 0.1017 - val_loss: 0.1441 - val_mae: 0.1441 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0810 - val_loss: 0.0711 - val_mae: 0.0711 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0562 - mae: 0.0562 - root_mean_squared_error: 0.0746 - val_loss: 0.1185 - val_mae: 0.1185 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0545 - mae: 0.0545 - root_mean_squared_error: 0.0736 - val_loss: 0.0657 - val_mae: 0.0657 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0515 - mae: 0.0515 - root_mean_squared_error: 0.0689 - val_loss: 0.0747 - val_mae: 0.0747 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0679 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0508 - mae: 0.0508 - root_mean_squared_error: 0.0683 - val_loss: 0.0709 - val_mae: 0.0709 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0481 - mae: 0.0481 - root_mean_squared_error: 0.0647 - val_loss: 0.1175 - val_mae: 0.1175 - val_root_mean_squared_error: 0.1314\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0436 - mae: 0.0436 - root_mean_squared_error: 0.0591 - val_loss: 0.1147 - val_mae: 0.1147 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0603 - val_loss: 0.1371 - val_mae: 0.1371 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0587 - val_loss: 0.1653 - val_mae: 0.1653 - val_root_mean_squared_error: 0.1762\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0546 - val_loss: 0.1428 - val_mae: 0.1428 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0544 - val_loss: 0.1299 - val_mae: 0.1299 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0555 - val_loss: 0.1610 - val_mae: 0.1610 - val_root_mean_squared_error: 0.1716\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0512 - val_loss: 0.1413 - val_mae: 0.1413 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0379 - mae: 0.0379 - root_mean_squared_error: 0.0533 - val_loss: 0.1370 - val_mae: 0.1370 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0545 - val_loss: 0.1199 - val_mae: 0.1199 - val_root_mean_squared_error: 0.1346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0542 - val_loss: 0.0910 - val_mae: 0.0910 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0584 - val_loss: 0.0774 - val_mae: 0.0774 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0504 - val_loss: 0.0934 - val_mae: 0.0934 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0494 - val_loss: 0.0843 - val_mae: 0.0843 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0502 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0516 - val_loss: 0.0803 - val_mae: 0.0803 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0529 - val_loss: 0.0759 - val_mae: 0.0759 - val_root_mean_squared_error: 0.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:27:54 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:28:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:28:02 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:28:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: batch_size = 64 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0964 - mae: 0.0964 - root_mean_squared_error: 0.1258 - val_loss: 0.0612 - val_mae: 0.0612 - val_root_mean_squared_error: 0.0738\n",
      "Epoch 2/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0655 - mae: 0.0655 - root_mean_squared_error: 0.0838 - val_loss: 0.0922 - val_mae: 0.0922 - val_root_mean_squared_error: 0.1058\n",
      "Epoch 3/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0620 - mae: 0.0620 - root_mean_squared_error: 0.0802 - val_loss: 0.0838 - val_mae: 0.0838 - val_root_mean_squared_error: 0.0975\n",
      "Epoch 4/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0605 - mae: 0.0605 - root_mean_squared_error: 0.0795 - val_loss: 0.0945 - val_mae: 0.0945 - val_root_mean_squared_error: 0.1075\n",
      "Epoch 5/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0559 - mae: 0.0559 - root_mean_squared_error: 0.0731 - val_loss: 0.0654 - val_mae: 0.0654 - val_root_mean_squared_error: 0.0780\n",
      "Epoch 6/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0548 - mae: 0.0548 - root_mean_squared_error: 0.0726 - val_loss: 0.1002 - val_mae: 0.1002 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 7/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0521 - mae: 0.0521 - root_mean_squared_error: 0.0681 - val_loss: 0.1141 - val_mae: 0.1141 - val_root_mean_squared_error: 0.1254\n",
      "Epoch 8/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0496 - mae: 0.0496 - root_mean_squared_error: 0.0654 - val_loss: 0.1224 - val_mae: 0.1224 - val_root_mean_squared_error: 0.1331\n",
      "Epoch 9/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0638 - val_loss: 0.1196 - val_mae: 0.1196 - val_root_mean_squared_error: 0.1303\n",
      "Epoch 10/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0486 - mae: 0.0486 - root_mean_squared_error: 0.0632 - val_loss: 0.0979 - val_mae: 0.0979 - val_root_mean_squared_error: 0.1104\n",
      "Epoch 11/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0489 - mae: 0.0489 - root_mean_squared_error: 0.0633 - val_loss: 0.0969 - val_mae: 0.0969 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 12/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0463 - mae: 0.0463 - root_mean_squared_error: 0.0606 - val_loss: 0.0894 - val_mae: 0.0894 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 13/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0462 - mae: 0.0462 - root_mean_squared_error: 0.0603 - val_loss: 0.0867 - val_mae: 0.0867 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 14/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0478 - mae: 0.0478 - root_mean_squared_error: 0.0624 - val_loss: 0.1034 - val_mae: 0.1034 - val_root_mean_squared_error: 0.1144\n",
      "Epoch 15/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0565 - val_loss: 0.0980 - val_mae: 0.0980 - val_root_mean_squared_error: 0.1091\n",
      "Epoch 16/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0427 - mae: 0.0427 - root_mean_squared_error: 0.0554 - val_loss: 0.0743 - val_mae: 0.0743 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 17/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0563 - val_loss: 0.0891 - val_mae: 0.0891 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 18/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0391 - mae: 0.0391 - root_mean_squared_error: 0.0510 - val_loss: 0.0866 - val_mae: 0.0866 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 19/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0532 - val_loss: 0.0627 - val_mae: 0.0627 - val_root_mean_squared_error: 0.0748\n",
      "Epoch 20/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0438 - mae: 0.0438 - root_mean_squared_error: 0.0570 - val_loss: 0.0817 - val_mae: 0.0817 - val_root_mean_squared_error: 0.0927\n",
      "Epoch 21/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0520 - val_loss: 0.0948 - val_mae: 0.0948 - val_root_mean_squared_error: 0.1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:28:39 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:28:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:28:47 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:28:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: batch_size = 128 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1029 - mae: 0.1029 - root_mean_squared_error: 0.1350 - val_loss: 0.1051 - val_mae: 0.1051 - val_root_mean_squared_error: 0.1150\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0639 - mae: 0.0639 - root_mean_squared_error: 0.0830 - val_loss: 0.0542 - val_mae: 0.0542 - val_root_mean_squared_error: 0.0657\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0726 - mae: 0.0726 - root_mean_squared_error: 0.0941 - val_loss: 0.1542 - val_mae: 0.1542 - val_root_mean_squared_error: 0.1634\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0628 - mae: 0.0628 - root_mean_squared_error: 0.0822 - val_loss: 0.1615 - val_mae: 0.1615 - val_root_mean_squared_error: 0.1705\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0587 - mae: 0.0587 - root_mean_squared_error: 0.0764 - val_loss: 0.1569 - val_mae: 0.1569 - val_root_mean_squared_error: 0.1661\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0542 - mae: 0.0542 - root_mean_squared_error: 0.0714 - val_loss: 0.1433 - val_mae: 0.1433 - val_root_mean_squared_error: 0.1537\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0583 - mae: 0.0583 - root_mean_squared_error: 0.0768 - val_loss: 0.1637 - val_mae: 0.1637 - val_root_mean_squared_error: 0.1726\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0565 - mae: 0.0565 - root_mean_squared_error: 0.0743 - val_loss: 0.1875 - val_mae: 0.1875 - val_root_mean_squared_error: 0.1953\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0540 - mae: 0.0540 - root_mean_squared_error: 0.0711 - val_loss: 0.1602 - val_mae: 0.1602 - val_root_mean_squared_error: 0.1696\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0524 - mae: 0.0524 - root_mean_squared_error: 0.0695 - val_loss: 0.1814 - val_mae: 0.1814 - val_root_mean_squared_error: 0.1900\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0530 - mae: 0.0530 - root_mean_squared_error: 0.0697 - val_loss: 0.1698 - val_mae: 0.1698 - val_root_mean_squared_error: 0.1794\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0557 - mae: 0.0557 - root_mean_squared_error: 0.0732 - val_loss: 0.1798 - val_mae: 0.1798 - val_root_mean_squared_error: 0.1887\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0593 - mae: 0.0593 - root_mean_squared_error: 0.0772 - val_loss: 0.1998 - val_mae: 0.1998 - val_root_mean_squared_error: 0.2082\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0672 - mae: 0.0672 - root_mean_squared_error: 0.0862 - val_loss: 0.1536 - val_mae: 0.1536 - val_root_mean_squared_error: 0.1627\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0696 - mae: 0.0696 - root_mean_squared_error: 0.0889 - val_loss: 0.1621 - val_mae: 0.1621 - val_root_mean_squared_error: 0.1712\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0653 - mae: 0.0653 - root_mean_squared_error: 0.0846 - val_loss: 0.1043 - val_mae: 0.1043 - val_root_mean_squared_error: 0.1148\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0542 - mae: 0.0542 - root_mean_squared_error: 0.0705 - val_loss: 0.1061 - val_mae: 0.1061 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0491 - mae: 0.0491 - root_mean_squared_error: 0.0642 - val_loss: 0.0920 - val_mae: 0.0920 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0528 - mae: 0.0528 - root_mean_squared_error: 0.0690 - val_loss: 0.0691 - val_mae: 0.0691 - val_root_mean_squared_error: 0.0808\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0542 - mae: 0.0542 - root_mean_squared_error: 0.0706 - val_loss: 0.0598 - val_mae: 0.0598 - val_root_mean_squared_error: 0.0710\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0621 - mae: 0.0621 - root_mean_squared_error: 0.0799 - val_loss: 0.0347 - val_mae: 0.0347 - val_root_mean_squared_error: 0.0437\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0649 - mae: 0.0649 - root_mean_squared_error: 0.0823 - val_loss: 0.0325 - val_mae: 0.0325 - val_root_mean_squared_error: 0.0420\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0607 - mae: 0.0607 - root_mean_squared_error: 0.0766 - val_loss: 0.0366 - val_mae: 0.0366 - val_root_mean_squared_error: 0.0461\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0522 - mae: 0.0522 - root_mean_squared_error: 0.0670 - val_loss: 0.0506 - val_mae: 0.0506 - val_root_mean_squared_error: 0.0615\n",
      "Epoch 25/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0520 - mae: 0.0520 - root_mean_squared_error: 0.0671 - val_loss: 0.0385 - val_mae: 0.0385 - val_root_mean_squared_error: 0.0479\n",
      "Epoch 26/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0531 - mae: 0.0531 - root_mean_squared_error: 0.0686 - val_loss: 0.0417 - val_mae: 0.0417 - val_root_mean_squared_error: 0.0515\n",
      "Epoch 27/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0586 - mae: 0.0586 - root_mean_squared_error: 0.0761 - val_loss: 0.0317 - val_mae: 0.0317 - val_root_mean_squared_error: 0.0404\n",
      "Epoch 28/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0594 - mae: 0.0594 - root_mean_squared_error: 0.0755 - val_loss: 0.0330 - val_mae: 0.0330 - val_root_mean_squared_error: 0.0418\n",
      "Epoch 29/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0655 - val_loss: 0.0419 - val_mae: 0.0419 - val_root_mean_squared_error: 0.0517\n",
      "Epoch 30/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0490 - mae: 0.0490 - root_mean_squared_error: 0.0632 - val_loss: 0.0428 - val_mae: 0.0428 - val_root_mean_squared_error: 0.0526\n",
      "Epoch 31/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0530 - mae: 0.0530 - root_mean_squared_error: 0.0686 - val_loss: 0.0310 - val_mae: 0.0310 - val_root_mean_squared_error: 0.0393\n",
      "Epoch 32/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0558 - mae: 0.0558 - root_mean_squared_error: 0.0713 - val_loss: 0.0326 - val_mae: 0.0326 - val_root_mean_squared_error: 0.0410\n",
      "Epoch 33/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0546 - mae: 0.0546 - root_mean_squared_error: 0.0695 - val_loss: 0.0377 - val_mae: 0.0377 - val_root_mean_squared_error: 0.0469\n",
      "Epoch 34/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0470 - mae: 0.0470 - root_mean_squared_error: 0.0603 - val_loss: 0.0676 - val_mae: 0.0676 - val_root_mean_squared_error: 0.0777\n",
      "Epoch 35/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0499 - mae: 0.0499 - root_mean_squared_error: 0.0653 - val_loss: 0.0382 - val_mae: 0.0382 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 36/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0516 - mae: 0.0516 - root_mean_squared_error: 0.0660 - val_loss: 0.0368 - val_mae: 0.0368 - val_root_mean_squared_error: 0.0455\n",
      "Epoch 37/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0482 - mae: 0.0482 - root_mean_squared_error: 0.0616 - val_loss: 0.0437 - val_mae: 0.0437 - val_root_mean_squared_error: 0.0533\n",
      "Epoch 38/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0505 - mae: 0.0505 - root_mean_squared_error: 0.0648 - val_loss: 0.0390 - val_mae: 0.0390 - val_root_mean_squared_error: 0.0479\n",
      "Epoch 39/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0500 - mae: 0.0500 - root_mean_squared_error: 0.0642 - val_loss: 0.0353 - val_mae: 0.0353 - val_root_mean_squared_error: 0.0437\n",
      "Epoch 40/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0502 - mae: 0.0502 - root_mean_squared_error: 0.0643 - val_loss: 0.0423 - val_mae: 0.0423 - val_root_mean_squared_error: 0.0517\n",
      "Epoch 41/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0432 - mae: 0.0432 - root_mean_squared_error: 0.0559 - val_loss: 0.0641 - val_mae: 0.0641 - val_root_mean_squared_error: 0.0738\n",
      "Epoch 42/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0433 - mae: 0.0433 - root_mean_squared_error: 0.0561 - val_loss: 0.0685 - val_mae: 0.0685 - val_root_mean_squared_error: 0.0781\n",
      "Epoch 43/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0559 - val_loss: 0.0769 - val_mae: 0.0769 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 44/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0565 - val_loss: 0.0704 - val_mae: 0.0704 - val_root_mean_squared_error: 0.0796\n",
      "Epoch 45/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0419 - mae: 0.0419 - root_mean_squared_error: 0.0542 - val_loss: 0.0905 - val_mae: 0.0905 - val_root_mean_squared_error: 0.0994\n",
      "Epoch 46/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0505 - val_loss: 0.0944 - val_mae: 0.0944 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 47/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0513 - val_loss: 0.0900 - val_mae: 0.0900 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 48/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0511 - val_loss: 0.1109 - val_mae: 0.1109 - val_root_mean_squared_error: 0.1186\n",
      "Epoch 49/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0487 - val_loss: 0.1042 - val_mae: 0.1042 - val_root_mean_squared_error: 0.1120\n",
      "Epoch 50/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0492 - val_loss: 0.1162 - val_mae: 0.1162 - val_root_mean_squared_error: 0.1238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:29:32 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:29:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:29:40 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:29:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 20:30:06 INFO mlflow.tracking.fluent: Experiment with name 'simplernn_learning_rate_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: learning_rate = 0.0001 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1003 - mae: 0.1003 - root_mean_squared_error: 0.1301 - val_loss: 0.0822 - val_mae: 0.0822 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0766 - mae: 0.0766 - root_mean_squared_error: 0.0984 - val_loss: 0.0870 - val_mae: 0.0870 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0663 - mae: 0.0663 - root_mean_squared_error: 0.0861 - val_loss: 0.0835 - val_mae: 0.0835 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0630 - mae: 0.0630 - root_mean_squared_error: 0.0811 - val_loss: 0.0956 - val_mae: 0.0956 - val_root_mean_squared_error: 0.1084\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0616 - mae: 0.0616 - root_mean_squared_error: 0.0790 - val_loss: 0.0954 - val_mae: 0.0954 - val_root_mean_squared_error: 0.1087\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0769 - val_loss: 0.1013 - val_mae: 0.1013 - val_root_mean_squared_error: 0.1147\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0575 - mae: 0.0575 - root_mean_squared_error: 0.0740 - val_loss: 0.0961 - val_mae: 0.0961 - val_root_mean_squared_error: 0.1104\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0747 - val_loss: 0.0886 - val_mae: 0.0886 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0559 - mae: 0.0559 - root_mean_squared_error: 0.0729 - val_loss: 0.0940 - val_mae: 0.0940 - val_root_mean_squared_error: 0.1085\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0567 - mae: 0.0567 - root_mean_squared_error: 0.0738 - val_loss: 0.0907 - val_mae: 0.0907 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0560 - mae: 0.0560 - root_mean_squared_error: 0.0727 - val_loss: 0.0887 - val_mae: 0.0887 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0545 - mae: 0.0545 - root_mean_squared_error: 0.0710 - val_loss: 0.1059 - val_mae: 0.1059 - val_root_mean_squared_error: 0.1200\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0524 - mae: 0.0524 - root_mean_squared_error: 0.0689 - val_loss: 0.0932 - val_mae: 0.0932 - val_root_mean_squared_error: 0.1080\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0526 - mae: 0.0526 - root_mean_squared_error: 0.0684 - val_loss: 0.1049 - val_mae: 0.1049 - val_root_mean_squared_error: 0.1193\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0511 - mae: 0.0511 - root_mean_squared_error: 0.0672 - val_loss: 0.1089 - val_mae: 0.1089 - val_root_mean_squared_error: 0.1229\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0666 - val_loss: 0.1070 - val_mae: 0.1070 - val_root_mean_squared_error: 0.1213\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0523 - mae: 0.0523 - root_mean_squared_error: 0.0687 - val_loss: 0.1113 - val_mae: 0.1113 - val_root_mean_squared_error: 0.1251\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0512 - mae: 0.0512 - root_mean_squared_error: 0.0678 - val_loss: 0.0973 - val_mae: 0.0973 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0510 - mae: 0.0510 - root_mean_squared_error: 0.0670 - val_loss: 0.1078 - val_mae: 0.1078 - val_root_mean_squared_error: 0.1215\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0489 - mae: 0.0489 - root_mean_squared_error: 0.0643 - val_loss: 0.0997 - val_mae: 0.0997 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0496 - mae: 0.0496 - root_mean_squared_error: 0.0648 - val_loss: 0.1045 - val_mae: 0.1045 - val_root_mean_squared_error: 0.1183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:30:20 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:30:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:30:27 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:30:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: learning_rate = 0.001 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0749 - mae: 0.0749 - root_mean_squared_error: 0.1017 - val_loss: 0.1441 - val_mae: 0.1441 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0810 - val_loss: 0.0711 - val_mae: 0.0711 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0562 - mae: 0.0562 - root_mean_squared_error: 0.0746 - val_loss: 0.1185 - val_mae: 0.1185 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0545 - mae: 0.0545 - root_mean_squared_error: 0.0736 - val_loss: 0.0657 - val_mae: 0.0657 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0515 - mae: 0.0515 - root_mean_squared_error: 0.0689 - val_loss: 0.0747 - val_mae: 0.0747 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0679 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0508 - mae: 0.0508 - root_mean_squared_error: 0.0683 - val_loss: 0.0709 - val_mae: 0.0709 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0481 - mae: 0.0481 - root_mean_squared_error: 0.0647 - val_loss: 0.1175 - val_mae: 0.1175 - val_root_mean_squared_error: 0.1314\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0436 - mae: 0.0436 - root_mean_squared_error: 0.0591 - val_loss: 0.1147 - val_mae: 0.1147 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0603 - val_loss: 0.1371 - val_mae: 0.1371 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0587 - val_loss: 0.1653 - val_mae: 0.1653 - val_root_mean_squared_error: 0.1762\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0546 - val_loss: 0.1428 - val_mae: 0.1428 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0544 - val_loss: 0.1299 - val_mae: 0.1299 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0555 - val_loss: 0.1610 - val_mae: 0.1610 - val_root_mean_squared_error: 0.1716\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0512 - val_loss: 0.1413 - val_mae: 0.1413 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0379 - mae: 0.0379 - root_mean_squared_error: 0.0533 - val_loss: 0.1370 - val_mae: 0.1370 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0545 - val_loss: 0.1199 - val_mae: 0.1199 - val_root_mean_squared_error: 0.1346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0542 - val_loss: 0.0910 - val_mae: 0.0910 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0584 - val_loss: 0.0774 - val_mae: 0.0774 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0504 - val_loss: 0.0934 - val_mae: 0.0934 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0494 - val_loss: 0.0843 - val_mae: 0.0843 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0502 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0516 - val_loss: 0.0803 - val_mae: 0.0803 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0529 - val_loss: 0.0759 - val_mae: 0.0759 - val_root_mean_squared_error: 0.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:31:08 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:31:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:31:16 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:31:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: learning_rate = 0.01 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0841 - mae: 0.0841 - root_mean_squared_error: 0.1243 - val_loss: 0.0688 - val_mae: 0.0688 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0612 - mae: 0.0612 - root_mean_squared_error: 0.0785 - val_loss: 0.1056 - val_mae: 0.1056 - val_root_mean_squared_error: 0.1187\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0754 - mae: 0.0754 - root_mean_squared_error: 0.0946 - val_loss: 0.0593 - val_mae: 0.0593 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2370 - mae: 0.2370 - root_mean_squared_error: 0.3469 - val_loss: 1.0895 - val_mae: 1.0895 - val_root_mean_squared_error: 1.0929\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2372 - mae: 0.2372 - root_mean_squared_error: 0.3173 - val_loss: 0.0892 - val_mae: 0.0892 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1478 - mae: 0.1478 - root_mean_squared_error: 0.1903 - val_loss: 0.1960 - val_mae: 0.1960 - val_root_mean_squared_error: 0.2163\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1544 - mae: 0.1544 - root_mean_squared_error: 0.1870 - val_loss: 0.1306 - val_mae: 0.1306 - val_root_mean_squared_error: 0.1527\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1336 - mae: 0.1336 - root_mean_squared_error: 0.1713 - val_loss: 0.1310 - val_mae: 0.1310 - val_root_mean_squared_error: 0.1531\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1227 - mae: 0.1227 - root_mean_squared_error: 0.1570 - val_loss: 0.0917 - val_mae: 0.0917 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1462 - mae: 0.1462 - root_mean_squared_error: 0.1764 - val_loss: 0.1936 - val_mae: 0.1936 - val_root_mean_squared_error: 0.2138\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1122 - mae: 0.1122 - root_mean_squared_error: 0.1471 - val_loss: 0.1783 - val_mae: 0.1783 - val_root_mean_squared_error: 0.1995\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1423 - mae: 0.1423 - root_mean_squared_error: 0.1734 - val_loss: 0.2742 - val_mae: 0.2742 - val_root_mean_squared_error: 0.2888\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1143 - mae: 0.1143 - root_mean_squared_error: 0.1396 - val_loss: 0.1672 - val_mae: 0.1672 - val_root_mean_squared_error: 0.1886\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1041 - mae: 0.1041 - root_mean_squared_error: 0.1412 - val_loss: 0.1223 - val_mae: 0.1223 - val_root_mean_squared_error: 0.1438\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1140 - mae: 0.1140 - root_mean_squared_error: 0.1413 - val_loss: 0.1624 - val_mae: 0.1624 - val_root_mean_squared_error: 0.1841\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1119 - mae: 0.1119 - root_mean_squared_error: 0.1368 - val_loss: 0.1159 - val_mae: 0.1159 - val_root_mean_squared_error: 0.1363\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1305 - mae: 0.1305 - root_mean_squared_error: 0.1627 - val_loss: 0.1326 - val_mae: 0.1326 - val_root_mean_squared_error: 0.1548\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1198 - mae: 0.1198 - root_mean_squared_error: 0.1496 - val_loss: 0.1899 - val_mae: 0.1899 - val_root_mean_squared_error: 0.2105\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1189 - mae: 0.1189 - root_mean_squared_error: 0.1434 - val_loss: 0.1491 - val_mae: 0.1491 - val_root_mean_squared_error: 0.1712\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1203 - mae: 0.1203 - root_mean_squared_error: 0.1535 - val_loss: 0.1050 - val_mae: 0.1050 - val_root_mean_squared_error: 0.1231\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1196 - mae: 0.1196 - root_mean_squared_error: 0.1566 - val_loss: 0.1573 - val_mae: 0.1573 - val_root_mean_squared_error: 0.1791\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1200 - mae: 0.1200 - root_mean_squared_error: 0.1471 - val_loss: 0.2972 - val_mae: 0.2972 - val_root_mean_squared_error: 0.3107\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1255 - mae: 0.1255 - root_mean_squared_error: 0.1547 - val_loss: 0.2768 - val_mae: 0.2768 - val_root_mean_squared_error: 0.2920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:31:58 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:32:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:32:06 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:32:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: learning_rate = 0.1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.0109 - mae: 1.0109 - root_mean_squared_error: 1.5651 - val_loss: 0.4398 - val_mae: 0.4398 - val_root_mean_squared_error: 0.4491\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4864 - mae: 0.4864 - root_mean_squared_error: 0.6162 - val_loss: 0.3101 - val_mae: 0.3101 - val_root_mean_squared_error: 0.3231\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4048 - mae: 0.4048 - root_mean_squared_error: 0.5266 - val_loss: 0.8216 - val_mae: 0.8216 - val_root_mean_squared_error: 0.8266\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5632 - mae: 0.5632 - root_mean_squared_error: 0.6968 - val_loss: 0.3760 - val_mae: 0.3760 - val_root_mean_squared_error: 0.3868\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5596 - mae: 0.5596 - root_mean_squared_error: 0.7278 - val_loss: 0.1956 - val_mae: 0.1956 - val_root_mean_squared_error: 0.2156\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3961 - mae: 0.3961 - root_mean_squared_error: 0.4795 - val_loss: 0.6875 - val_mae: 0.6875 - val_root_mean_squared_error: 0.6935\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3633 - mae: 0.3633 - root_mean_squared_error: 0.4388 - val_loss: 0.1911 - val_mae: 0.1911 - val_root_mean_squared_error: 0.2114\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2970 - mae: 0.2970 - root_mean_squared_error: 0.3621 - val_loss: 0.1710 - val_mae: 0.1710 - val_root_mean_squared_error: 0.1924\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2847 - mae: 0.2847 - root_mean_squared_error: 0.3497 - val_loss: 0.0857 - val_mae: 0.0857 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4379 - mae: 0.4379 - root_mean_squared_error: 0.5119 - val_loss: 0.6523 - val_mae: 0.6523 - val_root_mean_squared_error: 0.6586\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2773 - mae: 0.2773 - root_mean_squared_error: 0.3436 - val_loss: 0.1828 - val_mae: 0.1828 - val_root_mean_squared_error: 0.2037\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4718 - mae: 0.4718 - root_mean_squared_error: 0.5474 - val_loss: 0.3997 - val_mae: 0.3997 - val_root_mean_squared_error: 0.4098\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3475 - mae: 0.3475 - root_mean_squared_error: 0.4378 - val_loss: 0.4808 - val_mae: 0.4808 - val_root_mean_squared_error: 0.4894\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6402 - mae: 0.6402 - root_mean_squared_error: 0.7852 - val_loss: 0.6102 - val_mae: 0.6102 - val_root_mean_squared_error: 0.6170\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4094 - mae: 0.4094 - root_mean_squared_error: 0.5217 - val_loss: 0.1096 - val_mae: 0.1096 - val_root_mean_squared_error: 0.1286\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3868 - mae: 0.3868 - root_mean_squared_error: 0.4573 - val_loss: 0.5390 - val_mae: 0.5390 - val_root_mean_squared_error: 0.5466\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3436 - mae: 0.3436 - root_mean_squared_error: 0.4202 - val_loss: 0.8134 - val_mae: 0.8134 - val_root_mean_squared_error: 0.8185\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3709 - mae: 0.3709 - root_mean_squared_error: 0.4354 - val_loss: 0.4466 - val_mae: 0.4466 - val_root_mean_squared_error: 0.4558\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4757 - mae: 0.4757 - root_mean_squared_error: 0.5575 - val_loss: 0.5589 - val_mae: 0.5589 - val_root_mean_squared_error: 0.5663\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5052 - mae: 0.5052 - root_mean_squared_error: 0.6412 - val_loss: 0.1163 - val_mae: 0.1163 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3148 - mae: 0.3148 - root_mean_squared_error: 0.3882 - val_loss: 0.1077 - val_mae: 0.1077 - val_root_mean_squared_error: 0.1264\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3320 - mae: 0.3320 - root_mean_squared_error: 0.4074 - val_loss: 0.1040 - val_mae: 0.1040 - val_root_mean_squared_error: 0.1331\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3691 - mae: 0.3691 - root_mean_squared_error: 0.4494 - val_loss: 0.9765 - val_mae: 0.9765 - val_root_mean_squared_error: 0.9807\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4329 - mae: 0.4329 - root_mean_squared_error: 0.5545 - val_loss: 1.0149 - val_mae: 1.0149 - val_root_mean_squared_error: 1.0190\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3039 - mae: 0.3039 - root_mean_squared_error: 0.3800 - val_loss: 0.0796 - val_mae: 0.0796 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4672 - mae: 0.4672 - root_mean_squared_error: 0.5565 - val_loss: 0.5622 - val_mae: 0.5622 - val_root_mean_squared_error: 0.5695\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3167 - mae: 0.3167 - root_mean_squared_error: 0.4445 - val_loss: 0.6584 - val_mae: 0.6584 - val_root_mean_squared_error: 0.6646\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5250 - mae: 0.5250 - root_mean_squared_error: 0.6503 - val_loss: 0.0866 - val_mae: 0.0866 - val_root_mean_squared_error: 0.1003\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4308 - mae: 0.4308 - root_mean_squared_error: 0.5948 - val_loss: 0.0855 - val_mae: 0.0855 - val_root_mean_squared_error: 0.0990\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3519 - mae: 0.3519 - root_mean_squared_error: 0.4430 - val_loss: 0.2561 - val_mae: 0.2561 - val_root_mean_squared_error: 0.2718\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3583 - mae: 0.3583 - root_mean_squared_error: 0.4990 - val_loss: 0.6420 - val_mae: 0.6420 - val_root_mean_squared_error: 0.6484\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3231 - mae: 0.3231 - root_mean_squared_error: 0.4045 - val_loss: 0.0839 - val_mae: 0.0839 - val_root_mean_squared_error: 0.0970\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3659 - mae: 0.3659 - root_mean_squared_error: 0.4784 - val_loss: 0.0769 - val_mae: 0.0769 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4223 - mae: 0.4223 - root_mean_squared_error: 0.5366 - val_loss: 0.7358 - val_mae: 0.7358 - val_root_mean_squared_error: 0.7414\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3345 - mae: 0.3345 - root_mean_squared_error: 0.4283 - val_loss: 0.6729 - val_mae: 0.6729 - val_root_mean_squared_error: 0.6790\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5010 - mae: 0.5010 - root_mean_squared_error: 0.6568 - val_loss: 0.2098 - val_mae: 0.2098 - val_root_mean_squared_error: 0.2287\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3347 - mae: 0.3347 - root_mean_squared_error: 0.4525 - val_loss: 0.6453 - val_mae: 0.6453 - val_root_mean_squared_error: 0.6517\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3111 - mae: 0.3111 - root_mean_squared_error: 0.3819 - val_loss: 1.0201 - val_mae: 1.0201 - val_root_mean_squared_error: 1.0241\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4370 - mae: 0.4370 - root_mean_squared_error: 0.5144 - val_loss: 0.1274 - val_mae: 0.1274 - val_root_mean_squared_error: 0.1539\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3946 - mae: 0.3946 - root_mean_squared_error: 0.5131 - val_loss: 0.1459 - val_mae: 0.1459 - val_root_mean_squared_error: 0.1702\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5494 - mae: 0.5494 - root_mean_squared_error: 0.7027 - val_loss: 0.8051 - val_mae: 0.8051 - val_root_mean_squared_error: 0.8102\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3744 - mae: 0.3744 - root_mean_squared_error: 0.4886 - val_loss: 1.0744 - val_mae: 1.0744 - val_root_mean_squared_error: 1.0783\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4024 - mae: 0.4024 - root_mean_squared_error: 0.5096 - val_loss: 0.3691 - val_mae: 0.3691 - val_root_mean_squared_error: 0.3801\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3923 - mae: 0.3923 - root_mean_squared_error: 0.4883 - val_loss: 0.2133 - val_mae: 0.2133 - val_root_mean_squared_error: 0.2318\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4593 - mae: 0.4593 - root_mean_squared_error: 0.5412 - val_loss: 0.6565 - val_mae: 0.6565 - val_root_mean_squared_error: 0.6627\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3550 - mae: 0.3550 - root_mean_squared_error: 0.4299 - val_loss: 0.1745 - val_mae: 0.1745 - val_root_mean_squared_error: 0.1958\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2891 - mae: 0.2891 - root_mean_squared_error: 0.3364 - val_loss: 0.8455 - val_mae: 0.8455 - val_root_mean_squared_error: 0.8503\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4417 - mae: 0.4417 - root_mean_squared_error: 0.5755 - val_loss: 0.3035 - val_mae: 0.3035 - val_root_mean_squared_error: 0.3169\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3823 - mae: 0.3823 - root_mean_squared_error: 0.5364 - val_loss: 0.1476 - val_mae: 0.1476 - val_root_mean_squared_error: 0.1697\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2826 - mae: 0.2826 - root_mean_squared_error: 0.3492 - val_loss: 0.4601 - val_mae: 0.4601 - val_root_mean_squared_error: 0.4690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:33:01 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:33:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:33:09 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:33:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 20:33:37 INFO mlflow.tracking.fluent: Experiment with name 'simplernn_model_units_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: model_units = 10 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1581 - mae: 0.1581 - root_mean_squared_error: 0.2211 - val_loss: 0.1062 - val_mae: 0.1062 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0968 - mae: 0.0968 - root_mean_squared_error: 0.1277 - val_loss: 0.1225 - val_mae: 0.1225 - val_root_mean_squared_error: 0.1373\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0897 - mae: 0.0897 - root_mean_squared_error: 0.1168 - val_loss: 0.1419 - val_mae: 0.1419 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0787 - mae: 0.0787 - root_mean_squared_error: 0.1040 - val_loss: 0.1176 - val_mae: 0.1176 - val_root_mean_squared_error: 0.1329\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0766 - mae: 0.0766 - root_mean_squared_error: 0.1013 - val_loss: 0.1200 - val_mae: 0.1200 - val_root_mean_squared_error: 0.1348\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0717 - mae: 0.0717 - root_mean_squared_error: 0.0943 - val_loss: 0.1194 - val_mae: 0.1194 - val_root_mean_squared_error: 0.1337\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0693 - mae: 0.0693 - root_mean_squared_error: 0.0920 - val_loss: 0.1261 - val_mae: 0.1261 - val_root_mean_squared_error: 0.1407\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0657 - mae: 0.0657 - root_mean_squared_error: 0.0881 - val_loss: 0.1241 - val_mae: 0.1241 - val_root_mean_squared_error: 0.1386\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0613 - mae: 0.0613 - root_mean_squared_error: 0.0817 - val_loss: 0.1256 - val_mae: 0.1256 - val_root_mean_squared_error: 0.1407\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0604 - mae: 0.0604 - root_mean_squared_error: 0.0802 - val_loss: 0.1383 - val_mae: 0.1383 - val_root_mean_squared_error: 0.1539\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0564 - mae: 0.0564 - root_mean_squared_error: 0.0766 - val_loss: 0.1376 - val_mae: 0.1376 - val_root_mean_squared_error: 0.1545\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0561 - mae: 0.0561 - root_mean_squared_error: 0.0753 - val_loss: 0.1442 - val_mae: 0.1442 - val_root_mean_squared_error: 0.1591\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0549 - mae: 0.0549 - root_mean_squared_error: 0.0734 - val_loss: 0.1590 - val_mae: 0.1590 - val_root_mean_squared_error: 0.1737\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0518 - mae: 0.0518 - root_mean_squared_error: 0.0697 - val_loss: 0.1436 - val_mae: 0.1436 - val_root_mean_squared_error: 0.1598\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0504 - mae: 0.0504 - root_mean_squared_error: 0.0678 - val_loss: 0.1277 - val_mae: 0.1277 - val_root_mean_squared_error: 0.1433\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0499 - mae: 0.0499 - root_mean_squared_error: 0.0668 - val_loss: 0.1381 - val_mae: 0.1381 - val_root_mean_squared_error: 0.1539\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0658 - val_loss: 0.1239 - val_mae: 0.1239 - val_root_mean_squared_error: 0.1389\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0474 - mae: 0.0474 - root_mean_squared_error: 0.0639 - val_loss: 0.1421 - val_mae: 0.1421 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0468 - mae: 0.0468 - root_mean_squared_error: 0.0628 - val_loss: 0.1287 - val_mae: 0.1287 - val_root_mean_squared_error: 0.1435\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0450 - mae: 0.0450 - root_mean_squared_error: 0.0602 - val_loss: 0.1376 - val_mae: 0.1376 - val_root_mean_squared_error: 0.1523\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0589 - val_loss: 0.1251 - val_mae: 0.1251 - val_root_mean_squared_error: 0.1406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:33:50 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:33:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:33:58 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:34:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: model_units = 50 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0749 - mae: 0.0749 - root_mean_squared_error: 0.1017 - val_loss: 0.1441 - val_mae: 0.1441 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0810 - val_loss: 0.0711 - val_mae: 0.0711 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0562 - mae: 0.0562 - root_mean_squared_error: 0.0746 - val_loss: 0.1185 - val_mae: 0.1185 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0545 - mae: 0.0545 - root_mean_squared_error: 0.0736 - val_loss: 0.0657 - val_mae: 0.0657 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0515 - mae: 0.0515 - root_mean_squared_error: 0.0689 - val_loss: 0.0747 - val_mae: 0.0747 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0679 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0508 - mae: 0.0508 - root_mean_squared_error: 0.0683 - val_loss: 0.0709 - val_mae: 0.0709 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0481 - mae: 0.0481 - root_mean_squared_error: 0.0647 - val_loss: 0.1175 - val_mae: 0.1175 - val_root_mean_squared_error: 0.1314\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0436 - mae: 0.0436 - root_mean_squared_error: 0.0591 - val_loss: 0.1147 - val_mae: 0.1147 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0603 - val_loss: 0.1371 - val_mae: 0.1371 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0587 - val_loss: 0.1653 - val_mae: 0.1653 - val_root_mean_squared_error: 0.1762\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0546 - val_loss: 0.1428 - val_mae: 0.1428 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0544 - val_loss: 0.1299 - val_mae: 0.1299 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0555 - val_loss: 0.1610 - val_mae: 0.1610 - val_root_mean_squared_error: 0.1716\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0512 - val_loss: 0.1413 - val_mae: 0.1413 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0379 - mae: 0.0379 - root_mean_squared_error: 0.0533 - val_loss: 0.1370 - val_mae: 0.1370 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0545 - val_loss: 0.1199 - val_mae: 0.1199 - val_root_mean_squared_error: 0.1346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0542 - val_loss: 0.0910 - val_mae: 0.0910 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0584 - val_loss: 0.0774 - val_mae: 0.0774 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0504 - val_loss: 0.0934 - val_mae: 0.0934 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0494 - val_loss: 0.0843 - val_mae: 0.0843 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0502 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0516 - val_loss: 0.0803 - val_mae: 0.0803 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0529 - val_loss: 0.0759 - val_mae: 0.0759 - val_root_mean_squared_error: 0.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:34:40 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:34:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:34:48 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:34:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: model_units = 100 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0806 - mae: 0.0806 - root_mean_squared_error: 0.1233 - val_loss: 0.1348 - val_mae: 0.1348 - val_root_mean_squared_error: 0.1512\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0477 - mae: 0.0477 - root_mean_squared_error: 0.0633 - val_loss: 0.0813 - val_mae: 0.0813 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0525 - val_loss: 0.1018 - val_mae: 0.1018 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0415 - mae: 0.0415 - root_mean_squared_error: 0.0553 - val_loss: 0.0816 - val_mae: 0.0816 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0386 - mae: 0.0386 - root_mean_squared_error: 0.0503 - val_loss: 0.0379 - val_mae: 0.0379 - val_root_mean_squared_error: 0.0481\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0481 - val_loss: 0.0762 - val_mae: 0.0762 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0332 - mae: 0.0332 - root_mean_squared_error: 0.0448 - val_loss: 0.0305 - val_mae: 0.0305 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0368 - mae: 0.0368 - root_mean_squared_error: 0.0481 - val_loss: 0.0887 - val_mae: 0.0887 - val_root_mean_squared_error: 0.0963\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0325 - mae: 0.0325 - root_mean_squared_error: 0.0423 - val_loss: 0.0767 - val_mae: 0.0767 - val_root_mean_squared_error: 0.0863\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0306 - mae: 0.0306 - root_mean_squared_error: 0.0401 - val_loss: 0.0502 - val_mae: 0.0502 - val_root_mean_squared_error: 0.0604\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0448 - val_loss: 0.1086 - val_mae: 0.1086 - val_root_mean_squared_error: 0.1149\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0286 - mae: 0.0286 - root_mean_squared_error: 0.0379 - val_loss: 0.0347 - val_mae: 0.0347 - val_root_mean_squared_error: 0.0426\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0286 - mae: 0.0286 - root_mean_squared_error: 0.0376 - val_loss: 0.0579 - val_mae: 0.0579 - val_root_mean_squared_error: 0.0666\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0323 - mae: 0.0323 - root_mean_squared_error: 0.0422 - val_loss: 0.0801 - val_mae: 0.0801 - val_root_mean_squared_error: 0.0902\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0458 - val_loss: 0.0365 - val_mae: 0.0365 - val_root_mean_squared_error: 0.0444\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0281 - mae: 0.0281 - root_mean_squared_error: 0.0369 - val_loss: 0.0539 - val_mae: 0.0539 - val_root_mean_squared_error: 0.0621\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0364 - val_loss: 0.0986 - val_mae: 0.0986 - val_root_mean_squared_error: 0.1063\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0325 - mae: 0.0325 - root_mean_squared_error: 0.0430 - val_loss: 0.0612 - val_mae: 0.0612 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0270 - mae: 0.0270 - root_mean_squared_error: 0.0356 - val_loss: 0.0401 - val_mae: 0.0401 - val_root_mean_squared_error: 0.0485\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0347 - val_loss: 0.0865 - val_mae: 0.0865 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0280 - mae: 0.0280 - root_mean_squared_error: 0.0383 - val_loss: 0.0708 - val_mae: 0.0708 - val_root_mean_squared_error: 0.0750\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - mae: 0.0252 - root_mean_squared_error: 0.0330 - val_loss: 0.0199 - val_mae: 0.0199 - val_root_mean_squared_error: 0.0250\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0240 - mae: 0.0240 - root_mean_squared_error: 0.0318 - val_loss: 0.0391 - val_mae: 0.0391 - val_root_mean_squared_error: 0.0468\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - mae: 0.0226 - root_mean_squared_error: 0.0304 - val_loss: 0.0630 - val_mae: 0.0630 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0217 - mae: 0.0217 - root_mean_squared_error: 0.0288 - val_loss: 0.0564 - val_mae: 0.0564 - val_root_mean_squared_error: 0.0623\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0235 - mae: 0.0235 - root_mean_squared_error: 0.0314 - val_loss: 0.0386 - val_mae: 0.0386 - val_root_mean_squared_error: 0.0465\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0205 - mae: 0.0205 - root_mean_squared_error: 0.0274 - val_loss: 0.0219 - val_mae: 0.0219 - val_root_mean_squared_error: 0.0273\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0300 - mae: 0.0300 - root_mean_squared_error: 0.0388 - val_loss: 0.0210 - val_mae: 0.0210 - val_root_mean_squared_error: 0.0265\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0265 - mae: 0.0265 - root_mean_squared_error: 0.0342 - val_loss: 0.0571 - val_mae: 0.0571 - val_root_mean_squared_error: 0.0641\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0247 - mae: 0.0247 - root_mean_squared_error: 0.0330 - val_loss: 0.0365 - val_mae: 0.0365 - val_root_mean_squared_error: 0.0439\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - mae: 0.0253 - root_mean_squared_error: 0.0336 - val_loss: 0.0196 - val_mae: 0.0196 - val_root_mean_squared_error: 0.0238\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0238 - mae: 0.0238 - root_mean_squared_error: 0.0315 - val_loss: 0.0678 - val_mae: 0.0678 - val_root_mean_squared_error: 0.0739\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - mae: 0.0248 - root_mean_squared_error: 0.0336 - val_loss: 0.0261 - val_mae: 0.0261 - val_root_mean_squared_error: 0.0319\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0219 - mae: 0.0219 - root_mean_squared_error: 0.0288 - val_loss: 0.0451 - val_mae: 0.0451 - val_root_mean_squared_error: 0.0517\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - mae: 0.0256 - root_mean_squared_error: 0.0334 - val_loss: 0.0689 - val_mae: 0.0689 - val_root_mean_squared_error: 0.0754\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0209 - mae: 0.0209 - root_mean_squared_error: 0.0281 - val_loss: 0.0682 - val_mae: 0.0682 - val_root_mean_squared_error: 0.0745\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0219 - mae: 0.0219 - root_mean_squared_error: 0.0298 - val_loss: 0.1078 - val_mae: 0.1078 - val_root_mean_squared_error: 0.1123\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0237 - mae: 0.0237 - root_mean_squared_error: 0.0312 - val_loss: 0.0344 - val_mae: 0.0344 - val_root_mean_squared_error: 0.0418\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0234 - mae: 0.0234 - root_mean_squared_error: 0.0304 - val_loss: 0.0680 - val_mae: 0.0680 - val_root_mean_squared_error: 0.0731\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186 - mae: 0.0186 - root_mean_squared_error: 0.0254 - val_loss: 0.0451 - val_mae: 0.0451 - val_root_mean_squared_error: 0.0532\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0218 - mae: 0.0218 - root_mean_squared_error: 0.0290 - val_loss: 0.0135 - val_mae: 0.0135 - val_root_mean_squared_error: 0.0173\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0211 - mae: 0.0211 - root_mean_squared_error: 0.0286 - val_loss: 0.0219 - val_mae: 0.0219 - val_root_mean_squared_error: 0.0271\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0209 - mae: 0.0209 - root_mean_squared_error: 0.0275 - val_loss: 0.0678 - val_mae: 0.0678 - val_root_mean_squared_error: 0.0736\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0236 - mae: 0.0236 - root_mean_squared_error: 0.0305 - val_loss: 0.0767 - val_mae: 0.0767 - val_root_mean_squared_error: 0.0830\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0220 - mae: 0.0220 - root_mean_squared_error: 0.0286 - val_loss: 0.0330 - val_mae: 0.0330 - val_root_mean_squared_error: 0.0397\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0235 - mae: 0.0235 - root_mean_squared_error: 0.0305 - val_loss: 0.0302 - val_mae: 0.0302 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0256 - mae: 0.0256 - root_mean_squared_error: 0.0334 - val_loss: 0.0324 - val_mae: 0.0324 - val_root_mean_squared_error: 0.0393\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0222 - mae: 0.0222 - root_mean_squared_error: 0.0285 - val_loss: 0.0622 - val_mae: 0.0622 - val_root_mean_squared_error: 0.0674\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - mae: 0.0221 - root_mean_squared_error: 0.0291 - val_loss: 0.0386 - val_mae: 0.0386 - val_root_mean_squared_error: 0.0453\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0203 - mae: 0.0203 - root_mean_squared_error: 0.0279 - val_loss: 0.1115 - val_mae: 0.1115 - val_root_mean_squared_error: 0.1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:35:49 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:35:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:35:57 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:36:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: model_units = 200 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0715 - mae: 0.0715 - root_mean_squared_error: 0.1200 - val_loss: 0.0417 - val_mae: 0.0417 - val_root_mean_squared_error: 0.0505\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0413 - mae: 0.0413 - root_mean_squared_error: 0.0543 - val_loss: 0.0860 - val_mae: 0.0860 - val_root_mean_squared_error: 0.0928\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0556 - val_loss: 0.0599 - val_mae: 0.0599 - val_root_mean_squared_error: 0.0651\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0454 - mae: 0.0454 - root_mean_squared_error: 0.0588 - val_loss: 0.0390 - val_mae: 0.0390 - val_root_mean_squared_error: 0.0443\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0423 - mae: 0.0423 - root_mean_squared_error: 0.0540 - val_loss: 0.0227 - val_mae: 0.0227 - val_root_mean_squared_error: 0.0294\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0393 - mae: 0.0393 - root_mean_squared_error: 0.0500 - val_loss: 0.0364 - val_mae: 0.0364 - val_root_mean_squared_error: 0.0408\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0425 - mae: 0.0425 - root_mean_squared_error: 0.0536 - val_loss: 0.0447 - val_mae: 0.0447 - val_root_mean_squared_error: 0.0529\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0544 - val_loss: 0.0260 - val_mae: 0.0260 - val_root_mean_squared_error: 0.0338\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0406 - mae: 0.0406 - root_mean_squared_error: 0.0529 - val_loss: 0.0194 - val_mae: 0.0194 - val_root_mean_squared_error: 0.0256\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0436 - val_loss: 0.1157 - val_mae: 0.1157 - val_root_mean_squared_error: 0.1202\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0379 - mae: 0.0379 - root_mean_squared_error: 0.0489 - val_loss: 0.0617 - val_mae: 0.0617 - val_root_mean_squared_error: 0.0675\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0374 - mae: 0.0374 - root_mean_squared_error: 0.0492 - val_loss: 0.0520 - val_mae: 0.0520 - val_root_mean_squared_error: 0.0564\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0415 - mae: 0.0415 - root_mean_squared_error: 0.0529 - val_loss: 0.0351 - val_mae: 0.0351 - val_root_mean_squared_error: 0.0438\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0451 - val_loss: 0.0227 - val_mae: 0.0227 - val_root_mean_squared_error: 0.0263\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0306 - mae: 0.0306 - root_mean_squared_error: 0.0394 - val_loss: 0.0192 - val_mae: 0.0192 - val_root_mean_squared_error: 0.0243\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0458 - val_loss: 0.0307 - val_mae: 0.0307 - val_root_mean_squared_error: 0.0372\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0495 - val_loss: 0.0180 - val_mae: 0.0180 - val_root_mean_squared_error: 0.0240\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0511 - val_loss: 0.0374 - val_mae: 0.0374 - val_root_mean_squared_error: 0.0432\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0386 - mae: 0.0386 - root_mean_squared_error: 0.0486 - val_loss: 0.0468 - val_mae: 0.0468 - val_root_mean_squared_error: 0.0537\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0303 - mae: 0.0303 - root_mean_squared_error: 0.0384 - val_loss: 0.0371 - val_mae: 0.0371 - val_root_mean_squared_error: 0.0407\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0323 - mae: 0.0323 - root_mean_squared_error: 0.0419 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0286\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0538 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0308\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0492 - val_loss: 0.0594 - val_mae: 0.0594 - val_root_mean_squared_error: 0.0673\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0383 - mae: 0.0383 - root_mean_squared_error: 0.0489 - val_loss: 0.0183 - val_mae: 0.0183 - val_root_mean_squared_error: 0.0247\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0546 - val_loss: 0.0219 - val_mae: 0.0219 - val_root_mean_squared_error: 0.0287\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0374 - mae: 0.0374 - root_mean_squared_error: 0.0476 - val_loss: 0.0362 - val_mae: 0.0362 - val_root_mean_squared_error: 0.0396\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0392 - mae: 0.0392 - root_mean_squared_error: 0.0494 - val_loss: 0.0430 - val_mae: 0.0430 - val_root_mean_squared_error: 0.0483\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0482 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0292\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0439 - val_loss: 0.0562 - val_mae: 0.0562 - val_root_mean_squared_error: 0.0602\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0391 - mae: 0.0391 - root_mean_squared_error: 0.0519 - val_loss: 0.0771 - val_mae: 0.0771 - val_root_mean_squared_error: 0.0830\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0490 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0296\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0331 - mae: 0.0331 - root_mean_squared_error: 0.0431 - val_loss: 0.0627 - val_mae: 0.0627 - val_root_mean_squared_error: 0.0674\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0457 - val_loss: 0.0421 - val_mae: 0.0421 - val_root_mean_squared_error: 0.0494\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0449 - val_loss: 0.0398 - val_mae: 0.0398 - val_root_mean_squared_error: 0.0443\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0271 - mae: 0.0271 - root_mean_squared_error: 0.0344 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0297\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0438 - val_loss: 0.1142 - val_mae: 0.1142 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0258 - mae: 0.0258 - root_mean_squared_error: 0.0337 - val_loss: 0.0442 - val_mae: 0.0442 - val_root_mean_squared_error: 0.0475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:36:57 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:37:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:37:05 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:37:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 20:37:33 INFO mlflow.tracking.fluent: Experiment with name 'simplernn_dropout_rate_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: dropout_rate = 0 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0879 - mae: 0.0879 - root_mean_squared_error: 0.1408 - val_loss: 0.0969 - val_mae: 0.0969 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0658 - mae: 0.0658 - root_mean_squared_error: 0.0906 - val_loss: 0.1002 - val_mae: 0.1002 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0466 - mae: 0.0466 - root_mean_squared_error: 0.0616 - val_loss: 0.0637 - val_mae: 0.0637 - val_root_mean_squared_error: 0.0759\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0470 - mae: 0.0470 - root_mean_squared_error: 0.0644 - val_loss: 0.0912 - val_mae: 0.0912 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0519 - val_loss: 0.0701 - val_mae: 0.0701 - val_root_mean_squared_error: 0.0834\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0383 - mae: 0.0383 - root_mean_squared_error: 0.0484 - val_loss: 0.0726 - val_mae: 0.0726 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0462 - val_loss: 0.0989 - val_mae: 0.0989 - val_root_mean_squared_error: 0.1120\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0487 - val_loss: 0.0513 - val_mae: 0.0513 - val_root_mean_squared_error: 0.0621\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0508 - val_loss: 0.0550 - val_mae: 0.0550 - val_root_mean_squared_error: 0.0664\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0454 - val_loss: 0.0512 - val_mae: 0.0512 - val_root_mean_squared_error: 0.0620\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0467 - val_loss: 0.0429 - val_mae: 0.0429 - val_root_mean_squared_error: 0.0525\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0461 - val_loss: 0.0532 - val_mae: 0.0532 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0444 - val_loss: 0.0450 - val_mae: 0.0450 - val_root_mean_squared_error: 0.0548\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0479 - val_loss: 0.0395 - val_mae: 0.0395 - val_root_mean_squared_error: 0.0489\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0468 - val_loss: 0.0575 - val_mae: 0.0575 - val_root_mean_squared_error: 0.0691\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0331 - mae: 0.0331 - root_mean_squared_error: 0.0422 - val_loss: 0.1008 - val_mae: 0.1008 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0438 - val_loss: 0.0522 - val_mae: 0.0522 - val_root_mean_squared_error: 0.0628\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0450 - val_loss: 0.0493 - val_mae: 0.0493 - val_root_mean_squared_error: 0.0596\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0428 - val_loss: 0.0583 - val_mae: 0.0583 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0313 - mae: 0.0313 - root_mean_squared_error: 0.0397 - val_loss: 0.1211 - val_mae: 0.1211 - val_root_mean_squared_error: 0.1340\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0326 - mae: 0.0326 - root_mean_squared_error: 0.0424 - val_loss: 0.0506 - val_mae: 0.0506 - val_root_mean_squared_error: 0.0610\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0332 - mae: 0.0332 - root_mean_squared_error: 0.0414 - val_loss: 0.0771 - val_mae: 0.0771 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0332 - mae: 0.0332 - root_mean_squared_error: 0.0424 - val_loss: 0.0574 - val_mae: 0.0574 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0368 - mae: 0.0368 - root_mean_squared_error: 0.0462 - val_loss: 0.0641 - val_mae: 0.0641 - val_root_mean_squared_error: 0.0763\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0303 - mae: 0.0303 - root_mean_squared_error: 0.0389 - val_loss: 0.1359 - val_mae: 0.1359 - val_root_mean_squared_error: 0.1480\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0445 - val_loss: 0.0612 - val_mae: 0.0612 - val_root_mean_squared_error: 0.0731\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0444 - val_loss: 0.0530 - val_mae: 0.0530 - val_root_mean_squared_error: 0.0635\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0459 - val_loss: 0.0515 - val_mae: 0.0515 - val_root_mean_squared_error: 0.0620\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0443 - val_loss: 0.0507 - val_mae: 0.0507 - val_root_mean_squared_error: 0.0609\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0449 - val_loss: 0.0591 - val_mae: 0.0591 - val_root_mean_squared_error: 0.0708\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0426 - val_loss: 0.0694 - val_mae: 0.0694 - val_root_mean_squared_error: 0.0821\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0333 - mae: 0.0333 - root_mean_squared_error: 0.0417 - val_loss: 0.0567 - val_mae: 0.0567 - val_root_mean_squared_error: 0.0678\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0311 - mae: 0.0311 - root_mean_squared_error: 0.0409 - val_loss: 0.0749 - val_mae: 0.0749 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0292 - mae: 0.0292 - root_mean_squared_error: 0.0385 - val_loss: 0.1422 - val_mae: 0.1422 - val_root_mean_squared_error: 0.1557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:37:53 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:38:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:38:01 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:38:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: dropout_rate = 0.2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0749 - mae: 0.0749 - root_mean_squared_error: 0.1017 - val_loss: 0.1441 - val_mae: 0.1441 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0810 - val_loss: 0.0711 - val_mae: 0.0711 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0562 - mae: 0.0562 - root_mean_squared_error: 0.0746 - val_loss: 0.1185 - val_mae: 0.1185 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0545 - mae: 0.0545 - root_mean_squared_error: 0.0736 - val_loss: 0.0657 - val_mae: 0.0657 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0515 - mae: 0.0515 - root_mean_squared_error: 0.0689 - val_loss: 0.0747 - val_mae: 0.0747 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0679 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0508 - mae: 0.0508 - root_mean_squared_error: 0.0683 - val_loss: 0.0709 - val_mae: 0.0709 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0481 - mae: 0.0481 - root_mean_squared_error: 0.0647 - val_loss: 0.1175 - val_mae: 0.1175 - val_root_mean_squared_error: 0.1314\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0436 - mae: 0.0436 - root_mean_squared_error: 0.0591 - val_loss: 0.1147 - val_mae: 0.1147 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0603 - val_loss: 0.1371 - val_mae: 0.1371 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0587 - val_loss: 0.1653 - val_mae: 0.1653 - val_root_mean_squared_error: 0.1762\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0546 - val_loss: 0.1428 - val_mae: 0.1428 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0544 - val_loss: 0.1299 - val_mae: 0.1299 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0555 - val_loss: 0.1610 - val_mae: 0.1610 - val_root_mean_squared_error: 0.1716\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0512 - val_loss: 0.1413 - val_mae: 0.1413 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0379 - mae: 0.0379 - root_mean_squared_error: 0.0533 - val_loss: 0.1370 - val_mae: 0.1370 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0545 - val_loss: 0.1199 - val_mae: 0.1199 - val_root_mean_squared_error: 0.1346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0542 - val_loss: 0.0910 - val_mae: 0.0910 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0584 - val_loss: 0.0774 - val_mae: 0.0774 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0504 - val_loss: 0.0934 - val_mae: 0.0934 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0494 - val_loss: 0.0843 - val_mae: 0.0843 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0502 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0516 - val_loss: 0.0803 - val_mae: 0.0803 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0529 - val_loss: 0.0759 - val_mae: 0.0759 - val_root_mean_squared_error: 0.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:38:43 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:38:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:38:51 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:38:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: dropout_rate = 0.5 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1088 - mae: 0.1088 - root_mean_squared_error: 0.1481 - val_loss: 0.1721 - val_mae: 0.1721 - val_root_mean_squared_error: 0.1812\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0824 - mae: 0.0824 - root_mean_squared_error: 0.1116 - val_loss: 0.0714 - val_mae: 0.0714 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0785 - mae: 0.0785 - root_mean_squared_error: 0.1051 - val_loss: 0.0585 - val_mae: 0.0585 - val_root_mean_squared_error: 0.0700\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0752 - mae: 0.0752 - root_mean_squared_error: 0.1005 - val_loss: 0.0702 - val_mae: 0.0702 - val_root_mean_squared_error: 0.0835\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0674 - mae: 0.0674 - root_mean_squared_error: 0.0907 - val_loss: 0.0900 - val_mae: 0.0900 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0673 - mae: 0.0673 - root_mean_squared_error: 0.0911 - val_loss: 0.0834 - val_mae: 0.0834 - val_root_mean_squared_error: 0.0967\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0594 - mae: 0.0594 - root_mean_squared_error: 0.0812 - val_loss: 0.1097 - val_mae: 0.1097 - val_root_mean_squared_error: 0.1218\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0598 - mae: 0.0598 - root_mean_squared_error: 0.0820 - val_loss: 0.0879 - val_mae: 0.0879 - val_root_mean_squared_error: 0.1007\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0554 - mae: 0.0554 - root_mean_squared_error: 0.0755 - val_loss: 0.1092 - val_mae: 0.1092 - val_root_mean_squared_error: 0.1204\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0533 - mae: 0.0533 - root_mean_squared_error: 0.0737 - val_loss: 0.0910 - val_mae: 0.0910 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0489 - mae: 0.0489 - root_mean_squared_error: 0.0674 - val_loss: 0.1779 - val_mae: 0.1779 - val_root_mean_squared_error: 0.1873\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0469 - mae: 0.0469 - root_mean_squared_error: 0.0646 - val_loss: 0.1359 - val_mae: 0.1359 - val_root_mean_squared_error: 0.1463\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0437 - mae: 0.0437 - root_mean_squared_error: 0.0612 - val_loss: 0.1398 - val_mae: 0.1398 - val_root_mean_squared_error: 0.1501\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0607 - val_loss: 0.1272 - val_mae: 0.1272 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0422 - mae: 0.0422 - root_mean_squared_error: 0.0586 - val_loss: 0.1474 - val_mae: 0.1474 - val_root_mean_squared_error: 0.1567\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0411 - mae: 0.0411 - root_mean_squared_error: 0.0559 - val_loss: 0.1289 - val_mae: 0.1289 - val_root_mean_squared_error: 0.1391\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0383 - mae: 0.0383 - root_mean_squared_error: 0.0528 - val_loss: 0.1200 - val_mae: 0.1200 - val_root_mean_squared_error: 0.1322\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0541 - val_loss: 0.1426 - val_mae: 0.1426 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0398 - mae: 0.0398 - root_mean_squared_error: 0.0549 - val_loss: 0.1422 - val_mae: 0.1422 - val_root_mean_squared_error: 0.1527\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0401 - mae: 0.0401 - root_mean_squared_error: 0.0551 - val_loss: 0.1100 - val_mae: 0.1100 - val_root_mean_squared_error: 0.1217\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0528 - val_loss: 0.1348 - val_mae: 0.1348 - val_root_mean_squared_error: 0.1441\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0511 - val_loss: 0.1150 - val_mae: 0.1150 - val_root_mean_squared_error: 0.1278\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0392 - mae: 0.0392 - root_mean_squared_error: 0.0534 - val_loss: 0.1395 - val_mae: 0.1395 - val_root_mean_squared_error: 0.1492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:39:33 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:39:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:39:41 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:39:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: dropout_rate = 0.8 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1813 - mae: 0.1813 - root_mean_squared_error: 0.2503 - val_loss: 0.1257 - val_mae: 0.1257 - val_root_mean_squared_error: 0.1377\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1353 - mae: 0.1353 - root_mean_squared_error: 0.1811 - val_loss: 0.0594 - val_mae: 0.0594 - val_root_mean_squared_error: 0.0711\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1203 - mae: 0.1203 - root_mean_squared_error: 0.1617 - val_loss: 0.1465 - val_mae: 0.1465 - val_root_mean_squared_error: 0.1566\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1093 - mae: 0.1093 - root_mean_squared_error: 0.1454 - val_loss: 0.1162 - val_mae: 0.1162 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1038 - mae: 0.1038 - root_mean_squared_error: 0.1364 - val_loss: 0.1393 - val_mae: 0.1393 - val_root_mean_squared_error: 0.1502\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0936 - mae: 0.0936 - root_mean_squared_error: 0.1262 - val_loss: 0.1181 - val_mae: 0.1181 - val_root_mean_squared_error: 0.1296\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0870 - mae: 0.0870 - root_mean_squared_error: 0.1174 - val_loss: 0.1218 - val_mae: 0.1218 - val_root_mean_squared_error: 0.1330\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0871 - mae: 0.0871 - root_mean_squared_error: 0.1162 - val_loss: 0.0935 - val_mae: 0.0935 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0806 - mae: 0.0806 - root_mean_squared_error: 0.1073 - val_loss: 0.0884 - val_mae: 0.0884 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0740 - mae: 0.0740 - root_mean_squared_error: 0.0987 - val_loss: 0.0907 - val_mae: 0.0907 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0688 - mae: 0.0688 - root_mean_squared_error: 0.0928 - val_loss: 0.0762 - val_mae: 0.0762 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0697 - mae: 0.0697 - root_mean_squared_error: 0.0913 - val_loss: 0.0948 - val_mae: 0.0948 - val_root_mean_squared_error: 0.1063\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0755 - mae: 0.0755 - root_mean_squared_error: 0.0980 - val_loss: 0.0705 - val_mae: 0.0705 - val_root_mean_squared_error: 0.0817\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0639 - mae: 0.0639 - root_mean_squared_error: 0.0860 - val_loss: 0.1086 - val_mae: 0.1086 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0608 - mae: 0.0608 - root_mean_squared_error: 0.0819 - val_loss: 0.0373 - val_mae: 0.0373 - val_root_mean_squared_error: 0.0455\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0575 - mae: 0.0575 - root_mean_squared_error: 0.0776 - val_loss: 0.1160 - val_mae: 0.1160 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0571 - mae: 0.0571 - root_mean_squared_error: 0.0775 - val_loss: 0.0708 - val_mae: 0.0708 - val_root_mean_squared_error: 0.0813\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0550 - mae: 0.0550 - root_mean_squared_error: 0.0744 - val_loss: 0.0908 - val_mae: 0.0908 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0540 - mae: 0.0540 - root_mean_squared_error: 0.0742 - val_loss: 0.1036 - val_mae: 0.1036 - val_root_mean_squared_error: 0.1111\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0551 - mae: 0.0551 - root_mean_squared_error: 0.0757 - val_loss: 0.0972 - val_mae: 0.0972 - val_root_mean_squared_error: 0.1051\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0526 - mae: 0.0526 - root_mean_squared_error: 0.0731 - val_loss: 0.1151 - val_mae: 0.1151 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0547 - mae: 0.0547 - root_mean_squared_error: 0.0761 - val_loss: 0.0594 - val_mae: 0.0594 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0554 - mae: 0.0554 - root_mean_squared_error: 0.0766 - val_loss: 0.0962 - val_mae: 0.0962 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0556 - mae: 0.0556 - root_mean_squared_error: 0.0769 - val_loss: 0.0612 - val_mae: 0.0612 - val_root_mean_squared_error: 0.0713\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0602 - mae: 0.0602 - root_mean_squared_error: 0.0816 - val_loss: 0.0452 - val_mae: 0.0452 - val_root_mean_squared_error: 0.0544\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0543 - mae: 0.0543 - root_mean_squared_error: 0.0749 - val_loss: 0.0856 - val_mae: 0.0856 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0534 - mae: 0.0534 - root_mean_squared_error: 0.0744 - val_loss: 0.0430 - val_mae: 0.0430 - val_root_mean_squared_error: 0.0522\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0541 - mae: 0.0541 - root_mean_squared_error: 0.0753 - val_loss: 0.1156 - val_mae: 0.1156 - val_root_mean_squared_error: 0.1215\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0505 - mae: 0.0505 - root_mean_squared_error: 0.0713 - val_loss: 0.0558 - val_mae: 0.0558 - val_root_mean_squared_error: 0.0653\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0546 - mae: 0.0546 - root_mean_squared_error: 0.0762 - val_loss: 0.0738 - val_mae: 0.0738 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0527 - mae: 0.0527 - root_mean_squared_error: 0.0750 - val_loss: 0.1036 - val_mae: 0.1036 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0540 - mae: 0.0540 - root_mean_squared_error: 0.0770 - val_loss: 0.0746 - val_mae: 0.0746 - val_root_mean_squared_error: 0.0827\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0535 - mae: 0.0535 - root_mean_squared_error: 0.0757 - val_loss: 0.0695 - val_mae: 0.0695 - val_root_mean_squared_error: 0.0783\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0534 - mae: 0.0534 - root_mean_squared_error: 0.0745 - val_loss: 0.0704 - val_mae: 0.0704 - val_root_mean_squared_error: 0.0790\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0511 - mae: 0.0511 - root_mean_squared_error: 0.0722 - val_loss: 0.0757 - val_mae: 0.0757 - val_root_mean_squared_error: 0.0829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:40:30 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:40:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:40:38 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:40:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 20:41:06 INFO mlflow.tracking.fluent: Experiment with name 'simplernn_number_of_layer_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: number_of_layer = 1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0749 - mae: 0.0749 - root_mean_squared_error: 0.1017 - val_loss: 0.1441 - val_mae: 0.1441 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0810 - val_loss: 0.0711 - val_mae: 0.0711 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0562 - mae: 0.0562 - root_mean_squared_error: 0.0746 - val_loss: 0.1185 - val_mae: 0.1185 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0545 - mae: 0.0545 - root_mean_squared_error: 0.0736 - val_loss: 0.0657 - val_mae: 0.0657 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0515 - mae: 0.0515 - root_mean_squared_error: 0.0689 - val_loss: 0.0747 - val_mae: 0.0747 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0679 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0508 - mae: 0.0508 - root_mean_squared_error: 0.0683 - val_loss: 0.0709 - val_mae: 0.0709 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0481 - mae: 0.0481 - root_mean_squared_error: 0.0647 - val_loss: 0.1175 - val_mae: 0.1175 - val_root_mean_squared_error: 0.1314\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0436 - mae: 0.0436 - root_mean_squared_error: 0.0591 - val_loss: 0.1147 - val_mae: 0.1147 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0603 - val_loss: 0.1371 - val_mae: 0.1371 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0587 - val_loss: 0.1653 - val_mae: 0.1653 - val_root_mean_squared_error: 0.1762\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0546 - val_loss: 0.1428 - val_mae: 0.1428 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0544 - val_loss: 0.1299 - val_mae: 0.1299 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0555 - val_loss: 0.1610 - val_mae: 0.1610 - val_root_mean_squared_error: 0.1716\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0512 - val_loss: 0.1413 - val_mae: 0.1413 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0379 - mae: 0.0379 - root_mean_squared_error: 0.0533 - val_loss: 0.1370 - val_mae: 0.1370 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0545 - val_loss: 0.1199 - val_mae: 0.1199 - val_root_mean_squared_error: 0.1346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0542 - val_loss: 0.0910 - val_mae: 0.0910 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0584 - val_loss: 0.0774 - val_mae: 0.0774 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0504 - val_loss: 0.0934 - val_mae: 0.0934 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0494 - val_loss: 0.0843 - val_mae: 0.0843 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0502 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0516 - val_loss: 0.0803 - val_mae: 0.0803 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0529 - val_loss: 0.0759 - val_mae: 0.0759 - val_root_mean_squared_error: 0.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:41:22 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:41:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:41:30 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:41:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: number_of_layer = 2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1707 - mae: 0.1707 - root_mean_squared_error: 0.2378 - val_loss: 0.1105 - val_mae: 0.1105 - val_root_mean_squared_error: 0.1278\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0898 - mae: 0.0898 - root_mean_squared_error: 0.1196 - val_loss: 0.1429 - val_mae: 0.1429 - val_root_mean_squared_error: 0.1553\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0748 - mae: 0.0748 - root_mean_squared_error: 0.1003 - val_loss: 0.0929 - val_mae: 0.0929 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0628 - mae: 0.0628 - root_mean_squared_error: 0.0845 - val_loss: 0.1526 - val_mae: 0.1526 - val_root_mean_squared_error: 0.1653\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0595 - mae: 0.0595 - root_mean_squared_error: 0.0804 - val_loss: 0.1121 - val_mae: 0.1121 - val_root_mean_squared_error: 0.1274\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0547 - mae: 0.0547 - root_mean_squared_error: 0.0733 - val_loss: 0.1271 - val_mae: 0.1271 - val_root_mean_squared_error: 0.1397\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0542 - mae: 0.0542 - root_mean_squared_error: 0.0745 - val_loss: 0.0973 - val_mae: 0.0973 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0530 - mae: 0.0530 - root_mean_squared_error: 0.0724 - val_loss: 0.0824 - val_mae: 0.0824 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0511 - mae: 0.0511 - root_mean_squared_error: 0.0700 - val_loss: 0.0768 - val_mae: 0.0768 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0522 - mae: 0.0522 - root_mean_squared_error: 0.0705 - val_loss: 0.0686 - val_mae: 0.0686 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0508 - mae: 0.0508 - root_mean_squared_error: 0.0695 - val_loss: 0.0950 - val_mae: 0.0950 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0516 - mae: 0.0516 - root_mean_squared_error: 0.0710 - val_loss: 0.1141 - val_mae: 0.1141 - val_root_mean_squared_error: 0.1309\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0482 - mae: 0.0482 - root_mean_squared_error: 0.0660 - val_loss: 0.0845 - val_mae: 0.0845 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0478 - mae: 0.0478 - root_mean_squared_error: 0.0654 - val_loss: 0.0768 - val_mae: 0.0768 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0489 - mae: 0.0489 - root_mean_squared_error: 0.0654 - val_loss: 0.0717 - val_mae: 0.0717 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0485 - mae: 0.0485 - root_mean_squared_error: 0.0667 - val_loss: 0.0698 - val_mae: 0.0698 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0456 - mae: 0.0456 - root_mean_squared_error: 0.0618 - val_loss: 0.0870 - val_mae: 0.0870 - val_root_mean_squared_error: 0.1025\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0587 - val_loss: 0.0687 - val_mae: 0.0687 - val_root_mean_squared_error: 0.0815\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0433 - mae: 0.0433 - root_mean_squared_error: 0.0588 - val_loss: 0.0793 - val_mae: 0.0793 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0438 - mae: 0.0438 - root_mean_squared_error: 0.0593 - val_loss: 0.0838 - val_mae: 0.0838 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0439 - mae: 0.0439 - root_mean_squared_error: 0.0592 - val_loss: 0.0800 - val_mae: 0.0800 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0570 - val_loss: 0.0837 - val_mae: 0.0837 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0393 - mae: 0.0393 - root_mean_squared_error: 0.0519 - val_loss: 0.0683 - val_mae: 0.0683 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0413 - mae: 0.0413 - root_mean_squared_error: 0.0545 - val_loss: 0.0784 - val_mae: 0.0784 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0423 - mae: 0.0423 - root_mean_squared_error: 0.0559 - val_loss: 0.0803 - val_mae: 0.0803 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0409 - mae: 0.0409 - root_mean_squared_error: 0.0539 - val_loss: 0.0757 - val_mae: 0.0757 - val_root_mean_squared_error: 0.0897\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0410 - mae: 0.0410 - root_mean_squared_error: 0.0542 - val_loss: 0.0769 - val_mae: 0.0769 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0417 - mae: 0.0417 - root_mean_squared_error: 0.0552 - val_loss: 0.0971 - val_mae: 0.0971 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0398 - mae: 0.0398 - root_mean_squared_error: 0.0530 - val_loss: 0.0870 - val_mae: 0.0870 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0553 - val_loss: 0.0870 - val_mae: 0.0870 - val_root_mean_squared_error: 0.1027\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0515 - val_loss: 0.0947 - val_mae: 0.0947 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0391 - mae: 0.0391 - root_mean_squared_error: 0.0507 - val_loss: 0.0851 - val_mae: 0.0851 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0485 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0523 - val_loss: 0.1261 - val_mae: 0.1261 - val_root_mean_squared_error: 0.1405\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0374 - mae: 0.0374 - root_mean_squared_error: 0.0496 - val_loss: 0.0972 - val_mae: 0.0972 - val_root_mean_squared_error: 0.1139\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0503 - val_loss: 0.1377 - val_mae: 0.1377 - val_root_mean_squared_error: 0.1535\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0401 - mae: 0.0401 - root_mean_squared_error: 0.0539 - val_loss: 0.1014 - val_mae: 0.1014 - val_root_mean_squared_error: 0.1186\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0398 - mae: 0.0398 - root_mean_squared_error: 0.0527 - val_loss: 0.0931 - val_mae: 0.0931 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0470 - val_loss: 0.1053 - val_mae: 0.1053 - val_root_mean_squared_error: 0.1221\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0485 - val_loss: 0.0953 - val_mae: 0.0953 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0379 - mae: 0.0379 - root_mean_squared_error: 0.0489 - val_loss: 0.0865 - val_mae: 0.0865 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0474 - val_loss: 0.0796 - val_mae: 0.0796 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0468 - val_loss: 0.0775 - val_mae: 0.0775 - val_root_mean_squared_error: 0.0922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:42:39 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:42:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:42:47 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:42:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: number_of_layer = 3 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.3741 - mae: 0.3741 - root_mean_squared_error: 0.4809 - val_loss: 0.1035 - val_mae: 0.1035 - val_root_mean_squared_error: 0.1267\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1707 - mae: 0.1707 - root_mean_squared_error: 0.2187 - val_loss: 0.1194 - val_mae: 0.1194 - val_root_mean_squared_error: 0.1412\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1203 - mae: 0.1203 - root_mean_squared_error: 0.1580 - val_loss: 0.0722 - val_mae: 0.0722 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1085 - mae: 0.1085 - root_mean_squared_error: 0.1429 - val_loss: 0.0623 - val_mae: 0.0623 - val_root_mean_squared_error: 0.0757\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0979 - mae: 0.0979 - root_mean_squared_error: 0.1319 - val_loss: 0.0753 - val_mae: 0.0753 - val_root_mean_squared_error: 0.0885\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0884 - mae: 0.0884 - root_mean_squared_error: 0.1176 - val_loss: 0.0746 - val_mae: 0.0746 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0765 - mae: 0.0765 - root_mean_squared_error: 0.1032 - val_loss: 0.0638 - val_mae: 0.0638 - val_root_mean_squared_error: 0.0751\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0732 - mae: 0.0732 - root_mean_squared_error: 0.0995 - val_loss: 0.0655 - val_mae: 0.0655 - val_root_mean_squared_error: 0.0771\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0643 - mae: 0.0643 - root_mean_squared_error: 0.0868 - val_loss: 0.0946 - val_mae: 0.0946 - val_root_mean_squared_error: 0.1116\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0577 - mae: 0.0577 - root_mean_squared_error: 0.0776 - val_loss: 0.0755 - val_mae: 0.0755 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0616 - mae: 0.0616 - root_mean_squared_error: 0.0837 - val_loss: 0.0690 - val_mae: 0.0690 - val_root_mean_squared_error: 0.0814\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0608 - mae: 0.0608 - root_mean_squared_error: 0.0819 - val_loss: 0.0771 - val_mae: 0.0771 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0543 - mae: 0.0543 - root_mean_squared_error: 0.0730 - val_loss: 0.0728 - val_mae: 0.0728 - val_root_mean_squared_error: 0.0863\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0530 - mae: 0.0530 - root_mean_squared_error: 0.0709 - val_loss: 0.0779 - val_mae: 0.0779 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0526 - mae: 0.0526 - root_mean_squared_error: 0.0689 - val_loss: 0.0789 - val_mae: 0.0789 - val_root_mean_squared_error: 0.0937\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0490 - mae: 0.0490 - root_mean_squared_error: 0.0660 - val_loss: 0.0714 - val_mae: 0.0714 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0486 - mae: 0.0486 - root_mean_squared_error: 0.0641 - val_loss: 0.0706 - val_mae: 0.0706 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0474 - mae: 0.0474 - root_mean_squared_error: 0.0624 - val_loss: 0.0807 - val_mae: 0.0807 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0437 - mae: 0.0437 - root_mean_squared_error: 0.0574 - val_loss: 0.1171 - val_mae: 0.1171 - val_root_mean_squared_error: 0.1347\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0454 - mae: 0.0454 - root_mean_squared_error: 0.0599 - val_loss: 0.0992 - val_mae: 0.0992 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0531 - mae: 0.0531 - root_mean_squared_error: 0.0687 - val_loss: 0.1015 - val_mae: 0.1015 - val_root_mean_squared_error: 0.1187\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0586 - mae: 0.0586 - root_mean_squared_error: 0.0801 - val_loss: 0.1305 - val_mae: 0.1305 - val_root_mean_squared_error: 0.1480\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0439 - mae: 0.0439 - root_mean_squared_error: 0.0577 - val_loss: 0.1029 - val_mae: 0.1029 - val_root_mean_squared_error: 0.1211\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0445 - mae: 0.0445 - root_mean_squared_error: 0.0586 - val_loss: 0.0940 - val_mae: 0.0940 - val_root_mean_squared_error: 0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:43:48 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:43:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:43:56 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:44:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: number_of_layer = 4 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.3966 - mae: 0.3966 - root_mean_squared_error: 0.5021 - val_loss: 0.2162 - val_mae: 0.2162 - val_root_mean_squared_error: 0.2431\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.2548 - mae: 0.2548 - root_mean_squared_error: 0.3204 - val_loss: 0.0857 - val_mae: 0.0857 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1815 - mae: 0.1815 - root_mean_squared_error: 0.2300 - val_loss: 0.0801 - val_mae: 0.0801 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1422 - mae: 0.1422 - root_mean_squared_error: 0.1812 - val_loss: 0.0777 - val_mae: 0.0777 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1337 - mae: 0.1337 - root_mean_squared_error: 0.1746 - val_loss: 0.0768 - val_mae: 0.0768 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.1111 - root_mean_squared_error: 0.1434 - val_loss: 0.1384 - val_mae: 0.1384 - val_root_mean_squared_error: 0.1607\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1064 - mae: 0.1064 - root_mean_squared_error: 0.1342 - val_loss: 0.1189 - val_mae: 0.1189 - val_root_mean_squared_error: 0.1402\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1195 - mae: 0.1195 - root_mean_squared_error: 0.1513 - val_loss: 0.1037 - val_mae: 0.1037 - val_root_mean_squared_error: 0.1213\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0975 - mae: 0.0975 - root_mean_squared_error: 0.1277 - val_loss: 0.1010 - val_mae: 0.1010 - val_root_mean_squared_error: 0.1186\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1169 - mae: 0.1169 - root_mean_squared_error: 0.1497 - val_loss: 0.1744 - val_mae: 0.1744 - val_root_mean_squared_error: 0.1951\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0900 - mae: 0.0900 - root_mean_squared_error: 0.1159 - val_loss: 0.1318 - val_mae: 0.1318 - val_root_mean_squared_error: 0.1539\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1032 - mae: 0.1032 - root_mean_squared_error: 0.1336 - val_loss: 0.1513 - val_mae: 0.1513 - val_root_mean_squared_error: 0.1727\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0864 - mae: 0.0864 - root_mean_squared_error: 0.1124 - val_loss: 0.1348 - val_mae: 0.1348 - val_root_mean_squared_error: 0.1577\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1012 - mae: 0.1012 - root_mean_squared_error: 0.1343 - val_loss: 0.1887 - val_mae: 0.1887 - val_root_mean_squared_error: 0.2109\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0872 - mae: 0.0872 - root_mean_squared_error: 0.1127 - val_loss: 0.1171 - val_mae: 0.1171 - val_root_mean_squared_error: 0.1378\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1144 - mae: 0.1144 - root_mean_squared_error: 0.1499 - val_loss: 0.1336 - val_mae: 0.1336 - val_root_mean_squared_error: 0.1554\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1049 - mae: 0.1049 - root_mean_squared_error: 0.1371 - val_loss: 0.1447 - val_mae: 0.1447 - val_root_mean_squared_error: 0.1672\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1063 - mae: 0.1063 - root_mean_squared_error: 0.1377 - val_loss: 0.1186 - val_mae: 0.1186 - val_root_mean_squared_error: 0.1396\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0994 - mae: 0.0994 - root_mean_squared_error: 0.1345 - val_loss: 0.1529 - val_mae: 0.1529 - val_root_mean_squared_error: 0.1746\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0970 - mae: 0.0970 - root_mean_squared_error: 0.1249 - val_loss: 0.1581 - val_mae: 0.1581 - val_root_mean_squared_error: 0.1802\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0973 - mae: 0.0973 - root_mean_squared_error: 0.1271 - val_loss: 0.1398 - val_mae: 0.1398 - val_root_mean_squared_error: 0.1620\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1014 - mae: 0.1014 - root_mean_squared_error: 0.1321 - val_loss: 0.1308 - val_mae: 0.1308 - val_root_mean_squared_error: 0.1529\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1045 - mae: 0.1045 - root_mean_squared_error: 0.1341 - val_loss: 0.1351 - val_mae: 0.1351 - val_root_mean_squared_error: 0.1574\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1012 - mae: 0.1012 - root_mean_squared_error: 0.1321 - val_loss: 0.1531 - val_mae: 0.1531 - val_root_mean_squared_error: 0.1751\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0948 - mae: 0.0948 - root_mean_squared_error: 0.1280 - val_loss: 0.1271 - val_mae: 0.1271 - val_root_mean_squared_error: 0.1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:45:07 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:45:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:45:15 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:45:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 20:45:43 INFO mlflow.tracking.fluent: Experiment with name 'simplernn_loss_function_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: loss_function = mae ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0749 - mae: 0.0749 - root_mean_squared_error: 0.1017 - val_loss: 0.1441 - val_mae: 0.1441 - val_root_mean_squared_error: 0.1563\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0810 - val_loss: 0.0711 - val_mae: 0.0711 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0562 - mae: 0.0562 - root_mean_squared_error: 0.0746 - val_loss: 0.1185 - val_mae: 0.1185 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0545 - mae: 0.0545 - root_mean_squared_error: 0.0736 - val_loss: 0.0657 - val_mae: 0.0657 - val_root_mean_squared_error: 0.0784\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0515 - mae: 0.0515 - root_mean_squared_error: 0.0689 - val_loss: 0.0747 - val_mae: 0.0747 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0679 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0508 - mae: 0.0508 - root_mean_squared_error: 0.0683 - val_loss: 0.0709 - val_mae: 0.0709 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0481 - mae: 0.0481 - root_mean_squared_error: 0.0647 - val_loss: 0.1175 - val_mae: 0.1175 - val_root_mean_squared_error: 0.1314\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0436 - mae: 0.0436 - root_mean_squared_error: 0.0591 - val_loss: 0.1147 - val_mae: 0.1147 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0603 - val_loss: 0.1371 - val_mae: 0.1371 - val_root_mean_squared_error: 0.1496\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0587 - val_loss: 0.1653 - val_mae: 0.1653 - val_root_mean_squared_error: 0.1762\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0546 - val_loss: 0.1428 - val_mae: 0.1428 - val_root_mean_squared_error: 0.1551\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0544 - val_loss: 0.1299 - val_mae: 0.1299 - val_root_mean_squared_error: 0.1426\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0555 - val_loss: 0.1610 - val_mae: 0.1610 - val_root_mean_squared_error: 0.1716\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0512 - val_loss: 0.1413 - val_mae: 0.1413 - val_root_mean_squared_error: 0.1536\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0379 - mae: 0.0379 - root_mean_squared_error: 0.0533 - val_loss: 0.1370 - val_mae: 0.1370 - val_root_mean_squared_error: 0.1510\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0545 - val_loss: 0.1199 - val_mae: 0.1199 - val_root_mean_squared_error: 0.1346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0542 - val_loss: 0.0910 - val_mae: 0.0910 - val_root_mean_squared_error: 0.1073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0584 - val_loss: 0.0774 - val_mae: 0.0774 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0504 - val_loss: 0.0934 - val_mae: 0.0934 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0494 - val_loss: 0.0843 - val_mae: 0.0843 - val_root_mean_squared_error: 0.0998\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0502 - val_loss: 0.1038 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0516 - val_loss: 0.0803 - val_mae: 0.0803 - val_root_mean_squared_error: 0.0957\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0529 - val_loss: 0.0759 - val_mae: 0.0759 - val_root_mean_squared_error: 0.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:45:59 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:46:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:46:07 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:46:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: loss_function = mse ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0109 - mae: 0.0774 - root_mean_squared_error: 0.1042 - val_loss: 0.0139 - val_mae: 0.1062 - val_root_mean_squared_error: 0.1179\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - mae: 0.0580 - root_mean_squared_error: 0.0769 - val_loss: 0.0168 - val_mae: 0.1172 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - mae: 0.0521 - root_mean_squared_error: 0.0689 - val_loss: 0.0299 - val_mae: 0.1627 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0044 - mae: 0.0496 - root_mean_squared_error: 0.0661 - val_loss: 0.0298 - val_mae: 0.1624 - val_root_mean_squared_error: 0.1726\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0039 - mae: 0.0462 - root_mean_squared_error: 0.0621 - val_loss: 0.0182 - val_mae: 0.1214 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - mae: 0.0449 - root_mean_squared_error: 0.0605 - val_loss: 0.0298 - val_mae: 0.1611 - val_root_mean_squared_error: 0.1726\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - mae: 0.0466 - root_mean_squared_error: 0.0624 - val_loss: 0.0210 - val_mae: 0.1322 - val_root_mean_squared_error: 0.1449\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0037 - mae: 0.0448 - root_mean_squared_error: 0.0606 - val_loss: 0.0201 - val_mae: 0.1282 - val_root_mean_squared_error: 0.1416\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0035 - mae: 0.0443 - root_mean_squared_error: 0.0594 - val_loss: 0.0142 - val_mae: 0.1048 - val_root_mean_squared_error: 0.1190\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0039 - mae: 0.0470 - root_mean_squared_error: 0.0628 - val_loss: 0.0121 - val_mae: 0.0960 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0039 - mae: 0.0480 - root_mean_squared_error: 0.0626 - val_loss: 0.0204 - val_mae: 0.1311 - val_root_mean_squared_error: 0.1428\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0417 - root_mean_squared_error: 0.0553 - val_loss: 0.0170 - val_mae: 0.1177 - val_root_mean_squared_error: 0.1305\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0389 - root_mean_squared_error: 0.0525 - val_loss: 0.0261 - val_mae: 0.1505 - val_root_mean_squared_error: 0.1615\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0390 - root_mean_squared_error: 0.0535 - val_loss: 0.0291 - val_mae: 0.1593 - val_root_mean_squared_error: 0.1706\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0416 - root_mean_squared_error: 0.0559 - val_loss: 0.0140 - val_mae: 0.1035 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - mae: 0.0433 - root_mean_squared_error: 0.0579 - val_loss: 0.0094 - val_mae: 0.0827 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0030 - mae: 0.0405 - root_mean_squared_error: 0.0544 - val_loss: 0.0137 - val_mae: 0.1044 - val_root_mean_squared_error: 0.1172\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0025 - mae: 0.0367 - root_mean_squared_error: 0.0498 - val_loss: 0.0176 - val_mae: 0.1203 - val_root_mean_squared_error: 0.1327\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0384 - root_mean_squared_error: 0.0519 - val_loss: 0.0102 - val_mae: 0.0863 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0364 - root_mean_squared_error: 0.0489 - val_loss: 0.0127 - val_mae: 0.0995 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0020 - mae: 0.0331 - root_mean_squared_error: 0.0448 - val_loss: 0.0137 - val_mae: 0.1046 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0333 - root_mean_squared_error: 0.0454 - val_loss: 0.0123 - val_mae: 0.0979 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0344 - root_mean_squared_error: 0.0462 - val_loss: 0.0150 - val_mae: 0.1100 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0360 - root_mean_squared_error: 0.0480 - val_loss: 0.0190 - val_mae: 0.1261 - val_root_mean_squared_error: 0.1378\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0022 - mae: 0.0350 - root_mean_squared_error: 0.0470 - val_loss: 0.0136 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0020 - mae: 0.0339 - root_mean_squared_error: 0.0452 - val_loss: 0.0131 - val_mae: 0.1024 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0314 - root_mean_squared_error: 0.0423 - val_loss: 0.0114 - val_mae: 0.0936 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0357 - root_mean_squared_error: 0.0477 - val_loss: 0.0143 - val_mae: 0.1075 - val_root_mean_squared_error: 0.1195\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0021 - mae: 0.0348 - root_mean_squared_error: 0.0463 - val_loss: 0.0105 - val_mae: 0.0893 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0302 - root_mean_squared_error: 0.0402 - val_loss: 0.0136 - val_mae: 0.1055 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0014 - mae: 0.0272 - root_mean_squared_error: 0.0369 - val_loss: 0.0153 - val_mae: 0.1129 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0282 - root_mean_squared_error: 0.0380 - val_loss: 0.0114 - val_mae: 0.0949 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0015 - mae: 0.0301 - root_mean_squared_error: 0.0393 - val_loss: 0.0124 - val_mae: 0.1007 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0312 - root_mean_squared_error: 0.0407 - val_loss: 0.0123 - val_mae: 0.1012 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0011 - mae: 0.0255 - root_mean_squared_error: 0.0338 - val_loss: 0.0100 - val_mae: 0.0902 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0011 - mae: 0.0244 - root_mean_squared_error: 0.0330 - val_loss: 0.0167 - val_mae: 0.1196 - val_root_mean_squared_error: 0.1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:46:59 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:47:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:47:08 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:47:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: loss_function = huber ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0054 - mae: 0.0774 - root_mean_squared_error: 0.1042 - val_loss: 0.0069 - val_mae: 0.1061 - val_root_mean_squared_error: 0.1179\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0580 - root_mean_squared_error: 0.0769 - val_loss: 0.0084 - val_mae: 0.1172 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0521 - root_mean_squared_error: 0.0689 - val_loss: 0.0149 - val_mae: 0.1627 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0496 - root_mean_squared_error: 0.0661 - val_loss: 0.0149 - val_mae: 0.1624 - val_root_mean_squared_error: 0.1726\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0019 - mae: 0.0462 - root_mean_squared_error: 0.0621 - val_loss: 0.0091 - val_mae: 0.1214 - val_root_mean_squared_error: 0.1350\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0449 - root_mean_squared_error: 0.0605 - val_loss: 0.0149 - val_mae: 0.1611 - val_root_mean_squared_error: 0.1726\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0466 - root_mean_squared_error: 0.0624 - val_loss: 0.0105 - val_mae: 0.1321 - val_root_mean_squared_error: 0.1449\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0448 - root_mean_squared_error: 0.0606 - val_loss: 0.0100 - val_mae: 0.1282 - val_root_mean_squared_error: 0.1416\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0018 - mae: 0.0443 - root_mean_squared_error: 0.0594 - val_loss: 0.0071 - val_mae: 0.1047 - val_root_mean_squared_error: 0.1190\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0020 - mae: 0.0470 - root_mean_squared_error: 0.0628 - val_loss: 0.0061 - val_mae: 0.0960 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0480 - root_mean_squared_error: 0.0626 - val_loss: 0.0102 - val_mae: 0.1311 - val_root_mean_squared_error: 0.1428\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0417 - root_mean_squared_error: 0.0553 - val_loss: 0.0085 - val_mae: 0.1177 - val_root_mean_squared_error: 0.1305\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0389 - root_mean_squared_error: 0.0525 - val_loss: 0.0130 - val_mae: 0.1505 - val_root_mean_squared_error: 0.1615\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0014 - mae: 0.0390 - root_mean_squared_error: 0.0535 - val_loss: 0.0145 - val_mae: 0.1593 - val_root_mean_squared_error: 0.1706\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0416 - root_mean_squared_error: 0.0559 - val_loss: 0.0070 - val_mae: 0.1035 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0433 - root_mean_squared_error: 0.0579 - val_loss: 0.0047 - val_mae: 0.0827 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0405 - root_mean_squared_error: 0.0544 - val_loss: 0.0069 - val_mae: 0.1044 - val_root_mean_squared_error: 0.1172\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0367 - root_mean_squared_error: 0.0498 - val_loss: 0.0088 - val_mae: 0.1203 - val_root_mean_squared_error: 0.1326\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0013 - mae: 0.0384 - root_mean_squared_error: 0.0518 - val_loss: 0.0051 - val_mae: 0.0863 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0364 - root_mean_squared_error: 0.0489 - val_loss: 0.0064 - val_mae: 0.0995 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0331 - root_mean_squared_error: 0.0448 - val_loss: 0.0068 - val_mae: 0.1046 - val_root_mean_squared_error: 0.1169\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0010 - mae: 0.0333 - root_mean_squared_error: 0.0454 - val_loss: 0.0062 - val_mae: 0.0979 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0344 - root_mean_squared_error: 0.0462 - val_loss: 0.0075 - val_mae: 0.1100 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0012 - mae: 0.0360 - root_mean_squared_error: 0.0480 - val_loss: 0.0095 - val_mae: 0.1261 - val_root_mean_squared_error: 0.1378\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0011 - mae: 0.0350 - root_mean_squared_error: 0.0470 - val_loss: 0.0068 - val_mae: 0.1038 - val_root_mean_squared_error: 0.1167\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0339 - root_mean_squared_error: 0.0452 - val_loss: 0.0065 - val_mae: 0.1024 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.9394e-04 - mae: 0.0314 - root_mean_squared_error: 0.0423 - val_loss: 0.0057 - val_mae: 0.0936 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0357 - root_mean_squared_error: 0.0477 - val_loss: 0.0071 - val_mae: 0.1075 - val_root_mean_squared_error: 0.1195\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0348 - root_mean_squared_error: 0.0463 - val_loss: 0.0052 - val_mae: 0.0893 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0903e-04 - mae: 0.0302 - root_mean_squared_error: 0.0402 - val_loss: 0.0068 - val_mae: 0.1055 - val_root_mean_squared_error: 0.1168\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.8262e-04 - mae: 0.0272 - root_mean_squared_error: 0.0369 - val_loss: 0.0076 - val_mae: 0.1129 - val_root_mean_squared_error: 0.1235\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.2371e-04 - mae: 0.0282 - root_mean_squared_error: 0.0380 - val_loss: 0.0057 - val_mae: 0.0949 - val_root_mean_squared_error: 0.1067\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7395e-04 - mae: 0.0301 - root_mean_squared_error: 0.0393 - val_loss: 0.0062 - val_mae: 0.1007 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.2680e-04 - mae: 0.0312 - root_mean_squared_error: 0.0407 - val_loss: 0.0062 - val_mae: 0.1013 - val_root_mean_squared_error: 0.1109\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.7038e-04 - mae: 0.0255 - root_mean_squared_error: 0.0338 - val_loss: 0.0050 - val_mae: 0.0903 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.4518e-04 - mae: 0.0244 - root_mean_squared_error: 0.0330 - val_loss: 0.0083 - val_mae: 0.1196 - val_root_mean_squared_error: 0.1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:47:59 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:48:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:48:07 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:48:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow training cycle complete.\n"
     ]
    }
   ],
   "source": [
    "# MLflow Hyperparameter Sweep - Normal Price Values.\n",
    "\n",
    "# --- Configuration & Search Space ---\n",
    "date = datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
    "model_list = [\"lstm\", \"gru\", \"simplernn\"]\n",
    "\n",
    "search_space = {\n",
    "    \"input_width\": [12, 24, 48, 72, 96],\n",
    "    \"batch_size\": [16, 32, 64, 128],\n",
    "    \"learning_rate\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"model_units\": [10, 50, 100, 200],\n",
    "    \"dropout_rate\": [0, 0.2, 0.5, 0.8],\n",
    "    \"number_of_layer\": [1, 2, 3, 4],\n",
    "    \"loss_function\": ['mae', 'mse', 'huber'],\n",
    "}\n",
    "\n",
    "base_config = {\n",
    "    \"input_width\": 24,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 50,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"model_units\": 50,\n",
    "    \"dense_units\": 1,\n",
    "    \"dropout_rate\": 0.2,\n",
    "    \"number_of_layer\": 1,\n",
    "    \"loss_function\": 'mae',\n",
    "    \"train_ratio\": 0.7,\n",
    "    \"val_ratio\": 0.25,\n",
    "    'optimizer_name': 'adam',\n",
    "}\n",
    "\n",
    "# --- Experiment Loop ---\n",
    "\n",
    "for model_type in model_list:\n",
    "    for param_name, values in search_space.items():\n",
    "        # Set experiment scope per model/parameter combination\n",
    "        experiment_name = f\"{model_type}_{param_name}_{date}\"\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "\n",
    "        for value in values:\n",
    "            print(f\"--- Model: {model_type} | Param: {param_name} = {value} ---\")\n",
    "            \n",
    "            # Memoriy cleanup and seed reset for reproducibility\n",
    "            tf.keras.backend.clear_session()\n",
    "            set_seed(42)\n",
    "            \n",
    "            # Generate configuration for this specific run         \n",
    "            run_config = base_config.copy() \n",
    "            run_config[param_name] = value\n",
    "            run_name = f\"{param_name}_{value}\"\n",
    "\n",
    "            with mlflow.start_run(run_name=run_name):\n",
    "                # 1. Logging Metadata \n",
    "                mlflow.log_params(run_config)\n",
    "                mlflow.log_param(\"model_name\", model_type)\n",
    "                mlflow.log_param(\"studied_parameter\", param_name)\n",
    "\n",
    "                # 2. Data Preparation\n",
    "                df_raw = pd.read_csv('../data/dataset/BTCUSDT_1h.csv')\n",
    "                df_raw['timestamp'] = pd.to_datetime(df_raw['timestamp'], unit='ms')\n",
    "                df_raw.set_index('timestamp', inplace=True)\n",
    "                \n",
    "                # Filter for 2025 data (Normal values, no log-transform)\n",
    "                df_2025= df_raw[df_raw.index.year == 2025][['close']].sort_index()\n",
    "\n",
    "                df_train, df_val, df_test, train_gen, val_gen, test_gen, scaler = (\n",
    "                    split_and_generate_dataset(\n",
    "                        df_2025,\n",
    "                        input_width=run_config['input_width'],\n",
    "                        batch_size=run_config['batch_size'],\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # 3. Model Architecture Construction\n",
    "                input_shape = (run_config['input_width'], 1)\n",
    "                layer_config = []\n",
    "                \n",
    "                for i in range(run_config['number_of_layer']):\n",
    "                    layer_config.append({\n",
    "                        'type' : model_type,\n",
    "                        'units': run_config['model_units'],\n",
    "                        'return_sequences': True if i < run_config['number_of_layer'] - 1 else False\n",
    "                    })\n",
    "                    layer_config.append({\n",
    "                        'type' : 'dropout',\n",
    "                        'rate': run_config['dropout_rate']\n",
    "                    })\n",
    "                \n",
    "                layer_config.append({\n",
    "                    'type' : 'dense',\n",
    "                    'units': run_config['dense_units']\n",
    "                    })\n",
    "                    \n",
    "                mg = ModelGenerator(input_shape=input_shape)\n",
    "                model = mg.build_model(\n",
    "                    layers_config=layer_config,\n",
    "                    optimizer_name=run_config['optimizer_name'],\n",
    "                    optimizer_config={'learning_rate': run_config['learning_rate']},\n",
    "                    loss=run_config['loss_function'],\n",
    "                    metrics=['mae', RootMeanSquaredError()]\n",
    "                )\n",
    "                \n",
    "                # 4. Training with Early Stopping\n",
    "                early_stop = EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=20,\n",
    "                    restore_best_weights=True\n",
    "                    )\n",
    "                history = mg.train(\n",
    "                    train_gen,\n",
    "                    val_gen,\n",
    "                    epochs=run_config['epochs'],\n",
    "                    callbacks=[early_stop]\n",
    "                    )\n",
    "\n",
    "                # 5. Log Training Metrics\n",
    "                mlflow.log_metrics({\n",
    "                    \"final_train_loss\": history.history['loss'][-1],\n",
    "                    \"final_val_loss\": history.history['val_loss'][-1],\n",
    "                    \"final_val_mae\": history.history['val_mae'][-1],\n",
    "                    \"final_val_rmse\": history.history['val_root_mean_squared_error'][-1],\n",
    "                })\n",
    "\n",
    "\n",
    "                mlflow.keras.log_model(mg.model, name=\"model\")\n",
    "                mlflow.sklearn.log_model(scaler, name=\"scaler\")\n",
    "\n",
    "                # 6. Walk-Forward Prediction & Plotting\n",
    "                predictions_wf, y_true_wf, df_init, future_index = run_walkforward_prediction(\n",
    "                    df_test=df_test,\n",
    "                    model=mg.model,\n",
    "                    scaler=scaler,\n",
    "                    input_width=run_config['input_width']\n",
    "                )\n",
    "\n",
    "                if predictions_wf is not None:\n",
    "                    # Data consolidation for visualization\n",
    "                    plot_df = pd.DataFrame({\n",
    "                        'Date': future_index,\n",
    "                        'Real values': y_true_wf,\n",
    "                        'Predictions': predictions_wf\n",
    "                    }).melt(id_vars='Date', var_name='Type', value_name='Valeur')\n",
    "\n",
    "                    initial_df = pd.DataFrame({\n",
    "                        'Date': df_init.index,\n",
    "                        'Valeur': df_init['close'].values, \n",
    "                        'Type': 'Initial sequence'\n",
    "                    })\n",
    "\n",
    "                    full_plot_df = pd.concat([initial_df, plot_df], ignore_index=True)\n",
    "                    \n",
    "                    # Export data and log artifacts\n",
    "                    dir_path = f\"data/{date}/normal_value/{model_type}\"\n",
    "                    os.makedirs(dir_path, exist_ok=True)\n",
    "                    full_plot_df.to_csv(f\"{dir_path}/{run_name}.csv\", index=False)\n",
    "\n",
    "                    mlflow.log_table(data=full_plot_df, artifact_file=\"predictions_table.json\")\n",
    "                    \n",
    "                    fig2 = px.line(\n",
    "                        full_plot_df, x='Date', y='Valeur', color='Type',\n",
    "                        title=f'WF Pred: {model_type.upper()} | {param_name}={value}',\n",
    "                        template='simple_white', color_discrete_map=custom_colors\n",
    "                    )\n",
    "\n",
    "                    plot_path = f\"plot_{model_type}_{run_name}.html\"\n",
    "                    plot(fig2, filename=plot_path, auto_open=False)\n",
    "                    mlflow.log_artifact(plot_path)\n",
    "                    if os.path.exists(plot_path): os.remove(plot_path)\n",
    "\n",
    "print(\"MLflow grid search cycle complete.\")"
   ]
  },
  {
   "attachments": {
    "image-4.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzMAAAGUCAYAAAABLXzJAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAP+lSURBVHhe7J15nJxFnf8/09dM99xHMplMksk1BALhMkCiIKgBo6IIKKJx1yVBZH+S3fVYzbqo2cMVlVVXPEAIq64RRA4DCAESrgRDIIRjSEgyOWYmmcxk7p7p6fv4/VH1raee6qfP6YT0pN6vV16Z6e7p7nqqnqrv/S1JJBIJaDQajUaj0Wg0Gk2RYVMf0Gg0Go1Go9FoNJpiQCszGo1Go9FoNBqNpijRyoxGo9FoNBqNRqMpSrQyo9FoNBqNRqPRaIoSrcxoNBqNRqPRaDSaokQrMxqNRqPRaDQajaYo0cqMRqPRaDQajUajKUq0MqPRaDQajUaj0WiKEq3MaDQajUaj0Wg0mqJEKzMajUaj0Wg0Go2mKNHKjEaj0Wg0Go1GoylKtDKj0Wg0Go1Go9FoihKtzGg0Go1Go9FoNJqiRCszGo1Go9FoNBqNpijRyoxGo9FoNBqNRqMpSrQyM0m45pprsHTpUvXhk5LbbrsNra2t6OzsVJ/SnABWr15dNGtlMtDa2orVq1erD2tOEJ2dnWhtbcX69evVpzSaCTOZzrNrrrkGra2taG1tzfmMmEzXQVN8aGXmOLF06VKxKcj/tmzZor40JatXr875b3Jhy5Yt4ntNloOeBJdrrrlGfeq4k+2cr1+/Puk19M/qIMikqB7v8dI6tPqnji1XaA2eLOtPH8jZcbLNWyGhPcTq36nAZJ5bTWpWr16Nnp4etLe3o729Hdu2bVNfotGctGhlpsCQMNTU1CQ2Bfq3fPlyrFy58rgKnrnwwAMPiJ8feugh03Oa7Ml3zteuXWt67aJFi7Bs2bKTVojYtGmT6fuuXbsWK1euPGWEPM2pxfLly5Puz0Io8BrNycjGjRtx1VVXqQ9rNEWBVmYKyPr167Fu3TqsWrUKDz/8sPo07rjjDrS3t6sPp4Ref8kll6hPFYSNGzdi+fLlWL58Odra2iaFNbqlpQXt7e2W1/94UMg5p78vFsVyxYoVYmzpPEcazWSA7s9vfOMb6lMaTVFDZ//MmTPVpzSaokArMwXk5z//ORoaGrBmzRr1KROy0CuHEMnhDJ2dnSlDXuTwMPrX09Njek0myPp/3XXX4brrrgMA3HfffcqrzGE3ahiV+r1ShSOpr1NZunRpSmGYYnhl1O+h/m2rRY6CVWiX6gGh8BL1/dKRz5xPNtauXYuBgQHT9bS63uo137JlC1auXCneg15Dc5fLerJ6rdXr1LVz2223ieduu+02rFu3DgCwbNkyy+9M41LXVz7I8enp3pPuQfpHf5fq9ZlIt+cQ6a5TpnlLtW/RtZM9G+m+Sy57z4li0aJFGBgYANKEo1nNCz0u791Lly7N6z3U9UBzo94D6v5GqNcyl7kl0r0HlDUgr3P5O9F7ZDuXuayHVKG5dI1kaHwTva6wuC5WWM256u1Ld1/kipW8IL/Pli1bsGzZMkCZc/U75YN6PVotzle6vlZjozmRv4vV2aJSyOunKRISmoLQ0dGRmD9/fuKWW25Rn0rL1VdfnZg/f35i/vz56lOJ73//+4n58+cnOjo6xGO///3vE/Pnz0/8/ve/N712yZIliSVLlpgeS8fVV19ten2qv6fvoH4P9e8TiUTilltuSXz/+99Pekz9W3Vcqcb04osvJj0+f/78xNVXXy1+t7ru6u/0eS+++KJ4zOp70Xup40qF1WdnQ6rxpno/q2sto16TTNxyyy1p30/F6lqpqN/h97//fdJ3shq31RwT2a4nuodk1PVM1zbT2lHXpgqNQZ2jdFi9Xv0uqR6zGi9dM/U9syXdnpPtdUo3b6muIV07+T5M911y2XvSQd/f6rtaYTVeQl5r9DqZVH9L41DnN5/3kO8JuqapHpevdSHmNtv3kOdO/g4yS5YsScy3WCepyGU9WD2WkO4nmXTXL9Xj8pjSfS/1s+jvrd5Tvt7p7otcsDr7rB6jOVT321ywuu+XLFmSNP+p9mZ1vScs9k6av0xneaGun6Z40J6ZAtHV1QUAaG5uVp/KSENDQ9ahSGvXrsXy5cuxYsUK0+NNTU2m39PR2dmJtrY2U3zsVVddhYGBgZTWmE2bNqGlpUX8fu211ya9/o477kjyUHz9618HAGzdutX0uMyKFSvQ0NCQFF71wAMPoKGhQYyVPuvaa68Vr6GwsnTX/ZVXXkFDQ4MpXO+OO+7A2rVrTa+j98o28XEic27F9ddfj4aGBtxxxx3qUyc9DQ0NJu/gihUrkrxRNM8vv/yy6fFUZLue2trasHz5culVwLZt20zr+ytf+QoaGhpM36mlpQVr167Fxo0bs7bYUWjdROaILL4/+clPTI/fe++9aGtrE5bfLVu2YOPGjVi7dq3p3itE2GmqPadQ1ykXUn0XIpu950RA+yatNdovZFpaWrB8+XLs2LHD9Dh4Do56T+TzHvI9cfHFFwMAVq1aZfn4Sy+9JB4rxNzm+h6bNm1KuV63bduG9vZ209xmw/FYDxO5roT6vej+lr1WdH7L77lixQosX74cP//5z8VjyOK+yIZ169Zh+fLlpjlYs2YNFi1adELCJbdt25Y0/7fccgsGBgbEWqH1vnHjRtPraB+kPV/eD9WzvKGhAbfffrt4DAW6fpriQSszxxkrF69VMng20Ga9ZMkS9amcoHCyz372s+Ix+lkuCpAP6njJfX348GH1pSauuuqqpLwdNSFx1qxZAD8Q1INLFXplmpubMTAwkHTdV6xYkfNBmg3qNUg157JLv7W1FbfcckvWilSxoF6HgYEBdHd3qy9LiXotrdZTQ0MDNm7cmBTqIq+JtrY2LF682PQ8pDVFiumJgJRrde3RAU3KHglMJECdCE6m63Sycf311wOScEWo4YIbN24UoWjZku970BpS7ymrxwsxt4V4j2LA6vqle9yKlpYWNDQ04JVXXgEynN90RhWSdJ934YUXmhSK44kavkdGRHmtUKi7HML30EMPYdGiReKap9sPm5qaspoTzeRFKzMFgjZz9Ya65JJL0C5VxJkIdPPTZ+XLhg0bACUvgIRE1TqSC0uXLsXKlSuxVqrStWnTJvVllpDgSdYVEkxlgbSlpUW8H1XRon/puOOOO0SRA/lvVOE3VyY65/J1ot/zPVwK5R3Kl4GBAZN3kOKg1YpQDQ0Npr9LR7bradu2bWhoaMC6detM80uHOV3TjRs3mp5vbW0V+QEnUgjr6elJ60ml9UT/q0rP8eJku07vNup1oGqFNB8Uuy+Xs23nFQyzpRDvkQ2FmNtCvMepDF0b1YjV2toqcvXy3f+tyEZeOJ7z1clzg9atW2eqhKlGRICfmYsWLRLeqS1btqCtrQ1f+cpXxGtoP5TlFvrX1taWc96wZnKhlZkCQVYYq9CAk4ktW7ZgYGDAJCCqm0y6BMdUyO+rhsBly6pVq4QytWHDBssDvYWHZajf2crzIUNVxegfCb+qhycXCjnnJKSTUilzPKx2hYTWixz+t5FXyss3HCvX9UQhK+2SwkMCFgmfq1atSlrz9C+bzygUTU1NaQ/ed0sxPdmu07uNqoirIWIPPfQQGhoaJuRNLcR7ZEMh5rYQ73GqMTAwIO5nUiruvffepOtG/wppuMjGW5ZO0ZkoFAGiht+l4itf+YoIF6QQczmcjK6jes3o3/G+hzQnN1qZKSAUCzpRi38q0sXrZguFkVm5aukgUnNXsiEbK1AmKNRt9erVGBgYSArnWL9+fZLysWLFCixatCitcKhW4gGAH/7wh0CGjT4bCjXnLTzuHBaKGYUJqGOXHyM3/bvB2rVr0SDlNpF1MRuhPNV6yXY9dfKqVzItLS1YtWqVeB68ChV5JNNxIkqTpgrxUMNC0s378SLb65RpXk4FMnnYsqEQ75EthZjbbN9Dk3w/k2A+0VDubFHDVmVShboWklw9y5dccgkaGhrwwAMPYOPGjbjllltMz7/vfe8D8jS2aiY/WpkpICtWrMCqVauwbt26JIEUBRBKWnii3Lp160yC0OrVq9HW1mZ6bSo2btxoikNVoXAsVdDKBClH8kbd2dlp6WlIBY2PrPpW33HlypUm4bWTJ+VaxXETO3bsQKsSimal1JFbXC0dmY5Czjm9V1tbm0kBI4WNPA1EZ2cnVq5ciUWLFiUlWZ4IKERGtSyTx0oVepYuXZrkYaLXqgp0LuvJ6tpv2LDBdFj/5Cc/wYBF3hT496L1Tp9rVaYcBSrNTKGTlINB0FySUriCF0xQE3WtxlAosr1OqeYNklFCvobr16+3DC8pZhYvXpy0V65evTqnUN1CvEe2FGJus32PbMi1NHMuWBUFOF7XlVANY+r9DG742WiR39fJy00XGop2kBWA2267DW1tbcKgd7wgJU7+7Ez7wC233IKNGzeajGPEJZdcguXLl2OtRc7s+vXrJ7Qna4ofrcwUmDVr1qC9vR09PT1JcZ0rV67Epk2bksIVcoHyP+S40SVLlmDRokXqS5OwCgdSSddzJh0tPJ9Fjqe+/vrrLXMc0kEboJWnQVYc6DOWLVuGVatWpQ1nIkFbnouNGzcWzK1fyDlfs2aNUOjkw+3hhx/GqlWrTO9NY8/2vSeKGqu8du1a3HvvvZbufatrfv/996PBImfm/vvvN+UzrV69Ouv11NLSIqqAyZ/V1NSUpGClmqOmpiaxDlq4h0xeY8fDEtje3o6mpibT91huUe3K6jpSHHk2nq9cyfY6IcW80Xvce++9pmv48ssvpxViipFUe7FVeGwqCvEe2VKouc32Pd5N6KyQcyuP13UlvvGNb5iuh9X9vGLFCmzatCkpv2/ZsmWmYjeFYs2aNbj33ntNeTqUw3K8DWArVqzA2rVrTZ+daR8gY1Kqa0FVSNWc2bVr11rKDJpTh5JEIpFQH9Ro3i2WLl2KpqampENAUzhWr16NHTt2WCohmpMf8lBlm090qqOvl0ZTHJD3rD1N4RyNxgrtmdGcNKxfvx4DAwNpPUcazanE6tWrkzxD1OtDC+YajWay0NnZKULMNZpc0Z4ZzUkDhVVpj8HxRXtmigerOP9FixYJz2WqPCIr1NymUwXtmdFMBk70vW6V45iKbCuWpYP2ukK8l+bUQyszGo1Go9FoNBqNpijRYWYajUaj0Wg0Go2mKNHKjEaj0Wg0Go1GoylKtDKj0Wg0Go1Go9FoihKtzGg0Go1Go9FoNJqiRCszGo1Go9FoNBqNpijRyoxGo9FoNBqNRqMpSrQyo9FoNBqNRqPRaIoSrcxoNBqNRqPRaDSaokQrMxqNRqPRaDQajaYo0cqMRqPRaDQajUajKUq0MqPRaDQajUaj0WiKEq3MaDQajUaj0Wg0mqJEKzMajUaj0Wg0Go2mKNHKjEaj0Wg0Go1GoylKtDKj0Wg0Go1Go9FoihKtzGg0Go1Go9FoNJqiRCszGo1Go9FoNBqNpijRyoxGo9FoNBqNRqMpSrQyo9FoNBqNRqPRaIoSrcxoNBqNRqPRaDSaokQrMxqNRqPRaDQajaYo0cqMRqPRaDQajUajKUq0MqPRaDQajUaj0WiKEq3MaDQajUaj0Wg0mqJEKzMajUaj0Wg0Go2mKNHKjEaj0Wg0Go1GoylKtDKj0Wg0Go1Go9FoipKSRCKRUB/UaDQaTXHT2toKAGhoaMC2bdvUp4uSzs5OLFu2zPRYe3u76fdMXHPNNWhrawMAbNq0CS0tLepLNBqNRlNEaM+MRqPRaIoCUmSWL1+O9vb2nBWZU5H169ejtbUVra2tuO2229SnNRqNpujRyoxGo9FoTnrWr18vfl6yZInpOU0yS5cuRWtrK9auXas+pdFoNJMKrcxoNBqNRjPJ2LZtG9rb27Fq1Sr1KY1Go5lUaGVGo9Fo8uCaa64R4TudnZ2m3ylfhdiyZYt4fPXq1eLxzs5O8fg111wjHqfHli5danqNHCokv2drayu2bNki/l5FfQ/5O8iQNV/+J3tE1HHIv6f7/Eyon9mqXL/Vq1ebPAxr165FawHDptTrI/+TP0MO2VKv4erVq8Vz8jWT/4b+LV261PS3t912m+lv5d8J+e81Go1GY6CVGY1Go5kgy5Ytw1e+8hVTDocqsObDwMAArr/+epOFfd26dVi6dCl+8pOfoL29HYsWLQIArFy5Uvlrhvwe9957LwBg48aNJmGclJKBgQFs2rTJ9Nq1a9daKg0bN25M+ZnZQoI++Oe0t7cLpUVWCu644w6Th4Feu2bNGvFYIaCxy99j3bp14lqtWLECDQ0NAIAdO3aY/pZ+b2howIoVKwCu8K5du9aU47No0SIMDAykVErWrl2LdevWqQ9rNBqNJgVamdFoNJoJsmnTJlxyySUAT04HVyI6OzuVV+aGXInsfe97n3h88eLFePjhhwEAF154oXhc9ggQ8ntccsklQhjfuHGjeM03vvENgH93qu4lv3bDhg3itYQsoLe3t4vx5wIpDLICICsMJyrfo6WlBe3t7abKZqkUl6uuugrg80veqC1btmBgYAAAcMsttwB8Lqhq2te//nXx99dee6342Wq+SFGjfxqNRqNJj1ZmNBqN5jjR1dWlPvSus3jxYvHzli1bTIL4xo0bTeFM9Dj9X0jksDT5O6m/TyR8LVfkULFU4//sZz8rfn7ppZdM/4MrQQDw0EMPiceWLVsm3lNW0A4fPix+zoRWcDQajcYarcxoNBqNBrDwthxPATpbRS/b100ECrMjbxWNmTwzMi0tLSK0jzxWr7zyCiB55VTk8DX5X6HD5DQajeZURCszGo1GcwrR3d0tfp41a1bK54436menItvXTYSf/OQn4udNmzaZnrOCQsUo1IzCya677jrllYwToZBpNBrNqYpWZjQajeY4cyIE8mzp6ekBeJ5KS0uLKdelra1twnk+2SJ/bqpkeiivO1mgUDJI+UaLFi0yfVc5l+mBBx4QP+eLrmam0Wg01mhlRqPRaI4zLS0tlon3J9pif9ttt4n8jx/+8IficapcBgDXX3+9+Bm8IlchKrNZQfkjAwMDIhl+/fr14jueqAIAsuKxdetWQPkeVsiFHqAk9gPAmjVrRDjaxo0bLUtcWxUA0Gg0Gk1uaGVGo9FoTgBUUQySlZ2s+scTKgPc2toqSv7K1dfAvR/tStlg+tfW1iYqeBWaFStWiHwc6h1DCkx7e7vJA3I8WbNmjVBO6Hu8/PLLljkzhBpSZvVdH374YVOJa7qmVNLa6m8KBfUMkss8r1u3Tnt3NBrNpKMkkUgk1Ac1Go1Go9GkZv369ULxWr58Oe644w71JRqNRqM5AWhlRqPRaDQTZvXq1aYQukwUokKarFBkw7333luwHJylS5eKELNNmzaZetRoNBqN5sShlRmNRqPRaHJAVqIWLVokGphqNBqN5sSjlRmNRqPRaDQajUZTlOgCABqNRqPRaDQajaYo0cqMRqPRaDQajUajKUomrTKjS09qNBqNRqPRaDSTm0mrzGg0Go1Go9FoNJrJjVZmNBqNRqPRaDQaTVGilRmNRqPRaDQajUZTlGhlRqPRaDQajUaj0RQlWpnRaDQajUaj0Wg0RYlWZjQajUaj0Wg0Gk1RopUZjUaj0Wg0Go1GU5RoZUaj0Wg0Go1Go9EUJVqZ0Wg0Go1Go9FoNEWJVmY0Go1Go9FoNBpNUaKVGY1Go9FoNBqNRlOUaGVGo9FoNBqNRqPRFCXHRZlZvXo1Wltb0draimuuuUZ9OolsXn/bbbelfE6j0Wg0Go1Go9GcehRcmVm/fj127NiB9vZ2tLe3A1wRSUWm169fvx6tra1Yt26d9FcajUaj0Wg0Gs3kIPCP/wjf4sWIPvGE+pQmAwVXZh566CFcddVV4vdrr70WGzZsML1GJtPrV6xYgfb2dixfvlw8ptFoNBqNRqPRTBYSAwPs/6Eh9SlNBgquzPT09GDmzJni91mzZmGAT5AVub5eo9FoNBqNRqOZTCQGB9n/w8PqU5oMFFyZSaWIdHZ2qg8Bebxeo9FoNBqNRqOZNCQSwjMT18pMzhRcmWloaFAfAgC0tLSoDwF5vN6Kyy+/POmfRqPRaDQajWZyEfyXf0HgppuQOHJEfapoSYyMGD9rZSZnCq7MNDU14fDhw+L3rq6ulAoL8ni9Fc8880zSP41Go9FoNBrN5CL63HOI7dyJ+LFj6lNFC3llMAFl5vIfPYdFtz6JzkG/+tSkp+DKjJrAryb433bbbWhtbRW/Z3q9RqPRaDQajUYDvx+IRoEJCP0nI5QvgwmMKxyNAwBC0Zj61KSn4MrMihUrsHjxYtE3BgDWrFmjvkyQ6fVUmnnjxo1oa2tDa2srtmzZIr2DRqPRaDQajWayI1f6kkOzip1CeGaEMhNh/59KlCQSiYT64GSgtbVV9K3RaDQajUajOZUI33UXYLfDdeON6lNFS/ytt+BfuRIA4Lr55kkztsjvfofQz34mfq/YscP0fDa8Z+1TCEfj+N8bL8Li2XXq05OagntmNBqNRqPRaDTvHoneXoTvvhvhO+8EIhH16aIlPkk9M3Glsm8ij3ygU9kzo5UZjUaj0Wg0mkmEKRxLyscodgqRW3Iyos5RrmOLxowgK50zo9FoNBqNRqMpaiZtbok8rhwF/pOZiSoz4ZjhjdGeGY1Go9FoNJpTBZ8PsR07EN+zR32mqEl4vZY/FzsmZWZ01PRcMUMFAGynncZ+z1WZ4SFm0J4ZjUaj0Wg0mlOH2NtvI3DzzQh++9vqU0XNqRCOpXozipk4H4tt3jwgD2+aSZnRnhmNRqPRaDSaUwMS9HMVHk92Jmui/GQNM8PYGADA1tIC5DE2U5iZpNicKmhlRqPRaDQazSmJUGZyFB5PdmQFZjIpM+TBAMCaZ46Py08XJYneXgBASWMjSmpr2WM5rseIDjPTaDQajUajOfUwCY3cOj4ZmLQFABQhfzKMjfJlSurr81ZmdAEAjUaj0Wg0mjRE7rsPvsWLEfzud9Wnipp0ifIb23pwwz3bcf/2LtPjxYAsDE8GgV/g8wEAbKefDljMWTFC3iZZmYnnOGfaM6PRaDQajUaTBhKIc7UYn+yky8E4OhLAjo4hHOxnAnQxkW5cxYoIx5oyBSU1NewxaZzFiqhkJntmchyXnCejc2Y0Go1Go9FoFIQyMwks4TJx2YOhjC3O+xDKVu9iwVT1K0cr/8kKCfgl9fWGMjMJxkZzZRpXjgqoHGYWjGjPjEaj0Wg0Go0JocxMAuFRJl2ifCLBtJkoaTXFwvg4S47nqOMqVoQyU1eXd27JyYhJmamuZg/6fABff9kgK9xymeZTBa3MaDQajUZTICK/+x0CN92E6LPPqk8VNZPVM5MutyTGlZiIZPUuBmhMJQ0N7PdJ0o9F5JbIyswkUNRkZQYlJSipq2OP8/CzbJAVGO2Z0Wg0Go1GkzextjbEdu5EfP9+9ami5Cv37cSiW5/EaC8XrHK0GJ/UJBKA1EVeFYxpmEWnzPBxlDQ2Ah4Pe5Anzhcz5JmxSeFYcphgsRKXqpkByMvrFI4ZCoz2zGg0Go1Go8kb8lyognGxQoKRwycJ/TkmJ5+sqONQ54w8M9FYcSlvIhyrtjbvHIyTEeHBqK2dlJ4ZG/ek5aXMaM+MRqPRaDSaQiCUmUkSjhXhgnypN3U4VrGiCovquOLcNVNsnpm4rMxMJqHfqgBADgL/yUqivx8AUDJtGvs/j7HJyoz2zGg0Go1GcwLw/83fwLd4MWKvvKI+VdRMOmUmGkd5JGh6bLKMTRXw1d9JmYkWmTJDQrCtrm5yVf2yUtJyEPhPSsbGWLEGjwdwOADZM5PDnMkKt/bMaDQajUZzApi0CeU8/j0XQeRkJhyLozriNz02WeaM5sg2bx77XcqfgVyaudjCzChnZrIlypMy09BgKGnKnBUboqgBDzGDlDujhkGmQ3tmNBqNRqM5wZAQMlkEYwCA3xD6J8u4ItE4qiMB02OTZWzCgzFnDvtd9dSI0szFJRyK3JKaGkPonwRzZhVmJhdwKEZEvgxXYCCFmUX+8hfE9+wRj6fD1Gcmqj0zGo1Go9EcXxIJ1gvDQoAsZmSBcbKMKxyLozZkroRV9KE9nCRlRrGEG6WZi8wzY1EAgPJoipZEwvA48TEJRS2HEsYnG/TdyRsDAM6PfAT2889H4tgx+G+8EbHt26W/sMbkmYkUl/JdCLQyo9FoNCcxvsWL4Vu8eNIIx1AE/WIPE5ExWb8DgUlRwjgcnfxhZiV1dUBFBXtQKmFshJkVl3AoxiV7MIp8zoS3qa4OKCkxfi5yw4EcOicoL4f717+G48MfBoJBBH/wA+O5FJiqmekwM41Go9GcNMi9IYpcGJExeTAm07jUMKVJ0KwwEoujisLMyssBi3EWK6K5ZIqqX8VazcwyUb7I58ykzHBKqqvZc0U8NlPDTIWyb30LkOYzHfIaDekwM81k5PCQH7/c3I5HX+9Wn9JoNCcxstdiMnkwTI0KJ5Myo4ylmIUsIhKNoybMPDOpckuKFZMyYyEYG9XMisvDJkKXpk6FjcLMinzOxFzJygz/OfLoo4i9/DIQConnigVqmCnnzAi48SCbhqdyKOS7sV4TXV0Ife97CN1+u/rUCUErM6cA+4/58Kvn9uOBV7rUpzSaSUFiZAThu+5C5A9/UJ8qahJjY8bPk0noT9N1vZhR50j9vRgJx+KoDrP8JtusWcAkGRektVeSooRxXOTMFJFnhu4tHjZnNa5iJJ1nJvrEEwjccguC//Vf4rliIZ1nBjB6zySOHVOfMhFRQssCGcozR599FsFbb0X0iSfUp/IiumMHIo88gsj996tPnRC0MnMKQC5Hfzj94tZoipVETw/Cd9+N0N13q08VNZNW6JfGMlkEY1iMZTLMWSRmVDMTnplJMmcmz4yF0E85M++GpTtfZAUNfGzy48WKVW6J83OfQ+nXvsZyS4p0jFbjkrFal1bI1cwAIJShCEDkoYcQ3bgR4YceUp/Ki/jBg+Ln2BtvmJ47EWhl5hSAGij5w1H1KY1mUiCE/rGxSZF0TUza3JJTJcxsEowtHI2jljwzM2cCWQhWxYJlCWOLMLNi8syIviWU+F9Vxf7nazExMID4oUPi9cWCGBdXzgDANns2nJ/9LFx/+7eANJ/FRKK/H1A8TjJCGc2QN6P2lsmUN0NrIP7mmwWpBqeVGc1xhzT0gPbMnPIkhocR27ED8QMH1KeKmoQcUyyFZhU78rjkkLNix5T/M4lygYRVvLmZ/T4JxhZPAFW8mplt9mz24CQYlyiowUOVLHNmijDMjIRemyT0k0Ac/PrXMb58eValfk82RD8WC6FfCPzFVjI8kcjsmclWmcnFM+P3I9HXJ36NPv+86el8kBVkrcxojgsUO6k9M5rYli0I3HwzQj/5ifpUUWPyYEwSqzFOkXFhEo2NlBeRW1Lk4wpygaiGKzMldXVC+C/2sdEaJOFYCI3S2hRhZvRDESAUaosmjCS0FuPciZBAi9ySkqlTgeM0ruC3v43xZcsQ3bhRfWrCWJWbVsm2/HQunhnVMxd97jnT7zkzPi48TAAQe+st09MnAq3MnALQoqaDSXPqQgf1ZLAYy5wSVb8yHGbFRNIcTYJwLEhzZGtpYb8X+bjI2lvPm2aW1NVZejCKEWoimdSA0aTMFKFnRsoDImhstnPOYa/JYOU/GbEqAGCiooJVM/ObeyJNlOjzzyMxMoLopk3qU3kR/ctfELjpJoR/+9uMyf+QlO1Mc6YWAEjnmSFlxnHppQDAPHW8iXE+0PvZzjiD5dWp+/sJQCszpwDyotZFAE5tJqsyI5euLHYBUmayKmnqHE2WsQlrPykzRS7wR6JxlEeCAAC/swyAdThWMSI8GFzoF8rM8DCimzcj/tZbQpkppjQ8uccM4fjIR1D+6KNGbkmxhWPJ40oh+B+PULPE4CBrfkterQIoStFXX0Vs505En3kmK2WGxhXPMC4yPLhddtPvVgjl46yzYL/4YmCC3pl4RwcAwDZ3LuzveY/69AlBKzOnAFQAADrULGvCP/85fIsXI/zLX6pPFTUkNKrCZLEzaYX+U6A0M7IYW89IEK8eGsKRYd688SRFKDOTpIRxJBZHDU/+H3NXAik8GMWIUGYozIyPK/bOOwh+85vwr1yJ0/buFK8PFUlXdSvPjPOaa1AyfbrIozkeimjsjTcQ27FDfbhgCMF/yhT1KUCax0KOLd7Zafo9umWL6fd8EIn3e/YgfvQogNT5MpDHlcEzQ2FmVWVOAEAoTWnmGCkzc+bA+aEPAQCCP/4xEt359SKM8eR/25w5sJ9/vvr0CUErM6cAJmUmlHqBawyEB6PID2wVMZ7JVvVLVmYm0ZzJY5lU46LckrPOYr9nGNsjrx3GynXb8fu/MgvgSQv3ENqoAECGcZ3shKNxkS/jK2MN/GQPRjEjhH4KM+MeJwSZJwoAPOPG/EXTWLpPJqyaSxLHbe6CQQRuvBGBm28+LsUFhIJCldksEIpaBqE/F8jjQESfecb0ez7IxXeiL70EIEXDTI6YswzjImWmoswBZFC+qfKYbfZsOD7+ceZNGR1F4B//MS/vk/DMzJ4N+/nni944JxKtzJwCyLkymRopaRhkES92YUTFNB7twTjpMY2rgBbHd5tcPRh0MPuCEfWpkwY5vKeEC13FPmesYSYTbsZcHkAW+kdHEd+/v/CC8QlCeGZImZE8GShjIXUev3H/yR3WT2aswsyIbEOWciV++LD4OVKgJowyopJZOqH/OISZkWfG+dnPAgUINUv09pqU5Rj39GQTZpZRmeHKdiX3zMhGbBOhEBJHjgBc+QAA949+hJKZMxHv6EDwO99R/iAzpBzZ585FSUMDyh9/XH3JcScvZaazsxOtra3i35YMrrdMr1+9erV47pprrjE9d9ttt5n+1uo1mvTIVS38ocKGmQX+4R/gW7wY0aefVp8qahI8GW4ylcMFJnE41ikwLgSDQOTkFeZzgt9Xom9JlsrMWLCw+1chEcJxdbW5t0cRe0DDUUOZ8ZaaO8pHd+6E//rrMX755UI4KibUnBkAKN+wAaVr1sB1440AAHfASIqOxlNbuk8mrMLMBJUsVLDQBTfi0vxHn3vOJLDnS7yjA7EdO5AYHExbyYwQQn8BDQikzDguuECET4XuuosVGsgDuReLTNpx8ecyjYsKAFRxz4xa3YwgxdM2d67xYFUVPD//OQAgum2b8XiW0P1fwo1T7wZ5KTPXX3891q5di/b2dtx7771YuXKl+hIT6V6/fv167NixA+3t7Whvbwe4AiOzaNEi8Xx7ezsefvhh0/Oa9MjuxpTaep6IHIwTIEB2Dvrx6qEh9I/lt5HkwqTNLZmsYUuT1TOTY25JUUBjqKzMOpk8zA0yYyezZ4bGRX1LJkFuSSQWR02ECfSj5Jmh3JKtW8XrMs3fyYjwYFBzSbD+QM5PfQo2XurX5JmJTlwpTRw9Cv+nP43xyy/PWyDORCbBn/IzCjln8a4u4xe/H9EXXpCfzovQD36AwM03I7Jhg5EvY6WgcYTXKYMHIxdE+FRLC5xXXQUAiKxfj/GrrsorYV54MJYuNT2eaq4AAKWlgNvNFERejMAKI8wsvWeGwtyoSAlR0tzMykOHQkAOint83z5AVY7eBXJWZrZs2YKBgQGsWLECAHDJJZegoaEB69evV18KZPH6hx56CFfxRQIA1157LTZs2CB+nyy82rMXWw+/jWA0rD513JGbZfoK7JmhGHFV6Doe/OyZvVi5bjueautRnyo4kzbMTPZgTCavk1zN7ASsxRMG5WDwg2IyrEean5Lq6qwFfiPMrMD7VwERoXNqqd/hYcT37p1Q6dN3i0g0juoIE6BGFGVGppChPSeKdB4MeswTMPaVQnhm4gcPIn7oEKuYVgCBX0UNnbPieIRjJcjaP38+UKBQMxK64/v2ZaxkBnlcBVTShMehpQWOj30M7rvvhm3ePCQGBhBJIfOmQ5REvuwywMPuJ0gKZipEEYDhYRENE1GM+iLMzJ3BMyMl/ydB4bEZ9mMZ8X7Fpsx0dXWhQbnwTU1NOCzFTMpken1PTw9m8lADAJg1axYGBgakVwNtbW1FH2J2/cP/iU88cCs6vMfUp447clULWbEpBNSh/EQIkH2jzJI1fiIqspEycwLGdUKRLDu5bFgnO/IBNmnmjM9PSW2t4cGYBHNGYyipqjLGlWHO6GA+mT0zIgdN8cxEN22Cf8UK+C6/XH51URCWqpmNOJWcGYlCCpAninSCPz1WHpBzZqyFw1yQw7EKIfCr5OLByJSDkQvkmXH93d8BAGIvvYTwnXcifNddiL3yivLqLPB6xfeL7d2b3biyTJTPFjlJnrCfdx7K/uM/AEn2yYUYeUXmzYN94ULxeLpcIChzFt+9m/3Mrwkxzg3VlaVMmQnmocyUUBhiDoZO8X7SdXo3yFmZSaW0dKco6Zbp9ariQnTyWMU1a9aYQsza2tqSwtCKgZEgW/gjwewXSaEwl2YusDJzAj0YA2MsDnf8BFRkE4fz+HhRx7zLJJR77UTM2QlBOVSKUbCygu6tkurqya/MZJgzyvs7mXNmKKmakv9pbOE//IG9IBwuSC7BiSQaS6CS95kZ5sqMbepU2GbPRkldnQi9yTR/uZIYHkb0ySePay6m8MzwkDIZa8/MxM8BWZmJbd0qvkNiZKQgeUfpvE3E8fDMkDJjP/98kVsSvucehO++G9EXX1RenRkq9Qswr0+8h0VjpPXMSN4LABi/8kr4Fi9GvK1NeWV2yCFmMiUVLHcskUchAHpP+9y5sPNKjnC5jFymFNDYYu3t4l5TlRnC7eKemVRhZly2TqfMUM5wNsg9Zt5NclZmZC+KTDMvRamS6fWq14ZoURYQsWrVKryiaPqXX3550r+TCX80hATYRjgSzH6RFAo5Z6agfWbicSPuNwdNPl96vaTMFHAMVgSDJgVmMgiQQLL1W/29WBEWMu62nzTjonuqstKwOk6CsQklrabGpKQluroQefBBxN9+W/kLo/HvaBF4ZkR1LLL4F3FFulA0hlrumRl2uAGw2HrPgw+i/OmnUUIFHAo8rugLLyD47W8j+G//NqHqUSkJBNjZVc7KTavQ3FXKnpkUlu5cEFW/eLW06FNPIfLggxi/+mrEdu0yvzgPhLfJoiwzUfBwrECAGcpcLpRMnQrXl74E1xe/CMcHPgDkKBgTcvliAMK7k86DYVJmxsdZ5TAA8RRCfyZIQVM9DiV8zeQapp3o6wN8PvY9q6pgO/NMAJlDzACj7HRMSs5XjZOEy8HE+lSVa8W4ZsxQn8prbMKDZaEcnUhyVmaswsDUUDGZTK9XQ9SswtIy8cwzzyT9O5kYDRmbMXloTiSyZ6aQYWaykH+8Bf6xYFRYxgpdkU0lyX18nMd2olAFYfX3YoXGITbnyTIuyYNBlruCCSDvIpaeGa8XkY0bEbrtNgR/8APlL4wws0SisHtYIRHjojAsi54YxTZ/0VgC1bzPzJAjWfAXSnaBx0U5GAiFEN28WX16wtD37bO58cArUvI6UVYGlJbCGYvCzfNcC+mZcV1/PQAgdPvtCN12GzA2lpfQD8kDQZW/ICksVpjmbHQUvsWL4Vu8WH1Z1tCYqMy6/T3vgetLX4LjyivZC3IQjAlVmREep3RKGhU2GB42VQ1LJfRnIpVnhsJIcx2XmlviuOgiuO+8E+4sIo1oPqOSIT8ujYtyoctLHShz2oEUOTOJ4WHmIa6sBLiHSUZ4nbIdWyxm6jHzbpKzMqMm8KsJ/lu2bDGVX870ejXhXy0IIOfIdHZ2Yt26dbj22mvFY8XAaMjYpIbf9TCzAioCctJ1tos/TwakCmbHO2dGVWYmjdCvKGXq78WKsPRXVRnW8EkwNtO4JlOYGXkwqqqMJNhgUCREW41RzlfIJ9RsY1sPfrm5HQf7j58xSVjFKWfmBOSWJA4fRmTDhuPWeT0UjYmcmX4788zIHC9lJi6FrUceewwAEPrP/0Tk979PCivNBxKO+2xl2NtrfXaRAFkdGYcnEoTt4MEJhwkmqG/J5z/Pwotk8lFmfD7DA8ELCyCTMiPnX0hVyOh9ckVY+hWDtrDy5zEuUfVryRLT4+nCzAAwAT0UMnm5UoVjZSKlMgMjCiCX9ZDkwfB4YF+8GDYpdyYVQomTZS5JmaH90WW3oZR7ZqyqmSX4fUVNfZMgo1mW91j88GEgHkfJjBmAk1VRe7fIWZkBgPvvvx9r165Fa2srVq5ciXvvvVd9iYl0r1+xYgUWL14sEvzB82Rk6Llly5Zh1apVQhEqFrySMjMi/XyioBANAPAXMN/kRJbD7eP5MjgROTOKYna8x3bCIMsxueOPswJ6oqCNt6SmRljNJsPYLJW00VFEH38cwW9/G7E8YtFPBoQHg8KxuEU1vnev6XkZ+WDOpwjAhp3d+NVz+/FmV2GFbhmhpNG4SKCsqGDVi1KMbSKE//AHhP7jPxD66U/VpwpCOBpHnQgzY6FRMhT+UvAmjHJuyc6dCK5Zg8if/4zQT3+K2P79ptfmAyWJjzg9KdcTzWNt2I+zRg5jztduwvgEZA8SJEumTUNJTQ0c738/7O99r/Bg5CX0Sx6M+IEDRtWvdB4MUkCHh0X+BDABoZ8rMxRySAhlJkvBWCbGy/06ly83PZ5OSYP0vKzc5z0urnyUWCgzJXmENAtlJo/cEqtxy8oneWFcDhtKnUyst/LMCC+aRYgZYHhmVBkoFULhe5dDzJCvMtPS0mJKyr/kkkvEc5dccknSY+leDwB33HFHyh4yDz/8sOlvVUWnGHi3w8zk2EkrbT1f5E0ql5ta5qv3vY7vPbYro7VV9swEjrdnRlVm8hzbyYYQtvhGVmjB6t1CWMQrKiZN53XI46quNo0rsmkTok8+icizzyp/URyYPDOScCWwEOrkgznTXmEFFRDwBqwF10IgxsUVasfFF6Ps3/8dZd/+NkoaG9lrCrwuKTE6vmcPE2YPH4bvssvg52FME6VklO0RQy4m5KgCkuqZie/Zg8gjjyA+QYWDckvsF18M8IpwgjyEYxX6vsOl5SnLfQvPTHgczQGeqJ+nYAxZkORCf+maNXD/7Gewn346oJyn2ULVscAFS7FnWAi/hDBmjYwYOTzIvwqYaMKoNEwUyeQ5jisxPMyE6bIyOC691HiiooL1XEkDjS36+uvisbzmzOtluVoVFcn7kyT05zK2dFXEMmGaz4oKI0SMyyqUz+V02FDqYGFmQalZOkEez5Lp09WngDzmbCJjKjR5KTOa3Hg3w8zUw6eQIVomoT8UYrGYOfDW4RE8s6sX92/vMikrVsiNMlMdPoVi0ioz/KATh84kGZewIslNGMfGjA7SecZMv9tYeWYSIyOI8YO60ILxicKUCyQJ/zLqnFEPBQDwhXJXSELROFp8/QgNMMEmvncvgt/4BiK/+5360rwRgiSNq74ejo9+FI4PfShJ6C8UsjD6wL/9Ci9/93bA50N8//6CfFYJnyvqMaPmjajjim7bhtD3vofwr35lel1OeL1Moa2shOuznzUe50nziTSNA7OFvu+Iqzxl7zXDMzOOpgC/llkKeb/Y3I5/+sNO07mlWsWFB48EYwslPhMmz8zBg9l5ZqRqZrJnJt9E+USKMDMRipVjAQfR1HHePLanc8E7nYJGkKdQDjPOZ1wk9KfyYIjqY1muB8hlmfMQ/OX5tJ9+Omzkze7vB6T90WWXPDNSRA4hxpUizCxXJU2EA+YxpkKjlZkTgOyZ8Z7gamZqrfHjFWYG5C70v7C3T/ycKZenXw4zy/DaiTLRcZ2siER5qkA0WTwzFGZWWWl4MLxehL73PQRuvjmvTs0nBaTMSB6n2O7dwnNRCGE1E9Hnn0fwX/8V0Y0b1afyRvVg0NgAqSKdMjY5VDYfY8Y/Pn4H7t/6MyzY/GcAQOTPf0b02WcR/tOf1JfmDSlgJVOmqE8lCf2R9esRuOmmCV9XysEAgPfvexmL3nrJeDJLgSQdjjG2R3h5WeakXiukiPI5TZCnKA8BkhBCf3Mz7BddhLLbb0fp178uQo7U/Tkr/H4j0d3rFbklXqcn5Xoi4bkmPI7p3DMDaYzp+MPLndi8+xiOjhiKFyme5BkXUEW1POZL9oAlhoaEcpJO8BcGn+Fhc85MnkYf1eNECA9QjuOiMZHQbz/tNPZ7pnwZ6T6TyWdc8aNHAQC2VB6MHBXQxOAg288rKzPn/VggKzO2004Tobl7dnXgUP+4OcxMeGaSlZlMOTM5KzPaM3Nq8W6GmckNM5GmXF9eKAs+V6H/hT2yMpP+e1HDTJyAnBn1Rs51XCcrScpMgePc3y1SejDeeUf8fLyJ3H8/gmvXFjQRW1j6pRLGsvfzRCij0aeeYuVjn3pKfSpvUnlmSpqajJAbClvatw+xHTtQ6jcE2HzCzOrGmHC9cOeLgM+HCFcishVGMkJ7RoZSvzSu2OuvI7ZzJ2I8TygfhPJUU4Pg9JmoipqTkceHJr4+HKpnJpZc0UuMbXBQCIF5hfZwRNgSF/odl10G5/XXG9c2jzmTc3DiXV2Icw+G11WeMWemOuxHs98IwcpmbBT20zdqzAlVaFOt/SL/IksBUoZySwhRAMBCqPeHY3ipfQA/e5Wdu4nBQZGnBuQZZhYOs3XodFr260FJCYvaiCcL1qkQ1v558wAAtvnzgRRjUpGVOPq7fAobCMUzlTKTYwlj4W3KI18GMJdvti9YIBSi/314O36+eR8i/L4sdRgFAMJpwsxSKTPC45TtuEjxzHNchUQrMyeAUZ5AiXchzExVZgpZ1ljdfHMR+vtGQ6YqMpl6x8hhaJm8OBOGj4tKDeYyrpMZIRzX1hoxt+PjRnMxi/4ehSb0wx8icNNNBf0socxIuSWxN98UlWZOhNAfefxxRB9/HLFXX1WfyhuTx8nC2n88lLRf/uAP+M0//gB9XUwAiFJfgyxCe3yhKG64Zztu+k2Ga0D3E1dibAsWoKSxEY5LL00S+oP/9m8I3HwzTj9mhNOkEj7TMc3HBFBPyI/At79tHNYFurdlxdMKdVxxLmDlJUByyENQMmsW+t9/BQAgUOpGZxXLzwmMTPyssfvYewynyJmBJEAmvF7WS2OC4xJWcVXon0izQqk6WryrS+wJw67ylGcPjas24sd0SZnJxutERsNjvDcaZEEyVW5JFveYTGJggK3j8nKjDDJHXYf/vuFtXPTvT+Pm376Ke148iGCFRdnwPOYsU/d3YYTJUjiGpMyQMuL81KfgvvNOuG65RXllMiYPRmtrUm5JttC9pa5BImcPhtQsM2/4OrGdcYY4D2rDPowGIiInkBUA4J4ZNcwsFhOKXUolLYdxJXp6gGiUfRcKKXwX0crMCUAOLTvRTTNVT0wmD0guJB0qOWwYz+85Zvo9k4Iih5klEnxcPh8i999vaiRVCIQQSR6MAgk8ueC7+GL4Fi/Oy6qUCjnxmoT+eHe3+IzjIRyrRB57DLGdO0XiciEQgmRFhTg8hRB+Isbl9yO+Zw+AAlr65XVHYVg8Z0Ag3W+BW25B4KabJlyS+tMP3YFPvfQnRB59FPE33xSKfTaH23goih0dQ9i2fyA5HElCFfydn/40yv/yF5R+/etGCAx/TYLHhFdJzQvHckziV++hGG8bIKDGvxMgnUUc0uNiXCT0ZyEYp0KE90yfjsMXL8OXL7gBv/vcGngrmUAXGs1+P06Fc5SHY7lYWeaohYVdnjOhNIRCeXlQIFvFFeux8GDkcM4Qom8NKTPCM+NJ6emjOWv2D5m8XrkI/X1yzgzllijKjAitzHFccjiWHOZjlS+zs9PshQ+6k3uM5BWOxddgSVOT+hQjRw8GAMT4XkpjKmloYCWMUyhMMibPzNy54lrIPVmyQXgHU3kwSEnKYl8EJM9MFmNIRcVzz6Fixw7Y5s4VIXcNoTGMBaPCM+OUSjOTgkMkuJGgZNo0wM4UHhWhWGcxX2rfnHcbrcxIHBkbwNbDb+PQSOEESAAYCxtC/0BgYsJGroSjcZw93Il7Xvtf/OM7TxS04Zwq5OdiAZfzZZCFkiUnUoLn/sQPHEDo9tsR+OY3Tc9NFLqRaSNLeL2AzwffpZcWrEpQOhJdXYZXQVUYJ4AI75E9GK+9lvT88SLe0SEs/AUdF3lmpJwZUz1+Wqc+H8J33cV6VRSQ2FtviZ8LqsxI82X6v6bG1CAOwSBiL7/MlEQu/OfF2BjccaYouJ94DNG//lU8lc18yZbAQV+KYiDZhmPxsZPgWBcy5nMshSU9FeQF2VU9A14eLgVIQmQWY8uEmKsUuQqpxpWLYKwiLP3Tp2Pc5cbO+rkYaZqFSClTPILezAKJSqK/n90jf/wjAMA5zq77iIvNVyiNZybe1WVSDPMdm4jrVxPKSYDM0YMBSegGgHhnp1Aqh/m4rBQaGtfCEeNvgcwKqPxevV6+3/X1AeEwu2+VilyiHG6O65AEZPv8+SIkC7DuxXJkiL33Vz+8AAAw7jE8M7ZFiwBk53FSIQE5aa44uVj6Aa5QBYOA282E7hwxKTNz5ohE+UxzpkLGtlTKjBD6s9zvheAvzdNEoP2/LuSDNxBBmBut5Wpmcp4h5P0ixZiQ43ydTPky0MqMmXte/ws+8cCt+MVrRhPPQiD3mQEAXyT7RksTJRiJ4wxvN87sP4hzhjsRiCRv2nlDHgwq9ZvCg/GLze244Z7t2LbfsI68cpBtLh8/l91Y6QoTBMIx+MMxlDltmN3ADp/xUBQxfjPleghkQigz3NqUGB1lgvj4OKsSlKOVJ1di7e3GL1lsKtkiPDNSDkZs586k5+H1IrZjx4TLq6rEd+82finknMnKjFVlLArt6e5G+O67J96TIxRC6Ic/RPBrX2OKhFQGNB9BKxVCSePWRRKI7eefb1jDvV7TepxIHlSgyxDaXH09CP/hD8aTWcyXXDJ9aNxamcnFg5E4ZnhvqdcJ8igAQMLxYU8dnp71HoCX/BVx6FkKJOnIOC4eFpIYGRECIJC/wA9IYWbTpwvBxeWwIVbGlJlIHspMbNcudo/8z/8AAMp8PGfGyfZdK48bjdl0f+cpHENSPFShayK5JSZl5vBhwzPDCxtYrSm6x0jBJzLt/3IoHuXMpPI2QR5XFtZwGTonbPPnmz0zyhoc8UcQisZRWeZATTlr1DkmeWbs554L5LkWM3kwcu01I7xNeQr98tjtc+YYRQgyzJmJWMzwYmQaV5ZzRr2RJuKZkSGFdUpoDKP+sGU1M9UzI7xoKcYEGAaDbMaVKcTwRKOVGYlOLzs8feHCCSRQCgDgBBcBCEZiInnRE4skx1FOACH08/jLxOgoYm+8gfFlyxCUvCW7ur3Y0TGEzkF2Hfb3+RCMxDGnoRwzatnBmy7MbMDHrH0NlWUoL3UAvKKZXFbyuAiRFC/r9YqYV/BxggsTsR07hLBUKEwVarIQIrOGrlFZmfBgRGXPDBf6oy+/jMDNNyP4X/8lnisEMUnYydailQ1i45XC52RUaziQW0ikSrynB5EHHkD0hRcQffppkzKT7aGdFX6/KbSMrIH2c881hfbIVsdcLZAyfkmZAcz3VDbjkntYjfhTKDOZckvkcUleJpNnJscwsygXuI65a/Dj+Veg/NUdcP/0p4YQWYC1mGlcAPcEhcMiJwDIUchSkMvHkuBS5rQh5mGCVnQs85ypCEUrHAa8XpSOs/tkmHu0KLFdhqzhVHCDyHctUgieGrokrOF57IkmZaajQyjnPie7v8Ysyn2rXrbxWm7lzyD0y0LkMV64JqW3Cfl1kwek0KX585mAyvcKNcyMKqo11bjhcbHzc5R7pMBL/aK0lCn1OYZcZiphnK8Hw87zZXKlZMoUpghVV6OkpcUwImSYM5nEsWOsq326cKwcqpklRkZYbl5ZWV7eJitoXHUhH0aDUeExZdXMuDKTyjOTIl8GkCpLZrHfkzFZh5mdhHSNsk10PJzbppIJOcwMALxBH/r8IzgwbFjojhfBSAwzx9mhUs7jflPV1c8VocxInhly4cfeeEO8jhQVb4AJOF4/Ozhqy13wkHKS5jtRJbOplaVw8+S28VDUrGBksalkDY2LxzYnRkbMn8WF4/Cf/oTAzTcj/H//J54rBHHJM1OocYnKR9waLTwYkjdNCP3cypzLAZCKxMCAuHaxXbuMxws0LsAQmkpqa03KjLDKWSgzE/FgyJb18P33IyYVM8hH0LKCvqs8Hvedd8Lz4INwfuxj5jwFWZmZwJxFj7DDbmPT2eIx+/vex37IQtCSDSXDimfmja5h3HDPdjyyuQ2wEBQJ2TMjx7nXho3DNdf9K3qUeTCOutlnUuPMXASSTGSjzNBzSRWo8szpEonyTU3CG1DqsAMeZiCKZyGQqMh9a+Ld3XCPs/2BPBixeALBSByvHhpC2xFzGGRcVWbyWIskzKrd5AGgxM3GlY3V2IRkaQeMHKl+F6/cBGDcyjOjzOVACysRnGlcsmemnzwzUn6TJXkkqtM5IUoXcwu5em/1cGVmeo0b5aXs/PSWGsqMraUlPw+GtF5SeWaEopblWhQKWp6hSyV1dfD88Y+o2LyZ/c49GLnkzGScK+TowZD75hQIG5+v+hA3NvD9lnlmeJiZYngQCnUKxRMAYLMxpTiRyOixjvN9LN+5KjRamZHoGDk+nhkqANBSzarMjIR8+NPuF3DBvf8Pf/fYD8XrXuvdh62H30Ygam3VzIdQNIaZfibsuGPsfQuVNyMS5SXPDCVayla5lX+5E9s2fhvTX2IbzCgXJqo9Tnhc7MZLlzNDyf9TKkvh4ZuxPxQzKRiZbrxckKtIgR+gJoGVhGNK5p2AYGwFuaSB7MJ7skGEmCn5FzKFVmZi27ZhfPly+D//eWBszFQGtGCeNBKy+aFpCjO44AL2A59PeTxUmjUf4lL4U3zfPnOz2ALNlwidUzxNttmzmdVRysEweWYmMK4YD1vaU92MfZdfA/v558N55ZVZJ7vK+4qqzBweCmBHxxD6DvNqOimEftO4JM9MrRRmRvtHtsS7mSDb42bvTcpMvk39wPe32I4dQvgWykwKJQ3Sc7KxAhOYMzkURg4zK6lgQnosjz3R5MHo7oabl8SWc2a6hsaxct12rP4/VoY8aS5dLJQpH89MWg9Gnjkz8nWikCoAGJEEequcGQDwlhrhWL0zmbcgk2AsC5GhaBzeQMSwiluNC7kr1onDh1klqbo6USBElDBWcma6hw3PjNvJjIfDXDkFF25FDl6Oa1Fc25YW9SmAztAcxhWjSmYFEvxFzkwO4yIjQVI/IAmR55TFuI5Lbgk/v6kwBeUUOx02OGwlsJUkh4Rm45mBvBbT7PeJwUF2H1ZXp93zTiRameEEo2FRNln1pEyUUf5+s6uZi3Ek6MMhLzvUhwKGZfzzf/4+PvHArdg9IAnpEyQcimIa715cHmULPp3ikAtJifKjoybLHgkJ5QF2U9ioURn30FSVOeHmbu90JaOpLLMcZuYPhE3hXYWyiIOPA/ymFrklcpK3qszkcWinJBBAQhIosj0EMiGELX640P8yqjIDvz8ri3wqKPEawSBCd9xh7pGSZqPMBTn5H5AEHgD2M84whOPBQbMHI4NAkg6TlZdDHoyCjUtag1YIz8zwsGn95ZunAADg89XrrsErV1wH969/Dcfll2cdjiWHmQ0rYWbkeXXRfKkCMEfM1/CwCDcCgLqwD1VuJ5CHZwY9pMxwzwz/brnG88tEn3wSgZtvRui//xuQ768U44I0Z1Stichn/xBCJBdMjDAzO2zlXFDlyfu5oCozFdwQN8QF/0gsjiA/PwbHw0gkkhU4+3nnAXmOK51VPN/5kps6lkiVxEYkgT5Vue/RUuM13bN5D6QMgrHaDuHYaDCjByPXsYkcDEnoL1u7FhU7dsB1ww3SK40ws+k1bmEMHLTzkDRepp+qY+Wyf9A5lS50Ktc8J2HtL5Ayk4/HicZltQaJbAR+QpSaLqQyA6CnjO0nTf5hISO5eIiZVXlmUmbS5sxAUkDTjE2EAxZ4TBNBKzOc/cOGYFxozwzlyMyoYlaCkeA4OnnFtGEpf+bYOBMiB/yFqyplO9YDO4xGZ2WxcNr8lJwgZYYS5cfGTMoMCWTlvACCY5Qd+GQZrXI7hds7nYJF5S2nVpWinCs/iSNdpkZcudboT0s4zKyLZWWGB0O2vlPODBf+4xP0zEQ3bsT4xz+OwFe/KlzSRKHGJSf/y/9D3vBVZQaZD+50yJ2yIw8/zH7glXwKpXyKcUnKGY3NdsYZwoKVGB0tWJgZVbpxffGL4jEHKTOFGhcllKewegmhf3TUXABgAvNlO8aVmbIaU9inEEgyjM2kzCieGVJAXNzSn0roF0ra6KipMltFNIRpZSVAimTtdNj6mCftSDkT2ESYGQmQGcZlBQnItBZoD7ClmC9IcymXCUaec6Z2KJdj5u1ksAjkbogwlTDu6IArGsa43QW3hwm/0VjCNM/eQCRpLu1nnglMdFxq+WJZgMxxvoQyM2MGbJIHYUjyuqRaU7JnZqimkXnzMhh51PCevtGgoXxajAuQjDBZjk2ELrW2qk8lQWFmcs7MOzUz4bz6ajg+8hEARvhxLnOWydsESE0YsxhXoq+PXdcUfbXyQeTM5KCkZcoDgrwWMxh4IAv+BVLQwOWl/lLmkasN+0RescvORPoyqmhG+Vujo8yz7nIlee6SyCKEjqJiCq2gTQStzHAo+R8FVmbGeeWySpcb9W62+IaDY+jgn0eKDr0OAPrG84uhtsJ11JzU64kEhWVtQtBNLHkvEl6vsKyACyQAUMmte6W8ZwGFidR4XGJzlSshqQzwMLOGilJUlLHXO3jNfkEaK0IuiPwLLuhYWcaFR4Zv/NlslAf7fbjhnu249SHDw0PEdu9mxQRefBHRrVvNT2axWWaDiMunsCVJ+Le/h1V4KrQyY9VLxn7hheyHLA63bEjyzAAof/RReO6/H/YzzzRX/ZKVmSzmLBU0LvuFF6L0299G2X/9F5xcKChUE0YSjlVBkRBKttdr9jhNYFyuAeYJ6XVXm/tTZRlSIf/NCM+LI8a55buc52CkGpdYl+PjJmUYAFrs7MDOxTNDVta+UmN90P5D93g+a5EEZKq4JjwzFuGbhPoclcTd8vJePPZGbkVERElcbmWlPI0ypx2uSjYueyD9fKmohUzIGz3iKhce8Wg8bhLWh/3hpLm0LVwIIDcrPyGqfln1Lckx/4IQ/V2am02CN+UBAaygjBVjvPDBQGklgg5nVpZ+Nbxn5NgwWx8uV9K1InL2YOTQeZ3KQ8+odaOCz+Oh0lqU/uu/ovSrXwUgKdppxqUivE3pPBg5VP3KZUzZkte4sgnHykLgJ4RnRqn6NeAL4T8e3WUpE2TC649gmCvaU0JjwnhEyf+iohn3zGSjoBFC5kmzFo+Xt2kiaGWG0+k1QhoKqcxQJbOq0nLUlLFFMhIcF8n/pMwMS03h+v2FU2ZK+8w9czyxSMqNOxfIIiE3YEwoCgYJx9URdg3cPp5MyoWJyjKHyJlJJ6BQAYD5u1/F5Q/+Ch8++iZKe8xKWq7WupTwG1jkllhYWoXQz/9Pd9MTXYN+7OgYwnZeklpGbuoXvuceAFLDzgJ5ZkQOhkXOjH3xYkAaj+xpykcgIWhcJLQBgIM+K4trlhXKfAFM6LHNn2/yrCXUql8TUNJIgLVNmwbnVVfBccUVTAjnuQKFIGOp31Tjytfj5PfDNT6GgM0Jr6vclBCdrWfGKmcmsn49AjfdhBmvvAAAKOeGDav7ihCN7rj1Oc6va31oHJXcmDGawpKuQoc4hZjBImcmn7UoPNDBIAuJy+BJg8Vc2s84AwCw++1DuGOTuShAJtRmheQtcTlscFaz/djuz02ZkUPMAGM/H3GVw8336XA0bvKiD/pCyePi3oJ87jHyDFla++Xk5AxrUUZcqxkzTB4fuedQqjwsUni63bUIR+PCqp3OaKDmpPoPcit2irwSQBL6MxgMCBL8s6n6dYTnzEyrdqOMC7mqDJDNuFTk65qKfMKx7IVUZmhcw8Ns3WSBCMdKo8yIXMZMxiu/n11ThyPpOh3qH8cDr3Rhw+vdwrOSLd5AGIPcQFMX8okS4E5SZpTGmdmGmAG5hZkVUvGcKFqZ4ciembGCKjNsc6pyeVDNNeld/UZODHlk5HCzvvHChZm5e83WtvJoKGmzzQcR3uPxGNZ+hYTXa6rUU+lnfyMXACBPS6ows0P949jVza5H49ZNmPvGS1jV/izKe4+PMiMsLRaeGaFgjI6yjVGuBKZ0GVehvhtWVdtEbomE/ZxzgBwOt0yQomKpzFBSLDW0lD0z+QrHMDwYpf/wD0zBaG01vEAFUtLE+rLIAQKUhPICeZxorlXrsRD686xOJZMuobzXG8Q7AbZ1JxUAkIoT5AIVNejxsM+TvSzZKjNyrgCVZo6++ipiO3eivpMlvVfxRH5bCiUN8pzxazDewsIz5LwZq+pTVtAapOR/WHhm7n9uD67+2ZakxrzpMOXrdXcbVahS7IWwmEsbr0JVF/GjZySYMgndChGOxfck8gaUOewoq2b3giuc/XggCaeOK680PT7i8ggPejSeQFgqPez1R5hS6GDPl8yYgZJGVuhGznnKFuFFSRGOlU9ooMiBUJQZapiJFPsyAHi5AfKopxaxeEJUkUpXQET1zMSkz09FLmFLiEREWwI5t+Q3Ww/hF5vbRYNM8HOV1nt9hUt42FQZQISZ5aDMZFMdKxclLXYcqn6hpCQ3RS0UArxe5kWjPlRW2GwsZDqRSBtySJULrcZEVV0B4NWDqdeTFd5ABANcmWkIjQn5wsnDzETjTO5FFaGW2SgzWSigJ1uPGWhlxqBL8swkkECwQBXFSDGqLqtATRm7sd88Zm5G2O/3iuIDADAYmJgyE3v5ZYRuuw3xt99GxYBZUHbHCqTMkEW8qgooKTElXovXjI7CP2DcpFXc+zQWYAeHOcws+Tsd6PPhC3e/DF8oijObq1E2xFzFMwNDmNe2HQBgO5uXkc1is0xFIBzDDfdsx8p12xEa4UoaF0pMQj8pGIpgDGQWjge55cVKYBGKkBz6xT9rIuOSUZUZW10d22CrqmCbN88Inzh2zKykZRhXOmhc9vPOQ8WLL8Jz330FbVQISGFmKcJ7TB4MKdQgnTCSDhH7bpX0mmU4VjakU2Yefb0b39hoVNESCgz1pMki9EGFQrrIg2Fap1mEHUBRgOhwJUHS42XXu4YXQ7EaF6Fa+gNNTGCvCoyJnLnRFAnbKjRfvRaeGRK07KEA9vf5sL8v/fgIuUAHpIR+tb+HiilPbdo0UWmplu/9u4/msO/zfEESTih02OWwwV3HPseVY4sBEYoya5ZpfY+4ykV4UjgaNzU4pn2Nxm5ramKKTXk5EI3m5EFJ9Pay/h5Tp6b0copw0hzuMVNuh8sljBDUOwdpcmYeb7kAX77gBqyb/0FEYvGshH4SIGs9bAyOXt5NPoWCBuS2d8Q7OoBEgln6ebXN/rEQ/nvjHtz53H48vcs48ynErKXeGCu1N5DvV1EAIAfjVU45Mxn2DsgCchbeplzIZs4IoUynGxMnm75HIrfEwoMxNG4YG149lPm7yYwGIujnygz1EYRlmBmbY6F4ZqPM0LhSnSN+PztL3W7rc/BdQisznA5eXYygCmQTxcs9M5Uutwgz6+WJ/sRgYBRDkjJDhQDyJfj97yPy4IMIP/ggKod4uekpbNGVR8MprVA5QZsTeTBkiySV5vR6Eew3brQaHm42wquZVZYZpZnVMDNfKIov3P0yhv1hLJpRjXtWXogEPxQAwMGVTTuPz063oWSia4iFgL16aAh79nFhlTZhScFwnH8+wMelWt8zCf1UbQQWVkD629LVqwEw17goqpDF4ZYNwpNG81RdzerxP/sse5wL/aZy11mMKxXCe6EkcopeEYUaV6ZwLP64qcFqlgebFWTpp/mRmcjYoo89hvBddxmlzdOMyxeKwuvgvURovqqqhEU8n9BAsvT38go5pgIAWVrDVWUmkTC+X8UoV2b4HpBK+YQy5pKmJgQq2Wurgz5UuplQnar6lAqN66jkmREWUe5xoiqPHf2ZBS4gORyLmsFazZWMPOaSxkahANRxb9U7RzOErEhEX3wRgGEZDVKfGacN7ip2zuSqzIgQr+Zmk9Az4vSIKliRWNw0z4NcaaWxk3AjchVyWItyon5KsqysRyT6+4FwmFnnubJf+sUv4sCVn8G+qulC4RhLcSYec9dgZ/1cdHvqEIklsrLykwA5kysQ7n62Z6QL8cnW+wkY4ZdyiNndLxiFY+ScJgoxa6ph+wUAETJousezGJeKnIuUilyqtB2PnBnkODYROpdmTISI2kgl9EtzZZVbIsJdAbxiEX6eDm8ggp317D2X9hshqtP3vYXoE0+gKs7eW3hmlBy7tGRQQNON6d3klFZmbn3+Xnz2ke9hKDCGw9wz0+BmB45fSsifCCLMrNSDujLrUBhvaFzkzqAA1cxIC48+8wzquTLjn8U2CHc0ZKpGky9q4rV8UNsWLGCv8XoRGTIL/d4jPUaYmdspwkbUmOX+0RC8gQjqK1y4+4YLURENJVutqqqMstDqcznQNWj8bfsBszIjCygUjjURzwwAjEuWTRIgSpqa4PzoR+G5/36Ub9hguHoLHI6VSohMqczkkDgpQ6FzJGALKOm6UOPi1z2VIKmOK5+O0DLkwUgal3xw57EWQ+vWIXz33Yi9+SYgj8tivnzBCEalHhkA66dAlbSyObRVVGVGrniYrZKmFhYZ7TKE/poxFrNeyfsipA3HkoX+KVPgL2evrQ6MoqKMl2dOYUlXIeGkV1ZmuDEl5GSV9aiZcMdA+vERqjJDzSJTrUHCtEdOmSKUmXreEHRPT3bKTOLwYSAYZIoD3yco9KvUYUP5VPa+lZHc7jG5hLGsUIw4PcIzE4nFTR3uRZlrPnYbV2bI65SLYi0SytN4MHIKx5KKGMiWdscnPoG2Kz6No546TK1ia2AsRc5MXEqziMSknJnhYezv8+HVQ0PCC0mQADmzjikoNcNMtkinpGWTp0AIoZ8rM/1jIdz3smGsiUphbr1SWWaCGlXL0RBiXFnu94mREVF5LFWIL+RxZVDSEr29bE3X1GT0cOZKLsqMKKyRJl9GkEURgHS5JRSKCwCdg/6c8mZGAxEc9dShq6oRVdEgzh1in7PwvrsQ/M53cPu9X8P/vPoblHSxdSFyZtKsQSLTWkznbXo3OWWVmaHAGH752qN46uCr+MVrG+CPhlBbVommSnYj+QqUN0OemerSclTzMDOVkeCYSZnpn4AyY9qMeKfjo2U1iFcygcATCyd5QfKBFvoL3QEsuvVJDNrYoQAAdp7wnRgdRUQRGn3dfcIySlZWh52VXJUPjkHugp1R60F5qUMIx6EZs/D8VOaNsc+dK9zsuYQzqHQOGn/bfZgdPEKZoXCzqVNFWc1Ef3+SMpMpbEmOx5dDZChXwTZtGlBWJhLXReWeLA/tTKhNM1WE0M83XyJvoZ+S/y08GPLYdnQMYdGtT+KaO5QqblkiwudShC2JcVH1FRJqAoG0sc6poHVoedhNoDoWhS5RQz4xLouDne7fUSlMpqS+3ginyCFUhKD5IqHfFPaZ5bhUI4nvoFEQpCrkw7QgU6ijVdUsNDUFslJgmzIF4xXs93L/KKp4jl22e1gJz+XocddizhQ2Dgqhe7WPCRPlvJlwrsoMGTeoCWZGZUaay5Jp04QXozHI5npvCmUmEI6ZrO0x6vzOjUaQqpmVOu2odjsRtDGlL5c1LntGZMs0KwDAc2ZiCVEhCQAGfdxDft55sJ9/vijLLMJWc9g/RCWzNAJXLh4MyMLk6axHDEHepcZq5q1RveVEXEoaj8YTpmpm//3kHqxctx2bd5vz1GiuSIFo9DEhOp0yk2q/X7+tE7/c3C48YJB6zNzZGccN92zHDfe8LP2FsRYgNcycXmsoM+XcM2O6x0tLmXAeDGZlaBJ5SBnCscR8pRH4Acnab5FbMlHIexnduVN9KglZoc9ENsardEUN1IqPueTNkPF33zwWjn5x315cfOwduPuNCKMLBw/A/SpbG9n0ziEyedNix6MJaAE4ZZWZ7jFD6P/Va48CAGbXNKLcyTa3sVDmGzobSJmpKvWgVvHMzK1hgt5QYAxDUjWzQamRZq5YJaIfKa8XC7Q8GrTMT8kV2pzGHEyJCUiWYjrQMDqK2IhZMQv2Dwj3Krn4KW9GDh2haki15TxkjUqgTpmKdfMvw2+XXofSf/7nnC11VnRJQoyLypny97WfdhpcX/wiXF/6EnuchyqoidaZDm3ZM+OTxpnK0p/roZ0JNWcmCa60CasLt/plGlcqhGfGQpmRx3bMy4StbMOGAqtXI3DTTcLKRoJ7qv4eIqyOcrzq6oQQmc/YxHxlGFcuyCWIKWk6XZgZ5ZzJ1ZhK6usNQSsLC6QKzVcvLwAgez6yDjNT9pVQh7m6YesoG2eMh42lwuSZaWjAuIftm+UBn0hgVj25loyNIfbGGwDfA6dWsnuXjCkvHGZrYoaLCazZKjMkGFAVQCKVQk3Iz9u4h9DvYkJmeSSIA/0+RGPJFZf2HRvDB3/wLP574x70eoOGZV7qMULCOcXMBxx838xyX0wMDTEhtqLC5PGGKADAq5nF4iavHe3Tri9+Ee5f/xr2iy8G+H2GHNcieal/tSeAp95OPscAKbckg3BMxHbtAuQziUNNmqfwNWGVywgACUmZiUTjpuaStGdRXgoRprlw2jCtugxNXFlNWx0rRdL1Lzbvw6+e2499vcZ4af6fDpRjR8eQMMZ9ajEVgzC+cy/fX2XPjGhUrVY0y2HOsk4op/03w3wJZcZC6J8o1AMstmWLeCxw440Irl2LmNIKQe3flI5Ucybw+cR+btVfaITfO0vmsTWVS94MKUJ957BWB5cd243rO7cBAErXrMEjH1vFft6/xziz6uqMvMo0iHGNjeGOTfuw6NYnxb9vPPBGylLT7zanrDJzeNRI+Kdk/5aqRlTww2UsRxd9Kqg0c6XLg2olNOT8aewwGg76khSYHl/ughYkocTxwQ+Kjb/bUwebiA8PJwkd+UDKjM/OlRk3z51paDCq2YyMIDFsHsfoEXZjUdiC/LNVadc6rsyITWbaNOyvasKTcy+CbcEClJBykUHQSsdhXv3lzOZqVPL4ebqhS2bMgOtLX4LzqqvY71zQ2rzxFfZ7loIxWTChhJkJS7+SSKf2HXjunT7ccM923PW8uXhEtghlJkV4jxqORcpMJo9TKoS73ipBUIp7p5KSJFykZXQUsW3bENu5UyiToh9LCiVNVQZK6uvz6j1AyOtQRcxZlgIkYWo0298PRCJMsHQ4LA8fEkKGed4M6L7LwxpO0Hz1lLHrJXs+1LWYCrJIU+horNscjrVglHtXK6zXIGHKmZkyBWNudi+Wj42g2s32g1SWdBlKzB9uZhZEssKPBiIYDUax9QgbT20JEwyOjgSSGh5aITwzF1xgepzW1fN7+vDLze14+4iFh532Fb5HUrWs+tAYEgngHQvvjDcQwWgggt9sPYTLf/Qc3nr2VUC6RyEJsFTFaJwb5UYGsqusJ1f8giKkeuU+M7G4yTOjNkclRGhPDmuR7oPn/aU4mCJ/SSjWgQCee6cPi259El+42+yZkIm//TYAwH7WWabHSfmbWsnOL9nAJCN3UFfDzMjDTgYZgtZQqcOOs+NsDYSnp/HKyOOSzrFQNC6ULKEw+XzCYNlZMRV15S7cu+oirP/SUixsZnugXE3t6Ah7v+k1huGDFFP5HAIA29SpgLIfpSKr/CaCvE5pvIQxEpCPh2dm/nyUNDYiMTKC+NtvI/7WW4i98Qaijz+OwD/9E3yXXiquKYXoZ5Uzk204VoqCBsM8zOzyM9lZ8uqh7O8VMuY4zzkbQ64KNAeG8Z6hQ4i6PXB+9KMYmcGUwor9e3MKMYM8rrEx1L7xKm5sfxZnD7Nwte7hgBiXlbfp3eSUVWZkzwzRUt2IKm7tHC9QmBmFq5EiQ/+XOVxYUM8sKSNBn/DgEPlWNBOWgBkzUHrjjfjr/AuxadpZsFXwz42Fk2rM5wVXZobt7ND08etmmzlTCJaJsTEkvLy3jJMJXv4+dt1J4IGUkCgLUHSj13DvDY3L1sRufLERk6VuAspM1xC79jdcMhcVUTZfKYVj/rj7GBdqyYORxpoVjSVMY5O9ECSUJ1UFUTwKB/p92NExhK37ktetFbEdOxDn8eKAEXJoJRxDEiBJwBdWl9FR/O4lcx5NNojwOSsPhhS21MfD77LpG0KKBCQhSeQCWYRjQRqX+L22VggkuVTuIWhcVp6ZXCoSydBhAwDx/n6xllKVBiUBZ8RpGEdsDQ15CZAEzfug5D0Wgn2WYWYkIJIVuESaLwBoHWOGjFB56hh7KHNma2iAt4zdC2XjoyI0NRvPTHzvXgDA0AymzJDgOuAL4bVDQxh3sHuhJBAQIWidUv5cKoQys3Ch6X6i7/1UWw9+9dx+vLA3uTSxqPrF73dqfLeknu2BVnkzlJfSUFEKj8uOym4uTEieGcqZKeOVqqKl7Hv5R9JbxAmRr8IFHlnwGXF5xPtGYgmlAIB1nH8uVn6CvsOR8vqUpbflEBjaR49xg4hKoreXeTgrK0VZfYJaAUyp4gpuis+TiclhZv39wkNK3g+C7huXw4bTouwc99Wm72gvW8OJfmlcPTxcjDwYsblM6K8oc+CCOXU4e2YNXNwrF5EU8qM8Z2YaV+QBpCzPTGGTVFwCAEI//nFSHiWkPSsroT+LULPj6ZmB5J2JvvACwn/8o/nJ8XFRxEMoIFmMS+yLKcaVqbEkRahcNK8BFaUOdAyMZ91Ak/JtZtaV46UprMQ7AIx84ArA40HtmQvgt7vgHupHjCv02XibAHMBgPc+dR9WHXgO3wm2AQC8vQPM8OFyJd1T7zanrDJzZKwfAPA3iy4Xj82qNjwz1P9lohhhZmzh17nZQpld3Siqmw0HjTCzMh4e0DeenUVNRVRbamyE8/Ofx13v+xx21s+FvZJbNwtVAIAL2aNcmTlWOw0lTU2wzZljNNH0elEyxg7njnK2mYctlBkrzwy5UesquGeGW05cM9gmQwpZNnGr6QhF46Ip54fPmoa6BLfSRtjhrZLgN3rLuFnoTydA9o2Z15Ks2KTyzAA8jhlMESHLIVna0hHfuxeBm2+G/+//HuAHLyyE41cPDeH1TmvPRkltLVDPXv+/j2wXr8uWrMKxxsdNVk31cFWRE68ptwTUuDRFEqo6ZlM4Vpo5SwU1ErSar7zDzOSeJQMDhoJmEWIGSRn28r0KExwXKb2HK8wCF3k/rKzGVlABABKcHL1MmYmdyaziC3iYmd+Tg2dm6lTRhb3Mb4SZpQoLkolxZaZvGmtWWF7mFE0Dt+zrwxg3sMDrxZwGtj8e6k+/jyQGBliicn094HabBAT63lQZi7yOMuUPP4yKHTtg456Cfif73HMrmGfFSpkZHmfz/dFzmlAZD6M5MAyUlqJEasJIHgQSaEOl7JpRqflUfPoXL2HRrU/izbcOAS6XSL4vqamB47LL8KdZF2GsvEb0r4jE4qbzQ/Y4y+SSdA26rqEQxjxVCNpdqXOiSIAcHxf3AeWFqKQKMYO018iNmzPtP9F4gu3JlZUoqaxExMfWiqpMycUYWsJsfxqqYV6PlJD3QspXkfMsSWGiXizhFiYgkycOAJw891T2zNDZ1izlzAjPjGLUdFx2GQAgysOxYq+8gsgf/gD/pz6F4De/iTj3dELas7LxzIiqX2n2D8ptsh8HzwwAOC65BAAQ2bgR0aeeAgCUP/44nH/zNwBXpsQ5WV9vnL1pyFSkR3ibUigzFGZWV+7Cjz93PipKHdjwejc+9fOt+OXmdty/vUtEjajQ/tdc58aLU418sPGPXwMAOK+lFnuqmaxE481mriCNK37oEKYOM/mkcT+7l1o7mdInWkecRJy6yswoE4YumbkIN577UfzNostx8cyzUE5hZjw8bKJ4ecfrKp78TwrM7JppQrEZCfpEnxny1uRb0UyUxOVhDGRFs/PN0h0LJ7mX84GUh6ESpmy80noByh97DKXf+papMop9lAlmByvYZl7CBa1qC8+MHDoyxA9J4ZmhBozTm1BSYhw8otJSmo0yJV4vep/divmjvZjBN/t6HnLSHbVWZgJ8/hpCbL6oPGY6AVIuywyYK+eI+cogHFOcf99oKGMojAgTCLEKcFb5Mgf6fFi5bju+9BsWspKkzNTVIcYfqw/5sGl3ihj2FIgeBBbjksPMZEEgk4AqKzMJ2YPB11tKZOt5ba1ofJetoEUMH2bCebyq2tLDlXeYmTwusibz72oF3SejvDs5+HyJhn45josau+2tYHtGI7dWU+hftmFmfsUzU86TUcNnsYOPEt19PCQ1FWrOTCgaQ7+L7ZX1fF9MFRYkQ1XGeqewPbXUYRNhas/ypO24k+1Dc2vY450Z8mbUJHVZWSdlhr4bCZLp6Leza7WglP2NVa8ZssLWeFxYGGACV2yOWeijcsCVvEBChHtmgtwzbsWh/nGhPFVv2QyEw6bQudj3bsOPF16JWFmZSVBWhX4rL1k2zSVl6Loeq2LGh1Q5dLLxapR7RiD1NZIRyowSYgZpbXtcjqwVZEqsd5x/PhIDAzi3lynLgYFhhO+8U3hkDc+MHdN4BEhPRfo9yipkibzWkDws5MEI8eqkpLwCgMtu5DVBMprJId2Qqpmpob22009HSUMDEr29uG/9s+j9zR/Ec9HNm+H//OfF76onLy0WXieZRHe3YSBIERExUWhdkxzhuOwylEybJopoxPdOLBwr+uijrLS+1AIgXSUzSN7AyjIHls6rx31//17MrPNgb+8YfvXcfnzvsV34/V+TvWKQ9oRajwtvzFqEL19wA1YtuQmYzhSYM6ZXY28NGwcVKMnWMyPaUkg4xn14f8kwlg6w9yJP18nEKavMUM7M9Mp6/PBDN+F/rvgyWuuajQIABQozE54ZriRV8a7Ds6oaRcjZUGAMw9wzc1odW4DH8vXMkKWfKzNURtNZxRZoRTSUlPiXD1QdawRMGEg6fLiSUTrADt8Orsw4uXJT7TGUGSoAYEospZuVcmYkDwa9fjwUNSx1GQQtK6JbtqD+W1/FN3ZtwMx69j7VfL564uxzVcYkazikjSpdBSm15KLJMyN50pIga934uKkC2tEUlkjCJBwPDVkqM2TxIWVXzaUpqa1FuIoJZ3UhH56RGrFlxOtlihRVyFEwhZlJyowvZC3AEHKzwsTgYEahnzCFLU0gUf6tV5llstOZwrMgzVcuJJX65Ra91J4Ztn5SFgDIUoAkKMTinWq295ChYZyE1izHRQJ1U40brlgE7gC7J31zjTAIAPApuYMqajWzcDSOIW5EqAnx90xluSeCQdFb6MgUNq5Sh014hKk6lJ2vz/kV7Cg8lCJXg1CrOMlhlIYyw75bv+KRVfEGIhjije+mxdj9aJVnIyszrT6mhJFlnlANHHE3m7PIaOrxPP4mE95qQuOY1ncYKC01KTOUh+O02+CUQpjk0syQrqUMeUSpmlwmKPm/t4L9ndyYU0ZOupZL26reEQCIp/PM8LXqdtlRwRXApDNMgUoeU5GDi/vYfvDBQ68gfM898H3844jcf79QetxOO+q87Pw7LDVttUIY5aRzbEBaP5QzQ8n/gWbmQaOCD7DwzND/5FUjyDNDoXYyjksvBQAEH3oI1a+w5Pjyhx4ycigPHgRCIcOLYWWsUsgUPZEpHKsglJXBvnSp+NX52c8CMIpoxPbuNe5ti2gCK8RaHBxE8Ic/RPjuuxF5/nnxfLp+LKR813P5BgBmN5Tjj//vffjetWfjk+ezPStV2Ktob+FxotrjxM76udhdM1Mot7YSIDDPvO+mK0BhgirEKrxvrFP0tLFrZebkgXJmZlaZQyuquHt+vEAFAOh9angsej33xsyrbUKdmwlFIyEf+vxMyD+dPDOB/JQZNQeDQj+cPMzMEw0lWdYyEX30UQRuugmRP/3JeFB4Zqz7PpDgXD7CrvPwFHYjecaZElTF+0UAQDlvyCZ7jEQBAMUzUzJjhun1Ipk7has3HZSDURvxiw7J5Vyp7ExYu5mHeFgdUVJXl5RvoqKGYtC1SoyMMKHf47EMk5LDe2Tr5+Hh9F4oOWwpPjho9ASyUGbABSFVcLbV1iJUxa5tbWQcPSNB7OZN/V7c148jKdzfkBXPFDG1O46xQzrh95vizTN5DEnxA7/WmcKxCFPYUl2dIfSnUUCtcLWxcKwOV7L18P7tXbjzFfb9cl2LJHSTAEieEislTRbiRyTPjG3KlJw6XcvEuTKzq7oZtR4XyrlwJzwzGcIpCNpXpte4MWucl6OdPRu+SvM4vBmUGVRWwn3nnXDfeSdQWYlILI4BLvRXkYKUwYoe378fSCTY54ONp8xpR41kRDmvpVYYQ2a7meB+KJNnRgmvsQozoznK5JkZC0QwyHNmSse8IjxP/Q5y9cd5Y7xvWEuytVcWbGOkzIylVmY27GRjWcKtraFFLGeCIKXF5bCZwsxURUOu1EiUTJ+OkmnTEHv9dSEkRp9/HsFvflMoLjIiX8bDPBiy8UaGvIQIBEx7opqED8kzQyF9MiTIu5124blQlRm1shx5PMgqffEAu08/eXgHe8HoKEK3344Vf/xvgCsXFYPMaLrXnsIAQpDRR1Jm5L3xyHAAiYRRltnbzEIMZc+Mg88RFWig/50Ocxl0yn+yKqLx5kx2rT7dtR0AkPjgh1DS0gIbD2mMHzwo9mE5zDEdwoORQpmh0LlUifKFwsGVUNv8+bC/5z3sZx7WlujpEWGpqc6tJPhajL74oihuEG9juSUIBIz2BBahcyTfVEn7EbiX5hPnNWPV+9n9beUpTiSs1y+kNQAAleebQ8GyygMiuHFz0FWBfzv7WgDAB97YjNqIH4GaeksF7d3mlFVmqFrYzCpzLCvlzPjy8Mw83v4yHtj9vFBMAGCEh5lVcI/PPVd+HUNf+zO+eN7HUMNDz7p4w06PoxTNlUwgyStnJhplVlm7XQhC1BnaWcluPHcsnLNnJrpzJ2I7d4rDATA8M14u3KsuejVsKTiTbXz13LJqLgBAOTOSoEbWyHKXOZYVQDl5Zuj1JSVMKYinD79SIYt4XciHWfXlQDSK0sA4oiV2dCWfjQCA/hKzklNSXW0oVCks4kM8SZYatJGwIza7FNYtOWxJPrjTKRKQBC7w72TlmZEbhfrD0aT5Kqmrg7+cPVbL52zTrl78cnM7vvy7HXi1w3qsgFSEQhnXiD+Cz9+1DW8Ps7H4hsxWaFWYIALhGNqPjSEm58wMDmZM/idMYUtyP5YU85UK51H2+W1VzaKzNvHW4RG8PcznNcWhbcnoKIuT93hgO41Z0kTfEitlRrrPvNzLC4CFZ5SWsgM2FEpbOchE0Cj1u69qOsqlHAKRl5ZlLhCt66YaN6YHuNdsxgyMVJnnZ1gqXJAK++LFovRxMBLHEB+rh4eZWYU2ycR4iJnt9NNNPVjkfWfx7DqhqE0vYwJfpvLMQkDmh7lcUp3mi+aIvMup8ErKTPzIEcyfyoS+o6+8aTKMkOBT7XFixhC7t73TDUGS9l5ZmSHraiyFMvNG1zCOjQYxs86DT0TZuj40x+zBIM+Mw26Dw0ZW/wSCXMmZP5V99xGe06NCwmOUW6sjf/4zops3Y/zqqxG67TbT/UfKTJebrRUrQRuQQpZ8PpPCo+YnxQ8cYKFLTU2W95EIMys11oRqTKH+ZwQpNyVTpyI0Zx5qwn783f7nMMs/iFD9FJT94AcAgOZeFhpU6rTDdYQZKvYg2UOdBClq/N6VlcRYPIHhwz3M611RAX8N28NKuWICaf5Vz4xLyquBXADAInf2R946BKhHEYAd530AgBGBED94UCijaojZfzy6C5fdtjnZu0j7R38/fJddBv9nPiPOCPD3BID+Kc05G1pzwfmZz6Bixw547r/f9Dg1+Y6+8AL7PUsPhgjHkow8Ma7MUCXFVOWLRU6w5JmRmd3A9jv1nAGAIb6v1PN8YnlPk/eAeWe3YpgMXjabZf5qKmhf3DTtLOxpZjk5lT523h6Yd7bptScLp6QyQyFm08qTN7kKnhSaT5jZL3b8GTc/+VP8pZ1ZNQBglMLMLBpmUt8ZKstc667ElHJm3cuncabIv5A0cOHyrmECnScaQjCcm9AvyhZy4RGSIEjVeNTDRw5bGnWUoYxXIavj3a7lMDOyLMhubzrA68tdhreJ34xkORYbH20qkhD51/0D+OiPX8D1v/qreEyFhH5PLIw5VU5hqR8srbC09AHA0Zix+UTsDsDtzlhFinJmWngoG12rdL1YAHN1LNkinzHMTC71OzRkCP0mZUbyzETiKOF9LwSVlaK/x2wb+/53v3AAv3qOCb6vd6T2aojyxdK49vf58JlfvoQ3D4/Az6tIqZWW1DVEPLOrlzXVTJUon60y43YDZWVCuMk1t6Shg1nudtXMxIFj5u8+6AvBz4t3ZArHkpH7NYjSqOSZsfA4ydeIKgSaBGolhG40EMEjO4+Ykoll6NCNzJqNgMOFilIjhyCpYmCKmHeVunIXZvq5Z6a5GcPcq0IMU+J9loRjcYy4uGfZx/ZK1XiiQpXM7KefLjwMZVKYGQAsnlMnFLWqeBiVZQ6Mh6JJYaGCYBCxbayXg4OHYwnBp6xMJA2TJwVSroMVvlAUb9UypST2yitYWMOue+19v8X4Jz6B8C9/CYyPi3y5Go8TMwfYvT0yzehbQR4DWbAVQn+Ktfj4m+we/fh5zTjjMFsDz1eZBS8hDNttRqUsqQAA5UaRsUZFVmYSvb2mnh6RBx9E6Mc/Fr/TfdBRytZ8qr1AVqxlxV4NMxMhZhZeGUiCvMflSOmZUUP3YlJX56Fz2Px/af+zAICO910Bx4c+hJKaGrjDAdQFx1DhZfdAX2klusYzn7lq3ozq2Rtu4wr6vHmGgi6HmYk5Yt/T6jWQlBk1Z+av+wewp2cUrzcyo0pHeQMeirFzgbwL8YMHDe+kJGcM+8N44JUuDPrC+O6fuXeCQ4JxdMsWwOdD/MABEdoKSZn55itefOTHRpjW8aJvNIQv/98O/OQp7onhRiQqT59rzoygrIyFP/f2Ivrcc4BUIU7FGzBCR1Mxs46tdbmpN7hHF5ISI8tSsqfuPbNrsYuHDmdTdU7Gdd11CL7vUjzVfC4zAEpeuB1NZ5hee7JwiiozzNLfXJlcLrHcxT0NeTTN7PQyoXtI6hlDfWao5LOM2nemtqwSDW4meB0bTy0spkKE93ChSC4RSZa68lgoo8VQhQ4aEZbDD8hEuWFtUg8CkzLj8mBqVZkIi6kN+SwLANDmGogYHa/dLntSxS/hmaEwGIvE65cPDOLwkB+7ur3Y1W2tGMrhWC22kKGgucpTCiGdUcOlO86rMmXKVaAwM7K2kFVZeGas8mWUg5sEGgA4kinMTA7HGhw0hFBpTuQwM6EU8qR28lyM8P4ep5VGRYNTYkcaz4wobylZpf7u7pfFNR2nRqtes3CcKnToL28eRZOfrb1EFbs/EkND4npbCf0y9DwpnUL5zCXMzOdDwyC7rnuqpmN/n9niPTQexjjvuRQe82EsGOXduQ3DhhWmrutq5TULi7J8n+2rasIjf/cvcP/wh+IxWbEORuL48v/twHcebsPn72JCuAqFmI3P59a3Moe4v0zCjmI1ViFlu8rtRF25S8yXrbkZ46EouqWcgQGe9J4t4UgMneXs2tjb3gT4dQh+5zsI//znlvcdherZFiwQobYup92075w7ywgzw/g45k5h6z2Vdyb6MutnYj/3XHEv2VpaUPr1r8N9++2A0pcEFh4DmbFAFGNON/a3LAQAXNT7DmpC45j1zmtAOIzwvffC94lPYEYnUzZqIn44oxGMOD0Y4WsNAML8M2VlhnKBUikzG99ia/mqCj/KfF70lVbiiVFzCC2V+FXDzMgYRl3lU50n5FmLvfEGwr/9LQDA8dGPwn3PPYC09iEZYNqd7F5NpazKJYxlpVEV/NNVMoNkOPO47KjgIc/qZ8rKCyTlDgB6F7IwJeL1RSz0jPa8Wf4BeAaYPNDHoy1SGRQIypuJHziAwE034Qsb7gAAzOIh0IE9XEGfP18o6OacGbNnRii5ijKTKmfmj9tZpcb+L9yE2Jpv4UcLP44X9vQhEI4JT2T8wAHLHjMH+4x1tq93DL/ZypLfIc1ZjN8/gFGcA5Iyc7CiMSkkOxVtR7x49RDb43Ll+3/ZhRf39uPeLQfxTs+oKAJAZO2ZkfJBbfPnw3HRRQD3zpAyQxXiVMgzo56rMmT8VPNm5OR/AKKoCRQvXHmpAz3NzKMWaLCWMVLh/PzncfAfv4V3qptRW+4SxhsAeLEyuQHoycApqcxQvswMXjlFRoSZ5ZgzE0vE0csVEPK0jIUDSCCBSiVpXIaqm7Gfyw3PTB5hZmplLBJSyxw2IRh7eFNIK/elJbGY4ZnhQgP9H5OEyLFgFPLeLyszXqcH06rLMMxDRepDPpOFVCT087AWqmTWyKsqqRXaPDxnhoRfK2Vmt6TA/OnV5BhthEKmUI6mmF8ItyNONwZ9YVaKU6EjZNwyPp5flUmZIUvvbF7+Nckzk40yI+fMpAkzkxU0AHj82Tb8aROzlMlCv/weFDZCHgwSoqm/R2VgFB9c2IjTplXiia9eCo/LjsND/pQW7NhrrwGSVcoXisIbiMDttOPXf3cB/Ha2+YaV5GSrOPmh8TD+un8AzX52bf0zZjEBNBQSh2pGZYavRaHM0Ot5qGQ2UK3+t6tnIGx34kCSMhOCn4eShkd9eKm9Hzs6hrCjY8gyQZqQ+zWUcCMEYTUu2UMXcJRid+N82CSBjTrLxw8fxjceeB1vdI3grpd/jQ+8/bylIkIWUu8sZnn1lDqMakdS2KdVqNmLe/vxy83teOvwiLDWu512uF12zAiw+bLNnAlfKIr+UmM/6LMnG3bSEYrGsXUqFzhe2gp3NIxynxfRJ55A+De/wfgVVyB0220mzxEpafYFC4RhRPbMLJpRDY/LbspLW9DEvuMzKbrPk2eBEsABZiBwXn897EuWANIeRhxLkzdDimnHGUwwnvPOa/jo0TcAALaFC2G/6CLA68XpR5gyUz/KLP09ZdUmzwVde1lodfC+YiUWoYEv7uuHNxDBmc3VaNj9OgDgjWmnoX8sZPLYkmXfrMwkkjwzqRpnoqxMXCvKt3R+8pOi/DMpMInhYWYgq66Gj99DqTwzQqlWDDzHqKkkJ12+DCSDUpXbKSrAqRXyEgnz/k8FAACgu3keRrmHeVPjmeiIs59JmWnxDaCsjymMIzwkLJW3nwiUsuvZ8cCjiO3cifO630FDcBTnzOT7gNRYkuZAFl7VPjM0f8kFAJLvb0jn1NlLzkL1p64Bzmfr8qX2AcMzc+iQMFbJ1n5qckrf9Reb9wkFU+Q5SdC+kzh8GAiHMVBWKeY+lSFR5u/ueRkr123Hq4dy866/uLcfm3YxJZP93peUq5PqPE5CGtehM96DfQ3MexF56CFmUJTWv4pR1MOcMyNDSuxhRZkRVdD4XkbrF1IRCKLvsuX48gU3YPvHWAlqmRd4c983uqxlzWGpPYbjssuAc8/DgzMvxDs8TPxk4xRXZpI9M5V5Ns3sGDEOwCFeZnkszA4GSv63olZSZurcVSL0Tc67SceOQ0P46I9fwHW/eMloVMiVGdrMylx24Zlxx/gBOmAdS61CigRgdJEnoT9eY7Ycm4QfKaRpxFWOqVWlGOIhabVhszJD1WRI+aIbneJJhWeGhy0ZYWn888i6KsWuviOVOH3izaNJVig5rwQASka9YlyBCvbde5VN9ehIwNR13cvHQ0JyqjKkFPtMnhkhkPLDMmX1FD4uVehP1VcBFuNy+0ZRxRVzEupVZUiUuSYPBldmhrgnrXx8DH/7vtn4/ZeWYmadhyVOA9jJQ812Hx01rJpeL7O0eTwiFpkO8alVpVjYXA2/k1mVo1z4pN4f6hwBwMY2JhA08RyM/vI64cFIl1siQ+OySa8TeTPci5Xo6YH/uusQ+eMfLSvjUSw0ue0P9Jm9Sn2jIaGkxcf9eHEv8/7CojS3jNx5nRQRwlKZ4deZrHJk4SMosfXwI0/guXf6cKmvE2ePHMYtbz+O8SuvRPjuu02vJyVtcCYTVipLHZYFOWQPBvH4m9341XP7se3AgPB+lDltQDAoOkaPNDRhLBjFMe5xDtidGImaD9xMhKJxeF3lCJ19HgDgg2OH8JEe5qGheYw8+CBibzBFgKoIlUyfDlRVGR3ZnXZ8/NxmfO/as3HzB1gVI7nS0rWLWeLvY290W1p8o1yZofApK+Sy61AaH6qQR6P3bGb1dL/+Kq46zEul37AKzo99DAAwZXwIHpddhG/2empNSq2Vld7B73V7INkz85c32Pt87JzpiO3cCQAYPut8ADAJh0Y1rBIhEEdjcRGiNa2a7YXprOnytSppaYH9/POZ8ae8nOV/+HziHog3m8N7rCrWCcPR+DiW7H8V2zZ+G3dvu8usNIZCoieK/XSjB0cqUuXMUP6/m3u8yNMBroj+98KP4/HzluM38z8gkvUpUX6mfxCuY7yv0lRm6VdD4VQG4+xcK9v+knjsdH8/TpvG5tJ92OgoLxR0yRuX5JmRIzMkUvXVod9L+X586enMuPKDJ3bjS795FaONbH5irzMFWPbMkHHn8rOm4er3zEAwEsdmKucvh2PxUEzyzFDy//5yQ4Gg8+JQ/zhePTSUZDTbfXRUjO3NFIK4Ff5wDP+2ge3jHz+XKWJb9vabms/K4VTff3w3bvn9a5a5RZDWIgB8d6AOPzzM1lFsBysIQb1trCADQE2KnBkALI9XCjPbdmAQv33pkGigWsPXrSn/WA41BdC6cDZ21s/Fy/HkAhQPvNKFXz23H4+9YZYZCFGEqbwU9iVLUHHP3fjfC1kxAHVOTgZOSWWGcmYo2V4m39LMHTzEDAAGeb4L9YqhfjJWyJ4ZUmzo9eThSceBPh8OD/nxTs8ohg4yN7HwzKjWG+4W9USCJrdwOuSu6/D72UHBhfZwpVnYkpNyZUHM63RjSmUZhnjce1143Bxmxm9AOryobCHd6KrHiQoGiDAzpfRj93AAo8EoKkoduPT0qQhEYnjyLXM3ctWDkRgaEspMtJoJvaqFqGvQL/IUANYZG/IBKykzib4+cUiLnBmuzFDnaNHMStpMZciiFeTKTFNNGVwOG8ZD0SQhlqD5ok25OjhmKDNcwUypzJAHg4+nz8G+b9nYCOZOqYDbaUf0mWdw64Pfxz+88ySGNm7CG3u68ZlfvoT3/uczGA9FEeUHnf08JnhCCrVprHaj2u1EWRVbB34vG9c8nvisCoLgiigAXOBk37mzrBY2Uh6zVGYcy5bBfeedcN1yi3iMwiZIQI08+STiBw8i9KMfwXfZZQjxsCGClJm3a5jAK3tmyGtGyow9GMCLUvf3dCV6X3uJve/Nm3rwmQdYaBRhpcyQ0jijzjrEh0qr1ra9htJoGDcF2TXqLatBYmSE9UKg5NvRUbFGj05jFmVPqcNc+pyj3mOQFCmvPyL2mjKnHdGtW+GORXCwYir6aqZiPBRFH/fyjTg9SRbhTJDgEn4vEw4uObYbHzvChPCyf/1XOP/2bwFp7VPsOwkpsudiWnUZPnFeM96/gCuOZF31+bBwehXOnlmDsWAUT71thGoCLAcnMTCAksbGJEuujOpRkHuFqNB6tzc2wrZwITA+jln+QQy5ynHwtHNFTkKzfwi15S6xD/a4a0whgHJfE8JVxebLHgwismEDgt/5DmJbt8IfjomeUcsXNQmhsuEC5kW9dwuz/kMS3l12m7D4kjLtdtpFArKVZyYUjePVQ0Non29UVHJdfbX4mQTh+JEjwkMTnWYO71GrppkIBnFOH1vbc3x9onQx+FwBPBfCoh+U3N8DknCvhkrHuWeehHtZwR0NRPD09LOx52PX40Blo1BUSrjXqcXXDyc1jW1i40oXcggAIzYm6FcHjb3l7FA/mrgHrLaPnVn2+fMt82FcXJmheTMKAJjFPBHWnaTMGHMLAB88gykYvd4g/rp/ADvADZQhtqblnBkqaT5vagUumMP2553UkJkMIQAc738/ShobkRgZYT21jh5FxOlCe5VRLIau5Q+e2I2V67bjz7zqHvHWYUOBeaMr+1DhzbuPoW80hKXzG/Dtq5g3+83DI/C6PMIbQyFmg74w/vByJ17Y0yeMdlZUPP887v7Ct7G3ejr2VJnXr+ODHzT9LpNNmBl5ZroGWQGgm/73Fdz+5B78fDM7J0TOjCRLqZBBeMhC+ejicoBVbytIfyMXKaDmq7IH92ThlFRmunnDTLUsMwBUUmlmrsy83L0bWw8z62U6qCIZAAzzzYiS+Bs9yUIJUSd5baggQKOHCWfZFAGQK5707zd3JyeLnYdvTrSpeGLhpDjMVKiW/sTIiBDaw5XmClimnAfJGuN1euB22jFezgSaWinMLPrkkzj9/l/jO28+iE//6X8Qe+ONpEofas6MWjBAhMBwz8w7vITwWTOq8ZkL2eHy4A5zqFnSuIaHjb4lXIiUS2OC56oMcaEMPLcGAMK8hPHYUWMNhH72M4x/8pPwLV6M3z/9A1x5ZKco/zzsD7OqMAMDKKmrS63MCM8M8wJUlTmFd6c7Rd4MCaf2s1nFkfqwD9XcQ0jKjLoRkbCnhpn1Ossx4vTANToiQguiTz2Fmp4ufLbzr7jy/p8i8Z1bxft0DIwLq5SszPSSMsOrudU3MmWJKi1RroJqie0eDuBNfnAt8TCBaU+iIqlJJnnIUlHS0AD74sWmHB7Hhz4EABj4y9N49PVuBB97nL2WC1mRDRvEawEg9hYry3xw2lxMqy5DKBoXoZoUFllWyZW/aMgUFpjKM+MPxzDFxyzhR9216FcS5a2UGQqFIaud/DkAq7RkW7gQjmgEl/W9g5ltLGfnHxf/LcKLLwRglG8XFb/OPFMoGFVlUgGADGFmXq5IjfjDQiF2uxyIPvMMAODJpnNwdDiAsWBEhJmNuMqTBP5M0D6WuJgpM5d27MSc8X7Eqmtgv+QS4XGjkrFCoeceT9kzoyKUtEAA4TvvxNo9j6LVexR/eoXtpQR1RU9nbYXFGk7nmSGhusbjMgk+T04/F+3HxkQYT3NgBDUel9gH+8qqTZ9jJdiW8r5izqAf0WeeQfSJJxB59FFs3n0M4WgcF8ypQ0PAy/by8nIsX34Bmmvd6Br04xebealmClNyGH1maL25HDZhbLJqWNkxMI6V67bjCxsOovSf/gmuL34RjiuvFM8LZaarC/Eudq1DU83VD1XlQsD3qUv6mdJSHgujyjsgzgPyNj7ir8TPnjEbCAAjF4yE+kqRM6MoM9xzbi9J9iSS4a61ke09pEyRZ6ZlfAC2br4X83nM5JkZiievzwXjx9BYVYZm/xBc0TDzRFZVmcpmE1R9jZQYUZo5RZiZeh+Kcr/8usxuKEfbf34ET371Uixf1IRDFYa8VFJfb1IUKcxsTkMF3jOb3Y/bD/CmxlJuiePii4W3LLZ7N8Lr18MZCeOFxoXiHKBzl6p2qr2f3jpsKBeyYpOJnTzP8wOnT4XbacfS+cyYvWVfvziDSUGTi1q81G542VX2jSdw7zF2H4QcLrxTbSh4DqmvjYpcrTUVImdmYBzbDxoeU5KPKPGfZCmKcJARPZQs9lyqaLrn6KgpRYCgqmnU6w8AZvCiBKnkj3eT5NGfhCxduhStra1obW3Fbbfdpj6dkr9/8qfqQwCAbi5AzLAoAED5LeMRdkN99P5v4RMP3IqDI2ZLnUqX7JnhHhXKe5lqUTWNIAUGAOp53xnKmyHPDqRS0pH770fwm98U3WVld19Jih4zZFmiBENPNIRrf3krfIsXI8YP6VSQlVP8LikzQUWZkXMeTJ4Zlwdulx0B/vq68Li4AYM/+AGmPP0YPtLzJs441IZ4Z6eR4FbuYtVPqMwhr/9uVFviNyhZfnw+xLZuRelv1+Hs4U6cMb0al5w2BWVOG94+4jW5iynfgkq+xqWEcmcDE5Z7lDhsUgLCvEjEIE9kbi/hn//Wm8xqFQqJMo8A0BT04vygOQ4/tp0JmXaeNGgJFyCjYz6c4e3GZ9qewuWD7ABPlfNESpp90SKAV4+rVMLM5LLMkDx4IsyMe2ZGAxE818iSk6MbNwJjY6LM6p9mse9NZbPBDzTKl3FIykw/DwFp5DlQTU3s/cujIUwNeHHVzidwddcrSYfrE9yb9qGFjageYmt7R9STlCj/id++hbtfYOEK2eJYtgwAUPn26/jzXQ/DdrgLqKhA+Z//zBTxQECEm8U7OgCfD4OlFQg3TMU8XpKWKpqRQeG0aZUY4567qtA4bmx/Fje2P4sBrux0Dwfw6qEhESZ4bF8HmoLsHv/6Fy/HkLQXpPI2USgM5SuQQiFDgvE/7NkIZyiIQ1Na0FUxBRFuqKFwVFJQ7aefLrwEzDPDLbeSZVxudDp+xRXwLV6Mxi4m9Hr9ESH4VpdEheD/zPSzcXjIj/FQFPsrp8F3+iLsrJuT0quYChLW7dObROgiAAy/n80hKS2kpKmNaMNUzczisJc9TpHHH0fTlmfwwZH9ePPwCNqlinXRv7KqiOlCzCAZdKq4EJFOgCXhubLMAecHWAlcAPhL83lMmeHrvC7sQ4MjIUIie9y1pntFhJlJ43PXsnvdGfSL/IR4R4fwdF55brNR8e3MM1HqsOG7n2R7xp3P7cfBfp/IvXBKpZlJiXK77KivYMYJq2pm5I0MRuIYu/o6uL70JdOZQHt5/OhRsRcHppkrLqmKIUFzVi3ltc729YvwJBrv29UzLb1GQvHmyq3RNNP8eaTM2PjYZei19RWlqPE4EYzEMRqICIPJzMAQSrgyUzaHPZbJM9MbM3IfjjSw69My0oPpNW7MHeMGPe4VJEVFVmboZ+HJzOiZMY9XvS7EjDoPPn3BTBysNELB5F4sgUgMvd4gXA4bmmvdmF7jxpTKUgz7w+gc9JuUGfv73gfbGawaVuS++5A4dgxHPHU4MKUFnzyfzT8phhRelazMGApMIBLDnh4jgsUfjuGXm9txz4uGh5F4jSsz589m588lpzH578W9fXBddx1TuK+4AlAU9G37rfvHAcDPNzFl+YuXzsOZzdV4q5pdF/t732vZMJoQykwarwp5Zo4MB7BlHztnySAKbtyEpMyQZ06GFHW1uE7PSFAoMNF4QiijMkaYmaTM1PLvNGQtf7ybJI/+JGP16tVYvHgx2tvb0d7ejnXr1mFLBgGc+OPu50V+jIyoZmZRAEAOM9s7aFjzrd5HpouHrgFGNTPKeyHlxApzAQD281TuyaGKZs93vokz71qJGx+/HdGXXkJ082YRJiXHK0/ljTbpEE+Kq+WHQHksjCnDbHM0hZFZoD6fGB4WZV8DFeY4TPmGkcsWjjrd8Lgc8NWyzeN9/XtRUepgZU59PkSmTcfrtWzDT/T3i5uo1uNC9CUWP2y/8ELj+4uYfvZ5ontyIIDwQw/hvGcfxvuPvYOF09n3m9/IvstBKTSIhP7dVWwDTQwNifA5TyP7nr0jimeGW4piFez9esEO89766egob4A7GkJ061ZEt20DAgHYTj8dvWv+DQAwLcIUCHIr+1/iwlEaZYYO7eiYD5f27sJHXnsS79/N1r4cKtZ+bAwP7TiMXd1eQ5lpbUXM6YI7FkFjiK1HKr9Mf0vfRYThrFmDih074LrhBoAf2JuamIATefJJRDZtYu+9ZAm2f4DFzk7l7w0ARzt6WeiXywXbOUZ4CQl0U7kyM6OZKYvuWBjnDHfgzKcfxE37NyeFmT0uxfaTwHO0rBqDPFyR8LrK8bNn9mHbgUEMjofxrQffwu9e6kgqrSpTUlODfTOYhfA/3/gjACDxAeatoftHCP3cK/N29Uw0VLhEPxCqaEYJ/vUVpYiVsbV4lvcIVh14DqsOPAf/ESaE/mbrQaxct12E8kQeZ96gt+ediyXz2DU5Vsa9Y0rfH4IEYLqWqgAGGBV0qAz6m6ezNebj4ZMUriRKaM+YIayylWVOo3SrLOxwxTre0SGU/qpB9j7eQEQIQud2vQ2EwxicezqOuWtweIiV0H29fg56/+vHuPusjxrvmSWy4CZXB+p+L1NmKOeMlBhRYpU/LqqZKf02AIhcwsThw+K6vLeMHdSPvs69t6EQ4m+9hZjDidCFqa2tkPakOdzKnE6ApXDTKrcTJS0tqHj+ebz97z/DocpGtPcyRcrPBfzZsTEjZ6as2pTfQddHzp/w1LL1M2OsXxS6iB88iK3cyrzszGmmXjwAsHRePT52DguVuf3JPaYwJbp25JFwO+2ie7lVzoxcuavHIqGbPKDxri4RZjZWb/bMqMYNQg5bIub6+sU+Q56Zd2pmJIVhQlrXtM5JKFQ/j/L/bSUlRp4J3yvJQ1rldqKJ5w6RB7qTN/7E+DhQXo666fw8SVMAYNAXhpc3oAaAe5tYHlXjQDemVpVi/hiTL+JzWG6byIeV5pyE2exLMxtrCNLY6HmZC+fWY7zJUGDk8sV0rpJnBfz14N4Q29y5KPv+91F6660oqamBnSszlHvzVNPZWDKvATPr2LweGw2iRzp75eqCo4EIOgf9cDlsWL6I3d9y3sz6bR341XP78T9P7zUpIUPjYRwaGEdFqQMLprH9m5SZl/b1w/7e98L1pS/Bfj7LHZOV4P19PstKdLu6vXjunT64XXZ84eI5uLh1Cn668GN44J9/irJ/+Rf15SZEmFkazwyk8sxP8dzR73/6XJwzswYXza3HObPYfk4Ki9X+lqrs+OEhs0GTollkrJQZ+j5qqPrJwEmvzGzcuBHXXXed+H358uV44IEHTK9Jh9p80hcJit4vVAZZhbwzsjJDeTapkMPMKN+mnyszpJxYISszlCtz5lQm2G/uYHHhG/Yxgf6sqXON5GdeiYs8M1+a44AnFsaou0oc0EbODPfMcIFkZmhEFAKg0IVUqCEbiZEREY7lUwobyDeMbIUbcXpQ6rThYOu5CNidmOvrQ3zvXkS5cBz+6JV4dhqLYU0MDAhLd43Hybrr8lhbgtzkZLmTrasUsjA9MIwzprP5beXC5z4uIABGOBblQMg5M1XT2DVWc2boBrbxnj0UZub1R/B4M9sEA09uFGE2zg9/WAje9UG2WVCPHBvllmShzMDvx+xxNt+1vKKR3Djz188fwNo/v42NbT1Gha/mZgSrjQTFiNPYkMjDtKCJXRc1EZQYC0aws34uEjU1SHR3I/zrXwMAnMuXY8FpzQjanKgJ+3EdD+VLvM3yP9TeDiRkNPIO57NbeFW6aAinh5hgXBP2IzZujGnfsTEc7PfB47Lj/dPdgM+HsMOFobIqtEelsrQVVbhlGQsR+Np9O/GpO7bisTe68aMn38F+pReMzP3bu/BgNbPyV0XZ93thLislS1XFyOtEvVjaamairrwUc8kzw4sA0HqtK3eJOTvfZ4QxJo6yn6k/EFWnqXr+aQDAwfddgfJSBy6aW48+Hmome2Z+9dx+/JKH/sjW/AZhGTcLbLbZs0UpYwA4dO57AQC+ar53UHVC6uTd1CTe1+OyG9XMJOGOxkUCCABM4eG6w/6w2GvO3c88c+OXMUXjCFdmwA9dunfV8DiVX25uF2M2EtztcH70o3j93EvxyIzF6Ktjwi/Fu5MSI5Q0Hv9OSi15S2REDwyeCA8A07nhioQ06vuzq2Iabrx3u6UCSdB1pDWilgyWMeaSC7EVFWhewnJX2o+xzyYD0MzAkFCue901GQsAuGvMezMxc3wAHz5rGqrKHGJdk3AJALd8iN1L7cfGTH1m1CpJZN2nakyqoC6HVloVLKEws8Thw4h3smIRXqV8bKrrLCszg9wgOdt3jCmOXi8SR44gYHPiQGWjsIDL0FqlMZBnRrVeU2lmm83orE6NMylEsNrtxLQatq/RNegsNyI+bDNnin0vnWJ7aMAn+m8BwEtTFqCD38Px9nbMi/OiQi2s1K7lnPPxZGqaKaq3SWuI8oFUL47M+ZcZ5ajlfJmD/Ww/mzPFmJfzeZGYHR1DgMcDx+WXw/nJTwJgYa0yTzedjQXTqjCNX6dj3qCp/cBYMCoMRm28IefC6dV4D/ewvMnDzsZDUfxGyvmSy0MLrwz/XuBhdE01ZUBJSVL7BnVPtfLO/A8PYfyb985GtduJ97ay+Xp6yGhQaaXoQ/bMpMmZgRRq5g/HUFnmwKIZ1fj9l5binpUXCmPt1KpSLJ5dJ8L7ZIziFua1rUZ27OtNVmboGtTxcwaSMnN0xKzMPJWiAuSJJPXKPQno5JvcLJ5UBwDNzc3oVvId0tHH+x0QR7hXZl5t6lriVJ559wD7fCjKihVdo+ygcfPGeb3jw8KzMjWNZ4ZCyyCFnH1mIQs5eGTPVgwHx7BhH7Pif7x1iUh+Ju8ICVKfHmFWtmcajOot1H+ANjk6BBZHjfhLuSeJFeQBonr9smeGcmAI2VpoKs3s8qC81AF3TSU2NbFcjsiGDYhQLfbLrxD5AomBASHo1FeUCs8MJTZDihUVyhMdbmNjSPA10xwcES7Z07glRg4bIYFnFykzIyOiCWPdDHaoyiEi3kBEKDOOz3wG60//ENqrmjAaiGA0yJJBAaDk+ecMBeyKK9DPLe01PGSw2u3EuUOHUBIKwjZnjqlZZSASw6uHhowOysLj5BdNCCv72XzJMat0CB89wq2wZWUoqavDuMdQlANS01ZyKdN1Ic+MihAmll0OSMK947LLcMmCKRjifXa+MJdtdrX7mEWUrFsEhX9QmNmc+ewgrI340RowDonSAWNDpHCYDy2cBvubTIAO8Jj6+/cbHrayKfX40mXz8bFzpmMsaG54aCVEgZem/d5ju/ACD6EDgKNlNfjVAFsvonkleWb4WumomIK6cpcIM9vPBU66B+srSuHh4T0fgxF+5+KJwN1cOe4a8iO2YwcqBo6h212LxAUsl+Xi06ZgkOeWkDLTNxrCLze341fP7UfXoN/kQSFBUlUMRoNRPD+VCaj2iy+Go54d+oM83FWEY0lCv8kzw/eLcVnJpZBHXjEMAGbwctlefwTBSAxlsTBOb2dzVf5hFq5xeMgvcm/KpUppqlVYptcbxK+e249fPbcfw/6wqSdISXMztl1zI3541lWGZ5Yq01HpeCoYoigzVogQGKmss+eYeb7I0r+reibajnixap2h0PjDMTyy84hYd7QHNlaVwe20IxCJpQyXIi+HXFp1Zp0HZU4bBnws72q4hq3F6cM9wOgo4qWlGHV5zGFmQhA1hFY398yotIwP4J+uYEo8Jf/LygzFxPd6g0LAZWFmZlGBPotyt9RS5bIlWzUKQVJmYvv2sXDO8nJ4nWaPiyqA7epmvUViHuN1b57PPHXkmaGSzHt47sLweLLSTMYbUqypoIwadiXCzEpKhDJHoVtyaWfa13pHAvCHYzhcbuT02WbMwNRK7sFP45npHBiHj/ffeqdqOkZdHrRXMoE4+vzz+NDBV+C3u9C5kHls5HwmFfLIhBRjphX0PoEIG7saYibzifOacYgrarFpRgXOg9yoI3tmKJSLlAiZkpoaYTDqnspCYGfVs1504Oeuavk/xNcXhZidM7MGZ/My0K/zQgO/39aB0WAUF82tR0WpA3/dP4B9/MxXQ8yIz1zYgtFABD/fxAwnBHkl6HqQR5N4rWMY2/YPwOOy4+8uZgrm+S21cLvs2NXtxX0vd+Izv3wJ//Godb41eWbke98KCjUDgCXzkiOJwPea/73xItx+vRHaTdD7q4YBCjU/s5ntE7vTeGascmY6uAILXljh6/e/js27jVSLd4PUq/wkoItb2VV6FAH88ssvT/pHHFM8M5sPMQvcvJoU5XAlZaatz9Ds5TAylUA0jH6/FxXOMsyv4wlkgVGR8zIljWdGbpxJXppp5bW4Ys57EIpF8I9P/wIjQR8WNrRgXu104+DmgiVZwMo3PQkAeHr62UK4of4hpXTIcYHk9DHj+lFohiWhEFNcXC4Rq5sYHhbhWKOSVwmqZ0Zumun0oNRhQ2WZE49NZzdc5IEHgNFR2M44A2WzZmCYJ3HH+/uFRaD54C7A54Nt/nxh6QAXGiHdbORxiu1n3ekBYLoU/kRhZmSpTwwMAKEQxhxliE7nFsKhIdF3pn4mE5pFk8dQFF+8l+V0zG4oR/W1V+OR8z6Co546jIdiGA1E0F9WjVfqWQgAAgHYzjkHJY2NOIxSJBJA5egQkEjA47LjogGW32G/kAmxxI5DQ1i5bjs+e+dfEYrGhfLp8Pkw12esv4bgqElQH+HdhAOHmCJHgoLPYwg043yu6ECdWlUqrEKpPDN0YHuWf1g85vjAB4CKCiyeXYeZC5gHsTnKDpoZPex+Ubsek0WSDiuZOV5j/VUPGQcG5ct89JwmhHmTveCHlgMAehzGuiMP4Hc/eRbmTCnHpy+Yic8uYUm4VvkKL7UP4Mu/Y0UKLrlgvugP8tLc96Br0I9tBwZFzhlV/SKL/xFPHeoqDGXmAFcKqQBAfYVLVGqr6TASj8u5kkaeme7hgAgx2zBzsYhDvnTBVPRzgwaN65BUQr17JGDMSaldKPVq3kyvN4A7F1yBv/3CT+H+6U9FtZsBvh6EkkaemenTTe+blJMmW8N5eXbIygwPM1s4wstML1yIaS3sGh4e8ouDu6LM6GGj9mORkYVfq+IJ1F+Bklpvf3IPequ5Arp/PzNKlJWhpKbGSP5PIdBRiKqMbWwUVWG/+B6jrzEF7nBjC+rKXXinZxTfeYSFHv74qT34zsNt+PhPmAGD9sCKMgem8oIXlDOmoibyElTdb1/vGAYqmfA14xBTPBKNbB8058xYjzHAq+sBwP5GJnB9ZmocM+o8zCjV3w9UViZ1PKewEipewMLMzO9NYVdkHVYrIsleCDK8BMIxPLOrF/v7fOIeo1LftpkzRTUtQg2N+fbDbVi5bjuGwdZQwObEwcVMmZnt62PKDOXL1LAxqfcGLBLdSWBVS/BSmFlJibk0NeTcKLdTlKg+NhpEKBoTHhXwvbic56GFonHh0VHpGBjH1ikL8MKXv4vffPALAIB9lbzFwm9+A/DCEEeD7PNFmJnidZHnSa5Gp0KGEFLghILHjQ1WzKjz4A/LV+HLF9yAtpmGd4U8M7IyM39qBardTnQPByz3YceyZSipr8eLLUwemN3A2jeAG3DUxrWH+O+kzJw9swYLp1fB7bTjyHAAG9t68DvuifnKhxfgMxcxA/j/vcTyAnccYnsVeXOIFUtno9bjwtb2fpN3hmSQj5/H5DkqZkD8zzMs3+wL75tjUkjey4sK/Nfju7H76KjJgLqr24s/bu8SFdgoTDMdZCwAIEKRc4XuVdmoQpEdHz6LrTG5lQVB10D+ntOqy9BUU4bB8TC+80gbXtjTh3/6A5OpqY3Cu0XyKj+JkD0yMk1KX45nnnkm6R9xjCfOE//75kYAwKcXWndmhaTM7OpnNwIkj44VHV4mrMyqbkQdr3Y1GBjFMR9btA2SUKliVZoZAFYsYmEaj7ezrrlXtjKhS7ZC+kJRhKJxnO87CvT3Y6C8Fm/VtghLsdpMjYT+5gGj83I6z4xIpG1uFsKVXPVrhCsgdLPIpZnhcolqJxGeY1LtdqKtrgX9Uq6SY9kylJc6ROnWxMCAUFLq33iFvUbpokuHLblwaVxyV+GKoE80CZzPK86QlYZCsbo9dahq4tezr4+93uVCVV0VPC47AuEYBsfD+PL/7cA7PaOYWefBvatYWJjc6JOEkienG0K8czkTvI+MRTBcWo6SkhIkBgdRWebEewaZMuPggjTRJiU2vtk1LMZV12N4CMFD6OTwCbru5AEQFVl4GBwAjPMy0mSRmVHrEfHWaolOSIdbRakD9nPPFZY0x4cNxYa8Son+frTUezB9nN1raula2hSncAslAPjd7Ls1eI37qtbLlMnXO4fRMxJEVZkDSwcPsAIQlZWoW8HCTQek6mXkwXA77fi/m5biO1edJVzhasWV0UAE/7CehUFdu3gmbvv0OXD//Oeo2LED0VU3AQAeeKVTeGZUD0ZvWQ3qyktRUcoE1XA0jq5BPwZ5AnR9Rakh9IeN+akaZgq6CG+JhhB5mu1RjzefjyZe7nLOlHK0zTsP6+Z9AO1nMAusnOd1dNgvLGxVZU6hjKrWZ1JYyWJMoQY9Ln6P9fayMuteL1BejpKaGrEGKjKUZpaZyUMfAda0kHrL2M85B6UOm5hveh/5vdWQHhnZKkux87LFuJIrRLTutx0YQIeDjY0KUIgQM9oDU1mclXHRPndGzItAmBkqsItZVyMLzsBvvrgEZU4bNu06hu880ia6ptNeTONia8SwNFtB+RxqedbTuPFlX+8Yjpax71N3gO1tVOFMvn5Wla0AIMDzPyMOFzbUMe/LBXa+B1JTUYs+LPS9KdTH5UgdZraQh/KqMfeyEtrD1+OtD7+Fr973Ov7mrm3Y2Tlsqi4o520R6u90nvls7Hq9VdcCR0M9IjV1KI+FETpyFLE3Wf+hd3gupFXDWhLgDc8MV2aUz6MwM4fNUGYoH4XmrtrtRB0vUT3oCyMUiaNLrvrFFcVMoWYdA+MYKqtE+dKLULfwNAAwEu55KeRHZl0o8qxSzTl9z0A4Jr6r+hpIYycPqdH0Nr2nwHn6Auysn4uOsHE/iUpmUpgZAJzPw56svDOlX/0qyp96Cnc3MYMetS1o4iF75G0hzwEVAWg7Yigz4BVLAeCf//gGRoNRvP+0KTizuRqfW8LW1p93HsHvXurA3t4xlDpsOHeW2bBc5rThxkuZEfKu5w1jKBW1WDKvHvUVLgyNs2IGALD94CBe7xyGx2XH59/HSvwTpMxQyFzXoF94OL/9cBv+87Fd+O4jbD+pzhBihiw9M5mgMFZ5P6dQ88Vz6lHtdmIsGDUZkeT1rXL3DRehxuPEI68dwS2/Z/stADz3zrG0XvDjTfIqP4lo4WUOZQ9Nd3c3mqV4zUzIzSe3Hn4bB0d6UOeuxLWnpy6xWcErEsneGCoaYAVVMmupbkQ9z3sZCoyJz6ZGmFbUSj1oGqXXfbx1qSkE7ROnsbh3kTMzOCgOjCv72c3x+gK2MZCQTwe5GmbmGTOuSWJoyLIzOCSLdElzsxAa4wMDIqF0lF8n2qhVV2bgyc1Yuvw/4OOli0moeus8Qzlx8uohXq7gJI4dE8pM2cu8SV0KZUbUTqecGaVpJSktDRWlqHI7MegLY8QfEePqcddg+rRak0BDlbyotv8X730Fr3UMY0adB7/94hIhoFG4jC8YFULVc40L0Tv/LNjPP19Uyzo6HEC/pKhVljmwyMtLdvIGh4RsGdp+cDBlNZTp/mHTtabPX3GQFQewX8AE4X7e9BIweuJQc7mmGrdYF7ROZOj9KZ68/IknULFjhxgXZGWmrw8Lal2YEmaC0ne39GDRrU/iPx/bJTxItLkTTouxNfAqg2ThWX72dITuugsA4Pr0p1HbUIMVS1vgmWpYqOTcEtp4qdKXGt7y/J4+hKNxLJ3fgLWfNOf1XPMeFm64adcx+Hmu0dF9nXh2624gGITPU4WQwyV6a1ARgIP9PskzU2rqCk00+QZNYThL+ttREg5h+9QFGC6tEJ4ZAGi49L24p/WDeMrNvo9soeweDogDiYWZse/i5Z45gsL6SDCg++6Yg31OYmhIVDKj5HmygptDwSRlRhlXzFWKqmgQVbzs97HREM4ZZvu0nRd/oJAESAYPSkhVrfAy3SZlhs2hLJCpOQ5DvrBoyklNIMmTS9Zpq0pmUJW0ykrYeTnVRXG2R/Z29qC0/xhGXB64Z8/CnIZy/MuVzCr9yGuGUQhcgJdD6kiZtOozRIotXReZVh7+uf/YGI6UMuHLHmb3rWMaE3DlkCiy0qshQkEX26t2VTThYAVT0Eu6mMIZo14sUogZQRZyiqt32m1JSeFkCDHCVMyWXasCAFR1yheK4gt3v4zBGim3ZNYsoUzQfawWBCEBfvecc7Dn7PdhU+NZqHQ7EGvhFcTefpUVlQGws94QMlVviFFGnI0hVSgOhZmVlBhlj6OxuLBw09zVuI37MByNo8tj9swAwDRSbPm9KUKJOZ38Pp/dUI7Tm9h5sa/KMNr2zZyPA5WNIhyMQsjlCnaQvDDhWBxhvsasQtFExULFM0PXJBVWfUZoj2rlSjhBXpBDUkiSTP9YCIFwDFVlDjHnjVXs/cl7cekCtm4P9Y/jtY5heAMRTKksFefJuTwJ/oI5dVi97DR8+yq2r0+tKsXKS5g38kdPMkPAohnWETKfuWgW6itceO6dPuzlebVyw0gqNPBrruz8+nlmjFyxdHZSHt5lpzfi1zdciGf++QOGB5+H4ZGXhpS/2vJkRUFlYXM1PnPRLCxf1GRSbHLBan3TnM2s8wjvqlwVboQbyCgKRqal3oM7v3CB2FM/eEYjWhsrEYrG8cKe1BFMx5vkVX6SoSb8qwUBMiEXAPjtW6xJ4d+cZYShWUGeGZlOqfSyCuXTzKqeijqugPT7R0SJZtn7okJ9Ziq4FU3m+jNZ7sycmmlY2MAUOzlnhpSW93WyOPX95zEFjZQcsgioYWYqcnldGaqMZWtqwt1vsc2FSkKXTJ0qrDmUiKyGBRgbJLuZPnr2dNy76iKc9/efh+uLX0Tp174mhA6Pyy4aUiZGRjAtMIyS3l6U1NaKajtEeakDLodNHFKqoEXIXieqYLKvdxQJbuk64qnDrPpyk0BMygwJxO3HxuB22vHzz7/H5Fkgy1YgHBVekpDDhfs+989w//rX4j27R/wYkPKBpvFSvP7ahqT5eItbnQDglYODKcc1J8o2RfIIjfgjuPLITpwx1gNf00w4r78eANArhWN57ebQvNpylxBI1PAKSHMpkpMtELkl/f1YZGOb48jUZlF5pe3wiNEwUwkxK602H3wA0OwfxmgwKgo1fBx9iPNmlc7PfQ4AsOZjC/H01z8gFCmrEsZ04Ko5M8++w+7hj/DDSaa+woX38+o2L3CdeLSrG3ffzxTq/gq2LmhzF3kzfT5h/ZULAIAbAcCbHlK/HAA4f4jdQ6/WtKDa7TQJtHR40+tlJejYaFAI8OWldiEAqKWOqbQpGRmol8FoMCq+U4znvlBeCVloK91OofyYhEBpLdrOOANj05iQNoPncvV6Azh7hCszPMyQPGSQFCqjEmHymiMoVwVSeXRZaKso5cIuX6MDvhB6eW4aKTOkpKWtZKbsHfYzz4SNRwPMj7D71Pcas/Tvqp6J6VzpvOY9M8RaaagoFeE1A76QqULZFL7mrYoAyK9TIaGw/dgYOrg3jXA08/mSvAgiZ0ZRZsKlPFy6diZu/jtmhKD9O51nZkol+97k2bQShmnvOG1aJVwOm2hUTMiGhO5hlktCAvDneBjoroSxBzDPDPv7Br7PqrlGdJ69PO10bLjyRjw+8z2o8bjgnM8s61fveAwA8MYFH4JX8kqPKN4ZOQcrHXI1MyfPGYrGE0lzV+lmZwErUR7DSGk53px+Ouznny+8T+TtevnAAP727pfxvcdZbg9BYVSzG8pxZjOb87GKGoCHa3fwyn10phqhheYxOB1GrxkqAKCGHwKsBDuka5HtNZnFK4518wRw2p+sBG1SAn730iFTw1GCet3NlsLTVKPXxfw+OzTgE53qPyzt3yveOxuvfPcK3LvqItx02TzT33/lwwvwrSuNvEg1xIwoddhw3QXsvt+8i0XZkIGqrtwlcmIefb0bj795FK/wni8r3mt4FompVaVYysPBKCd1X++YZU5KpuR/8BCvWz9+Jn70GXPodi4Yxh9DXghEYnA77ajxOHE6966q1d+gVDKTObO5Gj/7/GJ8aGEj/mfF+aIKIhki1TPpRJC8yk8y7rjjDuzYsUP0mVm1ahUuydC4TKaPJ+EPBcbw0B5muf7COcwbkApZmalwlgmPSaryzKTozK6eJiqSUSW06RXp4xxb65rx6HX/iT99aq36FL5y4afw6HX/iT988l/FY3LOTP9YEOcNHkJVkOWVxLkni5JRk8LMlJAKqrqiNpAk6PGdYTee6GAbD1UBK6mrExsrHX6qJU1YH/nBN7WqFBfMqcOs+TPg+tKX4PzsZ8Vr3S47BrnQPzU0hoVRJsxREzIVusmOjQaTxkXKg1xWmvJmuncfROjHPwZ4kujMOo+lMiNvij/6zLlCeCUottgXipoSsNWQkp6RoBhXvK8P08bZRjhaZ67c0+sNYsQfEVaUN7pG4LeZBZ3gXBa+NTPMBK0Rnhztjobw9/tYZawXPvI34vXdMMYwxHvikPu8rtwlLLlWBQDkqlmpkMPMFvBqO7ttVeJg3H10VISq0GEukIVIHm7XFBjGeDAqDsoZb7FePM5PfSqpgSTdB+rjAITQKSszwUhc1Oq/hLq/K1x1PhPQ/3iQzeGU4Cim8QIi3R62Lmjdyb1mBrnxwBRmBtY0LWJ3oCbix779bC26nXacP8y8Ijvr5wrFi1jEwyZ2cy+dnDNzdDgg3P9VbqMAQK83iH/6w0781+O74Q+zng8ARCw/WQ+9/rAoO03KDIVjCc8MV9LV0BRTr4gFC+Dl67eZ582UdhyEJxaGv36qmJtmbhAAN0DAJESZBVUZyi2CFGYmKyMkPI4GIuJ69Lp5cQMeAkuhlqnySQRSCWz7woViv2keY2slsZsJnW9XN5vG8+/XnI1qtxO3fuJMEV4je2Y8LodI/LYKLUpnLBCemT4fjsRcIjEcXEmj+SRh36qyFQA0v38Jjs4+HZf+7Sew9KIFzNPr8yExMCDKMtsXGsIeQYYHUsKsci7kksAktFHcPe2H1IB1PBQVOQenN1Xhb3lozl4eGggAJbNmiX2DPl8tAED7VPewX1y/qjInPGewggZUofOJswzvMaSQGUJ0upcEd6HAS3t5TGqaSQpdJBZPmjsq7TwWjAov2S8++v+YUYvfC2RY+M3WQ3i9cxhdkseVlDwqWHPurFrcu+oi3LPyIlQ88QQ899+P/otYNU+6BrSu1ftUhMNFE0aRAIv5Mzwz7P2E4TFVOCZnOt+v6B41QsySDbaNVWV47/wG+MMxbGwzzmJCHTeUc7e8lFXvAt/Ln+R5lNcuNkpE10vnmBWfXdKCe1ddhKoyh2W1L2Imz00hQwoJ87XlLkyrLhOf+S9/YsaN6y+alTHnZcE0tr7bj41hL/d6fGhho7h/s1FmCgEZf8jYQGG8tG+RZ+b+7V249o6teHFvv7nXXwqWzqvHTz/Hiv2QgvnC3j6se/EgrvgRK+50Ikle5Sch27ZtE31m1qxZoz6dFioA8MheZmG9rOUczK4217NXodLM4Hkw1FwzVXlmCkdjYWZsYbwzwKyU6XrMEBfPPAsXTU+2kNW5K3HxzLOwoN64eYOOUsTLylgC+8Aw5oyzz7afdZZRqpUrMyI2mAsQshUyVGLHW7ySl1V55sTIiGj8+MejMQxLhQrAhX7aWCksQY1xziapkCgvdQglpC7sQ2uE3fyplBmy3g2Ph5M8HLvnMSuGXNxgPhc+F959OxAIYPuMs/DstLPQ0lAuvF2QhOMVS2dj1fvnYs3HFuLS05m1XIY2iEA4Bq9kheiTKtaQUBngYXaJgQFM4Tkiw7Xm96QQs3Nn1QrX+c7OIVOoWZx3cG8KMIFtjIe4fe7QS6gLj+P5qQvxYqWRZ9aVMA6GfhtfG5LFhQ40NVYc0sZHydZW2EiZOXZMCLVdPCyGILczHeaEvBapUl1TYBjD/rAQYD1vsER9ObSNsDU2omTGDFPcPSELUTSObfsHEI7GsWhGtbhPVK7gJWvfHI7Ab3ehKhrEfN6s7gi3kFN8PCVp7+pmzVg9Ljtzu8sejNZWDFezazSwh5UMvbSRlSb321m3aBIOiCq3Ey31HoSicew4NGSy6lPcuAhv4Yfh+m0d2Lz7GO57uRM7O4eSqsdRbLY3EBFljKOUW8I9GCT4UOgAKTUkCMrzZVuwAP18XDP5vDd2sDK/3vlG2BIJCJDCy6yKC6iQMgvJyyQL6nIMOFlQe9yKssvHSXuULHwn4WLXx7ZwofDMNIywdetpZ0L/O9UzTHNVX+HC/954ET60sFF46wZ9IakMtUPsUVY9KtIZC+rLXajxODEeYnHsPVxRA58vKu9O11A1WhG1//INnPbg77Hw46yJKu2lof/5HySOHYNt9uyk5H8AmML3c4IEZjlUzy39rObN0HinVJUJZZ28oqc3VaG51g2Xw4a3YfbMkJJB100N+yJF4eiwUQij0u2AfR4vvALg6CWX4+0I+3v67NSeGePaq8I91DAz3jgzGkuI5tA0d6IQRyCc0mOieqZHg4YRrMPCQ3HBnDqW31FWBtv8+XBVsPuPvh81glXn3BRmls4zI3Jm2DVWy1Wngq4pCcSkzMjJ/zKf5Aaih3YYbS4Iyt+Uk9xlZWYG/ywyHPnDMZzZXC3O8my5YE4dHvjyxSLPxgoaFylpNDdkMFr1fuadIW7gIWzpIKPEvt4xEcJ1wZw6fO0jZ2DV++dixVJr2abQkPGH5pp6zFAY8Ptap+CzS1rgctiw79gYvnrfTuFxo/MuEzNq3Vg4vQrhaBw/fXqvZbTH8SZ5lU8yjvGkZErm/+j81H09CNkz01LdiFm8Uk73mLmiBbFvkHkrZlVPRT1P9ifPTGOaSmb58LX7d+KIjd38/p5+tPAkXFtLi1h41HGcXP1iI5UEkuHaqejjoRmUQyIYHUXg7/8eicOHMVA9BTsqZ5rc9lCUGfLMmAoASBawtIIExyMpMw2hMcziJXtLpE7DMnVcQBvwhZLCsfwLWaNHeVytjZW4sX0zmrsPoGT6dPzrgqsAAHMarMPM5k2twD9dsSDlhkObvi9kLgdsruLDrn+03sgtqR1mQlKf0rCVEhvPbK7GhXPZd3h5/6DJ0u/kvXYa+Joe9ocxGohgWS8Lxfrj7CViExrwhUwd5YftboSicaHM1HhcwtqtKqGQvGwkhFpBRQHi/f2o40pat6cOLqmhGdWfJys1YbL0n3MO/M4yuGMRdO1lMf0LnSGW11FWBvti1v9Fpuz221H+5z8Lr44KhQlSqMwzPHzASjGV+di5zKJPzSvP5aFTB53sd0rWJms0hYdQLX55vuzz58PHe2dUDDJhbnmMKdiv1zHrNH1PGYrt3sCbNtLhTeFspBBYhSi9enDIuO+5YECWY68/AhtVkeJVyUqam0VIgBz/Tet7nARKeVxnnIEe7nEmJZbyZcYXGFWOZK8TGVTIiqqGEMnIDfNoLLJ3gITI0WBUCM6ywA9JScumf4br85+H47LLWJgZ32+oBPqUwyxO/p3q5qS5onAwCj/tHwuZco9ozFbGAnHNLeYQSv7BMY+0PzU2JhVRoDAzq3AwGdsctuaiT7LKl67Vq5VXMFQvKln2ZQt/mST0kmWXDDJUBW1KZam4Zs/uZvcfhfvOaSgX3k6UlaGkgVnwIe0VssIrhykNjoeFoaiqzAnbnDnwNs2Cz1GKR89cJu7Js3g+j+qZIaFODqkSFc2kuaICAHZbiciZicTiIsyMDD3y/ZWqHPLUqjKcNaMaD6++WNzP5JkgI8UcngRvhfr9kkLIOTRH4WhMKH9W64LubzJ40v8UEp4KI6ScGYoO9rFrrSb/Ex9c2IjyUgfe6BpJ6jJPeRuzpXFTzgwAzOQeG/m9r+bKUa4017qT8r5kaJ0eGfaL8H21WeSVPJTq4+dOT9oLrKBCHu/0jOIdrswsaKrCNe+ZgX+6YkFSjtHxgow/ZBwgRZTCgCvLHPjWlQvx7Dc/iAvm1CEUjeO3W5nxjeSsbLjiLCP87wfXGU2zTxTJq3wSUe4sQyAahi8SxN4hplyk6y9DyMrM7JppmFnFhFFK9Cc2HdqJ8+75EvYNHUGp3cmrmbEFSvky2XhmcuGMpmoM8UaMob5+UVGoZNasJM8MbfhkUZQFLf+UJmHNVD0z/q98BfH2dgSmNmHleV9A0FOJP//DJRjlSeTgQj9trOSZUS1pVhawVJS7HCIcqz40huk8GZwspSpGeeaIaVyd5VPQsIBZ6tQws091sbClkW/9G8adhtVQVmZsFjkYVpCQT5ZhOmzk6jkkiDmn8qINAwOo5l3TeyrMygwJAotm1oiqJa8eGhSlY/12F2qXMKG+gVf9GgtEEOzoxOzxAfidZXijbg66hwMIRGIY8oVN1cxGnG74QlGjUlyFS3jMyMonQ4KEVTUTQjRS7e6GvZf3v3HX4cNnNZmak8HCM0M9dADAdtppGOLJwH3tzOjwAR/Pv+DFDHJlRp3Z0vbCXqZEfuB0c3ifylW8FGcfTyg/h1fo6vbUmcIKPC67WPeQDnmTB2P+fESmsmtEQv9Z/eyQeL2Ol7WWkv+JRdyC+PTb7JrOnVphUgwoBloOU6AcjlcPDQqFmjqTU9GCofGw8FgQtqYmvMmTbSm3BtL6pntYvsds8+fjsJsJoqdFuUdxiM1b+AyjsIIcR08KCH13ubiAjNpfgvYwuRoZKQDjQWM903wRyQUAUhtUXP/v/6Hs9ttZ2GR5OUoaGmAPh3BN13aURUI4VD4Foy6PKWdOhh4f9IXEuCrKHGJPoDAwGTL8pAo1IWUZAIaqJM9xY6O4lsJKT2NMkRdEyHup7eyzTb27ZFQvAgnmJmVGup4LudJAoTTCM1NZKtY3eUhP54rP3KkVOFzegC33PoaKrSxqgsZDuUZyDqZ6DWmdVJY5gYoKjP36N7h82a14sIddi/pyl9hz1Ph9Ky+EVfijXJqZlGk5zIyUf0MxiIn3VhPzL5hTh/tufi9aGytF5S7KGSGjID1uxf9v7+6j46rue+F/JY3eZUmWZRtZluS3wTZGvMpYxihgbCc2IXEth0BQmgQEN4FYt6Uh1G2TVDePG7Qa8tDWedZKk8p52ot6udyLs5yb2/o+OEmDkhCok6aZvHYSQBZCGGQbv0myXp8/zvnt2WfPmTNn5JGYM/p+1tICz4xkec7L7N/+/fZvmyXBqu2yWWamyuGmMS6laC5lZjKwV8GR/d9kmRloWZjXzwwnzcwUhnJxxzXWtWhmZySYS5yZsYOZautnF4RyscsOKNJN/t43zo6qUnGzxOrxu65F5MAufOED/gbqV1QUobwohHMj46o7m2Qx55Lcy+W87RtyBjOiojgfD91ubZor16v5Hni566Z6PH7XtXjinutxxzWzc5y8xJ/lWUQ2q3zz4hn89rQ1yxmuSh7Zl2qL8RsqlqCu3JrN1Tua/XKoDx88/Hn0nT2J5tqr8MJ9B1GWX+ToQIYke8zMxLqactWadnroLdTbazDyVqxQA3zJFAzaAzk1aNcGWpPLlqlgRjaZA4CpX/8aU//+78iprETntofxVlEF/uDda7F6SRkKF2ubgVVVqQ8Y+fCLawDg8qGRSElhHobsQLB69DyusN/rRMFMrB3mJWBB7IO/r2QRGhqttSV6mVnJT4+jYnwEvymvwRf+w/q96u2LWbIxMAIbL/LhJwuUK0ry1Q1RZpZll9yiGnvfkrfeQulb1ns9oG2sBm2NROPyCpUO/+Xr5zBWZP2OshGb7M+wZOQs3h4eQ/4PrIFAdFWj+kB52V6UPhIqxFiePSuTX4zzI+NaA4DCWAMAl5ljmTl3q+nXSVmebCy48rorsbepLi6lr8+4QRscS+btgl12d+EVK4i57qTVbSlkd5dK1bJK630bfHsEx189jXMj47iiosgxSHSzobYCkQO7sOVm51qCN4or4zq7rNY+wCVgkAxGTk0NUFqK6WVWcLR8xApmyn5u1Vz/xM7M6OswxLX2eyeDu5XVZZDABNpM8Ppl5Xh01zrsuWE5/tJeIBp57SwuTUyhojjfURYks9Dj1c71Qpeql+DA/7LWhTxotyiFy+Au54orUHrsGEr+8R+BoiK8XGB9KC87/xZqhs9g8dh5XAgVIkdry62X88l5JOVrbtlAaB20zJlPvVRGAuwzw2OqDT0ADNrZNCC2pkpmyhN1M3Mj2ZlP/9LaC+jg2p2O2WOT/DtPnhtVg4CywpC6vmayJk2ftT230G52Ya8DkoGouWbGK2AD4CjJLHr0UcdzOjNoc8vM6OsU1tvdt14ZuoiRsUktmIlNGAlZRyBrLCQrAS2TL58n+n3J7R4FrYRmXU05FhRZpaWwJ/AkUNTb2EMvf9Ym2WLBQiwDNK02zQRC9r99YnI6bs0M7OAJ2p5CZsZEzwrI4F3WzfT+xvqs8yqfMttHqzIz47yOtZDWy8zizwuzrE7+67X+REj512unR5IGM9DWIv7DD17FC9p+LRLM6Wtm9EkvGWxvu2op9tywHO0tq+K6h6WTXOPSmS/R4vdUrLWvDdiTO8kaLMwGmUCSaguZCHCbSNu4skplWpFiMFNeFMKd1y5Te9fMNf93+ACShfvR06/hreGzKAkVYvmC5L26zTKz5XZJkN6q+e9/Zi24bl17C/7pni+odTh6q2VoAVW6rK1ZoMqHCofeRK29fiKnoUENqE5dGMPo+JTKEqhBhTYbnl9bi5OSmdEaAMhmfpO3bsXz1o/GB+zFb6EqrdyhslJ1QJKLxewxLjfeZB+ysG+iUmb2niW5qLQzGOaeJaKqNDYbCsTq3gcXLLJ2mC8osEpp7M5lE8eOAQC+s3QDnrcXgtfbNy99EbnbgnI3sku6zPyXaztBy8zOwGk70LE34Zx+6y0UnbC6Cb1SXIXnf2PtRP93z7+Mc6MTWFZZjIUlBSgM5WLTKit4OTNpXaInK60ZdSkTqh0+jXMjEyj71x8AAPrW3YhVS6x/z+/evKDel2j4OvzmijV4q6gc50cnHAsbVemCy2BLZo6TrXeSUjMpW/qTh3fhxhULVctWoWcxoAUzUu9+3i7HkgYTq/ustQozDWZUYHl2BN+xdybeut47K6OTTm3i9ZKquBv7Km3wIR98edddh6IDB1C4bx8AoKDBunaWDZ/BytA4pl99BSOhQvzK3qHcXDMDrd2tWLm41PE6tZi+IA8f3bISn29tRGlhyLGHgpkJU9kMrR0uSkvx1z8axBtnR3HTqkWqvh3aYEfvOpZTWYncK609MPpQguG8ApSMXMBHX7bW1v2ssj6uPl8GOdLFTM6ni5cmcOTfBvDPPxt0lJy9bpcFysJfYc5Ay9+jdz6TJgA52jo7CSTcZqcT0dfp/a/a6/HCkisd7bNNssbjNft6l/dOBppSBqZLtiZNGpYAwOnaVVa7d7vxjQpm7EG16mbmUk6kC910E4oOHEBRZydyXRb+C3MQJ3vM6HvNmBNUcs7+6HenVCvqJeWxMjPYk2oSvElJlWw8C8Q66kkwpZctS8mUSS+D3aRtKli7sERdrzKBI+TP+sAyNriPnYt6mZkeJKhjpwUz5fbaCrn3ex0LGTTLviW/ecPKaF1pB3puVPdM+3yOHXPncZC/d3xiSmsA4NwjCNrPk0yi2mfGx2Bb7kUvvmytQ6wuK0wYlMOenJEF9H/w1I/xq8FzeOPsqPpePdDTA2lZc7ehtgKfb23Ew9usrMFskXNV9nszr4OZ0CclpOX2XFNlZvaxlutTglLTJ7bG3mdzAi+TJb7issASO5j5Qb8187imyt/+NHowU1cey8xImdmlyXH8919Y3Ro+em1sE0EAWGJkYrw2zJyJuqoSvF1iXRR1/VEAwGStvTGXNpiWrIC+14OemakIr8QbRRWYnrY3B5yYACYnMfF/rPbV/7beWouwJVytbnCFi7QMRlUVRu3ZoeKCkFpL8NrpYfz2zQsYHZ9SwYwMZLxsWl2NT9xl/Z2VL1uLidVA2YVkZuSDaaLA+rdP1ljHWLoZTfX3A5OTGP/OdwAAW//wo+oiljaTM8nMyA1YFihXFOerAaTcLKTMrGqFdXxkH5xThWU4OTKFL3zrF3j6xRP46//PykLo2Qz5YH5j3LpETy20ghiZnV02cgajb53Cwt/+CpPIwVtXX6/2Pjn+ymn1vjzf9p/xt3v/CK+XVOHt4TE1c1leZO1KDWPWs//0MN44O6pKBpNmZrRjZJYwyYZmcElp5zU3o+DBB5G/dy8AYGyx9b1V509j9fmTKL54DjnLliVcM5WMvtfMt+1gZscG/zNG+r9FNi40b+z6gFOVmVVWIrRzp9pctGSVNTBePnwK7z5vlZgNrow1+3CbHYNxLqxcXObI4MjkgWnjythg7gqjVEjtSVMW+7lji5ei54U+FIZy8V/2WOvMRLKF+ueGx/CaveZh92s/xkhePr4W3hY3GJJrrUwyM/bPPXF6GJ959md47Jmf4ls/jZWDyjqztTXljsDInIGW8/JVew+LovxcvG6vLZH1MtAGwQk3zXQh2eBTJZX4q3V3AFrZohtZMyiz1BI4StmX3Cd1P7XLTswNM4U+CDq9eh2Kv/pVFNrZFLNEKPZvTPJxXlZmnZt33mk+E0cv93ErMzNn+yWY+UnfaZWZWVRWqPbrgjGYk4kAfQ8SCSTkOtOzd27ZLfO9089/mRiCS5mZtD3Xgwcz8wEAdiyDnJzYmpmJyWk1wy2Lw6FlS6UqwmsCT8ovT5y+qDZVrKvynrWXNUoSfKhjbgRNjgYAUmbm8ruoNXHGPjN+SsLlnvV9e1Iw0XoZXefvXY1b1y3ByPgkPv71f8UP7TbADdXx97+Htq7BtquWOjI2c0GyiD+3qyTMyauZ0DMz71ww4wxcZesOKec0bV2/BHtuXI4/vmM91mtZmkyX5O4XbBJYfL/fWiB9pY8SMxjBzKrKGqystD4cX7NbM3/j19/HubFhrKqsQUudcxBQkBdCUSh2EZjBTToUL7UGkBtOWbP8BStj5QNSgvHbk9YHq6OMRVt0vWj9Gkzm5mFINnR8801Mvvgips+cQU5dHb45YQ1UZN8LGAP9S+UV2q7BeSrdf/jHr2HP3/Ri55e+qzb48rqxi/ddtwzrNlilNzLoT1RiBu0DTzINw/aeCkX2ngMy6J8eHLR2BT93Drnr1qFp03p84z+/C/e3rMIK+ybsCGa0zmZe5KYvZTEVJfmxHb/tOn+ZNa6tLFZlLwDwWskivHZmBANnRlC7sBhtmxuwvqbcsanXTXZm5i+X3YLHN+zGf4StMiJppVsz8jaW/sLqSPXjRatQUlWpbpY/HzirMjNVpYVq9ldqlGX2SwZ4chy/8K1f4o7/+3s41Pty0jIYIR3NoAWQQhbg6h/6Iu/661Hw8Y+rTQonllr/rmXDp3H7G1bJWuhma6PYmZAPphd+ewqvvz2CiuJ8bFzpvs+AG2lhDABDdmbW7Oyil5lJAwBT5SrrHK4ZPYuPfe8pAMD5a6zNUs09ZnT6ubCy2pmZSRRgbrTPGQC4wijTkuP4dqgIKLLO07crrH/X+6+vjZulU8FMghbK50Yn8FpJ7O/7zLV349cVtXELiG8OL8bu62tVplF+rtSQQ1scDm0CYPnCEsf7bQ6e5X4jnaA21FaovWbkGoHfbmaG/I98BKXf/Ca+9sFPY9guOU4UdMIl6yjZAvk7zczMiy+fwg9/a22gK+sJTCUFeeocNncKj9XAW8cm1prZ/78xGb0JgJRY5dkdveDyfsrnxHO/eEN14Fu8oEht3ApjYLfCnnX/3ZvnVQZErbEszFPniWRB3LLH0tVNNGn7iNQuLFafhfIZAe28W1ld6rgvyb9HP9+lm1luDhCy95kZn5xSwZH+90sAK2VmXpmZBvvf/vKbF1SXq2Tlr0X2z5P3Qa3NMf4e1ahgYkqVouVrx01IVl4yrzJp4accM7ZY3rpW3doyu3ni7uuxvqYcZ4bH8OffsMZk+noZ8fC2MP7q3hviSk1nmwTess+ZVH9cDr10UBoCzDW5ls4Oj+PsyDguTUyhrDAUd+7oPr+nER++eYVnA6BMk/hfkwWuKLMG3z89ae3YeuUif8FMud2GeHFJBYpCBSgOFaCisBSjE2M4NXIO/xB5DgBw37U7je+06NkYKXVLpwXLrRnmsgnrxqnXQssAQHbQ1WfGciorkXfDDci74QaUrFqBiuJ8vC6lZm++ifF/+icAQOiO9+J5e8H07VfFBnX6oP9ccYUqCyjMz1UDLNnY6tSFMdXpxBzgJKIP+GGUe5gW2h9EMsvw5L2fxb1b9mHhjdbiPJmdnXr9dUx8+9sAgPx3W/sLFeXn4pH3rFWLpvUAxn9mxvlhXl6Ur4KEk+dGMT0d2/l62cJitScLAPRrnZf+7H0bsP+9V+GZT27BR7bEjuOG2goUF+Tht+U1+GZdE87WWYGeBAwNF97Euoi12/X3lq5HaWEIW8KLURjKRfTkefWhXVVWoG5Ir9p7lsiMpdzMpBxBsjk/f+3tuI3hEtEzM7LWQMhsrbmg2M1UjTUAvfH0K7j/d/8CACrQmQkZ/MuH9DbtPPZD/3dNLLWuN7PsQN97yHxOVC8qx5t2+SQA5N9zD8Z+7wOAFnC5uaYu9t4VF+Q5PtgTBZh60wVz8zlpH/v2xVhHs3N2MOM2G6vKblwyMzI4PLxhG8Za78JfXL0HP1xi7fVhDobaNjfgwN5r1O/m9ne98LtT6jhJ97llC4sdmTBzrwy537xm13+vq6nA34W34b98+u9Q+Kd/ql6XdJ+ZBHKWLUNRQ+zzQr+PutGzBDJ4kPfCHIj/5f+2Sigfvj3seX1JdsacDJCfL5mMWGer1P6NXvRrVn6unt0yM3CbVi9Cgb15pnz2LCkvxMKSWDnrOi0TUhDKxfKFxZiajg2K1VYCBaG42WTJMujBv9mc5MorFqjH6qpiwfBZbc3Mv9m/2w3GBoqumRk7yMrNyVGlWuOTU67NUeT/37Sz8l7HYvGCQhQX5GF4bBIv2hsw6oGeG1nDJgv1E5EgamxyCuOT1u/vlpU0O+1JQOzns1q6jAmv9TK6ovxcfOVjGx33MgnsMoFZSpronp4KR2bmHcpyyL3ywqVY90dzXVw2SHzFZQFz8b3fMrOrqhvwd3c+ij9/10fUY8vtjmadz/89fjRg7Z5879VW/36TdDTDLKyZAYAlK51BmZ7BWGTPJkRes1KlNcagpvirX0XxV78K2DelN+xgZvzppzHxXat07pfXbsHo+BRWLS5zfKjp60nOlJSrWveywtiHj3QfAoAXf2dlsvwsKgRgzRhr2SNzcKxT3czsD6qfn7qEVxYsRXilNQiV2dlLX/xiLEhz2a8EdgBT/JWvoPhv/xYo9HeRy4eBqCgpcJT5nTw3ismpaSwpL0QoNycuMwMAt69fihY7oDKFcnOwUfvArSi2bqyyL8T2k7/Alf3WoKh3yTqU2wu+32XPkP7EDmYWlRaqAZMs/NNnvPUPcfnQ/80b59X7migLIPQgTbJh4varrsCRP2jBUx9PnmHJrXce64JPfjJhtyU/9EEUjLaRfuiZmeYtVyNyYJdjgTzsQE8+FGTdhJt/Dm/BG0WV+NXuD6Pw0Uexdf0SRA7swn9/eIv5UuVda5fgUPsm/HWbtSmZnhkwzz1RGMpVexTFBTP2+XN+dFw1kThbKcFM/PUZGzDHD55kQfXpZStQ/OlH8a3l1u8IH9e6PglQUZyvyulkQ9N+O3tYu7DYMZgwZ7rNgE4CZ/3+Ay2YMTMJfuhZbTNzZdKPv1wzMoiUJgQA8I0fv4b/OHkeyxcW48MuO4jr7t28Av9XayP23Oi8NswSQJWZmcG/MRE92yQDc9lrBS7HuTCUiy1h52SUvCd/8+Eb8Sd3XoVrtTVd0AbBL9vt5PWgTN9LyHrO+jfqEwhui8H/4T8147v7b8fmNdUqo6WXmUmgZW6gKO+pXs5mV5nZwYz1HkxMTavzXw9E5f9lA91kx0IG8d+2s5J6oOdG3u/h8Ul1TbrNmutd1xKVokG7DmOtma2f6XYvMJlZSn3tYDJVpQX42n03qf20Nq9JvoZ5rpjrF9NRZlYYykXkwC5EDuzyNak3G+ReeUFrZZ+oxCzI4s/yLGJmRfyWmS0oKEbr2ltw74Zt6jFpz9zzc2uW/671t2KhFrTo9I5miV5zORrCzg83PTMjHyCyG7N5geqWLyxRe81MHDsGXLqEvBtvxLdPWR9atxl7ckjW4mx+sWpJLNxmGKUBQbJF5LpcbdDvtV5CBpFvnB3FxUsT2gyt9d5La1YAwMgIQrfdhhyt/MSU19SEvBut8h8/9EWLsGdP1ZqZc5dUuYx01dLLsdY1rce71i7Gn9yZeBEuANykLWiVG5K+HuAHDdfj4L1/hreKKtT7LzvxiqrSAvVcn909R79Jl9gfkiPjk+pDf2xiSrWKNgeNJv14mWVm5UUhrFpcFjdb76a0MIQ3iirRX1yFP975CAruu898Scrk3C8rDMUNtJJasECVY+W6bCwovnrfTfiX/dviWlHr/mXjLuy57VO4dE+b+VRCZYUhbFxZpQbpehbHbRAn/ut/akbkwC68z94vR8jM8dmRcRT+0R+h+Ctfwa+vttaombPs0AImtzUzcp5U2AGjHmiY14VJz8y87/patR/Rd351UjUtKQjlorqsUE3MwGVAZv490jBA1rAJCSSSridxcYXWQc7rPgojmJGBopn5BICnX7RafX9qZ2xz0UQ2r7aaMpiBlPzbpczMa9A6U44yM7vESj/Obu/nbVrb87LCWGvq5tWLcG9zQ9xMt5QnvfzWBXWeyQBdBtVS7ipBxtKKIvVz3ZonrFpcptavSYcxfZ+Zn7xqBTPXNyTPzExIZkbfZ2ZiynU9ofy/fOYlazghawhlT5O1Nd7jBP33S1RiBi2DOTYxpYJcM6sJR6mi9f6qbmYu9wKTbEosVvlYM6OrX1SCb3S04FuP3OronPVOMzPl5vkaVKqb2aVxDNmZQ2ZmAsbMzKyy177MxEca343HNt+tvv5wk7Vw2Y0EMzVl/mv0U7HiSiOY0TIzcgHKB6hXecTyhcX4eWUdXr5uCwoeeABFn/scij7zGfzLr60F0zLLLyQz83ZBmSoHkcGutFyFS22oOYvnRc9geK2ZgRZA/esr1hobve44d+VK5N99N4q++EWUffe7KHriCfVcOpgzWAuKYt3M3jg3qhYyS824nsG4446b8P/8flPc7LlJ1s1A+7fmLF2KqXs+hN+79VP4/A134xel1iy7DHDfdeViR/CwsLQgbn2PXhIjM4gjY5Nxm8vBT2ZGLzPzGPQnU1YUwtdX34oP37IPo6vS07VGyhnMoNyv0KZNVgcvPTA2rFlSFmvLnMD/+OQWRA7swi1h9yycX3K+yGL6VMj5c3Z4DLmrViGvqUntV+VWWhLrZhYfzEg5opQ/meU+XvSsUuuNy9Wx+d6v38TP7Y1jpdxDD7rNgZt+XpYU5KkOUWZmZibdzIQEMIWh3LjF5ia9DbV+fORalPuxrAGR3cFnQs2qG1kLM3t1OfTBjuxd4rVmBvbCYeGVqRSycPx3b15Qg2n5uWbAJlmbolCeOi6y6N6LfD6dGR7DK29dxNmRcZQX58cFiGrNjHa+u7ZmnortM6NnRszJvGTHQl/cXpSf62t9iJxL0uXNLfuj7zOjNs106WYWa1tt/axUOo9CG/gXF+TNKONgrjPLBNVlhdCXF+n7bgWZ3I8cmRkf12fQeF9xAaeXeNWXL3EszE/VztUbsf/mD6mv9YsSD7SlPXO6O5mJwlAuztgB01iBtXuyMD9EzJSwbnlVCZ5fuh7P7GpHwSc+gdD734+B0kXoOzWMssJQXCo+7+qr8T8/8sf482s+oBZ5ykyO3mFpv5FxmHEwY+9YnYjMvElnFH1DqtzVq1H46U8jtHWrYx+adDFr/yu1BgCvnR6OdZOz3389mPEqn9OtrylXQYo+YCx/9FM4WVyJcyPWgj5oH6bFBXm4eU3s76peEN82Ux8kyvEbHZ/EWaPrD4zj6sarzCwVC4ry8c26Jozl5bvuvTITf/ietfjc7qvx+1u8z6NEir70JZQeO4bca/1tkjbbZMDjVl6SjJwfMpiGNoBxm42NlTLFZqqFnHMyIJL/+vm9yotC+P6fbcf/+OQWhJcuQF1VCVZWl2J4bBL3dVub2spASV8zY3Zk0s9peZ2erRVqzUwK9yCx9opyHGrfhO72TeZTcfTBgf67yaJ8CThkzYO55i4VZYX24MRYT+J3IOqHnpmRgbk+QHc7ZxaWFKgMmZ/BkpSZvTJ0Ia7zpbyHbqV0ktWQdWBe5F739vC4KjHbrGW8hWp9rGVmVGtmrcxsfHJavVa/j5q/S7JjsUJbZ6I3+/BSnG/9vXKfNgN8aIHL+OQUxtXGmvG/i7kHj5yf5iRdInIM/K6XCQq9IUG2ZGZkDHFeC2b06ztbxF8NWUQPZvwu/k8HycyYZW7pdKnc+rddWOycNdZnCJGk1lsCHckiQNspvWWtyyxyWRmGN1yH31QsU+UcZsp/8YJCbFxZ5ciSJKrxdyPBjKNMLAEZxPwwatXbz2UbQXNRbnlxPgpDsRm2Lx+z2mbLwCxXmgyUlqYUXH2oeQX23Lgc1xtlTHKDkiYDescjadpQnJ/nqD8X+k1aBiXnRsbjFiojwQemTq03+spXfO/R40b27YGPkh6/rly6AHdtrMuoUobL8fcPWiVkqTYzgHa+6hsISr2822RDbHPL+MyM/Az5mfJftwGum4rifEeb0tvs/X9KtH1zAG0jUpfzUD+n5XWSuZK9Ps4Mj82om5koys/FxpVVahNTL/okkn6/M8uX1EbCM/h9hL5XD7Tshd+BqB+OYMYeyCfaNFO3df1SLF5QGHe/ciPrX15566J6XyRQkNlkFcxox3HTqkVoWlHlaF+diGTUzg6PqaYo5uJ/aO+dY82MvWgmNzfWAOCNs6N4+a0LqCxxdiI0s0Tm+WrSMzN+/h0w7tVIEKDr++GMT0gDgPjfRTIjUuYmG5aak3SJyCSdvoYpG8hG2siiYAba+S2l5n4mG4Im/izPIvm5IRVYrF3kbzY8Ha6qbsDNyzdgc633mojLURu2MkNLGq0uQkK/AJOlcmV2RRaGA8D37N2I9ZbMOhk0y5oQuaFuWrUIu6+vxe/bi1r1AUCiDz43sgbDq5OZkIXssvnYOzlolQ/NZztuwcduiWUCltk3/dy1a1Hw4IMo7OhQz/mxb3sYn9/TGNejXlLgMvMsWSrYZVX737teLR6XNrZCn/GWYzNoB6f6rHKy0hqR19SEvKYm8+GU6PXvXtlEmhnJzMgeGdAG1m5r2sxSJp2UmcnMtMxKzyRgAID3XH0FHrtjPb67fxse3bVOTcjo7a7NwaFe1iPns6xx+d///jra/vYFfOmffz0r60nc6IMDfU2TvCfye8jg3FzzkwoJ5NyaM6SLo8zMJZhJ9Ps/eOtqfOePb0fHdmtzVS/lxflYWFKAi5cm8Iq9R4+ci2b76REpM8vPxYdvXoGvP7AJ77028RpIIefmmYuxzMyNLsGMHCf9PZXWzDlamdnLb1pte82WwqmWmcmGkEhh/xH5HaUc2O3vUN3MtDUziUosVVMBbR2O3wmJts0rcKh9Ex7a6r6pdVDV2BNp2RTIQLtnyHUme2NlE/ezPIsstku9Vi9MfuNLlzvDzfjW3X+BRzZZLVhng8z0m4N+fQBQoy1gdaPPZE5OTWNkfFJ1IDPXywiZhZVSDrkh3tCwEAf2XoP7WlYBAK7WUuey4ZcfoZ07UfyVr6gN4ryY3UaStbdMN/0DTMqxygpD+NTOdfg/j96Gd199hdq8MGfJEhR8/OPI/0B6zgl9Ztpc4FlRnI+2zStUpxgzMyMlBtCOnxzP2oUlqpbdDIJmk15GZy7EpMunNwAQXhvlSXZBSpl0UuYiP1M6pfkdCJk21Fbg929eEZdZ0DMzZqmMPpiOBTPWtfbfftSHn/W/jR9Eh9RMezr3YHGjZ8T1zIwMLt02zpwpeZ8ujFp7RiDFCSM/ygpD2LymGk0rqlSA4bb24nLJvUYajsi5KHu4SPA3NsMMm+wV8t1fn8QrQxdRWZKPtS7rleR80rPTqswsN0d1cnvZ3uTT3NDRzNQnO98WlcZa5vv93JLj4FVmJufb+MRU0kX9laXW7/z28FjKa2ZqKouwcWWVY1PubOC2Xi8byPhE1s0mm+gOovirIcvs2/h7eGzz3bi1PjPq3tOl8LOfRdnx4yh48EHH4/oAwGvxP+ybtJRFnTg1jB9GhzA1DVxXXxm3zkLIRS7ZnEQ3P6mdRooftDnV1chranJ0aEtE73bUsKgkpb8nHcw2s7pllcX40j3X+9odeSb0QKo8SdBhlkDorZkl0JRgprIkX212aQZBs61xeQUWFIV8LYal1EjAoQczXoMdNbhzmf1/e0TKzKyfKXs+pfv68+pmpq/PkaykZGbKi0IoKcjD0IVL+KXd1bGoYHY/6hytme01LdDek9GxSfXem/eKVOnrmS6n9XQyX/3YRnz9gU3qvZZJEz9ro/ySNRcRu/mDBGryd0gwPTrDDJsEGd/48WuAnVFwI++flFtBKzPLQWzNjJQw1lU57+vmvdKttMv0wmd3IHJgl++KgiI7QJIyT7fMjPye8n55qbTvCW8Pj2sd2tJ3bINIxkx+qxKCwrxmk010B1H81ZBl7t2wDftv/hBWVlpdn7KdXkLkZ1AoMysDbw+r9TK3ai02TeYHsdtACHYdcPNqq7Z5tm6QeuC2Xlv8P1dkIS48yi5miz4TaJY4mMydsvUbtXyIq7U3xfnYUGtl1WbruCXyj5+4GT/8zI6kXd4odRLwSr09knQwUrP/LpmZMxedDQCk9NSthv9yODMzzo8qPWso97xllcW4e1M9/ulTt6l9hQbflk0M0/u7mRytmfUGABLMjE96NlxIhZTAXLw0odaSmO/PbJBSK7fzZaakPbNkZqSznupmZp+vEmSkeo7pawkLQ7m4t9m9fFnOd9kIGgAm7WhGz8wIc+NIM4udqLTrcsjvKEGx2zktwYysdfMK/uQzRDaeJqvkNXJgF77+QPKmH0GiN/IpLQypVuPZJPGZToFUGMpVUbifch1pEPDMSyfU7NWtbov/bWb61euD7Wv33YSvP7Ap6WB7pvTAbS4X/wvJzCRrzTsb9IBEZt0TMfcl0QMhOX6yBqqipADvvXYZvvmH78LX7rtJvY6CzWx1C23AY5Z3WY9Zr3dbM3PWzszIegT57+UO0t3IuWoO1vWZcMk0bt+wFJ953wZUFOfH7Stkfn+6lRWG1MBRnwUtsh+7NDHl2XBhJka0AMlPJuBySZlZKmXDyaywM9fSell1xzQyM5fUmpnU/m7JGgLA3qa6hJ9F8vfqDS+kNXNOTnwpr75QHC7HNNWgyw/5Hb0yMxJEXbSvc7fXCAn0ZCLL/Jyg7KHfL7Nx8T8YzGQnmSX00xVKFiJ+91dWVuaKiiLP7ir6egvM0gDGL32Rnt6Wea7IgC/RB+Rs0m9OZltQNzJg1RsFQPsQPqmVmVWW5GOlvW8HZQ8JgM29Jdz2mZEgQm/lLOT7ZMB569olONS+CX/4bmczknSQCQtzFtqtNbNuk9F+N9VB8ExsXb8UTSuqHJMbMvAfGUtfZgZahlwWg5vvz2yQAb1stJsOq43WvqrMzD6+EkzHyulSG7Lon1cf1RqzmMyuc9AaAOTm5MQFBQ0u90dH970Uf08/VAMAuwGHW9ZF9pm5aAdl5u+tk2tcJrLc7gOUHfQJFgYzFBhdd12LQ+2bcH198vaYD7xrFf7fB5rx8O1h3NCwENuu8i7HM2dx52KQkIje7MBv3XE6yWy3WXo3F/TsygIfJW4ScJmZNbN0wQxWKXtIKcwFe9M/Weyc6oysDDBloXtVaQE2rqzCmllo0/rRW1bioa1r1KaYwtmaOf7DeWFJATbYa7+QYOCXbl+8+zp8/YFNjvJeCTIuTcSCGbeGC6mSe8+pC1aJkNegNV3k70jnQL12YbHjd1etmSWTaGwMmmrQtnFlFbruuhaP33WtZ9m12mcmUQMArSynvCjkes/XJ7VS/T398Nea2fo9L9iTEGZGSSf3etXMJw1BNmUmvcwsGzuZgcFMdtpQW4GNK6t8r+O4ccVCPHT7Gvz9g83Y/9715tNx9M49Znp9LjUsKsGX7rkef3LnVe9IdkQCAb0ue644GwAk/7fL4EAPAIH4zQjNrjyUPSQAkGyLtAtOxJz9F/L9qQZBM7HnhuV4eFs4rmRWz8wkaqOqb444G4NLPySTcGliKuX2t17kepZZ+lQzFjMRyrX+jnRPYOmBqrw38tklg3J571INpMqL8/Hea5fhziRtnNWaGS0zE2sAEPu3w2irrNMDnNlYMyOZE8msugWwsTUzEvzFv0ZIMCNt+c2JSsoe+uRPNnYyA4MZmgl9wOt1s5wL7776ioSLOmebzEzPxaDO5NYW2ovs42IO/MxgNNn6GwoufVd1WYvgde7GSn1iAzwp93mnr3sAiBzYhciBXQkbVdwcjq39S3UQnC4ye57uMjNpMvCmvXjbbF09GyQ7Yd4zLpe+i7xZZibBjL5p5myRc1oCJ8nM5OY4MzP1xuJ/oXeNLJiF881cMyPrsXQS4Ej21eu8kM9xWTOTjvOSMpN+j9SblWST+KuBKAm9FCmdi0GDRnatL38HAgB9FtBPZiZhmZmxYaL5PGUPfbbba72MkNIbqb+Ho2lA4u/LFBtXVmHr+iX4UHNDXBA/V2Tg78jMpGFAvt7em+S7vzwJzFFmRmb9033P19fnmQ0AZJ8ZtWbGY3B+ucx1M/qmmXq5Vr3Rllk4y8zSfzz0cwkJAhX5PWWywi17I+LKzPIz/5qmmSnTMzMsMyOyyGZbCMigZrbcdVM9DrVvwodvdt+7YDZVaoMzt/ptk8x4VhqvNT90/QRGFEwyQDw3Oq7KULwGwTK4k85I+v8HZRb3b9puxJ/eeZX58JyRweTI2IQamKcjGLhtvdU+/1eD54A5KqNTwUwagjHdKm2tldo00z5XR8YnMTWtrZnxOF8vl1o3Y18bidbMJMzMaPfO2Qi6zCDYLVCRx+Rc81ozY35uzPZeTPTO0TMzbABAZJPNtjDLHy6ZblllsbULso+ucemmlzSYG7a5ueOaZXho6xrccqWz7bYZjOqtTCm7SKnhhdFxtW+H17o6t13RJQgyN2EjdxL0jU1MqQF5aRomgDavXuQ4Bm4D23TbseEKHGrfhAdvXW0+dVn0MjP9fJQB2AVtPx1zQJ9OMuEjx0nWzOTl5jjWwLh1MoNRsTAb+3iYEwhuExHye0qra6/zQp8Qg8tnAWUPRwOAcmZmiABjzcxsfrhQYnrZjJ9sym3rluDhbWFcU2dtiCnMjjh+AiMKJhlEnx+d0DIzia9fGdzpe9NI+Yo5sCJ3MkM/Oj6p1h55veepuHXdEvX/s7Hg3LSkvBAbV1bFdZa7XI4GANp7I4HNxdEJNTg371fpJBkzuTZk08ycnBzk6Q0AjD1mhARfbkFGOpjnjVvWRTY2FV7nhdnsxfz5lD0cDQCYmSGy6DM6vAG+M3JyYgNKP8FMIvrgoaI4Hznpn1CkDKEvqvazGF0Gk/rGmWrNDDMzvkjmenR8CiPj6Q0Et11llZphlgf5s60glIv3X1+LD95U79gbTQZgFy6NY2wivYGgGwn2JTMj9H1mygpDCddfyX14tkr+zCyq23thlg17VU6Y2VXz51P2kGNdUpCXtvtPpkl8phMloO8+n60XRhDs23YlHtq6BjUVM08b68fPnKmj7CIzx+dHx2O70Xtcv7F2tdqaGTu7wDau/siAc3Rc62bmMgidiZYrl6hyJnMQGzR/sfcafPb9GxyBQqndnOTC6IRqB56oc106qDVidvAe62YGrFpcii/efR0e89i6QNageAUQl8O8Vt1KyMzyNrfsjS5Ttlmg2VW7sBiRA7vw4ufebT6VNbzPdCIX+sJBt9khmhsf2bICD28LX1ZmRh+ULizNzvQzWaSjzcVLsbIdrzr5WEep2Ey1rLVhOaI/cn+8NDGpZvzNDoIzVZSfiy12+2lzH55soLrvaZnB2STHymwAkJuTg9LCEHY21mDPDcsd36OTNWlepV2XwwxY3YIZM3gx/2xyNC2YpSCMaC7w7KWU6WVmnM0JNr0kooKZmaymL6iW0jGvDIuUkkkAAy2wMWeJyZ2Uf42OT6m1GOlsgfvZ92/A8c734IM31ZtPBZ4EzEMXrL10ZvuzJr4BQKybmR8Ni0rx0NY1+Ogtq8yn0sKceHCbSDQDHDMAMi3UOpOyzIyCzPtMJ3Lh2GfG5YZKwaG3iTVbdVJ2kUzL+dEJ1aHM6/qVwdN5bWZcSnC8giCKKVZrZiZjwUwa37ul5UVJB6xBJYPrIXtjUK9zNR1kzyVVZmZ3M/O7jnBRWQEe3hbGPZtmJ7A0zxu3DJDZACA/ybmhf5YHed0VkfeZTuRCX1sx2x8wNLtksAWumcl6akH1qJ6ZSTwbK+VQ0oUL2voZzuL6IwPES/qamTQGM9lMgu9TF6wd72drLYqQAF0CfcnM5PqNZmaZ+VlrZmHgUlaWLNDVJ7BmO/NFNJu8z3QiF/oeJ+nYAI7eOfl5uZAqCn2WjrKP6mZ2aTy2G73H9SvdnZwNAJiZSUWsNfOUKtfzes8pptQ+X0/ZZWbmYD7d5Li4rZnJBOZ545ZJMbM1ZnBj0u/55s8nChLvM53IRU4OEDmwC5EDu1A+i91laG5IeQXLzLKbXmYWW7+ReACj9vlwlJnJInZe9344upnNwcaP2UTOVykzS5ZluFyx7n2SmbEe97lkZtYVhnIdJW9u74e5iN8te6Nz7BnHYIYCzPtMT6Cvrw/hcFh99fb2mi9xSPb6jo4O9Vxra6vjua6uLsf3ur2GiGZOBlfMzGQ3feZZsgReQYm0xtWDGVVm5lGeRjFSGsUys9RJJnHuMjPOTOSUbJqZKdGMEQgn2s9G/3WTBzNs5kPZwftMT+Cee+5BZ2cnotEoDh06hPvvv998iYPX63t6enD8+HFEo1FEo1HADmB0jY2N6vloNIrDhw87nieimZNSQa6ZyX7SivXkOWuA6FUuJutpZKYa2gaa6WovnO1kgDg6MaUFMwwE/YitmZmjYMb++WaZWV6GlJnBCIQLEqwh0kvLzLIzkx7MeK2fI8p03me6i97eXgwNDaGtrQ0A0NLSgurqavT09JgvBXy8/tlnn8Xu3bvV6/fu3YsjR46oPxPR7PrYlpV4aOsarFxcZj5FWUYGiG+dHwWSZAncyswksGFmxh99I0bZL4Wluf7IuSobZs52AwCVuTQaAGRQLOMIhN3KzGBkY5JnZlhmRtnB+0x3ceLECVRXVzseq6mpQX9/v+Mxkez1g4ODqKurU8/V19djaGhIezUQiURYYkY0S+7eVI+Ht4WxeAE3zcx2Urrzpp2Z8SotiXUzc2kA4FGeRk4hre5H/3/yZp5jicqq0kV1M5PMjL1mxu8+M3OhxFFm5j58c2RmErxGsAEAZQvvM91FoqBlYGDAfAjw8XozcBF9fX0AgP379ztKzCKRSFwZ2o4dO+K+iIjISWa7JSjxGsBI9sWxz4xaM5P4+8hJL4/yer/JSTZ5Febi9nQz18xkWmtmGN1DE3UqSyUzo2+U7DWxQZTpHGd6a2tr3GJ7+ero6AAARxZFV1tbaz4E+Hi9mbURDQ0N5kMAgPb2drz00kuOx5577rm4LyIicpLMjPBav1Fgd0+angYuTUwB2p4z5qw5JaaXRzGY8c/cy2i218xIZmbUzsxIA4BMCmbkd0yUlYGZmcnzfs+qSgvw0NY1eGjrmqSBD1Emc5y9hw8fdmRB9K+DBw8CCcrAzFIxXbLXmyVqbmVpRER0+WTjTJFsNnaBPaCU2WrJzHCxsH+OzEyS95tiJIso3PZVSScJNGVd2KQVv2dMa2Zo55LvYMbjdeLhbWE8vC1sPkwUKMnPdIO5gN9c4N/b2+tov5zs9eaCf7MhgL5Gpq+vD93d3di7d696jIiI/DFnu5NlCiQDc/HSJKamgYnJaeTkzH7JTzbRgxkGgf6VFoYci++LfAzML4feuhyOBgCZE83I71jgsX4oPy/2++bP8ntGlClmdKY//fTT6OzsRDgcxv33349Dhw6ZL3Hwen1bWxuamppUORvsdTI6eW779u1ob29XgRAREflnrkMwgxuTPD98aQLnR8etxzggTwnXzMycfq7NemYm3/q7Rsat7OOkHcxkUgMAyex5dXZzrJlJsK6GKNvM6ExvaGhwlKC1tLSo51paWuIe83o9ABw8eFA9Z+4hY5a+mYEOERH5U6aVmeXn5SYtoZEa/YuXJlTTgGQBEDnpJUEMZlKjr/Ga7TUzkm0cHbfqy+xYJuk1MpdkjZtX+ViqZWZE2YBnOhHRPCFrYOBzYK0yM2OTai2B10abFI+ZmZnTA+fZDmZgrJuRTTNzMyiaKbYDLq821XoA47W2hiib8EwnIponSrWZbj9Bib5xJveYmRlnAwC+d6nQmwB4lValS74duExMTmVkNzPJzHitWdMzM1wzQ/MFz3QionnCkZnxMdMtC9Yvjk2ozTNZZpYatmaeOUeZmUc2Il1CdiAwPjWNKcnMZE4s46sBANfM0HzEM52IaJ7Q18z4ybCUFNplN5cmWGY2Q85uZnzvUjHXmZmQ3QnMysxYj2VWZsY6f7zKx7hmhuYjnulERPNEebE2OPQx0Cm3g58LWjDDzExq9ACGg8vUVJQUqP/3k0m8XBIIWOtlMm/NjJxLXueRHjz7ucaJsgHPdCKieULfNNNPyZO85uKlSYyoDTOTfx/FOBsAMBBMhR44z8X6D2nDPD45rTbNzJxQBrjjmmWIHNiFv7r3BvMpxbHPDMvMaJ7gmU5ENE/og0M/wYy8fmSMrZlnSt8fZS6yC9lELzObi/culGsNifQGAJm0z4wfetZmLgJAokzAM52IaJ7QN830s/mlZGHOjUyondEZzKRGH4TLGiTyR28AMNubZkJfMzM1rYKZnAxaM+OHno0JBSwQI5opBjNERPOIBCN+Bod1VaUAgOjJ87hgZ2b8ZHQoxrFppo/3nGL0zEzRHGQZZPDvbM1svCjDSTDj1b6ZKNvwbCcimkckO+Nn7ctVteWAHcycGxkHjAEmJefsZsb3LhVzn5mxy8ympjFlr5nJpG5mfkhpGdsy03zCs52IaB6RzIyfgXVxfh5WVFvZmZ/0nQFYZpYyZwOA2R+QZxNna+bZf+9imZlYmVnQghkJYrhehuYTnu1ERPOIZGb8DqzXL7OyM/2nhwGfQRDFODbNnIMBeTbRA+c5KTNTmZkptWlm0BoASJmZV/tmomzDs52IaB4pK7TaM/sdWK+vsYIZ4ac8jWL099lvAEkWvZX4XAzOpa3x5NS02jQzYIkZ9T6xzIzmE57tRETzyDX1lWhaUYXlVSXmU6421FY4/lyqrWOg5PQyM5bopUbONb+B9+VSmZnJaUwGtDWzBGQFobl5z4gyAYMZIqJ55KGta/D1BzZhS7jafMrV+mXOYGauBpbZQs8o6IENJbeotACRA7vw0p+/23xqVsiamfHJKUwHtDWzyszMQSaLKFPwbCciooQWFIWwfGGx+jOzC6nRS8tYZpbZZL2Jtc+M9VjAEjPq36DvN0OU7Xi2ExGRJz07w2AmNYVauY++5wxlHsc+M9IAIGCZGTYAoPmIZzsREXm6Sls3wwYAqSmy3y++b5lP1sdYmRm7NXPAUjNrli7AQ1vXYM+Ny82niLIWgxkiIvJ0ld2emWVSqZN1Hy9+bm7WfdDMSQMAq5uZ7DNjvCjDNSwqwcPbwrjz2mXmU0RZi8EMERF5alxeiYe2rsHDt4fNp4iyRsjuBDYxOaW1Zg5YNEM0DzGYISIiTwuKQnh4Wxgfu2Wl+RRR1gjlWkOi8clpTAZ0zQzRfMRghoiIiOY92aNlYkpvzWy8iIgyDoMZIiIimvdi3cy01sxBWzRDNA8xmCEiIqJ5TxoATEwFtzUz0XzEYIaIiIjmvVgDgFg3M8YyRJmPwQwRERHNe9IAYGJyCpN2MCN7zxBR5mIwQ0RERPOevmmmHcuwNTNRADCYISIionkv1s2MrZmJgoTBDBEREc17epmZtGZmlRlR5mMwQ0RERPOeswGA9RjLzIgyH4MZIiIimvdirZlj3czYAIAo8zGYISIionkvtmnmFFszEwUIgxkiIiKa9/TMjGoAwMwMUcablWCmo6MD4XAY4XAYra2t5tNx/Ly+q6sr4XNEREREl0MyM+OTU2zNTBQgaQ9menp6cPz4cUSjUUSjUcAORBJJ9vqenh6Ew2F0d3dr30VERESUPvkua2aYmCHKfGkPZp599lns3r1b/Xnv3r04cuSI4zW6ZK9va2tDNBrFzp071WNERERE6SQlZZOT05jiPjNEgZH2YGZwcBB1dXXqz/X19RgaGnK8Rpfq64mIiIjSTbVmnppia2aiAEl7MJMoEOnr6zMfAmbwejc7duyI+yIiIiLyK7Zp5jQm2ZqZKDB8BzO9vb1qkb7blwQf1dXV5rcCABoaGsyHgBm83s1zzz0X90VERETkl56ZmWZrZqLA8B3MtLS0qEX6bl8SfNTU1KC/v19934kTJxIGLJjB64mIiIjSLdbNbBqTU9ZjXDNDlPl8BzN+mQv4zQX+XV1dCIfD6s/JXk9EREQ021Q3s8lYZiaXwQxRxkt7MNPW1oampiZVfgYA+/fvN1+mJHu9tGY+evQoIpEIwuEwent7tZ9AREREdHliZWax1syMZYgyX860TD9kmXA4rPatISIiIvJy4tQw3vvk99CwqAR9p4YBAJEDu8yXEVGGSXtmhoiIiCho9MwMEQUHgxkiIiKa96QN89iEvfqfiAKBwQwRERHNeyG7AQCDGaJgYTBDRERE816+kZkpyucQiSgIeKUSERHRvCeZmZHxSQBADluZEQUCgxkiIiKa92TNjGAoQxQMDGaIiIho3gsZwYwZ3BBRZmIwQ0RERPOeGbywzIwoGBjMEBEREWl7zQBAHoMZokBgMENERERklJqxyowoGBjMEBEREQEI5caGRbmMZogCgcEMERERkVFmlssyM6JAYDBDREREZGRmGMsQBQODGSIiIiKzAQDLzIgCgcEMEREREYBQnp6ZYTBDFAQMZoiIiIgA5GvZGC1JQ0QZjMEMERERkZGZYQMAomBgMENERERk7jPDNTNEgcBghoiIiAhAHlszEwUOgxkiIiIitmYmCiQGM0REREQA8vXWzIxmiAKBwQwRERER18wQBRKDGSIiIqK4bmaOp4goQzGYISIiIgIQYgMAosBhMENERERkNABgmRlRMDCYISIiIorLzDieIqIMxWCGiIiIyMzMsMyMKBAYzBARERGZ3cwYzBAFAoMZIiIiIpaZEQUSgxkiIiIiszUzoxmiQGAwQ0RERMQyM6JAYjBDRERExMwMUSAxmCEiIiKKy8w4niKiDDWjYKavrw/hcFh99fb2mi9x8PP63t5ehMNh82F0dXU5vjccDqO1tdV8GREREdFlydczMywzIwqEGQUz99xzDzo7OxGNRnHo0CHcf//95kscvF4vgY7Xz2hsbEQ0GlVfhw8fNl9CREREdFmc3cwYzBAFQcrBTG9vL4aGhtDW1gYAaGlpQXV1NXp6esyXAj5e39DQgGg0is7OTuM7iYiIiOYOy8yIgiflYObEiROorq52PFZTU4P+/n7HYyLV17uJRCIsMSMiIqJZlZfLBgBEQZNyMJMoCBkYGDAfAmbwetP+/fsdJWaRSARdXV2O1+zYsSPui4iIiCgVLDMjCh5HMNPa2hq32F6+Ojo6AAB1dXX6tyi1tbXmQ8AMXp9Me3s7XnrpJcdjzz33XNwXERERUSq4zwxR8DiCmcOHDzuyIPrXwYMHAQD19fUYGhrSvw2Dg4MJg5ZUX09ERET0TnB2M3M8RUQZKuUyM3MBv7nAX1osS/vlZK9PRl8j09fXh+7ubuzdu9fxGiIiIqLLxTIzouBJOZgBgKeffhqdnZ2qpfKhQ4fMlzh4vV5aM0s3s3A4HLcmRkrdtm/fjvb2dt+BEBEREZFfITYAIAqcnOnp6WnzwWwQDocRjUbNh4mIiIhcPfeLN/BH/+3fAAB3bazD53Zfbb6EiDLMjDIzRERERNmGmRmi4GEwQ0RERMQ1M0SBxGCGiIiIKK41s+MpIspQDGaIiIiIAIQcrZkZzRAFAYMZIiIiorjMDIMZoiBgMENERERkZmZYZ0YUCAxmiIiIiOIaADieIqIMxWCGiIiIiGVmRIHEYIaIiIjILDNjMEMUCAxmiIiIiADkszUzUeAwmCEiIiIyMzOMZogCgcEMEREREYA8rpkhChwGM0RERERmNzNmZogCgcEMEREREYBQrt4AwPEUEWUoBjNEREREZmaGZWZEgcBghoiIiAhAviMzw2CGKAgYzBARERHFZWYcTxFRhmIwQ0RERGSTjmZsAEAUDAxmiIiIiGwhCWZYZkYUCAxmiIiIiGwqM8NYhigQGMwQERER2UJ51tCIZWZEwcBghoiIiMiWbwcxeSwzIwoEBjNERERENsnMMJYhCgYGM0REREQ2ac/MBgBEwcBghoiIiMimuplxzQxRIDCYISIiIrKpBgCMZYgCgcEMERERkY37zBAFC4MZIiIiIlssM8NghigIGMwQERER2SQzI5tnElFmYzBDREREZJNuZkzMEAUDgxkiIiIiWyiXZWZEQcJghoiIiMh2VW0FmlZUoaq0wHyKiDJQzvT09LT5YDYIh8OIRqPmw0RERERElCVmJTPT0dGBcDiMcDiM1tZW8+k4Xq/XnwuHw+jq6nI8T0RERERE81Pag5menh4cP34c0WhUZUa8ApBkrx8YGFDPHTt2DN3d3ejt7dV+AhERERERzUdpD2aeffZZ7N69W/157969OHLkiOM1umSvP3z4sPr/hoYGVFdX48SJE+oxIiIiIiKan9IezAwODqKurk79ub6+HkNDQ47X6FJ9/dDQEOrr682HiYiIiIhonkl7MJMoEOnr6zMfAlJ8fUdHBxobG9HS0uJ4fMeOHXFfRERERESU3XwHM729vY6F+OaXBB/V1dXmtwJ2iZgbv6/v6OjA8ePHHWVn4rnnnov7IiIiIiKi7OY7mGlpaVEL8d2+JPioqalBf3+/+r4TJ04kDFjg8/USyLzwwguOx4mIiIiIaP7yHcz4ZS7gNxf4d3V1IRwOqz8ne31raysGBgYYyBARERERkUPag5m2tjY0NTWp8jMA2L9/v/kyxev1fX19iEQiiEQijpK2zZs3Gz+FiIiIiIjmm5zp6elp88FsEA6H1b41RERERESUfdKemSEiIiIiIpoLDGaIiIiIiCiQGMwQEREREVEgZfWaGSIiIiIimjtzvWY9a4OZ+WDHjh3cIDRAeLyCh8csWHi8goXHK3h4zIJlvhwvlpkREREREVEgMZghIiIiIqJAYjBDRERERESBxGCGiIiIiIgCiQ0AiIiIiIgokJiZISIiIiKiQGIwQ0REREREgcRghoiIiIiIAonBDBERERERBRKDmTnW0dGBcDjs+Orr6zNflja9vb0Ih8OOx/r6+uJ+B/kiJ7f3qqOjw3xZWrW2tqKrq8t8GK2trep3aG1tNZ8m2+bNmx3Ha/PmzeZL0sK8lt2OGTyOJ1l6enrirrGenh7zZZfN7VrWdXV1+Tqe853b+zhb90TzWu7t7XU8b/4ebq+h+Pdxtu6J5rWsf06Zz7m9hixu79U7cU9EkMYd0zRn9u3bN71nzx7HY0899dT0448/7ngsHV599dXpNWvWqK9kHn/88el9+/aZD89r8h4+//zzjsebm5sdf06Xffv2qeNlnhPmudPc3Mzj5aK5udn1vTOPYTrox8PtXPE6nmR56qmn4u5Pr776atx9Mh2eeuqp6aeeekr92bymzL9zzZo1jteT+3k+PUv3xFdffdVxj3M7V9x+F3Kay3vivn37pl999VX1Z7e/W7dnzx5eYwa38/yduieaf87kcQeDmTnU3Nyc9MKVE9kMQp5//vnpNWvWOAZIfk4qtwvDzZo1axw3IbLeu2Qf0mbQqH9AmMcr2c8Sbh8A5s/287vNN3Iskp3H+jExB7P6c35+li7R9e12PMmyb9++pPexdN8TRbJraM+ePTxuhmTvmWhublbHRH8PzePl52cJt+t7DYMZT27vmZtE98THH398urm5eXrPnj3qebd7XCJe1/fzzz+f0vGfL7zeM5Fo3JHue6J5fZnPZxKWmc2hpqYmdHZ2mg8rvb296OzsxLFjxxCNRrFz5864tF5tbS2i0SiOHTuGo0ePpiWl3tXVhZ07d6KhocF8al675ZZbMDQ05Flusn37dnR2diIajaKzsxP333+/4/mBgQFEo1FEo1HAfq/Tob6+HkNDQ+bD81pDQwOqq6vxyCOPmE8pXV1dOH78uDomg4ODjmNy9OhR9dzOnTs9f5ZpaGgI9fX15sPkobm52fM+Npv3xP7+ftTU1JgPA3b5RSQSQV1dnfnUvObnntja2oqmpiZ1TLq7ux3HZKb3xBMnTgD2da67//77VRmM32M/X6Tjnjg0NIRHHnlEfcZ5jWFMAwMDqK2tNR8GADz55JPYt2+f+fC8l+yeCB/jjtm4JyLDxx0MZubQwYMH0djYmLBe9JlnnnEEFR/84AcRiUS0nwB86EMfAuybVGNjI37wgx84np+J7u5uPProo+bD815DQwMOHTqE7u5uxzGTG0NPTw+qq6vR1tYGAOq/+o1j79696v93796Nl156Sf05FY2NjXjmmWfMh8nwwgsvIBKJOI6X/sF85MgRxweoeUx27typ/t/t+kuko6MDjY2NaGlpMZ8iD21tbWhvb3cMSPW67dm6J/b19aG7u9t1kBcOh7F9+3a0t7era5osye6JEgTK54nbMZnpPfGxxx5De3u74zEZgEejUXUekdPl3hOrq6vVfc3tMy6Rnp4eRCIR7N+/33wKvb29GBwc5PXlItk90c+4I133xCCNOxjMzLHDhw87bsCRSEQtnhwYGMDRo0fVySs35kQNAmprazEwMGA+nJKOjg5mZTy0tLS4fmD29fWhv78fQ0NDcTccmUE01dXVYXBw0HzYl8OHD8edG9XV1ebLyBjgyMBLFk8ODQ2hs7NTvY/d3d0Jj4lkWRJdf6KjowPHjx/H4cOHzafIh/379zuOWWNjo1qgPBv3xL6+PjWz6RZ8yu9x5MgR31mD+cTrnij3vu3bt6tjFolEEh4Tv/fEzZs3o6mpyXVgLOQ5PwPt+SZd90TYwU2izzjR09OjMqpuHnvsMWZlPHjdE1Mdd1zOPTFI4w4GM++w9vZ2daLV1tZi586djpM4Go0mDDS8Urh+9PX14ejRo8zKpEA+ME+cOIG6ujpUV1fHHa9Es03JUrjJ6H9He3s7mpqazJeQoaWlBY2Njejv7wfsD2JJz8vXCy+8YH4b4FHWopNAJtHPoNQ98sgjqpQh3fdE/UM70XUqmpqakg4CyHlPlAkAKQuUr4MHDxrfZfFzT5RAJtHPoNRczj0RPspp9UDG7TqVICrZ9Ucx+j0x1XHH5d4T9b8jk8cdDGbmkETQuu7ubtx0002AXUJx9OhRx6yjWR8uent7EYlEVDpxJp544glmZTx0dXXFzczKn1taWtDW1oahoSFHy8Surq6EM4Pd3d2OEouZ6u3tZWmgi97e3rjrRa6TLVu2AHYJxZe//GXHa8zvEU8++aSj7MzU2tqKgYEBzw9+8tba2hp3vTz55JNobGwE0vnBjX4AAAO7SURBVHxP7O3txfbt23Ho0CHXD23z5x49etRzEDAfJbsnSlnLE088oZ7v7e2N+x6R7J4YDoexe/du10Cmp6fHce/t6OhwlERR+u+JXV1dnu9xV1eXCowSjSu+/OUvMyvjIdk9MZVxx+XeE3WZPu7ImZ6enjYfpNnR1dWF7u5ux2NmNCyzGmLnzp04ePAgent74+qBDx06lPCmItG2rr29Xc2iJZs9IYsZgFZXVzsGr+b7rD9vfq/+/rvp6OjA0aNHHY9F7UWy5vGXx8mptbU1bk2FeY6b77Ncg+b3NjY2JiwdM4+70I+/+feAxy2OeV5Du+eJdN0T3Y4HPI5/sut1vjLva+Y9EXY2RV8oLNeg+b1e77F53IXX8ef1Fc88r5HCPdFtzOL1HpvHXcjfx0x2cm7ntXlPND9/5Bp0+97LuSeaP8/r2L/TGMwEhJxU5k2IMlc4HI4LVilztba2ora21nUWmDIP74nBw3tisHR1deHIkSMMPgJiPt8TWWZGRERERESBxMwMEREREREFEjMzREREREQUSAxmiIiIiIgokBjMEBERERFRIDGYISIiIiKiQGIwkwF6enoQDofVl7lhVV9fn+N5fXMk8zmzj39XV1fc8+bPJyIiIiIKIgYzGeBHP/oRjh07hmg0img0isHBQceOyffcc4/aVffQoUOOTYy+//3vq+ei0Sh27twZF6w0Njaq56PRaMKNAImIiIiIgoTBTAY4ePCgY4OjpqYmDAwMAPYmSENDQ2qTsZaWFlRXV6OnpwcA0NbW5tiArLm5GYODg+rPRERERETZisFMBhoYGEBtbS0A4MSJE6iurnY8X1NTg/7+fsdjor+/HzU1NY7HIpEIS8yIiIiIKOswmMkwPT09iEQi2L9/P2AHJ24kc6Pr6+tDd3c3HnnkEfXY/v37HSVmkUjEUcJGRERERBRUDGYySE9PDzo7O3Hs2DH1WF1dneM1QjI3oq+vD9u3b0dnZydaWlocz+na29vx0ksvmQ8TEREREQUOg5kMoQcy+vqZ+vp6DA0NOV47ODjoCHL0QEZfP0NERERElM0YzGSArq4u1ZFMD2TgsuDfbAjQ29uL7du349ChQ66BjL5GRsrQ9u7d63gNEREREVEQ5UxPT0+bD9Lc2rx5c1z2BYDK0kjmRRw6dEiVknV0dODo0aPad1kkS9Pa2opIJKIeb29vV+txiIiIiIiCjMEMEREREREFEsvMiIiIiIgokBjMEBERERFRIDGYISIiIiKiQGIwQ0REREREgfT/AwEsP5GghGOuAAAAAElFTkSuQmCC"
    },
    "image-5.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "9b139dcb",
   "metadata": {},
   "source": [
    "## 5- Log-return\n",
    "Une fois la première série d’expériences lancée, le constat est sans appel : les résultats sont insatisfaisants. Si une dégradation de la performance était attendue avec l’augmentation de l’horizon temporel, l'incapacité des modèles à capturer la dynamique immédiate des prix réels est flagrante : \n",
    "\n",
    "- **LSTM** : On observe une convergence systématique. Le modèle semble \"abandonner\" la capture de la volatilité au profit d’une convergence vers une moyenne stable, un comportement typique face à un signal non stationnaire.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    " \n",
    "- **GRU** : Les comportements sont similaires pour une moitié, l’autre adoptant un caractère oscillatoire qui peut donner l’impression que le modèle parvient à capter quelque chose. Mais en se penchant sur les courbes on remarque qu’il s’agit de la séquence initiale répétée.\n",
    "\n",
    "![image-4.png](attachment:image-4.png)\n",
    "\n",
    "- **SimpleRNN** : C'est ici que l'on trouve la plus grande diversité de comportements, sans pour autant obtenir de résultats probants. Les courbes sont en majorité oscillatoire comme celle vue en GRU, ou bien adoptent des trajectoires \"ésotériques\" qui ne représente aucune réalité.\n",
    "\n",
    "![image-5.png](attachment:image-5.png)\n",
    " \n",
    "Cette tendance suggère que le signal temporel utile est peut-être noyé dans la non-stationnarité des prix bruts. En effet, les séries de prix de cryptomonnaies présentent :\n",
    "\n",
    "- Une tendance forte et changeante (bull/bear markets),\n",
    "\n",
    "- Une volatilité hétérogène (calme prolongé suivi de fortes variations),\n",
    "\n",
    "- Une absence de moyenne stable.\n",
    "\n",
    "Or, les réseaux récurrents, bien qu’ils possèdent une mémoire temporelle, supposent implicitement que les statistiques locales (moyenne, variance, autocorrélation) restent relativement constantes au cours du temps. Quand ce n’est pas le cas, le modèle apprend à minimiser l’erreur en « moyennant » les régimes passés, ce qui produit exactement les courbes plates ou oscillantes que nous observons.\n",
    "Pour contourner ce problème, une pratique standard en finance consiste à transformer les prix en rendements, c’est-à-dire à se concentrer sur les variations relatives plutôt que sur les niveaux absolus. Parmi les formulations possibles, nous retenons le log-return :\n",
    "\n",
    "$$l_t = \\log \\left( \\frac{P_t}{P_{t-1}} \\right)$$\n",
    "\n",
    "avec $l_t$​ : Log-rendement à l'instant t.\n",
    "\n",
    "$P_t$​ : Prix de close actuel.\n",
    "\n",
    "$P_{t−1}$ : Prix de close de la bougie précédente.\n",
    "\n",
    "Cette transformation est motivée par trois propriétés essentielles :\n",
    "\n",
    "- Stationnarité améliorée : Ils offrent une distribution plus stable (moyenne proche de zéro et variance finie), ce qui facilite grandement la convergence des gradients.\n",
    "- Additivité temporelle : Le rendement total sur périodes devient la simple somme des log-rendements de chaque période, simplifiant la manipulation mathématique par rapport aux rendements simples.\n",
    "- Symétrie mathématique : contrairement aux rendements simples, les log-returns traitent les hausses et baisses de façon équilibrée (une hausse de +x suivie d’une baisse de –x ramène exactement au point de départ).\n",
    "Malgré cette transformation les résultats, restent insatisfaisants :\n",
    "\n",
    "- Les modèles LSTM persistent à produire des droites centrée sur zéro.\n",
    " \n",
    "- Les GRU et SimpleRNN continuent de générer des motifs basé sur la séquence initiale, oscillant autour d’une moyenne.\n",
    "\n",
    "En conclusion, même après stationnarisation, aucun modèle ne parvient à capturer une dynamique prédictive exploitable. Ce résultat démontre que l'approche univariée, limitée aux seuls prix passés, est insuffisante pour extraire un signal prédictif exploitable sur le BTC/USDT. Le modèle se contente d’apprendre une tendance de fond ou une moyenne, ce qui confirme que la complexité du marché ne peut être capturée par une approche univariée : d’autres variables ou une architecture fondamentalement différente sont nécessaires.\n",
    "\n",
    "Cette question sera approfondie dans l’article 5, qui posera les jalons pour la suite des actions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683be7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:48:36 INFO mlflow.tracking.fluent: Experiment with name 'log_return_lstm_input_width_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: input_width = 12 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0811 - mae: 0.0811 - root_mean_squared_error: 0.1258 - val_loss: 0.0276 - val_mae: 0.0276 - val_root_mean_squared_error: 0.0381\n",
      "Epoch 2/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0483 - mae: 0.0483 - root_mean_squared_error: 0.0658 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 3/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0458 - mae: 0.0458 - root_mean_squared_error: 0.0630 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 4/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0446 - mae: 0.0446 - root_mean_squared_error: 0.0623 - val_loss: 0.0270 - val_mae: 0.0270 - val_root_mean_squared_error: 0.0375\n",
      "Epoch 5/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0429 - mae: 0.0429 - root_mean_squared_error: 0.0604 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 6/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0597 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 7/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0414 - mae: 0.0414 - root_mean_squared_error: 0.0590 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 8/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0409 - mae: 0.0409 - root_mean_squared_error: 0.0585 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 9/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0575 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 10/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0392 - mae: 0.0392 - root_mean_squared_error: 0.0568 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 11/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0557 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 12/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0382 - mae: 0.0382 - root_mean_squared_error: 0.0558 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 13/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0551 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 14/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0372 - mae: 0.0372 - root_mean_squared_error: 0.0550 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 15/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0546 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 16/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0538 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 17/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0526 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0339\n",
      "Epoch 18/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0520 - val_loss: 0.0219 - val_mae: 0.0219 - val_root_mean_squared_error: 0.0319\n",
      "Epoch 19/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0480 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0328\n",
      "Epoch 20/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0312 - mae: 0.0312 - root_mean_squared_error: 0.0450 - val_loss: 0.0184 - val_mae: 0.0184 - val_root_mean_squared_error: 0.0260\n",
      "Epoch 21/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0293 - mae: 0.0293 - root_mean_squared_error: 0.0421 - val_loss: 0.0203 - val_mae: 0.0203 - val_root_mean_squared_error: 0.0271\n",
      "Epoch 22/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0395 - val_loss: 0.0195 - val_mae: 0.0195 - val_root_mean_squared_error: 0.0256\n",
      "Epoch 23/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0253 - mae: 0.0253 - root_mean_squared_error: 0.0366 - val_loss: 0.0148 - val_mae: 0.0148 - val_root_mean_squared_error: 0.0208\n",
      "Epoch 24/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0245 - mae: 0.0245 - root_mean_squared_error: 0.0348 - val_loss: 0.0146 - val_mae: 0.0146 - val_root_mean_squared_error: 0.0206\n",
      "Epoch 25/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0238 - mae: 0.0238 - root_mean_squared_error: 0.0340 - val_loss: 0.0169 - val_mae: 0.0169 - val_root_mean_squared_error: 0.0224\n",
      "Epoch 26/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0229 - mae: 0.0229 - root_mean_squared_error: 0.0333 - val_loss: 0.0138 - val_mae: 0.0138 - val_root_mean_squared_error: 0.0191\n",
      "Epoch 27/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0213 - mae: 0.0213 - root_mean_squared_error: 0.0309 - val_loss: 0.0132 - val_mae: 0.0132 - val_root_mean_squared_error: 0.0184\n",
      "Epoch 28/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0209 - mae: 0.0209 - root_mean_squared_error: 0.0306 - val_loss: 0.0169 - val_mae: 0.0169 - val_root_mean_squared_error: 0.0219\n",
      "Epoch 29/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197 - mae: 0.0197 - root_mean_squared_error: 0.0295 - val_loss: 0.0173 - val_mae: 0.0173 - val_root_mean_squared_error: 0.0215\n",
      "Epoch 30/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0193 - root_mean_squared_error: 0.0286 - val_loss: 0.0118 - val_mae: 0.0118 - val_root_mean_squared_error: 0.0166\n",
      "Epoch 31/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186 - mae: 0.0186 - root_mean_squared_error: 0.0275 - val_loss: 0.0124 - val_mae: 0.0124 - val_root_mean_squared_error: 0.0172\n",
      "Epoch 32/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181 - mae: 0.0181 - root_mean_squared_error: 0.0270 - val_loss: 0.0113 - val_mae: 0.0113 - val_root_mean_squared_error: 0.0157\n",
      "Epoch 33/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0170 - mae: 0.0170 - root_mean_squared_error: 0.0256 - val_loss: 0.0096 - val_mae: 0.0096 - val_root_mean_squared_error: 0.0137\n",
      "Epoch 34/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0165 - mae: 0.0165 - root_mean_squared_error: 0.0249 - val_loss: 0.0095 - val_mae: 0.0095 - val_root_mean_squared_error: 0.0134\n",
      "Epoch 35/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0152 - mae: 0.0152 - root_mean_squared_error: 0.0231 - val_loss: 0.0089 - val_mae: 0.0089 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 36/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0150 - mae: 0.0150 - root_mean_squared_error: 0.0217 - val_loss: 0.0087 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 37/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0136 - root_mean_squared_error: 0.0202 - val_loss: 0.0119 - val_mae: 0.0119 - val_root_mean_squared_error: 0.0148\n",
      "Epoch 38/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0132 - mae: 0.0132 - root_mean_squared_error: 0.0190 - val_loss: 0.0130 - val_mae: 0.0130 - val_root_mean_squared_error: 0.0156\n",
      "Epoch 39/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0125 - root_mean_squared_error: 0.0185 - val_loss: 0.0095 - val_mae: 0.0095 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 40/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0165 - val_loss: 0.0072 - val_mae: 0.0072 - val_root_mean_squared_error: 0.0098\n",
      "Epoch 41/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0111 - mae: 0.0111 - root_mean_squared_error: 0.0160 - val_loss: 0.0068 - val_mae: 0.0068 - val_root_mean_squared_error: 0.0095\n",
      "Epoch 42/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0098 - root_mean_squared_error: 0.0147 - val_loss: 0.0060 - val_mae: 0.0060 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 43/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0096 - mae: 0.0096 - root_mean_squared_error: 0.0135 - val_loss: 0.0060 - val_mae: 0.0060 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 44/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088 - root_mean_squared_error: 0.0127 - val_loss: 0.0076 - val_mae: 0.0076 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 45/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0097 - root_mean_squared_error: 0.0136 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 46/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - mae: 0.0087 - root_mean_squared_error: 0.0124 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 47/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0084 - root_mean_squared_error: 0.0128 - val_loss: 0.0041 - val_mae: 0.0041 - val_root_mean_squared_error: 0.0058\n",
      "Epoch 48/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - mae: 0.0079 - root_mean_squared_error: 0.0114 - val_loss: 0.0076 - val_mae: 0.0076 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 49/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - mae: 0.0076 - root_mean_squared_error: 0.0108 - val_loss: 0.0053 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0066\n",
      "Epoch 50/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0069 - mae: 0.0069 - root_mean_squared_error: 0.0097 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:49:13 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:49:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:49:21 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:49:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: input_width = 24 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0791 - mae: 0.0791 - root_mean_squared_error: 0.1224 - val_loss: 0.0277 - val_mae: 0.0277 - val_root_mean_squared_error: 0.0386\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0498 - mae: 0.0498 - root_mean_squared_error: 0.0675 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0466 - mae: 0.0466 - root_mean_squared_error: 0.0649 - val_loss: 0.0268 - val_mae: 0.0268 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0453 - mae: 0.0453 - root_mean_squared_error: 0.0627 - val_loss: 0.0267 - val_mae: 0.0267 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0594 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0416 - mae: 0.0416 - root_mean_squared_error: 0.0593 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0578 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0574 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0564 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0561 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0559 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0553 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0549 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0552 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0543 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0540 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0534 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0529 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:50:26 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:50:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:50:35 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:50:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: input_width = 48 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0787 - mae: 0.0787 - root_mean_squared_error: 0.1221 - val_loss: 0.0308 - val_mae: 0.0308 - val_root_mean_squared_error: 0.0412\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0495 - mae: 0.0495 - root_mean_squared_error: 0.0670 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0467 - mae: 0.0467 - root_mean_squared_error: 0.0646 - val_loss: 0.0330 - val_mae: 0.0330 - val_root_mean_squared_error: 0.0430\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0455 - mae: 0.0455 - root_mean_squared_error: 0.0627 - val_loss: 0.0271 - val_mae: 0.0271 - val_root_mean_squared_error: 0.0380\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0622 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0419 - mae: 0.0419 - root_mean_squared_error: 0.0593 - val_loss: 0.0252 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0416 - mae: 0.0416 - root_mean_squared_error: 0.0591 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0404 - mae: 0.0404 - root_mean_squared_error: 0.0578 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0575 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0566 - val_loss: 0.0261 - val_mae: 0.0261 - val_root_mean_squared_error: 0.0370\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0564 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0382 - mae: 0.0382 - root_mean_squared_error: 0.0561 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0554 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0551 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0552 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0545 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0358 - mae: 0.0358 - root_mean_squared_error: 0.0541 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0541 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0542 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0536 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0536 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0536 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0530 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0533 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0529 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0530 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0532 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0528 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0529 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0528 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0527 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0526 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0525 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0525 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0525 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0525 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:52:25 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:52:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:52:33 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:52:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: input_width = 72 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0793 - mae: 0.0793 - root_mean_squared_error: 0.1225 - val_loss: 0.0301 - val_mae: 0.0301 - val_root_mean_squared_error: 0.0405\n",
      "Epoch 2/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0496 - mae: 0.0496 - root_mean_squared_error: 0.0678 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 3/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0470 - mae: 0.0470 - root_mean_squared_error: 0.0647 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 4/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0454 - mae: 0.0454 - root_mean_squared_error: 0.0632 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 5/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0440 - mae: 0.0440 - root_mean_squared_error: 0.0613 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 6/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0432 - mae: 0.0432 - root_mean_squared_error: 0.0608 - val_loss: 0.0310 - val_mae: 0.0310 - val_root_mean_squared_error: 0.0412\n",
      "Epoch 7/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0426 - mae: 0.0426 - root_mean_squared_error: 0.0609 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 8/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0418 - mae: 0.0418 - root_mean_squared_error: 0.0595 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 9/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0411 - mae: 0.0411 - root_mean_squared_error: 0.0589 - val_loss: 0.0295 - val_mae: 0.0295 - val_root_mean_squared_error: 0.0399\n",
      "Epoch 10/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0572 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 11/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0569 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 12/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0568 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 13/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0560 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 14/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0372 - mae: 0.0372 - root_mean_squared_error: 0.0554 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0362\n",
      "Epoch 15/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0555 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 16/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0555 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 17/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0552 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 18/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0546 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 19/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0540 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 20/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0541 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 21/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0539 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 22/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0537 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 23/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0537 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 24/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0535 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 25/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0533 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 26/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0532 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 27/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0532 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 28/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0532 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 29/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 30/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0530 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 31/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0530 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 32/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0528 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 33/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 34/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0528 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 35/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0528 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 36/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0528 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 37/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0527 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 38/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0528 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 39/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0527 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 40/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0527 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 41/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 42/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0527 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 43/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0527 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 44/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 45/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 46/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 47/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 48/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 49/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 50/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0526 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:54:50 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:54:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:54:58 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:55:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: input_width = 96 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.0792 - mae: 0.0792 - root_mean_squared_error: 0.1226 - val_loss: 0.0263 - val_mae: 0.0263 - val_root_mean_squared_error: 0.0373\n",
      "Epoch 2/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0671 - val_loss: 0.0275 - val_mae: 0.0275 - val_root_mean_squared_error: 0.0384\n",
      "Epoch 3/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0475 - mae: 0.0475 - root_mean_squared_error: 0.0650 - val_loss: 0.0267 - val_mae: 0.0267 - val_root_mean_squared_error: 0.0377\n",
      "Epoch 4/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0456 - mae: 0.0456 - root_mean_squared_error: 0.0631 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 5/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0441 - mae: 0.0441 - root_mean_squared_error: 0.0622 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 6/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0438 - mae: 0.0438 - root_mean_squared_error: 0.0616 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 7/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0426 - mae: 0.0426 - root_mean_squared_error: 0.0607 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 8/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0601 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 9/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0410 - mae: 0.0410 - root_mean_squared_error: 0.0589 - val_loss: 0.0250 - val_mae: 0.0250 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 10/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0401 - mae: 0.0401 - root_mean_squared_error: 0.0579 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 11/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0398 - mae: 0.0398 - root_mean_squared_error: 0.0576 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 12/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0567 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 13/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0563 - val_loss: 0.0253 - val_mae: 0.0253 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 14/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0379 - mae: 0.0379 - root_mean_squared_error: 0.0560 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 15/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0561 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 16/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0374 - mae: 0.0374 - root_mean_squared_error: 0.0556 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 17/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0551 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 18/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0364 - mae: 0.0364 - root_mean_squared_error: 0.0547 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 19/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0544 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 20/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0364 - mae: 0.0364 - root_mean_squared_error: 0.0545 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 21/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0540 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 22/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0539 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 23/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0536 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 24/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0537 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 25/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0536 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 26/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0537 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 27/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0533 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 28/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 29/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 30/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0533 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 31/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0532 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 32/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0530 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 33/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0530 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 34/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0530 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:56:58 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:57:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:57:06 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:57:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 20:57:28 INFO mlflow.tracking.fluent: Experiment with name 'log_return_lstm_batch_size_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: batch_size = 16 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0659 - mae: 0.0659 - root_mean_squared_error: 0.1001 - val_loss: 0.0264 - val_mae: 0.0264 - val_root_mean_squared_error: 0.0373\n",
      "Epoch 2/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0475 - mae: 0.0475 - root_mean_squared_error: 0.0659 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 3/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0450 - mae: 0.0450 - root_mean_squared_error: 0.0628 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 4/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0431 - mae: 0.0431 - root_mean_squared_error: 0.0610 - val_loss: 0.0258 - val_mae: 0.0258 - val_root_mean_squared_error: 0.0367\n",
      "Epoch 5/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0422 - mae: 0.0422 - root_mean_squared_error: 0.0601 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 6/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0576 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 7/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0393 - mae: 0.0393 - root_mean_squared_error: 0.0573 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0367\n",
      "Epoch 8/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0383 - mae: 0.0383 - root_mean_squared_error: 0.0564 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 9/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0553 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 10/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0546 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 11/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0545 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 12/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0538 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 13/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0536 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 14/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0533 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 15/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0532 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 16/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0529 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 17/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0528 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 18/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 19/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 20/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 21/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 22/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 23/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 25/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 26/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 27/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 28/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0523 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 29/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0523 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:58:15 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:58:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:58:23 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:58:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: batch_size = 32 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0791 - mae: 0.0791 - root_mean_squared_error: 0.1224 - val_loss: 0.0277 - val_mae: 0.0277 - val_root_mean_squared_error: 0.0386\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0498 - mae: 0.0498 - root_mean_squared_error: 0.0675 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0466 - mae: 0.0466 - root_mean_squared_error: 0.0649 - val_loss: 0.0268 - val_mae: 0.0268 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0453 - mae: 0.0453 - root_mean_squared_error: 0.0627 - val_loss: 0.0267 - val_mae: 0.0267 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0594 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0416 - mae: 0.0416 - root_mean_squared_error: 0.0593 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0578 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0574 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0564 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0561 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0559 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0553 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0549 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0552 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0543 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0540 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0534 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0529 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 20:59:27 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 20:59:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 20:59:35 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 20:59:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: batch_size = 64 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1072 - mae: 0.1072 - root_mean_squared_error: 0.1599 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 2/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0516 - mae: 0.0516 - root_mean_squared_error: 0.0702 - val_loss: 0.0265 - val_mae: 0.0265 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 3/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0498 - mae: 0.0498 - root_mean_squared_error: 0.0672 - val_loss: 0.0256 - val_mae: 0.0256 - val_root_mean_squared_error: 0.0367\n",
      "Epoch 4/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0477 - mae: 0.0477 - root_mean_squared_error: 0.0651 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 5/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0464 - mae: 0.0464 - root_mean_squared_error: 0.0645 - val_loss: 0.0268 - val_mae: 0.0268 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 6/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0460 - mae: 0.0460 - root_mean_squared_error: 0.0641 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 7/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0445 - mae: 0.0445 - root_mean_squared_error: 0.0623 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 8/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0443 - mae: 0.0443 - root_mean_squared_error: 0.0618 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 9/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0448 - mae: 0.0448 - root_mean_squared_error: 0.0631 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 10/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0612 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 11/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0423 - mae: 0.0423 - root_mean_squared_error: 0.0598 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 12/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0423 - mae: 0.0423 - root_mean_squared_error: 0.0603 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 13/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0415 - mae: 0.0415 - root_mean_squared_error: 0.0592 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 14/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0411 - mae: 0.0411 - root_mean_squared_error: 0.0592 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 15/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0580 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 16/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0398 - mae: 0.0398 - root_mean_squared_error: 0.0576 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 17/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0395 - mae: 0.0395 - root_mean_squared_error: 0.0575 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 18/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0575 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 19/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0386 - mae: 0.0386 - root_mean_squared_error: 0.0566 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 20/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0386 - mae: 0.0386 - root_mean_squared_error: 0.0566 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 21/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0559 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 22/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0559 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 23/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0557 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 24/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0549 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 25/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0551 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 26/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0549 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 27/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0545 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 28/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0364 - mae: 0.0364 - root_mean_squared_error: 0.0548 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 29/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0540 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 30/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0545 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 31/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0542 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 32/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0537 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 33/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0535 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 34/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0534 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 35/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0536 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 36/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0536 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 37/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 38/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 39/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 40/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0530 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 41/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 42/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0530 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 43/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 44/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 45/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 46/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 47/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 48/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 49/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 50/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:00:41 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:00:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:00:49 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:00:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: batch_size = 128 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.1518 - mae: 0.1518 - root_mean_squared_error: 0.2097 - val_loss: 0.0324 - val_mae: 0.0324 - val_root_mean_squared_error: 0.0425\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0566 - mae: 0.0566 - root_mean_squared_error: 0.0753 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0526 - mae: 0.0526 - root_mean_squared_error: 0.0711 - val_loss: 0.0271 - val_mae: 0.0271 - val_root_mean_squared_error: 0.0381\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0512 - mae: 0.0512 - root_mean_squared_error: 0.0693 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0494 - mae: 0.0494 - root_mean_squared_error: 0.0673 - val_loss: 0.0263 - val_mae: 0.0263 - val_root_mean_squared_error: 0.0374\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0491 - mae: 0.0491 - root_mean_squared_error: 0.0671 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0479 - mae: 0.0479 - root_mean_squared_error: 0.0659 - val_loss: 0.0258 - val_mae: 0.0258 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0467 - mae: 0.0467 - root_mean_squared_error: 0.0647 - val_loss: 0.0270 - val_mae: 0.0270 - val_root_mean_squared_error: 0.0379\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0462 - mae: 0.0462 - root_mean_squared_error: 0.0639 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0454 - mae: 0.0454 - root_mean_squared_error: 0.0629 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0451 - mae: 0.0451 - root_mean_squared_error: 0.0633 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0450 - mae: 0.0450 - root_mean_squared_error: 0.0635 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0441 - mae: 0.0441 - root_mean_squared_error: 0.0616 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0620 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0437 - mae: 0.0437 - root_mean_squared_error: 0.0619 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0609 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0604 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0422 - mae: 0.0422 - root_mean_squared_error: 0.0600 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0598 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0419 - mae: 0.0419 - root_mean_squared_error: 0.0595 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0603 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0414 - mae: 0.0414 - root_mean_squared_error: 0.0591 - val_loss: 0.0250 - val_mae: 0.0250 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0585 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0580 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 25/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0408 - mae: 0.0408 - root_mean_squared_error: 0.0589 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 26/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0404 - mae: 0.0404 - root_mean_squared_error: 0.0582 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 27/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0578 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 28/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0410 - mae: 0.0410 - root_mean_squared_error: 0.0587 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 29/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0573 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 30/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0566 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 31/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0570 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 32/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0392 - mae: 0.0392 - root_mean_squared_error: 0.0573 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 33/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0565 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 34/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0570 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 35/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0570 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 36/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0557 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 37/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0554 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 38/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0561 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 39/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0550 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 40/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0379 - mae: 0.0379 - root_mean_squared_error: 0.0554 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 41/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0372 - mae: 0.0372 - root_mean_squared_error: 0.0552 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 42/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0552 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 43/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0549 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 44/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0544 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 45/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0546 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 46/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0543 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 47/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0364 - mae: 0.0364 - root_mean_squared_error: 0.0549 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 48/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0545 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 49/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0359 - mae: 0.0359 - root_mean_squared_error: 0.0541 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 50/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0359 - mae: 0.0359 - root_mean_squared_error: 0.0543 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:01:47 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:01:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:01:55 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:01:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 21:02:22 INFO mlflow.tracking.fluent: Experiment with name 'log_return_lstm_learning_rate_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: learning_rate = 0.0001 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2273 - mae: 0.2273 - root_mean_squared_error: 0.2828 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0362\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0629 - mae: 0.0629 - root_mean_squared_error: 0.0819 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0573 - mae: 0.0573 - root_mean_squared_error: 0.0769 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0544 - mae: 0.0544 - root_mean_squared_error: 0.0723 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0530 - mae: 0.0530 - root_mean_squared_error: 0.0716 - val_loss: 0.0276 - val_mae: 0.0276 - val_root_mean_squared_error: 0.0384\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0520 - mae: 0.0520 - root_mean_squared_error: 0.0703 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0508 - mae: 0.0508 - root_mean_squared_error: 0.0686 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0688 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0500 - mae: 0.0500 - root_mean_squared_error: 0.0678 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0490 - mae: 0.0490 - root_mean_squared_error: 0.0671 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0476 - mae: 0.0476 - root_mean_squared_error: 0.0654 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0480 - mae: 0.0480 - root_mean_squared_error: 0.0658 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:02:37 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:02:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:02:45 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:02:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: learning_rate = 0.001 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0791 - mae: 0.0791 - root_mean_squared_error: 0.1224 - val_loss: 0.0277 - val_mae: 0.0277 - val_root_mean_squared_error: 0.0386\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0498 - mae: 0.0498 - root_mean_squared_error: 0.0675 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0466 - mae: 0.0466 - root_mean_squared_error: 0.0649 - val_loss: 0.0268 - val_mae: 0.0268 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0453 - mae: 0.0453 - root_mean_squared_error: 0.0627 - val_loss: 0.0267 - val_mae: 0.0267 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0594 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0416 - mae: 0.0416 - root_mean_squared_error: 0.0593 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0578 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0574 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0564 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0561 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0559 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0553 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0549 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0552 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0543 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0540 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0534 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0529 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:03:50 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:03:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:03:58 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:04:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: learning_rate = 0.01 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0583 - mae: 0.0583 - root_mean_squared_error: 0.0935 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0582 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0548 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0534 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0532 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0528 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:04:55 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:05:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:05:03 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:05:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: learning_rate = 0.1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0877 - mae: 0.0877 - root_mean_squared_error: 0.4230 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0549 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0559 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0545 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0547 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0545 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0547 - val_loss: 0.0275 - val_mae: 0.0275 - val_root_mean_squared_error: 0.0380\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0551 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0547 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0544 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0550 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0366\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0543 - val_loss: 0.0250 - val_mae: 0.0250 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0359 - mae: 0.0359 - root_mean_squared_error: 0.0545 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0550 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:05:48 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:05:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:05:57 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:06:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 21:06:26 INFO mlflow.tracking.fluent: Experiment with name 'log_return_lstm_model_units_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: model_units = 10 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0988 - mae: 0.0988 - root_mean_squared_error: 0.1289 - val_loss: 0.0298 - val_mae: 0.0298 - val_root_mean_squared_error: 0.0403\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0717 - mae: 0.0717 - root_mean_squared_error: 0.0930 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0637 - mae: 0.0637 - root_mean_squared_error: 0.0840 - val_loss: 0.0310 - val_mae: 0.0310 - val_root_mean_squared_error: 0.0413\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0581 - mae: 0.0581 - root_mean_squared_error: 0.0773 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0525 - mae: 0.0525 - root_mean_squared_error: 0.0708 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0470 - mae: 0.0470 - root_mean_squared_error: 0.0653 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0619 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0408 - mae: 0.0408 - root_mean_squared_error: 0.0585 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0562 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0545 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0535 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0530 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0528 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:06:49 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:06:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:06:57 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:07:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: model_units = 50 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0791 - mae: 0.0791 - root_mean_squared_error: 0.1224 - val_loss: 0.0277 - val_mae: 0.0277 - val_root_mean_squared_error: 0.0386\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0498 - mae: 0.0498 - root_mean_squared_error: 0.0675 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0466 - mae: 0.0466 - root_mean_squared_error: 0.0649 - val_loss: 0.0268 - val_mae: 0.0268 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0453 - mae: 0.0453 - root_mean_squared_error: 0.0627 - val_loss: 0.0267 - val_mae: 0.0267 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0594 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0416 - mae: 0.0416 - root_mean_squared_error: 0.0593 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0578 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0574 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0564 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0561 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0559 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0553 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0549 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0552 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0543 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0540 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0534 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0529 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:08:04 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:08:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:08:12 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:08:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: model_units = 100 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0649 - mae: 0.0649 - root_mean_squared_error: 0.1073 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0445 - mae: 0.0445 - root_mean_squared_error: 0.0624 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0362\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0606 - val_loss: 0.0298 - val_mae: 0.0298 - val_root_mean_squared_error: 0.0402\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0420 - mae: 0.0420 - root_mean_squared_error: 0.0594 - val_loss: 0.0253 - val_mae: 0.0253 - val_root_mean_squared_error: 0.0364\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0411 - mae: 0.0411 - root_mean_squared_error: 0.0588 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0408 - mae: 0.0408 - root_mean_squared_error: 0.0587 - val_loss: 0.0305 - val_mae: 0.0305 - val_root_mean_squared_error: 0.0408\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0401 - mae: 0.0401 - root_mean_squared_error: 0.0581 - val_loss: 0.0292 - val_mae: 0.0292 - val_root_mean_squared_error: 0.0396\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0393 - mae: 0.0393 - root_mean_squared_error: 0.0574 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0570 - val_loss: 0.0258 - val_mae: 0.0258 - val_root_mean_squared_error: 0.0367\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0382 - mae: 0.0382 - root_mean_squared_error: 0.0565 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0392 - mae: 0.0392 - root_mean_squared_error: 0.0572 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0560 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0374 - mae: 0.0374 - root_mean_squared_error: 0.0555 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0556 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0546 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0368 - mae: 0.0368 - root_mean_squared_error: 0.0549 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0366 - mae: 0.0366 - root_mean_squared_error: 0.0549 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0542 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0546 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0543 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0539 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0536 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0536 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0532 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0534 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0535 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0532 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0530 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0531 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0530 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0529 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0528 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0526 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0524 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0520 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0520 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0517 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0516 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0510 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0338\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0506 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:09:50 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:09:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:09:58 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:10:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: model_units = 200 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.0589 - mae: 0.0589 - root_mean_squared_error: 0.0980 - val_loss: 0.0260 - val_mae: 0.0260 - val_root_mean_squared_error: 0.0372\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0419 - mae: 0.0419 - root_mean_squared_error: 0.0601 - val_loss: 0.0264 - val_mae: 0.0264 - val_root_mean_squared_error: 0.0373\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0581 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0368\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0587 - val_loss: 0.0250 - val_mae: 0.0250 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0395 - mae: 0.0395 - root_mean_squared_error: 0.0579 - val_loss: 0.0284 - val_mae: 0.0284 - val_root_mean_squared_error: 0.0389\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0576 - val_loss: 0.0290 - val_mae: 0.0290 - val_root_mean_squared_error: 0.0394\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0567 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0566 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0387 - mae: 0.0387 - root_mean_squared_error: 0.0565 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0564 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0372 - mae: 0.0372 - root_mean_squared_error: 0.0553 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0553 - val_loss: 0.0269 - val_mae: 0.0269 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0553 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0368 - mae: 0.0368 - root_mean_squared_error: 0.0550 - val_loss: 0.0300 - val_mae: 0.0300 - val_root_mean_squared_error: 0.0402\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0368 - mae: 0.0368 - root_mean_squared_error: 0.0549 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0551 - val_loss: 0.0255 - val_mae: 0.0255 - val_root_mean_squared_error: 0.0364\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0542 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0364 - mae: 0.0364 - root_mean_squared_error: 0.0546 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0364 - mae: 0.0364 - root_mean_squared_error: 0.0548 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0544 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0543 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0545 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0358 - mae: 0.0358 - root_mean_squared_error: 0.0541 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0541 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0359 - mae: 0.0359 - root_mean_squared_error: 0.0542 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0542 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0536 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0535 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0536 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0535 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0534 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0535 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0530 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0533 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0530 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0534 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0532 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0531 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0530 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0532 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0529 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0527 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:12:37 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:12:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:12:48 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:12:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 21:13:22 INFO mlflow.tracking.fluent: Experiment with name 'log_return_lstm_dropout_rate_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: dropout_rate = 0 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0612 - mae: 0.0612 - root_mean_squared_error: 0.1137 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0543 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0538 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0540 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0538 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0537 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0537 - val_loss: 0.0258 - val_mae: 0.0258 - val_root_mean_squared_error: 0.0367\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0538 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0535 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0534 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0530 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0518 - val_loss: 0.0228 - val_mae: 0.0228 - val_root_mean_squared_error: 0.0335\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0515 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0329 - mae: 0.0329 - root_mean_squared_error: 0.0505 - val_loss: 0.0223 - val_mae: 0.0223 - val_root_mean_squared_error: 0.0322\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0331 - mae: 0.0331 - root_mean_squared_error: 0.0502 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0334\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0321 - mae: 0.0321 - root_mean_squared_error: 0.0484 - val_loss: 0.0223 - val_mae: 0.0223 - val_root_mean_squared_error: 0.0319\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0312 - mae: 0.0312 - root_mean_squared_error: 0.0467 - val_loss: 0.0212 - val_mae: 0.0212 - val_root_mean_squared_error: 0.0300\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0312 - mae: 0.0312 - root_mean_squared_error: 0.0468 - val_loss: 0.0227 - val_mae: 0.0227 - val_root_mean_squared_error: 0.0323\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0316 - mae: 0.0316 - root_mean_squared_error: 0.0482 - val_loss: 0.0211 - val_mae: 0.0211 - val_root_mean_squared_error: 0.0302\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0299 - mae: 0.0299 - root_mean_squared_error: 0.0452 - val_loss: 0.0213 - val_mae: 0.0213 - val_root_mean_squared_error: 0.0295\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0311 - mae: 0.0311 - root_mean_squared_error: 0.0462 - val_loss: 0.0200 - val_mae: 0.0200 - val_root_mean_squared_error: 0.0286\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0294 - mae: 0.0294 - root_mean_squared_error: 0.0444 - val_loss: 0.0202 - val_mae: 0.0202 - val_root_mean_squared_error: 0.0284\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0290 - mae: 0.0290 - root_mean_squared_error: 0.0438 - val_loss: 0.0198 - val_mae: 0.0198 - val_root_mean_squared_error: 0.0279\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0299 - mae: 0.0299 - root_mean_squared_error: 0.0444 - val_loss: 0.0199 - val_mae: 0.0199 - val_root_mean_squared_error: 0.0280\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0314 - mae: 0.0314 - root_mean_squared_error: 0.0464 - val_loss: 0.0200 - val_mae: 0.0200 - val_root_mean_squared_error: 0.0282\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0421 - val_loss: 0.0203 - val_mae: 0.0203 - val_root_mean_squared_error: 0.0279\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0268 - mae: 0.0268 - root_mean_squared_error: 0.0408 - val_loss: 0.0191 - val_mae: 0.0191 - val_root_mean_squared_error: 0.0269\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0412 - val_loss: 0.0191 - val_mae: 0.0191 - val_root_mean_squared_error: 0.0266\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0395 - val_loss: 0.0199 - val_mae: 0.0199 - val_root_mean_squared_error: 0.0269\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0255 - mae: 0.0255 - root_mean_squared_error: 0.0386 - val_loss: 0.0201 - val_mae: 0.0201 - val_root_mean_squared_error: 0.0273\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0251 - mae: 0.0251 - root_mean_squared_error: 0.0372 - val_loss: 0.0165 - val_mae: 0.0165 - val_root_mean_squared_error: 0.0233\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0246 - mae: 0.0246 - root_mean_squared_error: 0.0373 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0239\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0240 - mae: 0.0240 - root_mean_squared_error: 0.0361 - val_loss: 0.0152 - val_mae: 0.0152 - val_root_mean_squared_error: 0.0215\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0236 - mae: 0.0236 - root_mean_squared_error: 0.0355 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0319\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0232 - mae: 0.0232 - root_mean_squared_error: 0.0347 - val_loss: 0.0144 - val_mae: 0.0144 - val_root_mean_squared_error: 0.0204\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0228 - mae: 0.0228 - root_mean_squared_error: 0.0337 - val_loss: 0.0187 - val_mae: 0.0187 - val_root_mean_squared_error: 0.0245\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0209 - mae: 0.0209 - root_mean_squared_error: 0.0315 - val_loss: 0.0137 - val_mae: 0.0137 - val_root_mean_squared_error: 0.0194\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0204 - mae: 0.0204 - root_mean_squared_error: 0.0300 - val_loss: 0.0158 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0215\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0202 - mae: 0.0202 - root_mean_squared_error: 0.0299 - val_loss: 0.0204 - val_mae: 0.0204 - val_root_mean_squared_error: 0.0258\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0200 - mae: 0.0200 - root_mean_squared_error: 0.0300 - val_loss: 0.0131 - val_mae: 0.0131 - val_root_mean_squared_error: 0.0193\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0187 - mae: 0.0187 - root_mean_squared_error: 0.0280 - val_loss: 0.0120 - val_mae: 0.0120 - val_root_mean_squared_error: 0.0173\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0182 - mae: 0.0182 - root_mean_squared_error: 0.0271 - val_loss: 0.0122 - val_mae: 0.0122 - val_root_mean_squared_error: 0.0171\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0176 - mae: 0.0176 - root_mean_squared_error: 0.0265 - val_loss: 0.0115 - val_mae: 0.0115 - val_root_mean_squared_error: 0.0161\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0179 - mae: 0.0179 - root_mean_squared_error: 0.0257 - val_loss: 0.0118 - val_mae: 0.0118 - val_root_mean_squared_error: 0.0162\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0166 - mae: 0.0166 - root_mean_squared_error: 0.0240 - val_loss: 0.0107 - val_mae: 0.0107 - val_root_mean_squared_error: 0.0154\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0163 - mae: 0.0163 - root_mean_squared_error: 0.0242 - val_loss: 0.0160 - val_mae: 0.0160 - val_root_mean_squared_error: 0.0200\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0162 - mae: 0.0162 - root_mean_squared_error: 0.0237 - val_loss: 0.0100 - val_mae: 0.0100 - val_root_mean_squared_error: 0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:14:21 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:14:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:14:30 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:14:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: dropout_rate = 0.2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0791 - mae: 0.0791 - root_mean_squared_error: 0.1224 - val_loss: 0.0277 - val_mae: 0.0277 - val_root_mean_squared_error: 0.0386\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0498 - mae: 0.0498 - root_mean_squared_error: 0.0675 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0466 - mae: 0.0466 - root_mean_squared_error: 0.0649 - val_loss: 0.0268 - val_mae: 0.0268 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0453 - mae: 0.0453 - root_mean_squared_error: 0.0627 - val_loss: 0.0267 - val_mae: 0.0267 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0594 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0416 - mae: 0.0416 - root_mean_squared_error: 0.0593 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0578 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0574 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0564 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0561 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0559 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0553 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0549 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0552 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0543 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0540 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0534 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0529 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:15:41 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:15:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:15:50 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:15:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: dropout_rate = 0.5 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1033 - mae: 0.1033 - root_mean_squared_error: 0.1445 - val_loss: 0.0358 - val_mae: 0.0358 - val_root_mean_squared_error: 0.0456\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0669 - mae: 0.0669 - root_mean_squared_error: 0.0866 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0610 - mae: 0.0610 - root_mean_squared_error: 0.0802 - val_loss: 0.0250 - val_mae: 0.0250 - val_root_mean_squared_error: 0.0362\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0566 - mae: 0.0566 - root_mean_squared_error: 0.0751 - val_loss: 0.0253 - val_mae: 0.0253 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0520 - mae: 0.0520 - root_mean_squared_error: 0.0702 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0480 - mae: 0.0480 - root_mean_squared_error: 0.0659 - val_loss: 0.0256 - val_mae: 0.0256 - val_root_mean_squared_error: 0.0366\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0435 - mae: 0.0435 - root_mean_squared_error: 0.0608 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0411 - mae: 0.0411 - root_mean_squared_error: 0.0591 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0564 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0552 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0543 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0538 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0529 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0529 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0530 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0523 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:16:54 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:17:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:17:03 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:17:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: dropout_rate = 0.8 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1530 - mae: 0.1530 - root_mean_squared_error: 0.1990 - val_loss: 0.0503 - val_mae: 0.0503 - val_root_mean_squared_error: 0.0584\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1000 - mae: 0.1000 - root_mean_squared_error: 0.1269 - val_loss: 0.0306 - val_mae: 0.0306 - val_root_mean_squared_error: 0.0409\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0812 - mae: 0.0812 - root_mean_squared_error: 0.1031 - val_loss: 0.0324 - val_mae: 0.0324 - val_root_mean_squared_error: 0.0424\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0646 - mae: 0.0646 - root_mean_squared_error: 0.0843 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0511 - mae: 0.0511 - root_mean_squared_error: 0.0689 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0415 - mae: 0.0415 - root_mean_squared_error: 0.0591 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0364 - mae: 0.0364 - root_mean_squared_error: 0.0550 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0539 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0530 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0530 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0527 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0529 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:18:07 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:18:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:18:15 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:18:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 21:18:50 INFO mlflow.tracking.fluent: Experiment with name 'log_return_lstm_number_of_layer_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: number_of_layer = 1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0791 - mae: 0.0791 - root_mean_squared_error: 0.1224 - val_loss: 0.0277 - val_mae: 0.0277 - val_root_mean_squared_error: 0.0386\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0498 - mae: 0.0498 - root_mean_squared_error: 0.0675 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0466 - mae: 0.0466 - root_mean_squared_error: 0.0649 - val_loss: 0.0268 - val_mae: 0.0268 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0453 - mae: 0.0453 - root_mean_squared_error: 0.0627 - val_loss: 0.0267 - val_mae: 0.0267 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0594 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0416 - mae: 0.0416 - root_mean_squared_error: 0.0593 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0578 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0574 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0564 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0561 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0559 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0553 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0549 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0552 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0543 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0540 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0534 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0529 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:19:30 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:19:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:19:38 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:19:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: number_of_layer = 2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0729 - mae: 0.0729 - root_mean_squared_error: 0.1115 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0367\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0498 - mae: 0.0498 - root_mean_squared_error: 0.0674 - val_loss: 0.0296 - val_mae: 0.0296 - val_root_mean_squared_error: 0.0400\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0473 - mae: 0.0473 - root_mean_squared_error: 0.0649 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0368\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0449 - mae: 0.0449 - root_mean_squared_error: 0.0626 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0440 - mae: 0.0440 - root_mean_squared_error: 0.0620 - val_loss: 0.0261 - val_mae: 0.0261 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0432 - mae: 0.0432 - root_mean_squared_error: 0.0608 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0427 - mae: 0.0427 - root_mean_squared_error: 0.0604 - val_loss: 0.0252 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0415 - mae: 0.0415 - root_mean_squared_error: 0.0595 - val_loss: 0.0254 - val_mae: 0.0254 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0582 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0398 - mae: 0.0398 - root_mean_squared_error: 0.0575 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0392 - mae: 0.0392 - root_mean_squared_error: 0.0572 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0366\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0564 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0560 - val_loss: 0.0255 - val_mae: 0.0255 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0555 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0547 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0366 - mae: 0.0366 - root_mean_squared_error: 0.0548 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0545 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0541 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0538 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0535 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0538 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0538 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0532 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0532 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0530 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0529 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0527 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0525 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:21:21 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:21:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:21:29 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:21:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: number_of_layer = 3 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0667 - mae: 0.0667 - root_mean_squared_error: 0.1009 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0368\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0500 - mae: 0.0500 - root_mean_squared_error: 0.0677 - val_loss: 0.0275 - val_mae: 0.0275 - val_root_mean_squared_error: 0.0379\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0462 - mae: 0.0462 - root_mean_squared_error: 0.0633 - val_loss: 0.0279 - val_mae: 0.0279 - val_root_mean_squared_error: 0.0383\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0462 - mae: 0.0462 - root_mean_squared_error: 0.0639 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0440 - mae: 0.0440 - root_mean_squared_error: 0.0614 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0603 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0417 - mae: 0.0417 - root_mean_squared_error: 0.0588 - val_loss: 0.0283 - val_mae: 0.0283 - val_root_mean_squared_error: 0.0387\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0419 - mae: 0.0419 - root_mean_squared_error: 0.0594 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0401 - mae: 0.0401 - root_mean_squared_error: 0.0578 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0404 - mae: 0.0404 - root_mean_squared_error: 0.0581 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0386 - mae: 0.0386 - root_mean_squared_error: 0.0565 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0564 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0382 - mae: 0.0382 - root_mean_squared_error: 0.0563 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0557 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0554 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0550 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0548 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0359 - mae: 0.0359 - root_mean_squared_error: 0.0542 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0358 - mae: 0.0358 - root_mean_squared_error: 0.0542 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0535 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0537 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0532 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0535 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0532 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0530 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0531 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:23:12 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:23:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:23:21 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:23:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: number_of_layer = 4 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.0758 - mae: 0.0758 - root_mean_squared_error: 0.1175 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0503 - mae: 0.0503 - root_mean_squared_error: 0.0681 - val_loss: 0.0306 - val_mae: 0.0306 - val_root_mean_squared_error: 0.0406\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0478 - mae: 0.0478 - root_mean_squared_error: 0.0660 - val_loss: 0.0288 - val_mae: 0.0288 - val_root_mean_squared_error: 0.0391\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0448 - mae: 0.0448 - root_mean_squared_error: 0.0622 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0451 - mae: 0.0451 - root_mean_squared_error: 0.0626 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0427 - mae: 0.0427 - root_mean_squared_error: 0.0600 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0422 - mae: 0.0422 - root_mean_squared_error: 0.0594 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0417 - mae: 0.0417 - root_mean_squared_error: 0.0595 - val_loss: 0.0271 - val_mae: 0.0271 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0406 - mae: 0.0406 - root_mean_squared_error: 0.0585 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0567 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0395 - mae: 0.0395 - root_mean_squared_error: 0.0571 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0567 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0559 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0553 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0551 - val_loss: 0.0256 - val_mae: 0.0256 - val_root_mean_squared_error: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:24:49 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:24:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:24:57 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:25:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 21:25:31 INFO mlflow.tracking.fluent: Experiment with name 'log_return_lstm_loss_function_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: loss_function = mae ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0791 - mae: 0.0791 - root_mean_squared_error: 0.1224 - val_loss: 0.0277 - val_mae: 0.0277 - val_root_mean_squared_error: 0.0386\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0498 - mae: 0.0498 - root_mean_squared_error: 0.0675 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0466 - mae: 0.0466 - root_mean_squared_error: 0.0649 - val_loss: 0.0268 - val_mae: 0.0268 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0453 - mae: 0.0453 - root_mean_squared_error: 0.0627 - val_loss: 0.0267 - val_mae: 0.0267 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0594 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0416 - mae: 0.0416 - root_mean_squared_error: 0.0593 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0578 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0574 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0564 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0561 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0559 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0553 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0549 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0552 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0543 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0540 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0534 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0529 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:26:10 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:26:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:26:19 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:26:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: loss_function = mse ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0159 - mae: 0.0829 - root_mean_squared_error: 0.1259 - val_loss: 0.0013 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0517 - root_mean_squared_error: 0.0695 - val_loss: 0.0013 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0045 - mae: 0.0489 - root_mean_squared_error: 0.0673 - val_loss: 0.0013 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0470 - root_mean_squared_error: 0.0644 - val_loss: 0.0013 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0042 - mae: 0.0466 - root_mean_squared_error: 0.0647 - val_loss: 0.0012 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0457 - root_mean_squared_error: 0.0637 - val_loss: 0.0014 - val_mae: 0.0260 - val_root_mean_squared_error: 0.0370\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0452 - root_mean_squared_error: 0.0625 - val_loss: 0.0012 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0446 - root_mean_squared_error: 0.0624 - val_loss: 0.0013 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0436 - root_mean_squared_error: 0.0611 - val_loss: 0.0012 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0433 - root_mean_squared_error: 0.0611 - val_loss: 0.0013 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0417 - root_mean_squared_error: 0.0595 - val_loss: 0.0014 - val_mae: 0.0262 - val_root_mean_squared_error: 0.0370\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0419 - root_mean_squared_error: 0.0597 - val_loss: 0.0012 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0417 - root_mean_squared_error: 0.0592 - val_loss: 0.0014 - val_mae: 0.0269 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0406 - root_mean_squared_error: 0.0583 - val_loss: 0.0014 - val_mae: 0.0272 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0404 - root_mean_squared_error: 0.0579 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0404 - root_mean_squared_error: 0.0583 - val_loss: 0.0012 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0397 - root_mean_squared_error: 0.0573 - val_loss: 0.0013 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0362\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0032 - mae: 0.0387 - root_mean_squared_error: 0.0567 - val_loss: 0.0012 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0032 - mae: 0.0386 - root_mean_squared_error: 0.0566 - val_loss: 0.0012 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0032 - mae: 0.0385 - root_mean_squared_error: 0.0567 - val_loss: 0.0012 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0031 - mae: 0.0378 - root_mean_squared_error: 0.0557 - val_loss: 0.0012 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0031 - mae: 0.0374 - root_mean_squared_error: 0.0553 - val_loss: 0.0012 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0031 - mae: 0.0371 - root_mean_squared_error: 0.0554 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0365 - root_mean_squared_error: 0.0545 - val_loss: 0.0012 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0366 - root_mean_squared_error: 0.0551 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0029 - mae: 0.0362 - root_mean_squared_error: 0.0542 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0358 - root_mean_squared_error: 0.0540 - val_loss: 0.0012 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0360 - root_mean_squared_error: 0.0544 - val_loss: 0.0012 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0354 - root_mean_squared_error: 0.0536 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0355 - root_mean_squared_error: 0.0539 - val_loss: 0.0012 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0352 - root_mean_squared_error: 0.0536 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0351 - root_mean_squared_error: 0.0534 - val_loss: 0.0012 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0346 - root_mean_squared_error: 0.0531 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0349 - root_mean_squared_error: 0.0532 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0028 - mae: 0.0349 - root_mean_squared_error: 0.0532 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0347 - root_mean_squared_error: 0.0530 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0344 - root_mean_squared_error: 0.0529 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0344 - root_mean_squared_error: 0.0528 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0343 - root_mean_squared_error: 0.0528 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0343 - root_mean_squared_error: 0.0529 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0341 - root_mean_squared_error: 0.0525 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0340 - root_mean_squared_error: 0.0526 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0341 - root_mean_squared_error: 0.0526 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0340 - root_mean_squared_error: 0.0526 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0012 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0012 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:27:47 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:27:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:27:55 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:27:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: lstm | Param: loss_function = huber ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0079 - mae: 0.0830 - root_mean_squared_error: 0.1260 - val_loss: 6.6501e-04 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0517 - root_mean_squared_error: 0.0695 - val_loss: 6.3370e-04 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0023 - mae: 0.0489 - root_mean_squared_error: 0.0673 - val_loss: 6.6032e-04 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0470 - root_mean_squared_error: 0.0644 - val_loss: 6.6000e-04 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0021 - mae: 0.0466 - root_mean_squared_error: 0.0647 - val_loss: 6.2283e-04 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0020 - mae: 0.0457 - root_mean_squared_error: 0.0637 - val_loss: 6.8396e-04 - val_mae: 0.0260 - val_root_mean_squared_error: 0.0370\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0020 - mae: 0.0452 - root_mean_squared_error: 0.0625 - val_loss: 6.1894e-04 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0019 - mae: 0.0446 - root_mean_squared_error: 0.0624 - val_loss: 6.2845e-04 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0019 - mae: 0.0436 - root_mean_squared_error: 0.0611 - val_loss: 6.1370e-04 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0019 - mae: 0.0433 - root_mean_squared_error: 0.0611 - val_loss: 6.4084e-04 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0018 - mae: 0.0417 - root_mean_squared_error: 0.0595 - val_loss: 6.8612e-04 - val_mae: 0.0262 - val_root_mean_squared_error: 0.0370\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0018 - mae: 0.0419 - root_mean_squared_error: 0.0597 - val_loss: 6.2254e-04 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0018 - mae: 0.0417 - root_mean_squared_error: 0.0592 - val_loss: 7.0556e-04 - val_mae: 0.0269 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0017 - mae: 0.0406 - root_mean_squared_error: 0.0583 - val_loss: 7.1485e-04 - val_mae: 0.0272 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0404 - root_mean_squared_error: 0.0580 - val_loss: 6.0057e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0404 - root_mean_squared_error: 0.0583 - val_loss: 6.0438e-04 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0397 - root_mean_squared_error: 0.0574 - val_loss: 6.5426e-04 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0362\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0387 - root_mean_squared_error: 0.0567 - val_loss: 6.0258e-04 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0016 - mae: 0.0386 - root_mean_squared_error: 0.0566 - val_loss: 6.0520e-04 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0385 - root_mean_squared_error: 0.0567 - val_loss: 6.1561e-04 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0378 - root_mean_squared_error: 0.0557 - val_loss: 6.1253e-04 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0374 - root_mean_squared_error: 0.0553 - val_loss: 6.0106e-04 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0371 - root_mean_squared_error: 0.0554 - val_loss: 5.9677e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0365 - root_mean_squared_error: 0.0545 - val_loss: 5.9948e-04 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0367 - root_mean_squared_error: 0.0551 - val_loss: 5.9589e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0362 - root_mean_squared_error: 0.0542 - val_loss: 5.9589e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0358 - root_mean_squared_error: 0.0540 - val_loss: 6.0775e-04 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0360 - root_mean_squared_error: 0.0544 - val_loss: 6.0207e-04 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0354 - root_mean_squared_error: 0.0536 - val_loss: 5.9572e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0355 - root_mean_squared_error: 0.0539 - val_loss: 5.9815e-04 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0352 - root_mean_squared_error: 0.0536 - val_loss: 5.9647e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0351 - root_mean_squared_error: 0.0534 - val_loss: 6.0075e-04 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0346 - root_mean_squared_error: 0.0531 - val_loss: 5.9638e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0349 - root_mean_squared_error: 0.0532 - val_loss: 5.9533e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0349 - root_mean_squared_error: 0.0532 - val_loss: 5.9490e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0347 - root_mean_squared_error: 0.0530 - val_loss: 5.9596e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0344 - root_mean_squared_error: 0.0529 - val_loss: 5.9476e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0344 - root_mean_squared_error: 0.0528 - val_loss: 5.9500e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0343 - root_mean_squared_error: 0.0528 - val_loss: 5.9533e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 5.9444e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0343 - root_mean_squared_error: 0.0529 - val_loss: 5.9443e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0341 - root_mean_squared_error: 0.0525 - val_loss: 5.9631e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0340 - root_mean_squared_error: 0.0526 - val_loss: 5.9666e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0341 - root_mean_squared_error: 0.0526 - val_loss: 5.9399e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0340 - root_mean_squared_error: 0.0526 - val_loss: 5.9459e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 5.9469e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 5.9573e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 5.9396e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 5.9343e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 5.9121e-04 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:29:24 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:29:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:29:32 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:29:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 21:30:05 INFO mlflow.tracking.fluent: Experiment with name 'log_return_gru_input_width_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: input_width = 12 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0815 - mae: 0.0815 - root_mean_squared_error: 0.1257 - val_loss: 0.0280 - val_mae: 0.0280 - val_root_mean_squared_error: 0.0387\n",
      "Epoch 2/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0484 - mae: 0.0484 - root_mean_squared_error: 0.0664 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 3/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0458 - mae: 0.0458 - root_mean_squared_error: 0.0633 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 4/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0448 - mae: 0.0448 - root_mean_squared_error: 0.0626 - val_loss: 0.0294 - val_mae: 0.0294 - val_root_mean_squared_error: 0.0397\n",
      "Epoch 5/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0429 - mae: 0.0429 - root_mean_squared_error: 0.0606 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 6/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0426 - mae: 0.0426 - root_mean_squared_error: 0.0600 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 7/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0415 - mae: 0.0415 - root_mean_squared_error: 0.0593 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 8/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0408 - mae: 0.0408 - root_mean_squared_error: 0.0586 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 9/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0401 - mae: 0.0401 - root_mean_squared_error: 0.0575 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 10/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0392 - mae: 0.0392 - root_mean_squared_error: 0.0568 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 11/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0386 - mae: 0.0386 - root_mean_squared_error: 0.0558 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 12/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0383 - mae: 0.0383 - root_mean_squared_error: 0.0558 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 13/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0377 - mae: 0.0377 - root_mean_squared_error: 0.0549 - val_loss: 0.0231 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 14/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0546 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 15/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0541 - val_loss: 0.0228 - val_mae: 0.0228 - val_root_mean_squared_error: 0.0336\n",
      "Epoch 16/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0532 - val_loss: 0.0231 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0338\n",
      "Epoch 17/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0523 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0335\n",
      "Epoch 18/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0521 - val_loss: 0.0221 - val_mae: 0.0221 - val_root_mean_squared_error: 0.0325\n",
      "Epoch 19/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0510 - val_loss: 0.0225 - val_mae: 0.0225 - val_root_mean_squared_error: 0.0323\n",
      "Epoch 20/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0319 - mae: 0.0319 - root_mean_squared_error: 0.0481 - val_loss: 0.0195 - val_mae: 0.0195 - val_root_mean_squared_error: 0.0280\n",
      "Epoch 21/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0286 - mae: 0.0286 - root_mean_squared_error: 0.0416 - val_loss: 0.0289 - val_mae: 0.0289 - val_root_mean_squared_error: 0.0334\n",
      "Epoch 22/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0233 - mae: 0.0233 - root_mean_squared_error: 0.0327 - val_loss: 0.0130 - val_mae: 0.0130 - val_root_mean_squared_error: 0.0188\n",
      "Epoch 23/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0207 - mae: 0.0207 - root_mean_squared_error: 0.0290 - val_loss: 0.0131 - val_mae: 0.0131 - val_root_mean_squared_error: 0.0166\n",
      "Epoch 24/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178 - mae: 0.0178 - root_mean_squared_error: 0.0243 - val_loss: 0.0138 - val_mae: 0.0138 - val_root_mean_squared_error: 0.0161\n",
      "Epoch 25/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0140 - root_mean_squared_error: 0.0195 - val_loss: 0.0065 - val_mae: 0.0065 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 26/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0124 - root_mean_squared_error: 0.0170 - val_loss: 0.0057 - val_mae: 0.0057 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 27/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122 - root_mean_squared_error: 0.0167 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 28/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0103 - mae: 0.0103 - root_mean_squared_error: 0.0143 - val_loss: 0.0068 - val_mae: 0.0068 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 29/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0100 - root_mean_squared_error: 0.0140 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0056\n",
      "Epoch 30/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - mae: 0.0085 - root_mean_squared_error: 0.0124 - val_loss: 0.0074 - val_mae: 0.0074 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 31/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0078 - root_mean_squared_error: 0.0109 - val_loss: 0.0026 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0037\n",
      "Epoch 32/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0067 - mae: 0.0067 - root_mean_squared_error: 0.0098 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 33/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0061 - mae: 0.0061 - root_mean_squared_error: 0.0088 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 34/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0086 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 35/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0059 - mae: 0.0059 - root_mean_squared_error: 0.0089 - val_loss: 0.0072 - val_mae: 0.0072 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 36/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0080 - val_loss: 0.0023 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 37/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0049 - mae: 0.0049 - root_mean_squared_error: 0.0071 - val_loss: 0.0014 - val_mae: 0.0014 - val_root_mean_squared_error: 0.0021\n",
      "Epoch 38/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0048 - mae: 0.0048 - root_mean_squared_error: 0.0072 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 39/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0050 - mae: 0.0050 - root_mean_squared_error: 0.0074 - val_loss: 0.0012 - val_mae: 0.0012 - val_root_mean_squared_error: 0.0018\n",
      "Epoch 40/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0079 - val_loss: 0.0023 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 41/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0046 - mae: 0.0046 - root_mean_squared_error: 0.0067 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 42/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0042 - mae: 0.0042 - root_mean_squared_error: 0.0064 - val_loss: 0.0015 - val_mae: 0.0015 - val_root_mean_squared_error: 0.0022\n",
      "Epoch 43/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0044 - mae: 0.0044 - root_mean_squared_error: 0.0064 - val_loss: 0.0070 - val_mae: 0.0070 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 44/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040 - mae: 0.0040 - root_mean_squared_error: 0.0062 - val_loss: 0.0031 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0032\n",
      "Epoch 45/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0044 - mae: 0.0044 - root_mean_squared_error: 0.0063 - val_loss: 0.0062 - val_mae: 0.0062 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 46/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0059 - mae: 0.0059 - root_mean_squared_error: 0.0081 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 47/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0044 - mae: 0.0044 - root_mean_squared_error: 0.0063 - val_loss: 0.0023 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 48/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0044 - mae: 0.0044 - root_mean_squared_error: 0.0063 - val_loss: 8.3556e-04 - val_mae: 8.3556e-04 - val_root_mean_squared_error: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0039 - root_mean_squared_error: 0.0060 - val_loss: 0.0076 - val_mae: 0.0076 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 50/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - mae: 0.0039 - root_mean_squared_error: 0.0059 - val_loss: 0.0035 - val_mae: 0.0035 - val_root_mean_squared_error: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:30:50 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:30:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:30:58 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:31:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: input_width = 24 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0823 - mae: 0.0823 - root_mean_squared_error: 0.1266 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0377\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0670 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0468 - mae: 0.0468 - root_mean_squared_error: 0.0651 - val_loss: 0.0301 - val_mae: 0.0301 - val_root_mean_squared_error: 0.0404\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0455 - mae: 0.0455 - root_mean_squared_error: 0.0628 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0423 - mae: 0.0423 - root_mean_squared_error: 0.0595 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0373\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0420 - mae: 0.0420 - root_mean_squared_error: 0.0595 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0404 - mae: 0.0404 - root_mean_squared_error: 0.0578 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0576 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0387 - mae: 0.0387 - root_mean_squared_error: 0.0564 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0562 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0561 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0377 - mae: 0.0377 - root_mean_squared_error: 0.0554 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0549 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0551 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0543 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0539 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0538 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0539 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0525 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0527 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0521 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0339\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0332 - mae: 0.0332 - root_mean_squared_error: 0.0509 - val_loss: 0.0224 - val_mae: 0.0224 - val_root_mean_squared_error: 0.0329\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0496 - val_loss: 0.0220 - val_mae: 0.0220 - val_root_mean_squared_error: 0.0315\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0309 - mae: 0.0309 - root_mean_squared_error: 0.0458 - val_loss: 0.0199 - val_mae: 0.0199 - val_root_mean_squared_error: 0.0279\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0274 - mae: 0.0274 - root_mean_squared_error: 0.0403 - val_loss: 0.0158 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0214\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0215 - mae: 0.0215 - root_mean_squared_error: 0.0309 - val_loss: 0.0119 - val_mae: 0.0119 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0190 - mae: 0.0190 - root_mean_squared_error: 0.0270 - val_loss: 0.0099 - val_mae: 0.0099 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0151 - mae: 0.0151 - root_mean_squared_error: 0.0215 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0139 - mae: 0.0139 - root_mean_squared_error: 0.0189 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0161 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0099 - mae: 0.0099 - root_mean_squared_error: 0.0140 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0130 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0084 - root_mean_squared_error: 0.0118 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0107 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0070 - mae: 0.0070 - root_mean_squared_error: 0.0100 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0092 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0096 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0081 - val_loss: 0.0017 - val_mae: 0.0017 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0045 - root_mean_squared_error: 0.0070 - val_loss: 0.0031 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0087 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0079 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:32:31 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:32:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:32:39 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:32:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: input_width = 48 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0825 - mae: 0.0825 - root_mean_squared_error: 0.1267 - val_loss: 0.0282 - val_mae: 0.0282 - val_root_mean_squared_error: 0.0391\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0491 - mae: 0.0491 - root_mean_squared_error: 0.0665 - val_loss: 0.0276 - val_mae: 0.0276 - val_root_mean_squared_error: 0.0385\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0463 - mae: 0.0463 - root_mean_squared_error: 0.0645 - val_loss: 0.0283 - val_mae: 0.0283 - val_root_mean_squared_error: 0.0390\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0456 - mae: 0.0456 - root_mean_squared_error: 0.0630 - val_loss: 0.0283 - val_mae: 0.0283 - val_root_mean_squared_error: 0.0390\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0447 - mae: 0.0447 - root_mean_squared_error: 0.0626 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0432 - mae: 0.0432 - root_mean_squared_error: 0.0611 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0595 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0418 - mae: 0.0418 - root_mean_squared_error: 0.0593 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0581 - val_loss: 0.0255 - val_mae: 0.0255 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0577 - val_loss: 0.0271 - val_mae: 0.0271 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0571 - val_loss: 0.0279 - val_mae: 0.0279 - val_root_mean_squared_error: 0.0384\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0567 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0387 - mae: 0.0387 - root_mean_squared_error: 0.0564 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0379 - mae: 0.0379 - root_mean_squared_error: 0.0557 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0553 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0557 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0368 - mae: 0.0368 - root_mean_squared_error: 0.0547 - val_loss: 0.0258 - val_mae: 0.0258 - val_root_mean_squared_error: 0.0367\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0544 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0359 - mae: 0.0359 - root_mean_squared_error: 0.0543 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0358 - mae: 0.0358 - root_mean_squared_error: 0.0544 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0537 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0538 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0538 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0532 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0535 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0531 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0532 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0533 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0529 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0530 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0529 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0528 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0527 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0528 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0528 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0526 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0526 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0525 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0525 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0525 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:34:49 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:34:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:34:58 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:35:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: input_width = 72 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 0.0825 - mae: 0.0825 - root_mean_squared_error: 0.1267 - val_loss: 0.0284 - val_mae: 0.0284 - val_root_mean_squared_error: 0.0391\n",
      "Epoch 2/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0490 - mae: 0.0490 - root_mean_squared_error: 0.0673 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 3/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0464 - mae: 0.0464 - root_mean_squared_error: 0.0641 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 4/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0452 - mae: 0.0452 - root_mean_squared_error: 0.0630 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 5/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0439 - mae: 0.0439 - root_mean_squared_error: 0.0611 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 6/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0435 - mae: 0.0435 - root_mean_squared_error: 0.0611 - val_loss: 0.0316 - val_mae: 0.0316 - val_root_mean_squared_error: 0.0417\n",
      "Epoch 7/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0429 - mae: 0.0429 - root_mean_squared_error: 0.0613 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 8/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0422 - mae: 0.0422 - root_mean_squared_error: 0.0598 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 9/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0411 - mae: 0.0411 - root_mean_squared_error: 0.0590 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 10/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0574 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 11/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0573 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 12/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0393 - mae: 0.0393 - root_mean_squared_error: 0.0571 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 13/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0563 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 14/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0556 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 15/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0558 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 16/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0558 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 17/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0554 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 18/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0364 - mae: 0.0364 - root_mean_squared_error: 0.0549 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 19/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0359 - mae: 0.0359 - root_mean_squared_error: 0.0540 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 20/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0359 - mae: 0.0359 - root_mean_squared_error: 0.0542 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 21/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0541 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 22/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0538 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 23/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0538 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 24/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0537 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 25/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0535 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 26/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0534 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 27/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0534 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 28/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0533 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 29/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 30/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0531 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 31/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0532 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 32/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0529 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 33/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0528 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 34/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0528 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 35/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0528 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 36/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0529 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 37/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0528 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 38/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0528 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 39/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0527 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 40/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0527 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 41/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0527 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:37:29 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:37:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:37:38 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:37:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: input_width = 96 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 0.0829 - mae: 0.0829 - root_mean_squared_error: 0.1271 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 2/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0488 - mae: 0.0488 - root_mean_squared_error: 0.0668 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 3/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 0.0467 - mae: 0.0467 - root_mean_squared_error: 0.0643 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 4/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0461 - mae: 0.0461 - root_mean_squared_error: 0.0635 - val_loss: 0.0258 - val_mae: 0.0258 - val_root_mean_squared_error: 0.0367\n",
      "Epoch 5/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0623 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 6/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0439 - mae: 0.0439 - root_mean_squared_error: 0.0617 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 7/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0429 - mae: 0.0429 - root_mean_squared_error: 0.0610 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 8/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0431 - mae: 0.0431 - root_mean_squared_error: 0.0603 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0362\n",
      "Epoch 9/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0412 - mae: 0.0412 - root_mean_squared_error: 0.0591 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 10/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0406 - mae: 0.0406 - root_mean_squared_error: 0.0584 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 11/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0579 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 12/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0392 - mae: 0.0392 - root_mean_squared_error: 0.0570 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 13/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0387 - mae: 0.0387 - root_mean_squared_error: 0.0565 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 14/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0382 - mae: 0.0382 - root_mean_squared_error: 0.0563 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 15/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0563 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 16/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0558 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 17/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0553 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 18/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0368 - mae: 0.0368 - root_mean_squared_error: 0.0550 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 19/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0546 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 20/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0546 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 21/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0359 - mae: 0.0359 - root_mean_squared_error: 0.0542 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 22/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0541 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 23/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0537 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 24/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0538 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 25/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0536 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 26/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0537 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 27/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0534 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 28/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0531 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 29/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0531 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 30/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0534 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 31/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0533 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:40:01 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:40:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:40:11 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:40:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 21:40:37 INFO mlflow.tracking.fluent: Experiment with name 'log_return_gru_batch_size_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: batch_size = 16 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0663 - mae: 0.0663 - root_mean_squared_error: 0.1019 - val_loss: 0.0250 - val_mae: 0.0250 - val_root_mean_squared_error: 0.0362\n",
      "Epoch 2/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0472 - mae: 0.0472 - root_mean_squared_error: 0.0652 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 3/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0453 - mae: 0.0453 - root_mean_squared_error: 0.0630 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 4/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0432 - mae: 0.0432 - root_mean_squared_error: 0.0609 - val_loss: 0.0254 - val_mae: 0.0254 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 5/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0425 - mae: 0.0425 - root_mean_squared_error: 0.0604 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 6/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0578 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 7/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0395 - mae: 0.0395 - root_mean_squared_error: 0.0575 - val_loss: 0.0277 - val_mae: 0.0277 - val_root_mean_squared_error: 0.0382\n",
      "Epoch 8/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0567 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 9/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0377 - mae: 0.0377 - root_mean_squared_error: 0.0554 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 10/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0374 - mae: 0.0374 - root_mean_squared_error: 0.0548 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 11/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0545 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 12/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0538 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 13/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0538 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 14/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0534 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 15/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0530 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 16/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0529 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 17/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0528 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 18/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 19/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0523 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 20/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 21/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0523 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 22/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0519 - val_loss: 0.0231 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 23/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0332 - mae: 0.0332 - root_mean_squared_error: 0.0511 - val_loss: 0.0221 - val_mae: 0.0221 - val_root_mean_squared_error: 0.0324\n",
      "Epoch 24/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0326 - mae: 0.0326 - root_mean_squared_error: 0.0499 - val_loss: 0.0214 - val_mae: 0.0214 - val_root_mean_squared_error: 0.0311\n",
      "Epoch 25/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0306 - mae: 0.0306 - root_mean_squared_error: 0.0462 - val_loss: 0.0196 - val_mae: 0.0196 - val_root_mean_squared_error: 0.0276\n",
      "Epoch 26/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0275 - mae: 0.0275 - root_mean_squared_error: 0.0407 - val_loss: 0.0154 - val_mae: 0.0154 - val_root_mean_squared_error: 0.0223\n",
      "Epoch 27/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0215 - mae: 0.0215 - root_mean_squared_error: 0.0317 - val_loss: 0.0098 - val_mae: 0.0098 - val_root_mean_squared_error: 0.0137\n",
      "Epoch 28/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0156 - mae: 0.0156 - root_mean_squared_error: 0.0226 - val_loss: 0.0081 - val_mae: 0.0081 - val_root_mean_squared_error: 0.0104\n",
      "Epoch 29/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0115 - mae: 0.0115 - root_mean_squared_error: 0.0168 - val_loss: 0.0060 - val_mae: 0.0060 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 30/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0087 - mae: 0.0087 - root_mean_squared_error: 0.0128 - val_loss: 0.0038 - val_mae: 0.0038 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 31/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0117 - val_loss: 0.0046 - val_mae: 0.0046 - val_root_mean_squared_error: 0.0059\n",
      "Epoch 32/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0070 - mae: 0.0070 - root_mean_squared_error: 0.0106 - val_loss: 0.0026 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0037\n",
      "Epoch 33/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0076 - mae: 0.0076 - root_mean_squared_error: 0.0108 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 34/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0105 - val_loss: 0.0026 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 35/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0059 - mae: 0.0059 - root_mean_squared_error: 0.0088 - val_loss: 0.0050 - val_mae: 0.0050 - val_root_mean_squared_error: 0.0057\n",
      "Epoch 36/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0058 - mae: 0.0058 - root_mean_squared_error: 0.0088 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 37/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0050 - root_mean_squared_error: 0.0072 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 38/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0079 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 39/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0048 - root_mean_squared_error: 0.0072 - val_loss: 0.0016 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0022\n",
      "Epoch 40/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0047 - root_mean_squared_error: 0.0073 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 41/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0051 - mae: 0.0051 - root_mean_squared_error: 0.0075 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0033\n",
      "Epoch 42/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0044 - mae: 0.0044 - root_mean_squared_error: 0.0069 - val_loss: 0.0015 - val_mae: 0.0015 - val_root_mean_squared_error: 0.0018\n",
      "Epoch 43/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0048 - root_mean_squared_error: 0.0070 - val_loss: 8.4791e-04 - val_mae: 8.4791e-04 - val_root_mean_squared_error: 0.0012\n",
      "Epoch 44/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0045 - mae: 0.0045 - root_mean_squared_error: 0.0068 - val_loss: 0.0031 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0033\n",
      "Epoch 45/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0043 - mae: 0.0043 - root_mean_squared_error: 0.0064 - val_loss: 0.0016 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0022\n",
      "Epoch 46/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0042 - mae: 0.0042 - root_mean_squared_error: 0.0067 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 47/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0041 - root_mean_squared_error: 0.0063 - val_loss: 0.0012 - val_mae: 0.0012 - val_root_mean_squared_error: 0.0017\n",
      "Epoch 48/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0048 - root_mean_squared_error: 0.0071 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 49/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0042 - mae: 0.0042 - root_mean_squared_error: 0.0066 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 50/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0042 - mae: 0.0042 - root_mean_squared_error: 0.0064 - val_loss: 0.0025 - val_mae: 0.0025 - val_root_mean_squared_error: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:42:28 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:42:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:42:37 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:42:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: batch_size = 32 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0823 - mae: 0.0823 - root_mean_squared_error: 0.1266 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0377\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0670 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0468 - mae: 0.0468 - root_mean_squared_error: 0.0651 - val_loss: 0.0301 - val_mae: 0.0301 - val_root_mean_squared_error: 0.0404\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0455 - mae: 0.0455 - root_mean_squared_error: 0.0628 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0423 - mae: 0.0423 - root_mean_squared_error: 0.0595 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0373\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0420 - mae: 0.0420 - root_mean_squared_error: 0.0595 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0404 - mae: 0.0404 - root_mean_squared_error: 0.0578 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0576 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0387 - mae: 0.0387 - root_mean_squared_error: 0.0564 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0562 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0561 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0377 - mae: 0.0377 - root_mean_squared_error: 0.0554 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0549 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0551 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0543 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0539 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0538 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0539 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0525 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0527 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0521 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0339\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0332 - mae: 0.0332 - root_mean_squared_error: 0.0509 - val_loss: 0.0224 - val_mae: 0.0224 - val_root_mean_squared_error: 0.0329\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0496 - val_loss: 0.0220 - val_mae: 0.0220 - val_root_mean_squared_error: 0.0315\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0309 - mae: 0.0309 - root_mean_squared_error: 0.0458 - val_loss: 0.0199 - val_mae: 0.0199 - val_root_mean_squared_error: 0.0279\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0274 - mae: 0.0274 - root_mean_squared_error: 0.0403 - val_loss: 0.0158 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0214\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0215 - mae: 0.0215 - root_mean_squared_error: 0.0309 - val_loss: 0.0119 - val_mae: 0.0119 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0190 - mae: 0.0190 - root_mean_squared_error: 0.0270 - val_loss: 0.0099 - val_mae: 0.0099 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0151 - mae: 0.0151 - root_mean_squared_error: 0.0215 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0139 - mae: 0.0139 - root_mean_squared_error: 0.0189 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0161 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0099 - mae: 0.0099 - root_mean_squared_error: 0.0140 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0130 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0084 - root_mean_squared_error: 0.0118 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0107 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0070 - mae: 0.0070 - root_mean_squared_error: 0.0100 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0092 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0096 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0081 - val_loss: 0.0017 - val_mae: 0.0017 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0045 - mae: 0.0045 - root_mean_squared_error: 0.0070 - val_loss: 0.0031 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0087 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0079 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:44:34 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:44:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:44:44 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:44:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: batch_size = 64 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.1088 - mae: 0.1088 - root_mean_squared_error: 0.1628 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 2/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0522 - mae: 0.0522 - root_mean_squared_error: 0.0710 - val_loss: 0.0263 - val_mae: 0.0263 - val_root_mean_squared_error: 0.0374\n",
      "Epoch 3/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0494 - mae: 0.0494 - root_mean_squared_error: 0.0670 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 4/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0471 - mae: 0.0471 - root_mean_squared_error: 0.0649 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 5/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0459 - mae: 0.0459 - root_mean_squared_error: 0.0639 - val_loss: 0.0276 - val_mae: 0.0276 - val_root_mean_squared_error: 0.0382\n",
      "Epoch 6/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0455 - mae: 0.0455 - root_mean_squared_error: 0.0635 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 7/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0440 - mae: 0.0440 - root_mean_squared_error: 0.0618 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 8/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0440 - mae: 0.0440 - root_mean_squared_error: 0.0614 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 9/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0625 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 10/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0426 - mae: 0.0426 - root_mean_squared_error: 0.0607 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 11/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0420 - mae: 0.0420 - root_mean_squared_error: 0.0593 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 12/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0599 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 13/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0413 - mae: 0.0413 - root_mean_squared_error: 0.0588 - val_loss: 0.0265 - val_mae: 0.0265 - val_root_mean_squared_error: 0.0371\n",
      "Epoch 14/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0410 - mae: 0.0410 - root_mean_squared_error: 0.0590 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 15/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0577 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 16/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0570 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 17/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0395 - mae: 0.0395 - root_mean_squared_error: 0.0572 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 18/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0392 - mae: 0.0392 - root_mean_squared_error: 0.0571 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 19/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0563 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 20/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0383 - mae: 0.0383 - root_mean_squared_error: 0.0562 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 21/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0555 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 22/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0374 - mae: 0.0374 - root_mean_squared_error: 0.0555 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 23/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0553 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 24/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0545 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 25/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0366 - mae: 0.0366 - root_mean_squared_error: 0.0547 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 26/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0364 - mae: 0.0364 - root_mean_squared_error: 0.0544 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 27/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0542 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 28/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0364 - mae: 0.0364 - root_mean_squared_error: 0.0545 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 29/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0533 - val_loss: 0.0231 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 30/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0541 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 31/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0536 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 32/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0532 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 33/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0527 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 34/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0527 - val_loss: 0.0231 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 35/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0531 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 36/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 37/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0523 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 38/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0521 - val_loss: 0.0228 - val_mae: 0.0228 - val_root_mean_squared_error: 0.0336\n",
      "Epoch 39/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0515 - val_loss: 0.0226 - val_mae: 0.0226 - val_root_mean_squared_error: 0.0333\n",
      "Epoch 40/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0511 - val_loss: 0.0225 - val_mae: 0.0225 - val_root_mean_squared_error: 0.0331\n",
      "Epoch 41/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0328 - mae: 0.0328 - root_mean_squared_error: 0.0502 - val_loss: 0.0220 - val_mae: 0.0220 - val_root_mean_squared_error: 0.0324\n",
      "Epoch 42/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0325 - mae: 0.0325 - root_mean_squared_error: 0.0494 - val_loss: 0.0217 - val_mae: 0.0217 - val_root_mean_squared_error: 0.0315\n",
      "Epoch 43/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0314 - mae: 0.0314 - root_mean_squared_error: 0.0472 - val_loss: 0.0208 - val_mae: 0.0208 - val_root_mean_squared_error: 0.0298\n",
      "Epoch 44/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0281 - mae: 0.0281 - root_mean_squared_error: 0.0421 - val_loss: 0.0227 - val_mae: 0.0227 - val_root_mean_squared_error: 0.0287\n",
      "Epoch 45/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0257 - mae: 0.0257 - root_mean_squared_error: 0.0363 - val_loss: 0.0160 - val_mae: 0.0160 - val_root_mean_squared_error: 0.0215\n",
      "Epoch 46/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0205 - mae: 0.0205 - root_mean_squared_error: 0.0301 - val_loss: 0.0150 - val_mae: 0.0150 - val_root_mean_squared_error: 0.0189\n",
      "Epoch 47/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0174 - mae: 0.0174 - root_mean_squared_error: 0.0247 - val_loss: 0.0098 - val_mae: 0.0098 - val_root_mean_squared_error: 0.0136\n",
      "Epoch 48/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0154 - mae: 0.0154 - root_mean_squared_error: 0.0217 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0108\n",
      "Epoch 49/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0150 - mae: 0.0150 - root_mean_squared_error: 0.0208 - val_loss: 0.0097 - val_mae: 0.0097 - val_root_mean_squared_error: 0.0119\n",
      "Epoch 50/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0124 - mae: 0.0124 - root_mean_squared_error: 0.0172 - val_loss: 0.0072 - val_mae: 0.0072 - val_root_mean_squared_error: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:46:20 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:46:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:46:31 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:46:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: batch_size = 128 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.1581 - mae: 0.1581 - root_mean_squared_error: 0.2162 - val_loss: 0.0345 - val_mae: 0.0345 - val_root_mean_squared_error: 0.0444\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0586 - mae: 0.0586 - root_mean_squared_error: 0.0779 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0540 - mae: 0.0540 - root_mean_squared_error: 0.0728 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0519 - mae: 0.0519 - root_mean_squared_error: 0.0701 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0364\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0487 - mae: 0.0487 - root_mean_squared_error: 0.0667 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0483 - mae: 0.0483 - root_mean_squared_error: 0.0665 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0474 - mae: 0.0474 - root_mean_squared_error: 0.0655 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0465 - mae: 0.0465 - root_mean_squared_error: 0.0644 - val_loss: 0.0288 - val_mae: 0.0288 - val_root_mean_squared_error: 0.0394\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0461 - mae: 0.0461 - root_mean_squared_error: 0.0639 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0449 - mae: 0.0449 - root_mean_squared_error: 0.0625 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0450 - mae: 0.0450 - root_mean_squared_error: 0.0630 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0362\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0448 - mae: 0.0448 - root_mean_squared_error: 0.0633 - val_loss: 0.0252 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0362\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0439 - mae: 0.0439 - root_mean_squared_error: 0.0616 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0438 - mae: 0.0438 - root_mean_squared_error: 0.0616 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0615 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0428 - mae: 0.0428 - root_mean_squared_error: 0.0607 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0426 - mae: 0.0426 - root_mean_squared_error: 0.0600 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0600 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0596 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0417 - mae: 0.0417 - root_mean_squared_error: 0.0591 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0422 - mae: 0.0422 - root_mean_squared_error: 0.0600 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0412 - mae: 0.0412 - root_mean_squared_error: 0.0588 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0404 - mae: 0.0404 - root_mean_squared_error: 0.0580 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0576 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 25/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0408 - mae: 0.0408 - root_mean_squared_error: 0.0587 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 26/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0579 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 27/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0398 - mae: 0.0398 - root_mean_squared_error: 0.0573 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 28/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0402 - mae: 0.0402 - root_mean_squared_error: 0.0577 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 29/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0570 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 30/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0563 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 31/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0391 - mae: 0.0391 - root_mean_squared_error: 0.0568 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 32/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0390 - mae: 0.0390 - root_mean_squared_error: 0.0568 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 33/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0383 - mae: 0.0383 - root_mean_squared_error: 0.0561 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 34/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0387 - mae: 0.0387 - root_mean_squared_error: 0.0565 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 35/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0566 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 36/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0550 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 37/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0549 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 38/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0374 - mae: 0.0374 - root_mean_squared_error: 0.0555 - val_loss: 0.0231 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 39/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0544 - val_loss: 0.0231 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 40/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0377 - mae: 0.0377 - root_mean_squared_error: 0.0549 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 41/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0372 - mae: 0.0372 - root_mean_squared_error: 0.0548 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 42/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0364 - mae: 0.0364 - root_mean_squared_error: 0.0544 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 43/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0544 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 44/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0359 - mae: 0.0359 - root_mean_squared_error: 0.0537 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 45/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0538 - val_loss: 0.0231 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 46/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0536 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 47/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0540 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 48/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0359 - mae: 0.0359 - root_mean_squared_error: 0.0537 - val_loss: 0.0231 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0339\n",
      "Epoch 49/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0532 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0338\n",
      "Epoch 50/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0534 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:48:02 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:48:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:48:11 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:48:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 21:48:53 INFO mlflow.tracking.fluent: Experiment with name 'log_return_gru_learning_rate_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: learning_rate = 0.0001 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2585 - mae: 0.2585 - root_mean_squared_error: 0.3030 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0362\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0635 - mae: 0.0635 - root_mean_squared_error: 0.0829 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0597 - mae: 0.0597 - root_mean_squared_error: 0.0799 - val_loss: 0.0262 - val_mae: 0.0262 - val_root_mean_squared_error: 0.0374\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0568 - mae: 0.0568 - root_mean_squared_error: 0.0752 - val_loss: 0.0260 - val_mae: 0.0260 - val_root_mean_squared_error: 0.0372\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0557 - mae: 0.0557 - root_mean_squared_error: 0.0745 - val_loss: 0.0250 - val_mae: 0.0250 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0537 - mae: 0.0537 - root_mean_squared_error: 0.0724 - val_loss: 0.0260 - val_mae: 0.0260 - val_root_mean_squared_error: 0.0371\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0520 - mae: 0.0520 - root_mean_squared_error: 0.0699 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0515 - mae: 0.0515 - root_mean_squared_error: 0.0698 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0505 - mae: 0.0505 - root_mean_squared_error: 0.0684 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0491 - mae: 0.0491 - root_mean_squared_error: 0.0674 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0478 - mae: 0.0478 - root_mean_squared_error: 0.0656 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0482 - mae: 0.0482 - root_mean_squared_error: 0.0659 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0477 - mae: 0.0477 - root_mean_squared_error: 0.0654 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0469 - mae: 0.0469 - root_mean_squared_error: 0.0647 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0468 - mae: 0.0468 - root_mean_squared_error: 0.0645 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0473 - mae: 0.0473 - root_mean_squared_error: 0.0652 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0464 - mae: 0.0464 - root_mean_squared_error: 0.0643 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0457 - mae: 0.0457 - root_mean_squared_error: 0.0637 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0455 - mae: 0.0455 - root_mean_squared_error: 0.0636 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0456 - mae: 0.0456 - root_mean_squared_error: 0.0640 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0454 - mae: 0.0454 - root_mean_squared_error: 0.0630 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0448 - mae: 0.0448 - root_mean_squared_error: 0.0622 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0447 - mae: 0.0447 - root_mean_squared_error: 0.0627 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0443 - mae: 0.0443 - root_mean_squared_error: 0.0617 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0449 - mae: 0.0449 - root_mean_squared_error: 0.0630 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0442 - mae: 0.0442 - root_mean_squared_error: 0.0616 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0434 - mae: 0.0434 - root_mean_squared_error: 0.0613 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0446 - mae: 0.0446 - root_mean_squared_error: 0.0626 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0435 - mae: 0.0435 - root_mean_squared_error: 0.0612 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0439 - mae: 0.0439 - root_mean_squared_error: 0.0618 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0432 - mae: 0.0432 - root_mean_squared_error: 0.0612 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0438 - mae: 0.0438 - root_mean_squared_error: 0.0613 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0426 - mae: 0.0426 - root_mean_squared_error: 0.0604 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0431 - mae: 0.0431 - root_mean_squared_error: 0.0608 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0432 - mae: 0.0432 - root_mean_squared_error: 0.0611 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0429 - mae: 0.0429 - root_mean_squared_error: 0.0602 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0425 - mae: 0.0425 - root_mean_squared_error: 0.0598 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0425 - mae: 0.0425 - root_mean_squared_error: 0.0600 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0425 - mae: 0.0425 - root_mean_squared_error: 0.0599 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0419 - mae: 0.0419 - root_mean_squared_error: 0.0595 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0423 - mae: 0.0423 - root_mean_squared_error: 0.0602 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0597 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0415 - mae: 0.0415 - root_mean_squared_error: 0.0592 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0417 - mae: 0.0417 - root_mean_squared_error: 0.0595 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0418 - mae: 0.0418 - root_mean_squared_error: 0.0595 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0413 - mae: 0.0413 - root_mean_squared_error: 0.0590 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0411 - mae: 0.0411 - root_mean_squared_error: 0.0587 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0405 - mae: 0.0405 - root_mean_squared_error: 0.0581 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0408 - mae: 0.0408 - root_mean_squared_error: 0.0587 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0411 - mae: 0.0411 - root_mean_squared_error: 0.0585 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:50:01 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:50:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:50:10 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:50:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: learning_rate = 0.001 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0823 - mae: 0.0823 - root_mean_squared_error: 0.1266 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0377\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0670 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0468 - mae: 0.0468 - root_mean_squared_error: 0.0651 - val_loss: 0.0301 - val_mae: 0.0301 - val_root_mean_squared_error: 0.0404\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0455 - mae: 0.0455 - root_mean_squared_error: 0.0628 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0423 - mae: 0.0423 - root_mean_squared_error: 0.0595 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0373\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0420 - mae: 0.0420 - root_mean_squared_error: 0.0595 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0404 - mae: 0.0404 - root_mean_squared_error: 0.0578 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0576 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0387 - mae: 0.0387 - root_mean_squared_error: 0.0564 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0562 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0561 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0377 - mae: 0.0377 - root_mean_squared_error: 0.0554 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0549 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0551 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0543 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0539 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0538 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0539 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0525 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0527 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0521 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0339\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0332 - mae: 0.0332 - root_mean_squared_error: 0.0509 - val_loss: 0.0224 - val_mae: 0.0224 - val_root_mean_squared_error: 0.0329\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0496 - val_loss: 0.0220 - val_mae: 0.0220 - val_root_mean_squared_error: 0.0315\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0309 - mae: 0.0309 - root_mean_squared_error: 0.0458 - val_loss: 0.0199 - val_mae: 0.0199 - val_root_mean_squared_error: 0.0279\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0274 - mae: 0.0274 - root_mean_squared_error: 0.0403 - val_loss: 0.0158 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0214\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0215 - mae: 0.0215 - root_mean_squared_error: 0.0309 - val_loss: 0.0119 - val_mae: 0.0119 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0190 - mae: 0.0190 - root_mean_squared_error: 0.0270 - val_loss: 0.0099 - val_mae: 0.0099 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0151 - mae: 0.0151 - root_mean_squared_error: 0.0215 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0139 - mae: 0.0139 - root_mean_squared_error: 0.0189 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0161 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0099 - mae: 0.0099 - root_mean_squared_error: 0.0140 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0130 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0084 - root_mean_squared_error: 0.0118 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0107 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0070 - mae: 0.0070 - root_mean_squared_error: 0.0100 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0092 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0096 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0081 - val_loss: 0.0017 - val_mae: 0.0017 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0045 - mae: 0.0045 - root_mean_squared_error: 0.0070 - val_loss: 0.0031 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0087 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0079 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:52:04 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:52:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:52:14 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:52:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: learning_rate = 0.01 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0586 - mae: 0.0586 - root_mean_squared_error: 0.0882 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0422 - mae: 0.0422 - root_mean_squared_error: 0.0598 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0368 - mae: 0.0368 - root_mean_squared_error: 0.0550 - val_loss: 0.0231 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0528 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0521 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0327 - mae: 0.0327 - root_mean_squared_error: 0.0503 - val_loss: 0.0195 - val_mae: 0.0195 - val_root_mean_squared_error: 0.0280\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0205 - mae: 0.0205 - root_mean_squared_error: 0.0317 - val_loss: 0.0281 - val_mae: 0.0281 - val_root_mean_squared_error: 0.0293\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0163 - mae: 0.0163 - root_mean_squared_error: 0.0239 - val_loss: 0.0223 - val_mae: 0.0223 - val_root_mean_squared_error: 0.0248\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0109 - root_mean_squared_error: 0.0185 - val_loss: 0.0098 - val_mae: 0.0098 - val_root_mean_squared_error: 0.0115\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0094 - mae: 0.0094 - root_mean_squared_error: 0.0151 - val_loss: 0.0038 - val_mae: 0.0038 - val_root_mean_squared_error: 0.0056\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0090 - mae: 0.0090 - root_mean_squared_error: 0.0147 - val_loss: 0.0085 - val_mae: 0.0085 - val_root_mean_squared_error: 0.0114\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0087 - mae: 0.0087 - root_mean_squared_error: 0.0142 - val_loss: 0.0078 - val_mae: 0.0078 - val_root_mean_squared_error: 0.0114\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0089 - mae: 0.0089 - root_mean_squared_error: 0.0156 - val_loss: 0.0079 - val_mae: 0.0079 - val_root_mean_squared_error: 0.0098\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0081 - mae: 0.0081 - root_mean_squared_error: 0.0130 - val_loss: 0.0060 - val_mae: 0.0060 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0072 - mae: 0.0072 - root_mean_squared_error: 0.0123 - val_loss: 0.0051 - val_mae: 0.0051 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0085 - mae: 0.0085 - root_mean_squared_error: 0.0153 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0062\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0100 - mae: 0.0100 - root_mean_squared_error: 0.0175 - val_loss: 0.0070 - val_mae: 0.0070 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0077 - mae: 0.0077 - root_mean_squared_error: 0.0125 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0022\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0117 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0070 - mae: 0.0070 - root_mean_squared_error: 0.0114 - val_loss: 0.0014 - val_mae: 0.0014 - val_root_mean_squared_error: 0.0020\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0106 - val_loss: 0.0073 - val_mae: 0.0073 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0139 - val_loss: 0.0023 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0067 - mae: 0.0067 - root_mean_squared_error: 0.0124 - val_loss: 0.0080 - val_mae: 0.0080 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0078 - mae: 0.0078 - root_mean_squared_error: 0.0125 - val_loss: 0.0066 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0070\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0068 - mae: 0.0068 - root_mean_squared_error: 0.0107 - val_loss: 0.0025 - val_mae: 0.0025 - val_root_mean_squared_error: 0.0039\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0104 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0103 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0055 - mae: 0.0055 - root_mean_squared_error: 0.0083 - val_loss: 0.0023 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0061 - root_mean_squared_error: 0.0096 - val_loss: 0.0052 - val_mae: 0.0052 - val_root_mean_squared_error: 0.0063\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0151 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:53:52 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:54:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:54:17 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:54:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: learning_rate = 0.1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1264 - mae: 0.1264 - root_mean_squared_error: 0.4389 - val_loss: 0.0254 - val_mae: 0.0254 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0463 - mae: 0.0463 - root_mean_squared_error: 0.0662 - val_loss: 0.0213 - val_mae: 0.0213 - val_root_mean_squared_error: 0.0314\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0473 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0297\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0391 - mae: 0.0391 - root_mean_squared_error: 0.0524 - val_loss: 0.0574 - val_mae: 0.0574 - val_root_mean_squared_error: 0.0600\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0329 - mae: 0.0329 - root_mean_squared_error: 0.0448 - val_loss: 0.0317 - val_mae: 0.0317 - val_root_mean_squared_error: 0.0332\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0273 - mae: 0.0273 - root_mean_squared_error: 0.0359 - val_loss: 0.0360 - val_mae: 0.0360 - val_root_mean_squared_error: 0.0417\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0225 - mae: 0.0225 - root_mean_squared_error: 0.0323 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0246\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171 - mae: 0.0171 - root_mean_squared_error: 0.0241 - val_loss: 0.0277 - val_mae: 0.0277 - val_root_mean_squared_error: 0.0331\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0235 - mae: 0.0235 - root_mean_squared_error: 0.0294 - val_loss: 0.0103 - val_mae: 0.0103 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0157 - mae: 0.0157 - root_mean_squared_error: 0.0213 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0207\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0173 - mae: 0.0173 - root_mean_squared_error: 0.0229 - val_loss: 0.0214 - val_mae: 0.0214 - val_root_mean_squared_error: 0.0215\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0163 - mae: 0.0163 - root_mean_squared_error: 0.0209 - val_loss: 0.0107 - val_mae: 0.0107 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0145 - mae: 0.0145 - root_mean_squared_error: 0.0193 - val_loss: 0.0127 - val_mae: 0.0127 - val_root_mean_squared_error: 0.0130\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0152 - mae: 0.0152 - root_mean_squared_error: 0.0198 - val_loss: 0.0275 - val_mae: 0.0275 - val_root_mean_squared_error: 0.0287\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0163 - mae: 0.0163 - root_mean_squared_error: 0.0212 - val_loss: 0.0058 - val_mae: 0.0058 - val_root_mean_squared_error: 0.0072\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0123 - mae: 0.0123 - root_mean_squared_error: 0.0174 - val_loss: 0.0084 - val_mae: 0.0084 - val_root_mean_squared_error: 0.0098\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0131 - mae: 0.0131 - root_mean_squared_error: 0.0182 - val_loss: 0.0053 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0066\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8349 - mae: 0.8349 - root_mean_squared_error: 1.2972 - val_loss: 2.4689 - val_mae: 2.4689 - val_root_mean_squared_error: 2.4691\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6487 - mae: 0.6487 - root_mean_squared_error: 0.8205 - val_loss: 0.4490 - val_mae: 0.4490 - val_root_mean_squared_error: 0.4504\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3142 - mae: 0.3142 - root_mean_squared_error: 0.3794 - val_loss: 0.4937 - val_mae: 0.4937 - val_root_mean_squared_error: 0.4949\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2842 - mae: 0.2842 - root_mean_squared_error: 0.3646 - val_loss: 0.3751 - val_mae: 0.3751 - val_root_mean_squared_error: 0.3767\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2174 - mae: 0.2174 - root_mean_squared_error: 0.2755 - val_loss: 0.0781 - val_mae: 0.0781 - val_root_mean_squared_error: 0.0842\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2391 - mae: 0.2391 - root_mean_squared_error: 0.2882 - val_loss: 0.1374 - val_mae: 0.1374 - val_root_mean_squared_error: 0.1412\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3082 - mae: 0.3082 - root_mean_squared_error: 0.3794 - val_loss: 0.1147 - val_mae: 0.1147 - val_root_mean_squared_error: 0.1189\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2592 - mae: 0.2592 - root_mean_squared_error: 0.3177 - val_loss: 0.1537 - val_mae: 0.1537 - val_root_mean_squared_error: 0.1568\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1331 - mae: 0.1331 - root_mean_squared_error: 0.1682 - val_loss: 0.1313 - val_mae: 0.1313 - val_root_mean_squared_error: 0.1351\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1613 - mae: 0.1613 - root_mean_squared_error: 0.1971 - val_loss: 0.2581 - val_mae: 0.2581 - val_root_mean_squared_error: 0.2601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:55:42 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:55:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:55:51 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:55:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 21:56:33 INFO mlflow.tracking.fluent: Experiment with name 'log_return_gru_model_units_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: model_units = 10 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1113 - mae: 0.1113 - root_mean_squared_error: 0.1437 - val_loss: 0.0311 - val_mae: 0.0311 - val_root_mean_squared_error: 0.0417\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0745 - mae: 0.0745 - root_mean_squared_error: 0.0967 - val_loss: 0.0250 - val_mae: 0.0250 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0647 - mae: 0.0647 - root_mean_squared_error: 0.0851 - val_loss: 0.0308 - val_mae: 0.0308 - val_root_mean_squared_error: 0.0412\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.0585 - root_mean_squared_error: 0.0779 - val_loss: 0.0251 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0528 - mae: 0.0528 - root_mean_squared_error: 0.0711 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0470 - mae: 0.0470 - root_mean_squared_error: 0.0653 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0436 - mae: 0.0436 - root_mean_squared_error: 0.0621 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0406 - mae: 0.0406 - root_mean_squared_error: 0.0583 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0561 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0366 - mae: 0.0366 - root_mean_squared_error: 0.0545 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0535 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0530 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0528 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0530 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0526 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0523 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0522 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0523 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0523 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0522 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0523 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0523 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0521 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0522 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0522 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0523 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0522 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0521 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0521 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0521 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0522 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0521 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0520 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0520 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:57:31 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:57:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:57:39 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:57:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: model_units = 50 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0823 - mae: 0.0823 - root_mean_squared_error: 0.1266 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0377\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0670 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0468 - mae: 0.0468 - root_mean_squared_error: 0.0651 - val_loss: 0.0301 - val_mae: 0.0301 - val_root_mean_squared_error: 0.0404\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0455 - mae: 0.0455 - root_mean_squared_error: 0.0628 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0423 - mae: 0.0423 - root_mean_squared_error: 0.0595 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0373\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0420 - mae: 0.0420 - root_mean_squared_error: 0.0595 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0404 - mae: 0.0404 - root_mean_squared_error: 0.0578 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0576 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0387 - mae: 0.0387 - root_mean_squared_error: 0.0564 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0562 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0561 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0377 - mae: 0.0377 - root_mean_squared_error: 0.0554 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0549 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0551 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0543 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0539 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0538 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0539 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0525 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0527 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0521 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0339\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0332 - mae: 0.0332 - root_mean_squared_error: 0.0509 - val_loss: 0.0224 - val_mae: 0.0224 - val_root_mean_squared_error: 0.0329\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0496 - val_loss: 0.0220 - val_mae: 0.0220 - val_root_mean_squared_error: 0.0315\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0309 - mae: 0.0309 - root_mean_squared_error: 0.0458 - val_loss: 0.0199 - val_mae: 0.0199 - val_root_mean_squared_error: 0.0279\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0274 - mae: 0.0274 - root_mean_squared_error: 0.0403 - val_loss: 0.0158 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0214\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0215 - mae: 0.0215 - root_mean_squared_error: 0.0309 - val_loss: 0.0119 - val_mae: 0.0119 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0190 - mae: 0.0190 - root_mean_squared_error: 0.0270 - val_loss: 0.0099 - val_mae: 0.0099 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0151 - mae: 0.0151 - root_mean_squared_error: 0.0215 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0139 - mae: 0.0139 - root_mean_squared_error: 0.0189 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0161 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0099 - mae: 0.0099 - root_mean_squared_error: 0.0140 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0130 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0084 - mae: 0.0084 - root_mean_squared_error: 0.0118 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0107 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0070 - mae: 0.0070 - root_mean_squared_error: 0.0100 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0092 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0096 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0081 - val_loss: 0.0017 - val_mae: 0.0017 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0045 - root_mean_squared_error: 0.0070 - val_loss: 0.0031 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0087 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0079 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 21:59:29 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 21:59:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 21:59:38 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 21:59:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: model_units = 100 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0694 - mae: 0.0694 - root_mean_squared_error: 0.1149 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0441 - mae: 0.0441 - root_mean_squared_error: 0.0622 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0422 - mae: 0.0422 - root_mean_squared_error: 0.0599 - val_loss: 0.0267 - val_mae: 0.0267 - val_root_mean_squared_error: 0.0376\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0414 - mae: 0.0414 - root_mean_squared_error: 0.0588 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0404 - mae: 0.0404 - root_mean_squared_error: 0.0580 - val_loss: 0.0275 - val_mae: 0.0275 - val_root_mean_squared_error: 0.0381\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0408 - mae: 0.0408 - root_mean_squared_error: 0.0586 - val_loss: 0.0319 - val_mae: 0.0319 - val_root_mean_squared_error: 0.0419\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0577 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0571 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0386 - mae: 0.0386 - root_mean_squared_error: 0.0565 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0559 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0560 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0552 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0546 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0546 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0339\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0531 - val_loss: 0.0226 - val_mae: 0.0226 - val_root_mean_squared_error: 0.0333\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0360 - mae: 0.0360 - root_mean_squared_error: 0.0527 - val_loss: 0.0224 - val_mae: 0.0224 - val_root_mean_squared_error: 0.0328\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0514 - val_loss: 0.0228 - val_mae: 0.0228 - val_root_mean_squared_error: 0.0325\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0327 - mae: 0.0327 - root_mean_squared_error: 0.0480 - val_loss: 0.0252 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0325\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0286 - mae: 0.0286 - root_mean_squared_error: 0.0405 - val_loss: 0.0198 - val_mae: 0.0198 - val_root_mean_squared_error: 0.0250\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0235 - mae: 0.0235 - root_mean_squared_error: 0.0316 - val_loss: 0.0135 - val_mae: 0.0135 - val_root_mean_squared_error: 0.0175\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0192 - mae: 0.0192 - root_mean_squared_error: 0.0254 - val_loss: 0.0175 - val_mae: 0.0175 - val_root_mean_squared_error: 0.0198\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0164 - mae: 0.0164 - root_mean_squared_error: 0.0216 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0095\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0166 - mae: 0.0166 - root_mean_squared_error: 0.0214 - val_loss: 0.0066 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0155 - mae: 0.0155 - root_mean_squared_error: 0.0200 - val_loss: 0.0053 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0138 - mae: 0.0138 - root_mean_squared_error: 0.0176 - val_loss: 0.0099 - val_mae: 0.0099 - val_root_mean_squared_error: 0.0119\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0130 - mae: 0.0130 - root_mean_squared_error: 0.0168 - val_loss: 0.0058 - val_mae: 0.0058 - val_root_mean_squared_error: 0.0072\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0120 - mae: 0.0120 - root_mean_squared_error: 0.0156 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0143 - val_loss: 0.0050 - val_mae: 0.0050 - val_root_mean_squared_error: 0.0063\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0107 - mae: 0.0107 - root_mean_squared_error: 0.0139 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0052\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0106 - mae: 0.0106 - root_mean_squared_error: 0.0137 - val_loss: 0.0057 - val_mae: 0.0057 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0104 - mae: 0.0104 - root_mean_squared_error: 0.0134 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0097 - mae: 0.0097 - root_mean_squared_error: 0.0127 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0088 - mae: 0.0088 - root_mean_squared_error: 0.0115 - val_loss: 0.0097 - val_mae: 0.0097 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0086 - mae: 0.0086 - root_mean_squared_error: 0.0112 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0109 - val_loss: 0.0025 - val_mae: 0.0025 - val_root_mean_squared_error: 0.0033\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0076 - mae: 0.0076 - root_mean_squared_error: 0.0100 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0037\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0075 - mae: 0.0075 - root_mean_squared_error: 0.0099 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0078 - mae: 0.0078 - root_mean_squared_error: 0.0101 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0069 - mae: 0.0069 - root_mean_squared_error: 0.0091 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0089 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0063 - mae: 0.0063 - root_mean_squared_error: 0.0083 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0061 - mae: 0.0061 - root_mean_squared_error: 0.0083 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0037\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0055 - root_mean_squared_error: 0.0076 - val_loss: 0.0023 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0058 - mae: 0.0058 - root_mean_squared_error: 0.0080 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0074 - val_loss: 0.0050 - val_mae: 0.0050 - val_root_mean_squared_error: 0.0055\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0074 - val_loss: 0.0057 - val_mae: 0.0057 - val_root_mean_squared_error: 0.0059\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0051 - mae: 0.0051 - root_mean_squared_error: 0.0070 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0039\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - mae: 0.0052 - root_mean_squared_error: 0.0075 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:01:45 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:01:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:01:54 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:01:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: model_units = 200 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 0.0586 - mae: 0.0586 - root_mean_squared_error: 0.0995 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0412 - mae: 0.0412 - root_mean_squared_error: 0.0595 - val_loss: 0.0258 - val_mae: 0.0258 - val_root_mean_squared_error: 0.0368\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0395 - mae: 0.0395 - root_mean_squared_error: 0.0577 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0395 - mae: 0.0395 - root_mean_squared_error: 0.0577 - val_loss: 0.0255 - val_mae: 0.0255 - val_root_mean_squared_error: 0.0364\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0580 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0391 - mae: 0.0391 - root_mean_squared_error: 0.0569 - val_loss: 0.0263 - val_mae: 0.0263 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0377 - mae: 0.0377 - root_mean_squared_error: 0.0555 - val_loss: 0.0255 - val_mae: 0.0255 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0374 - mae: 0.0374 - root_mean_squared_error: 0.0552 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0548 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0540 - val_loss: 0.0226 - val_mae: 0.0226 - val_root_mean_squared_error: 0.0333\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0525 - val_loss: 0.0221 - val_mae: 0.0221 - val_root_mean_squared_error: 0.0323\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0507 - val_loss: 0.0206 - val_mae: 0.0206 - val_root_mean_squared_error: 0.0293\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0307 - mae: 0.0307 - root_mean_squared_error: 0.0430 - val_loss: 0.0187 - val_mae: 0.0187 - val_root_mean_squared_error: 0.0245\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0258 - mae: 0.0258 - root_mean_squared_error: 0.0350 - val_loss: 0.0104 - val_mae: 0.0104 - val_root_mean_squared_error: 0.0144\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0214 - mae: 0.0214 - root_mean_squared_error: 0.0280 - val_loss: 0.0098 - val_mae: 0.0098 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0189 - mae: 0.0189 - root_mean_squared_error: 0.0242 - val_loss: 0.0118 - val_mae: 0.0118 - val_root_mean_squared_error: 0.0154\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0167 - mae: 0.0167 - root_mean_squared_error: 0.0220 - val_loss: 0.0097 - val_mae: 0.0097 - val_root_mean_squared_error: 0.0112\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0164 - mae: 0.0164 - root_mean_squared_error: 0.0210 - val_loss: 0.0091 - val_mae: 0.0091 - val_root_mean_squared_error: 0.0112\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0143 - mae: 0.0143 - root_mean_squared_error: 0.0184 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0138 - mae: 0.0138 - root_mean_squared_error: 0.0178 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0062\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0133 - mae: 0.0133 - root_mean_squared_error: 0.0173 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0127 - mae: 0.0127 - root_mean_squared_error: 0.0164 - val_loss: 0.0135 - val_mae: 0.0135 - val_root_mean_squared_error: 0.0140\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0124 - mae: 0.0124 - root_mean_squared_error: 0.0155 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0058\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0141 - mae: 0.0141 - root_mean_squared_error: 0.0181 - val_loss: 0.0107 - val_mae: 0.0107 - val_root_mean_squared_error: 0.0114\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0129 - mae: 0.0129 - root_mean_squared_error: 0.0165 - val_loss: 0.0032 - val_mae: 0.0032 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0121 - mae: 0.0121 - root_mean_squared_error: 0.0155 - val_loss: 0.0057 - val_mae: 0.0057 - val_root_mean_squared_error: 0.0062\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0119 - mae: 0.0119 - root_mean_squared_error: 0.0151 - val_loss: 0.0026 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0105 - mae: 0.0105 - root_mean_squared_error: 0.0133 - val_loss: 0.0113 - val_mae: 0.0113 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0107 - mae: 0.0107 - root_mean_squared_error: 0.0137 - val_loss: 0.0031 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0104 - mae: 0.0104 - root_mean_squared_error: 0.0133 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0106 - mae: 0.0106 - root_mean_squared_error: 0.0134 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0104 - mae: 0.0104 - root_mean_squared_error: 0.0131 - val_loss: 0.0101 - val_mae: 0.0101 - val_root_mean_squared_error: 0.0103\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0097 - mae: 0.0097 - root_mean_squared_error: 0.0125 - val_loss: 0.0039 - val_mae: 0.0039 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0098 - mae: 0.0098 - root_mean_squared_error: 0.0125 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0094 - mae: 0.0094 - root_mean_squared_error: 0.0120 - val_loss: 0.0088 - val_mae: 0.0088 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0090 - mae: 0.0090 - root_mean_squared_error: 0.0116 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0088 - mae: 0.0088 - root_mean_squared_error: 0.0113 - val_loss: 0.0091 - val_mae: 0.0091 - val_root_mean_squared_error: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:04:26 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:04:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:04:34 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:04:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 22:05:20 INFO mlflow.tracking.fluent: Experiment with name 'log_return_gru_dropout_rate_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: dropout_rate = 0 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0668 - mae: 0.0668 - root_mean_squared_error: 0.1217 - val_loss: 0.0252 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0364\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0544 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0536 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0532 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0533 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0531 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0529 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0528 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0526 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0524 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0523 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0521 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0519 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0333 - mae: 0.0333 - root_mean_squared_error: 0.0515 - val_loss: 0.0229 - val_mae: 0.0229 - val_root_mean_squared_error: 0.0337\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0504 - val_loss: 0.0218 - val_mae: 0.0218 - val_root_mean_squared_error: 0.0320\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0300 - mae: 0.0300 - root_mean_squared_error: 0.0457 - val_loss: 0.0179 - val_mae: 0.0179 - val_root_mean_squared_error: 0.0256\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0249 - mae: 0.0249 - root_mean_squared_error: 0.0371 - val_loss: 0.0137 - val_mae: 0.0137 - val_root_mean_squared_error: 0.0186\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0201 - mae: 0.0201 - root_mean_squared_error: 0.0289 - val_loss: 0.0142 - val_mae: 0.0142 - val_root_mean_squared_error: 0.0189\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0167 - mae: 0.0167 - root_mean_squared_error: 0.0238 - val_loss: 0.0087 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0127\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0144 - mae: 0.0144 - root_mean_squared_error: 0.0203 - val_loss: 0.0076 - val_mae: 0.0076 - val_root_mean_squared_error: 0.0110\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0113 - mae: 0.0113 - root_mean_squared_error: 0.0164 - val_loss: 0.0079 - val_mae: 0.0079 - val_root_mean_squared_error: 0.0107\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0091 - mae: 0.0091 - root_mean_squared_error: 0.0135 - val_loss: 0.0058 - val_mae: 0.0058 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0073 - mae: 0.0073 - root_mean_squared_error: 0.0111 - val_loss: 0.0051 - val_mae: 0.0051 - val_root_mean_squared_error: 0.0066\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0072 - mae: 0.0072 - root_mean_squared_error: 0.0104 - val_loss: 0.0032 - val_mae: 0.0032 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0072 - mae: 0.0072 - root_mean_squared_error: 0.0104 - val_loss: 0.0066 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0072 - mae: 0.0072 - root_mean_squared_error: 0.0100 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0081 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0085 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0047 - root_mean_squared_error: 0.0071 - val_loss: 0.0041 - val_mae: 0.0041 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0052 - mae: 0.0052 - root_mean_squared_error: 0.0077 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0076 - val_loss: 0.0073 - val_mae: 0.0073 - val_root_mean_squared_error: 0.0077\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0058 - mae: 0.0058 - root_mean_squared_error: 0.0079 - val_loss: 0.0025 - val_mae: 0.0025 - val_root_mean_squared_error: 0.0032\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0072 - val_loss: 0.0049 - val_mae: 0.0049 - val_root_mean_squared_error: 0.0057\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0078 - val_loss: 0.0015 - val_mae: 0.0015 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0081 - val_loss: 0.0016 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0055 - mae: 0.0055 - root_mean_squared_error: 0.0080 - val_loss: 0.0140 - val_mae: 0.0140 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0042 - mae: 0.0042 - root_mean_squared_error: 0.0063 - val_loss: 0.0044 - val_mae: 0.0044 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0041 - root_mean_squared_error: 0.0059 - val_loss: 0.0104 - val_mae: 0.0104 - val_root_mean_squared_error: 0.0106\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0047 - root_mean_squared_error: 0.0067 - val_loss: 0.0081 - val_mae: 0.0081 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0041 - root_mean_squared_error: 0.0056 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0042 - mae: 0.0042 - root_mean_squared_error: 0.0058 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0032\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0034 - root_mean_squared_error: 0.0049 - val_loss: 0.0012 - val_mae: 0.0012 - val_root_mean_squared_error: 0.0017\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0033 - mae: 0.0033 - root_mean_squared_error: 0.0047 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0036 - root_mean_squared_error: 0.0050 - val_loss: 0.0088 - val_mae: 0.0088 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0041 - mae: 0.0041 - root_mean_squared_error: 0.0054 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0036 - root_mean_squared_error: 0.0050 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0045 - mae: 0.0045 - root_mean_squared_error: 0.0060 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:06:26 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:06:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:06:36 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:06:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: dropout_rate = 0.2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0823 - mae: 0.0823 - root_mean_squared_error: 0.1266 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0377\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0670 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0468 - mae: 0.0468 - root_mean_squared_error: 0.0651 - val_loss: 0.0301 - val_mae: 0.0301 - val_root_mean_squared_error: 0.0404\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0455 - mae: 0.0455 - root_mean_squared_error: 0.0628 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0423 - mae: 0.0423 - root_mean_squared_error: 0.0595 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0373\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0420 - mae: 0.0420 - root_mean_squared_error: 0.0595 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0404 - mae: 0.0404 - root_mean_squared_error: 0.0578 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0576 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0387 - mae: 0.0387 - root_mean_squared_error: 0.0564 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0562 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0561 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0377 - mae: 0.0377 - root_mean_squared_error: 0.0554 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0549 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0551 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0543 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0539 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0538 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0539 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0525 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0527 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0521 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0339\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0332 - mae: 0.0332 - root_mean_squared_error: 0.0509 - val_loss: 0.0224 - val_mae: 0.0224 - val_root_mean_squared_error: 0.0329\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0496 - val_loss: 0.0220 - val_mae: 0.0220 - val_root_mean_squared_error: 0.0315\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0309 - mae: 0.0309 - root_mean_squared_error: 0.0458 - val_loss: 0.0199 - val_mae: 0.0199 - val_root_mean_squared_error: 0.0279\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0274 - mae: 0.0274 - root_mean_squared_error: 0.0403 - val_loss: 0.0158 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0214\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0215 - mae: 0.0215 - root_mean_squared_error: 0.0309 - val_loss: 0.0119 - val_mae: 0.0119 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0190 - mae: 0.0190 - root_mean_squared_error: 0.0270 - val_loss: 0.0099 - val_mae: 0.0099 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0151 - mae: 0.0151 - root_mean_squared_error: 0.0215 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0139 - mae: 0.0139 - root_mean_squared_error: 0.0189 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0161 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0099 - mae: 0.0099 - root_mean_squared_error: 0.0140 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0130 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0084 - mae: 0.0084 - root_mean_squared_error: 0.0118 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0107 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0070 - mae: 0.0070 - root_mean_squared_error: 0.0100 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0092 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0096 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0081 - val_loss: 0.0017 - val_mae: 0.0017 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0045 - mae: 0.0045 - root_mean_squared_error: 0.0070 - val_loss: 0.0031 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0087 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0079 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:08:31 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:08:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:08:40 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:08:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: dropout_rate = 0.5 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1064 - mae: 0.1064 - root_mean_squared_error: 0.1490 - val_loss: 0.0340 - val_mae: 0.0340 - val_root_mean_squared_error: 0.0440\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0666 - mae: 0.0666 - root_mean_squared_error: 0.0864 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0618 - mae: 0.0618 - root_mean_squared_error: 0.0811 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0573 - mae: 0.0573 - root_mean_squared_error: 0.0760 - val_loss: 0.0253 - val_mae: 0.0253 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0525 - mae: 0.0525 - root_mean_squared_error: 0.0707 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0485 - mae: 0.0485 - root_mean_squared_error: 0.0665 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0440 - mae: 0.0440 - root_mean_squared_error: 0.0612 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0415 - mae: 0.0415 - root_mean_squared_error: 0.0594 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0386 - mae: 0.0386 - root_mean_squared_error: 0.0566 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0375 - mae: 0.0375 - root_mean_squared_error: 0.0553 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0545 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0539 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0530 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0530 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0530 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0525 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0337 - mae: 0.0337 - root_mean_squared_error: 0.0524 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:09:59 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:10:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:10:08 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:10:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: dropout_rate = 0.8 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1542 - mae: 0.1542 - root_mean_squared_error: 0.2019 - val_loss: 0.0455 - val_mae: 0.0455 - val_root_mean_squared_error: 0.0543\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0997 - mae: 0.0997 - root_mean_squared_error: 0.1265 - val_loss: 0.0268 - val_mae: 0.0268 - val_root_mean_squared_error: 0.0377\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0817 - mae: 0.0817 - root_mean_squared_error: 0.1039 - val_loss: 0.0327 - val_mae: 0.0327 - val_root_mean_squared_error: 0.0427\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0650 - mae: 0.0650 - root_mean_squared_error: 0.0848 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0512 - mae: 0.0512 - root_mean_squared_error: 0.0693 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0412 - mae: 0.0412 - root_mean_squared_error: 0.0590 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0364 - mae: 0.0364 - root_mean_squared_error: 0.0550 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0534 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0532 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0535 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0529 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0529 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0526 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0528 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0527 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:11:24 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:11:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:11:33 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:11:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 22:12:20 INFO mlflow.tracking.fluent: Experiment with name 'log_return_gru_number_of_layer_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: number_of_layer = 1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0823 - mae: 0.0823 - root_mean_squared_error: 0.1266 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0377\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0670 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0468 - mae: 0.0468 - root_mean_squared_error: 0.0651 - val_loss: 0.0301 - val_mae: 0.0301 - val_root_mean_squared_error: 0.0404\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0455 - mae: 0.0455 - root_mean_squared_error: 0.0628 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0423 - mae: 0.0423 - root_mean_squared_error: 0.0595 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0373\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0420 - mae: 0.0420 - root_mean_squared_error: 0.0595 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0404 - mae: 0.0404 - root_mean_squared_error: 0.0578 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0576 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0387 - mae: 0.0387 - root_mean_squared_error: 0.0564 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0562 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0561 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0377 - mae: 0.0377 - root_mean_squared_error: 0.0554 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0549 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0551 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0543 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0539 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0538 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0539 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0525 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0527 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0521 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0339\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0332 - mae: 0.0332 - root_mean_squared_error: 0.0509 - val_loss: 0.0224 - val_mae: 0.0224 - val_root_mean_squared_error: 0.0329\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0496 - val_loss: 0.0220 - val_mae: 0.0220 - val_root_mean_squared_error: 0.0315\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0309 - mae: 0.0309 - root_mean_squared_error: 0.0458 - val_loss: 0.0199 - val_mae: 0.0199 - val_root_mean_squared_error: 0.0279\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0274 - mae: 0.0274 - root_mean_squared_error: 0.0403 - val_loss: 0.0158 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0214\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0215 - mae: 0.0215 - root_mean_squared_error: 0.0309 - val_loss: 0.0119 - val_mae: 0.0119 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0190 - mae: 0.0190 - root_mean_squared_error: 0.0270 - val_loss: 0.0099 - val_mae: 0.0099 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0151 - mae: 0.0151 - root_mean_squared_error: 0.0215 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0139 - mae: 0.0139 - root_mean_squared_error: 0.0189 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0161 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0099 - mae: 0.0099 - root_mean_squared_error: 0.0140 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0130 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0084 - mae: 0.0084 - root_mean_squared_error: 0.0118 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0107 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0070 - mae: 0.0070 - root_mean_squared_error: 0.0100 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0092 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0096 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0081 - val_loss: 0.0017 - val_mae: 0.0017 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0045 - root_mean_squared_error: 0.0070 - val_loss: 0.0031 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0087 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0079 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:13:26 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:13:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:13:35 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:13:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: number_of_layer = 2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.0652 - mae: 0.0652 - root_mean_squared_error: 0.0896 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0371\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0512 - mae: 0.0512 - root_mean_squared_error: 0.0695 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0472 - mae: 0.0472 - root_mean_squared_error: 0.0650 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0454 - mae: 0.0454 - root_mean_squared_error: 0.0631 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0441 - mae: 0.0441 - root_mean_squared_error: 0.0622 - val_loss: 0.0276 - val_mae: 0.0276 - val_root_mean_squared_error: 0.0382\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0436 - mae: 0.0436 - root_mean_squared_error: 0.0613 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0432 - mae: 0.0432 - root_mean_squared_error: 0.0608 - val_loss: 0.0256 - val_mae: 0.0256 - val_root_mean_squared_error: 0.0364\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0417 - mae: 0.0417 - root_mean_squared_error: 0.0596 - val_loss: 0.0254 - val_mae: 0.0254 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0587 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0403 - mae: 0.0403 - root_mean_squared_error: 0.0578 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0573 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0386 - mae: 0.0386 - root_mean_squared_error: 0.0565 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0383 - mae: 0.0383 - root_mean_squared_error: 0.0563 - val_loss: 0.0254 - val_mae: 0.0254 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0377 - mae: 0.0377 - root_mean_squared_error: 0.0556 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0549 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0551 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0366 - mae: 0.0366 - root_mean_squared_error: 0.0546 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0361 - mae: 0.0361 - root_mean_squared_error: 0.0542 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0358 - mae: 0.0358 - root_mean_squared_error: 0.0541 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0353 - mae: 0.0353 - root_mean_squared_error: 0.0536 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0540 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0358 - mae: 0.0358 - root_mean_squared_error: 0.0541 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0533 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0348 - mae: 0.0348 - root_mean_squared_error: 0.0533 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0345 - mae: 0.0345 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0529 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0527 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0528 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0526 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0526 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0524 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:15:39 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:15:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:15:49 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:15:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: number_of_layer = 3 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 0.0671 - mae: 0.0671 - root_mean_squared_error: 0.0975 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0495 - mae: 0.0495 - root_mean_squared_error: 0.0672 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0467 - mae: 0.0467 - root_mean_squared_error: 0.0638 - val_loss: 0.0279 - val_mae: 0.0279 - val_root_mean_squared_error: 0.0384\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0456 - mae: 0.0456 - root_mean_squared_error: 0.0632 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0437 - mae: 0.0437 - root_mean_squared_error: 0.0613 - val_loss: 0.0260 - val_mae: 0.0260 - val_root_mean_squared_error: 0.0368\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0429 - mae: 0.0429 - root_mean_squared_error: 0.0604 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0415 - mae: 0.0415 - root_mean_squared_error: 0.0587 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0415 - mae: 0.0415 - root_mean_squared_error: 0.0591 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0405 - mae: 0.0405 - root_mean_squared_error: 0.0581 - val_loss: 0.0271 - val_mae: 0.0271 - val_root_mean_squared_error: 0.0377\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0579 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0567 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0386 - mae: 0.0386 - root_mean_squared_error: 0.0565 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0565 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0559 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0556 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0553 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:17:27 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:17:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:17:36 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:17:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: number_of_layer = 4 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.0712 - mae: 0.0712 - root_mean_squared_error: 0.1064 - val_loss: 0.0357 - val_mae: 0.0357 - val_root_mean_squared_error: 0.0453\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0505 - mae: 0.0505 - root_mean_squared_error: 0.0684 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0466 - mae: 0.0466 - root_mean_squared_error: 0.0647 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0439 - mae: 0.0439 - root_mean_squared_error: 0.0613 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0449 - mae: 0.0449 - root_mean_squared_error: 0.0622 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0427 - mae: 0.0427 - root_mean_squared_error: 0.0601 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0422 - mae: 0.0422 - root_mean_squared_error: 0.0595 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0599 - val_loss: 0.0279 - val_mae: 0.0279 - val_root_mean_squared_error: 0.0383\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0585 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0568 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0394 - mae: 0.0394 - root_mean_squared_error: 0.0570 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 0.0392 - mae: 0.0392 - root_mean_squared_error: 0.0571 - val_loss: 0.0244 - val_mae: 0.0244 - val_root_mean_squared_error: 0.0354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:19:19 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:19:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:19:29 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:19:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 22:20:22 INFO mlflow.tracking.fluent: Experiment with name 'log_return_gru_loss_function_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: loss_function = mae ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0823 - mae: 0.0823 - root_mean_squared_error: 0.1266 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0377\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0492 - mae: 0.0492 - root_mean_squared_error: 0.0670 - val_loss: 0.0246 - val_mae: 0.0246 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0468 - mae: 0.0468 - root_mean_squared_error: 0.0651 - val_loss: 0.0301 - val_mae: 0.0301 - val_root_mean_squared_error: 0.0404\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0455 - mae: 0.0455 - root_mean_squared_error: 0.0628 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0444 - mae: 0.0444 - root_mean_squared_error: 0.0625 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0430 - mae: 0.0430 - root_mean_squared_error: 0.0610 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0423 - mae: 0.0423 - root_mean_squared_error: 0.0595 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0373\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0420 - mae: 0.0420 - root_mean_squared_error: 0.0595 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0404 - mae: 0.0404 - root_mean_squared_error: 0.0578 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0576 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0387 - mae: 0.0387 - root_mean_squared_error: 0.0564 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0384 - mae: 0.0384 - root_mean_squared_error: 0.0562 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0561 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0377 - mae: 0.0377 - root_mean_squared_error: 0.0554 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0371 - mae: 0.0371 - root_mean_squared_error: 0.0549 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0551 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0543 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0350\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0539 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0356 - mae: 0.0356 - root_mean_squared_error: 0.0538 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0539 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0531 - val_loss: 0.0234 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0345\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0530 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0525 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0344 - mae: 0.0344 - root_mean_squared_error: 0.0527 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0341 - mae: 0.0341 - root_mean_squared_error: 0.0521 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0339\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0338 - mae: 0.0338 - root_mean_squared_error: 0.0519 - val_loss: 0.0233 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0332 - mae: 0.0332 - root_mean_squared_error: 0.0509 - val_loss: 0.0224 - val_mae: 0.0224 - val_root_mean_squared_error: 0.0329\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0324 - mae: 0.0324 - root_mean_squared_error: 0.0496 - val_loss: 0.0220 - val_mae: 0.0220 - val_root_mean_squared_error: 0.0315\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0309 - mae: 0.0309 - root_mean_squared_error: 0.0458 - val_loss: 0.0199 - val_mae: 0.0199 - val_root_mean_squared_error: 0.0279\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0274 - mae: 0.0274 - root_mean_squared_error: 0.0403 - val_loss: 0.0158 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0214\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0215 - mae: 0.0215 - root_mean_squared_error: 0.0309 - val_loss: 0.0119 - val_mae: 0.0119 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0190 - mae: 0.0190 - root_mean_squared_error: 0.0270 - val_loss: 0.0099 - val_mae: 0.0099 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0151 - mae: 0.0151 - root_mean_squared_error: 0.0215 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0139 - mae: 0.0139 - root_mean_squared_error: 0.0189 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0161 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0099 - mae: 0.0099 - root_mean_squared_error: 0.0140 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0130 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0084 - root_mean_squared_error: 0.0118 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0107 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0070 - mae: 0.0070 - root_mean_squared_error: 0.0100 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0092 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0096 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0081 - val_loss: 0.0017 - val_mae: 0.0017 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0045 - mae: 0.0045 - root_mean_squared_error: 0.0070 - val_loss: 0.0031 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0087 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0079 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:21:33 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:21:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:21:42 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:21:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: loss_function = mse ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0169 - mae: 0.0868 - root_mean_squared_error: 0.1299 - val_loss: 0.0013 - val_mae: 0.0255 - val_root_mean_squared_error: 0.0367\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0525 - root_mean_squared_error: 0.0706 - val_loss: 0.0013 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0489 - root_mean_squared_error: 0.0674 - val_loss: 0.0013 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0468 - root_mean_squared_error: 0.0642 - val_loss: 0.0013 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0042 - mae: 0.0464 - root_mean_squared_error: 0.0645 - val_loss: 0.0012 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0456 - root_mean_squared_error: 0.0636 - val_loss: 0.0013 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0449 - root_mean_squared_error: 0.0622 - val_loss: 0.0012 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0446 - root_mean_squared_error: 0.0622 - val_loss: 0.0012 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0436 - root_mean_squared_error: 0.0609 - val_loss: 0.0012 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0037 - mae: 0.0432 - root_mean_squared_error: 0.0609 - val_loss: 0.0012 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0416 - root_mean_squared_error: 0.0593 - val_loss: 0.0013 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0035 - mae: 0.0419 - root_mean_squared_error: 0.0595 - val_loss: 0.0012 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0416 - root_mean_squared_error: 0.0589 - val_loss: 0.0013 - val_mae: 0.0258 - val_root_mean_squared_error: 0.0365\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0405 - root_mean_squared_error: 0.0579 - val_loss: 0.0013 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0359\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0403 - root_mean_squared_error: 0.0575 - val_loss: 0.0012 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0403 - root_mean_squared_error: 0.0578 - val_loss: 0.0012 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0032 - mae: 0.0396 - root_mean_squared_error: 0.0568 - val_loss: 0.0013 - val_mae: 0.0250 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - mae: 0.0385 - root_mean_squared_error: 0.0560 - val_loss: 0.0012 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0341\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0031 - mae: 0.0382 - root_mean_squared_error: 0.0557 - val_loss: 0.0011 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0338\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mae: 0.0381 - root_mean_squared_error: 0.0555 - val_loss: 0.0012 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0369 - root_mean_squared_error: 0.0538 - val_loss: 0.0011 - val_mae: 0.0227 - val_root_mean_squared_error: 0.0331\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0360 - root_mean_squared_error: 0.0524 - val_loss: 9.8418e-04 - val_mae: 0.0215 - val_root_mean_squared_error: 0.0314\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0344 - root_mean_squared_error: 0.0501 - val_loss: 7.6886e-04 - val_mae: 0.0193 - val_root_mean_squared_error: 0.0277\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0290 - root_mean_squared_error: 0.0410 - val_loss: 4.6139e-04 - val_mae: 0.0162 - val_root_mean_squared_error: 0.0215\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0242 - root_mean_squared_error: 0.0330 - val_loss: 3.3690e-04 - val_mae: 0.0143 - val_root_mean_squared_error: 0.0184\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.4932e-04 - mae: 0.0201 - root_mean_squared_error: 0.0274 - val_loss: 1.9926e-04 - val_mae: 0.0107 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.0095e-04 - mae: 0.0185 - root_mean_squared_error: 0.0245 - val_loss: 1.1177e-04 - val_mae: 0.0076 - val_root_mean_squared_error: 0.0106\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.1072e-04 - mae: 0.0171 - root_mean_squared_error: 0.0226 - val_loss: 8.5383e-05 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4.1741e-04 - mae: 0.0154 - root_mean_squared_error: 0.0204 - val_loss: 1.1660e-04 - val_mae: 0.0089 - val_root_mean_squared_error: 0.0108\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.8868e-04 - mae: 0.0150 - root_mean_squared_error: 0.0197 - val_loss: 6.2491e-05 - val_mae: 0.0060 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.0676e-04 - mae: 0.0133 - root_mean_squared_error: 0.0175 - val_loss: 4.1001e-05 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.7962e-04 - mae: 0.0126 - root_mean_squared_error: 0.0167 - val_loss: 8.1552e-05 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.3165e-04 - mae: 0.0116 - root_mean_squared_error: 0.0152 - val_loss: 5.0008e-05 - val_mae: 0.0057 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.2725e-04 - mae: 0.0114 - root_mean_squared_error: 0.0151 - val_loss: 4.3101e-05 - val_mae: 0.0052 - val_root_mean_squared_error: 0.0066\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.9767e-04 - mae: 0.0106 - root_mean_squared_error: 0.0141 - val_loss: 2.1869e-05 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7434e-04 - mae: 0.0100 - root_mean_squared_error: 0.0132 - val_loss: 6.4704e-05 - val_mae: 0.0070 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.6796e-04 - mae: 0.0098 - root_mean_squared_error: 0.0130 - val_loss: 1.7473e-05 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0042\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 1.3877e-04 - mae: 0.0089 - root_mean_squared_error: 0.0118 - val_loss: 1.4661e-05 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2890e-04 - mae: 0.0084 - root_mean_squared_error: 0.0114 - val_loss: 1.6567e-05 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2633e-04 - mae: 0.0083 - root_mean_squared_error: 0.0112 - val_loss: 2.4015e-05 - val_mae: 0.0039 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 1.2068e-04 - mae: 0.0080 - root_mean_squared_error: 0.0110 - val_loss: 9.5965e-06 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.9123e-05 - mae: 0.0072 - root_mean_squared_error: 0.0100 - val_loss: 8.7271e-06 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.8710e-05 - mae: 0.0074 - root_mean_squared_error: 0.0099 - val_loss: 1.5679e-05 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.4859e-05 - mae: 0.0073 - root_mean_squared_error: 0.0097 - val_loss: 1.3055e-05 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7.1357e-05 - mae: 0.0061 - root_mean_squared_error: 0.0084 - val_loss: 9.6526e-06 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.3109e-05 - mae: 0.0063 - root_mean_squared_error: 0.0086 - val_loss: 1.3660e-05 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0037\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.5282e-05 - mae: 0.0069 - root_mean_squared_error: 0.0092 - val_loss: 7.7473e-06 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.9239e-05 - mae: 0.0055 - root_mean_squared_error: 0.0077 - val_loss: 2.9743e-05 - val_mae: 0.0051 - val_root_mean_squared_error: 0.0055\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.8541e-05 - mae: 0.0053 - root_mean_squared_error: 0.0077 - val_loss: 5.5009e-06 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.3720e-05 - mae: 0.0051 - root_mean_squared_error: 0.0073 - val_loss: 4.1769e-06 - val_mae: 0.0015 - val_root_mean_squared_error: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:23:38 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:23:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:23:47 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:23:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: gru | Param: loss_function = huber ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0084 - mae: 0.0868 - root_mean_squared_error: 0.1299 - val_loss: 6.7524e-04 - val_mae: 0.0255 - val_root_mean_squared_error: 0.0367\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0525 - root_mean_squared_error: 0.0706 - val_loss: 6.3580e-04 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0357\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0489 - root_mean_squared_error: 0.0674 - val_loss: 6.3001e-04 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0469 - root_mean_squared_error: 0.0642 - val_loss: 6.2596e-04 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0354\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0465 - root_mean_squared_error: 0.0645 - val_loss: 6.1657e-04 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0456 - root_mean_squared_error: 0.0637 - val_loss: 6.5132e-04 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0450 - root_mean_squared_error: 0.0623 - val_loss: 6.0771e-04 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0447 - root_mean_squared_error: 0.0623 - val_loss: 6.0605e-04 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0019 - mae: 0.0436 - root_mean_squared_error: 0.0610 - val_loss: 6.0637e-04 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0432 - root_mean_squared_error: 0.0609 - val_loss: 6.0664e-04 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0417 - root_mean_squared_error: 0.0594 - val_loss: 6.3925e-04 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0420 - root_mean_squared_error: 0.0596 - val_loss: 6.0404e-04 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0417 - root_mean_squared_error: 0.0590 - val_loss: 6.7118e-04 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0366\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0405 - root_mean_squared_error: 0.0580 - val_loss: 6.5220e-04 - val_mae: 0.0253 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0403 - root_mean_squared_error: 0.0577 - val_loss: 5.8725e-04 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0404 - root_mean_squared_error: 0.0580 - val_loss: 5.8604e-04 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0397 - root_mean_squared_error: 0.0570 - val_loss: 6.4032e-04 - val_mae: 0.0251 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0386 - root_mean_squared_error: 0.0562 - val_loss: 5.8830e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0384 - root_mean_squared_error: 0.0560 - val_loss: 5.8347e-04 - val_mae: 0.0233 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0383 - root_mean_squared_error: 0.0560 - val_loss: 6.0332e-04 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0374 - root_mean_squared_error: 0.0547 - val_loss: 5.8702e-04 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0370 - root_mean_squared_error: 0.0541 - val_loss: 5.6925e-04 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0337\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0364 - root_mean_squared_error: 0.0537 - val_loss: 5.6520e-04 - val_mae: 0.0234 - val_root_mean_squared_error: 0.0336\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0352 - root_mean_squared_error: 0.0516 - val_loss: 5.2278e-04 - val_mae: 0.0226 - val_root_mean_squared_error: 0.0323\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0338 - root_mean_squared_error: 0.0493 - val_loss: 4.0210e-04 - val_mae: 0.0203 - val_root_mean_squared_error: 0.0284\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.9485e-04 - mae: 0.0281 - root_mean_squared_error: 0.0399 - val_loss: 2.3694e-04 - val_mae: 0.0165 - val_root_mean_squared_error: 0.0218\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.0379e-04 - mae: 0.0231 - root_mean_squared_error: 0.0317 - val_loss: 1.1554e-04 - val_mae: 0.0110 - val_root_mean_squared_error: 0.0152\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.6047e-04 - mae: 0.0199 - root_mean_squared_error: 0.0269 - val_loss: 7.5882e-05 - val_mae: 0.0088 - val_root_mean_squared_error: 0.0123\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.7240e-04 - mae: 0.0173 - root_mean_squared_error: 0.0233 - val_loss: 8.0025e-05 - val_mae: 0.0101 - val_root_mean_squared_error: 0.0127\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.3402e-04 - mae: 0.0163 - root_mean_squared_error: 0.0216 - val_loss: 4.3042e-05 - val_mae: 0.0069 - val_root_mean_squared_error: 0.0093\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.7781e-04 - mae: 0.0141 - root_mean_squared_error: 0.0189 - val_loss: 3.0379e-05 - val_mae: 0.0056 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.5923e-04 - mae: 0.0135 - root_mean_squared_error: 0.0178 - val_loss: 4.5830e-05 - val_mae: 0.0078 - val_root_mean_squared_error: 0.0096\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3032e-04 - mae: 0.0122 - root_mean_squared_error: 0.0161 - val_loss: 1.8178e-05 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2486e-04 - mae: 0.0120 - root_mean_squared_error: 0.0158 - val_loss: 2.1382e-05 - val_mae: 0.0049 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1303e-04 - mae: 0.0115 - root_mean_squared_error: 0.0150 - val_loss: 1.4692e-05 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 9.1551e-05 - mae: 0.0103 - root_mean_squared_error: 0.0135 - val_loss: 1.8547e-05 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.0141e-05 - mae: 0.0102 - root_mean_squared_error: 0.0134 - val_loss: 1.0688e-05 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.6697e-05 - mae: 0.0094 - root_mean_squared_error: 0.0124 - val_loss: 8.7973e-06 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0042\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.8052e-05 - mae: 0.0087 - root_mean_squared_error: 0.0117 - val_loss: 7.2807e-06 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.5985e-05 - mae: 0.0085 - root_mean_squared_error: 0.0115 - val_loss: 8.0493e-06 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.4494e-05 - mae: 0.0084 - root_mean_squared_error: 0.0114 - val_loss: 7.9518e-06 - val_mae: 0.0032 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.4515e-05 - mae: 0.0076 - root_mean_squared_error: 0.0104 - val_loss: 5.0919e-06 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0032\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.2880e-05 - mae: 0.0078 - root_mean_squared_error: 0.0103 - val_loss: 7.0940e-06 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.9459e-05 - mae: 0.0074 - root_mean_squared_error: 0.0099 - val_loss: 6.4814e-06 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.6934e-05 - mae: 0.0062 - root_mean_squared_error: 0.0086 - val_loss: 5.2088e-06 - val_mae: 0.0025 - val_root_mean_squared_error: 0.0032\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.8412e-05 - mae: 0.0065 - root_mean_squared_error: 0.0088 - val_loss: 6.9443e-06 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0037\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.5621e-05 - mae: 0.0072 - root_mean_squared_error: 0.0096 - val_loss: 4.9517e-06 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.0374e-05 - mae: 0.0056 - root_mean_squared_error: 0.0078 - val_loss: 1.5064e-05 - val_mae: 0.0052 - val_root_mean_squared_error: 0.0055\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.0596e-05 - mae: 0.0054 - root_mean_squared_error: 0.0078 - val_loss: 3.1917e-06 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.8484e-05 - mae: 0.0052 - root_mean_squared_error: 0.0075 - val_loss: 2.2643e-06 - val_mae: 0.0015 - val_root_mean_squared_error: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:25:43 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:25:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:25:53 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:25:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 22:26:42 INFO mlflow.tracking.fluent: Experiment with name 'log_return_simplernn_input_width_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: input_width = 12 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0591 - mae: 0.0591 - root_mean_squared_error: 0.0822 - val_loss: 0.0330 - val_mae: 0.0330 - val_root_mean_squared_error: 0.0355\n",
      "Epoch 2/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0407 - mae: 0.0407 - root_mean_squared_error: 0.0520 - val_loss: 0.0066 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 3/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0447 - val_loss: 0.0125 - val_mae: 0.0125 - val_root_mean_squared_error: 0.0135\n",
      "Epoch 4/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0426 - val_loss: 0.0044 - val_mae: 0.0044 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 5/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0298 - mae: 0.0298 - root_mean_squared_error: 0.0382 - val_loss: 0.0178 - val_mae: 0.0178 - val_root_mean_squared_error: 0.0188\n",
      "Epoch 6/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0285 - mae: 0.0285 - root_mean_squared_error: 0.0367 - val_loss: 0.0167 - val_mae: 0.0167 - val_root_mean_squared_error: 0.0172\n",
      "Epoch 7/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0267 - mae: 0.0267 - root_mean_squared_error: 0.0346 - val_loss: 0.0090 - val_mae: 0.0090 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 8/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0262 - mae: 0.0262 - root_mean_squared_error: 0.0334 - val_loss: 0.0062 - val_mae: 0.0062 - val_root_mean_squared_error: 0.0077\n",
      "Epoch 9/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0232 - mae: 0.0232 - root_mean_squared_error: 0.0298 - val_loss: 0.0058 - val_mae: 0.0058 - val_root_mean_squared_error: 0.0067\n",
      "Epoch 10/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0222 - mae: 0.0222 - root_mean_squared_error: 0.0284 - val_loss: 0.0086 - val_mae: 0.0086 - val_root_mean_squared_error: 0.0093\n",
      "Epoch 11/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0210 - mae: 0.0210 - root_mean_squared_error: 0.0268 - val_loss: 0.0186 - val_mae: 0.0186 - val_root_mean_squared_error: 0.0190\n",
      "Epoch 12/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.0208 - root_mean_squared_error: 0.0267 - val_loss: 0.0087 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0100\n",
      "Epoch 13/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186 - mae: 0.0186 - root_mean_squared_error: 0.0238 - val_loss: 0.0179 - val_mae: 0.0179 - val_root_mean_squared_error: 0.0184\n",
      "Epoch 14/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0183 - mae: 0.0183 - root_mean_squared_error: 0.0236 - val_loss: 0.0035 - val_mae: 0.0035 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 15/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176 - mae: 0.0176 - root_mean_squared_error: 0.0229 - val_loss: 0.0133 - val_mae: 0.0133 - val_root_mean_squared_error: 0.0140\n",
      "Epoch 16/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0159 - mae: 0.0159 - root_mean_squared_error: 0.0208 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0072\n",
      "Epoch 17/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0148 - mae: 0.0148 - root_mean_squared_error: 0.0192 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 18/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0143 - root_mean_squared_error: 0.0184 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 19/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0129 - root_mean_squared_error: 0.0170 - val_loss: 0.0133 - val_mae: 0.0133 - val_root_mean_squared_error: 0.0139\n",
      "Epoch 20/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - root_mean_squared_error: 0.0157 - val_loss: 0.0056 - val_mae: 0.0056 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 21/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0149 - val_loss: 0.0057 - val_mae: 0.0057 - val_root_mean_squared_error: 0.0062\n",
      "Epoch 22/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0104 - root_mean_squared_error: 0.0139 - val_loss: 0.0073 - val_mae: 0.0073 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 23/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0099 - root_mean_squared_error: 0.0132 - val_loss: 0.0025 - val_mae: 0.0025 - val_root_mean_squared_error: 0.0032\n",
      "Epoch 24/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0090 - mae: 0.0090 - root_mean_squared_error: 0.0121 - val_loss: 0.0017 - val_mae: 0.0017 - val_root_mean_squared_error: 0.0022\n",
      "Epoch 25/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0085 - root_mean_squared_error: 0.0115 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 26/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - mae: 0.0081 - root_mean_squared_error: 0.0109 - val_loss: 0.0016 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 27/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0073 - mae: 0.0073 - root_mean_squared_error: 0.0102 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 28/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0064 - mae: 0.0064 - root_mean_squared_error: 0.0091 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 29/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0091 - val_loss: 0.0058 - val_mae: 0.0058 - val_root_mean_squared_error: 0.0059\n",
      "Epoch 30/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0086 - val_loss: 0.0089 - val_mae: 0.0089 - val_root_mean_squared_error: 0.0095\n",
      "Epoch 31/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0068 - mae: 0.0068 - root_mean_squared_error: 0.0091 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 32/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0055 - mae: 0.0055 - root_mean_squared_error: 0.0078 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 33/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0081 - val_loss: 0.0046 - val_mae: 0.0046 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 34/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0055 - mae: 0.0055 - root_mean_squared_error: 0.0078 - val_loss: 0.0023 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 35/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0082 - val_loss: 0.0025 - val_mae: 0.0025 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 36/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0077 - val_loss: 0.0011 - val_mae: 0.0011 - val_root_mean_squared_error: 0.0016\n",
      "Epoch 37/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0045 - mae: 0.0045 - root_mean_squared_error: 0.0070 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 38/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0045 - mae: 0.0045 - root_mean_squared_error: 0.0069 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 39/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0047 - mae: 0.0047 - root_mean_squared_error: 0.0072 - val_loss: 0.0034 - val_mae: 0.0034 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 40/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0043 - mae: 0.0043 - root_mean_squared_error: 0.0068 - val_loss: 0.0012 - val_mae: 0.0012 - val_root_mean_squared_error: 0.0018\n",
      "Epoch 41/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - mae: 0.0043 - root_mean_squared_error: 0.0065 - val_loss: 0.0023 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 42/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0041 - mae: 0.0041 - root_mean_squared_error: 0.0066 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 43/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0043 - mae: 0.0043 - root_mean_squared_error: 0.0067 - val_loss: 0.0010 - val_mae: 0.0010 - val_root_mean_squared_error: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0045 - mae: 0.0045 - root_mean_squared_error: 0.0072 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 45/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0039 - mae: 0.0039 - root_mean_squared_error: 0.0062 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0033\n",
      "Epoch 46/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0041 - mae: 0.0041 - root_mean_squared_error: 0.0066 - val_loss: 0.0010 - val_mae: 0.0010 - val_root_mean_squared_error: 0.0014\n",
      "Epoch 47/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0040 - mae: 0.0040 - root_mean_squared_error: 0.0071 - val_loss: 0.0013 - val_mae: 0.0013 - val_root_mean_squared_error: 0.0016\n",
      "Epoch 48/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - mae: 0.0040 - root_mean_squared_error: 0.0065 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 49/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0040 - mae: 0.0040 - root_mean_squared_error: 0.0062 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 50/50\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0038 - root_mean_squared_error: 0.0065 - val_loss: 0.0026 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:27:19 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:27:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:27:29 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:27:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: input_width = 24 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0664 - mae: 0.0664 - root_mean_squared_error: 0.0907 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0233\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0449 - mae: 0.0449 - root_mean_squared_error: 0.0587 - val_loss: 0.0125 - val_mae: 0.0125 - val_root_mean_squared_error: 0.0173\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0505 - val_loss: 0.0210 - val_mae: 0.0210 - val_root_mean_squared_error: 0.0239\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0449 - val_loss: 0.0295 - val_mae: 0.0295 - val_root_mean_squared_error: 0.0312\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0331 - mae: 0.0331 - root_mean_squared_error: 0.0424 - val_loss: 0.0139 - val_mae: 0.0139 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.0303 - root_mean_squared_error: 0.0393 - val_loss: 0.0075 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0373 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0357 - val_loss: 0.0159 - val_mae: 0.0159 - val_root_mean_squared_error: 0.0183\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0339 - val_loss: 0.0106 - val_mae: 0.0106 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - mae: 0.0248 - root_mean_squared_error: 0.0318 - val_loss: 0.0177 - val_mae: 0.0177 - val_root_mean_squared_error: 0.0193\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0227 - mae: 0.0227 - root_mean_squared_error: 0.0293 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0219 - mae: 0.0219 - root_mean_squared_error: 0.0280 - val_loss: 0.0150 - val_mae: 0.0150 - val_root_mean_squared_error: 0.0168\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0205 - mae: 0.0205 - root_mean_squared_error: 0.0265 - val_loss: 0.0046 - val_mae: 0.0046 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0206 - mae: 0.0206 - root_mean_squared_error: 0.0266 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0191 - root_mean_squared_error: 0.0247 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0063\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173 - mae: 0.0173 - root_mean_squared_error: 0.0225 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171 - mae: 0.0171 - root_mean_squared_error: 0.0220 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0058\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0154 - mae: 0.0154 - root_mean_squared_error: 0.0202 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0152 - mae: 0.0152 - root_mean_squared_error: 0.0199 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0141 - root_mean_squared_error: 0.0187 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0135 - root_mean_squared_error: 0.0182 - val_loss: 0.0053 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - root_mean_squared_error: 0.0161 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - root_mean_squared_error: 0.0159 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0150 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0053\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0108 - mae: 0.0108 - root_mean_squared_error: 0.0143 - val_loss: 0.0084 - val_mae: 0.0084 - val_root_mean_squared_error: 0.0097\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0104 - mae: 0.0104 - root_mean_squared_error: 0.0141 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0093 - root_mean_squared_error: 0.0127 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0126 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0116 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - mae: 0.0080 - root_mean_squared_error: 0.0114 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0073 - mae: 0.0073 - root_mean_squared_error: 0.0101 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0108 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0024\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0094 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0067 - mae: 0.0067 - root_mean_squared_error: 0.0098 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0097 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0099 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0061 - mae: 0.0061 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0059 - mae: 0.0059 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0089 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0088 - val_loss: 0.0012 - val_mae: 0.0012 - val_root_mean_squared_error: 0.0019\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0051 - mae: 0.0051 - root_mean_squared_error: 0.0081 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0090 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0099 - val_loss: 0.0016 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0088 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0089 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0033\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0052 - mae: 0.0052 - root_mean_squared_error: 0.0085 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:29:02 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:29:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:29:11 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:29:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: input_width = 48 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0737 - mae: 0.0737 - root_mean_squared_error: 0.0986 - val_loss: 0.0356 - val_mae: 0.0356 - val_root_mean_squared_error: 0.0426\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0527 - mae: 0.0527 - root_mean_squared_error: 0.0677 - val_loss: 0.0202 - val_mae: 0.0202 - val_root_mean_squared_error: 0.0261\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0454 - mae: 0.0454 - root_mean_squared_error: 0.0591 - val_loss: 0.0434 - val_mae: 0.0434 - val_root_mean_squared_error: 0.0486\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0447 - mae: 0.0447 - root_mean_squared_error: 0.0586 - val_loss: 0.0149 - val_mae: 0.0149 - val_root_mean_squared_error: 0.0200\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0395 - mae: 0.0395 - root_mean_squared_error: 0.0516 - val_loss: 0.0147 - val_mae: 0.0147 - val_root_mean_squared_error: 0.0191\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0358 - mae: 0.0358 - root_mean_squared_error: 0.0469 - val_loss: 0.0126 - val_mae: 0.0126 - val_root_mean_squared_error: 0.0170\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0452 - val_loss: 0.0288 - val_mae: 0.0288 - val_root_mean_squared_error: 0.0326\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0349 - mae: 0.0349 - root_mean_squared_error: 0.0457 - val_loss: 0.0296 - val_mae: 0.0296 - val_root_mean_squared_error: 0.0328\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0315 - mae: 0.0315 - root_mean_squared_error: 0.0407 - val_loss: 0.0291 - val_mae: 0.0291 - val_root_mean_squared_error: 0.0327\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0309 - mae: 0.0309 - root_mean_squared_error: 0.0399 - val_loss: 0.0158 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0195\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0277 - mae: 0.0277 - root_mean_squared_error: 0.0363 - val_loss: 0.0336 - val_mae: 0.0336 - val_root_mean_squared_error: 0.0361\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0283 - mae: 0.0283 - root_mean_squared_error: 0.0367 - val_loss: 0.0152 - val_mae: 0.0152 - val_root_mean_squared_error: 0.0188\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0268 - mae: 0.0268 - root_mean_squared_error: 0.0347 - val_loss: 0.0109 - val_mae: 0.0109 - val_root_mean_squared_error: 0.0139\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0250 - mae: 0.0250 - root_mean_squared_error: 0.0326 - val_loss: 0.0119 - val_mae: 0.0119 - val_root_mean_squared_error: 0.0149\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0238 - mae: 0.0238 - root_mean_squared_error: 0.0308 - val_loss: 0.0120 - val_mae: 0.0120 - val_root_mean_squared_error: 0.0150\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0220 - mae: 0.0220 - root_mean_squared_error: 0.0289 - val_loss: 0.0130 - val_mae: 0.0130 - val_root_mean_squared_error: 0.0160\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0218 - mae: 0.0218 - root_mean_squared_error: 0.0285 - val_loss: 0.0082 - val_mae: 0.0082 - val_root_mean_squared_error: 0.0110\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0209 - mae: 0.0209 - root_mean_squared_error: 0.0274 - val_loss: 0.0147 - val_mae: 0.0147 - val_root_mean_squared_error: 0.0172\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0203 - mae: 0.0203 - root_mean_squared_error: 0.0267 - val_loss: 0.0072 - val_mae: 0.0072 - val_root_mean_squared_error: 0.0093\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187 - mae: 0.0187 - root_mean_squared_error: 0.0250 - val_loss: 0.0081 - val_mae: 0.0081 - val_root_mean_squared_error: 0.0106\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184 - mae: 0.0184 - root_mean_squared_error: 0.0245 - val_loss: 0.0080 - val_mae: 0.0080 - val_root_mean_squared_error: 0.0104\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0178 - mae: 0.0178 - root_mean_squared_error: 0.0235 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0164 - mae: 0.0164 - root_mean_squared_error: 0.0217 - val_loss: 0.0065 - val_mae: 0.0065 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0154 - mae: 0.0154 - root_mean_squared_error: 0.0206 - val_loss: 0.0056 - val_mae: 0.0056 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0153 - mae: 0.0153 - root_mean_squared_error: 0.0206 - val_loss: 0.0096 - val_mae: 0.0096 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0151 - mae: 0.0151 - root_mean_squared_error: 0.0207 - val_loss: 0.0057 - val_mae: 0.0057 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0144 - mae: 0.0144 - root_mean_squared_error: 0.0195 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0137 - mae: 0.0137 - root_mean_squared_error: 0.0187 - val_loss: 0.0058 - val_mae: 0.0058 - val_root_mean_squared_error: 0.0077\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0132 - mae: 0.0132 - root_mean_squared_error: 0.0187 - val_loss: 0.0063 - val_mae: 0.0063 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0122 - root_mean_squared_error: 0.0171 - val_loss: 0.0055 - val_mae: 0.0055 - val_root_mean_squared_error: 0.0077\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0120 - root_mean_squared_error: 0.0173 - val_loss: 0.0049 - val_mae: 0.0049 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0113 - mae: 0.0113 - root_mean_squared_error: 0.0159 - val_loss: 0.0057 - val_mae: 0.0057 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0104 - mae: 0.0104 - root_mean_squared_error: 0.0149 - val_loss: 0.0093 - val_mae: 0.0093 - val_root_mean_squared_error: 0.0111\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0108 - mae: 0.0108 - root_mean_squared_error: 0.0156 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0101 - mae: 0.0101 - root_mean_squared_error: 0.0151 - val_loss: 0.0058 - val_mae: 0.0058 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0102 - mae: 0.0102 - root_mean_squared_error: 0.0157 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0096 - mae: 0.0096 - root_mean_squared_error: 0.0151 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0098 - mae: 0.0098 - root_mean_squared_error: 0.0152 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0095 - root_mean_squared_error: 0.0148 - val_loss: 0.0070 - val_mae: 0.0070 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0095 - mae: 0.0095 - root_mean_squared_error: 0.0147 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0096 - mae: 0.0096 - root_mean_squared_error: 0.0154 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0094 - mae: 0.0094 - root_mean_squared_error: 0.0148 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0056\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0099 - mae: 0.0099 - root_mean_squared_error: 0.0154 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0153 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0100 - mae: 0.0100 - root_mean_squared_error: 0.0161 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0053\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0088 - mae: 0.0088 - root_mean_squared_error: 0.0142 - val_loss: 0.0068 - val_mae: 0.0068 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0099 - mae: 0.0099 - root_mean_squared_error: 0.0158 - val_loss: 0.0070 - val_mae: 0.0070 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0085 - mae: 0.0085 - root_mean_squared_error: 0.0140 - val_loss: 0.0055 - val_mae: 0.0055 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0088 - mae: 0.0088 - root_mean_squared_error: 0.0141 - val_loss: 0.0041 - val_mae: 0.0041 - val_root_mean_squared_error: 0.0062\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0096 - mae: 0.0096 - root_mean_squared_error: 0.0151 - val_loss: 0.0062 - val_mae: 0.0062 - val_root_mean_squared_error: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:30:55 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:31:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:31:04 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:31:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: input_width = 72 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0786 - mae: 0.0786 - root_mean_squared_error: 0.1056 - val_loss: 0.0356 - val_mae: 0.0356 - val_root_mean_squared_error: 0.0448\n",
      "Epoch 2/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0598 - mae: 0.0598 - root_mean_squared_error: 0.0785 - val_loss: 0.0248 - val_mae: 0.0248 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 3/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0521 - mae: 0.0521 - root_mean_squared_error: 0.0695 - val_loss: 0.0235 - val_mae: 0.0235 - val_root_mean_squared_error: 0.0321\n",
      "Epoch 4/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0476 - mae: 0.0476 - root_mean_squared_error: 0.0636 - val_loss: 0.0263 - val_mae: 0.0263 - val_root_mean_squared_error: 0.0342\n",
      "Epoch 5/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0459 - mae: 0.0459 - root_mean_squared_error: 0.0615 - val_loss: 0.0264 - val_mae: 0.0264 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 6/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0436 - mae: 0.0436 - root_mean_squared_error: 0.0582 - val_loss: 0.0207 - val_mae: 0.0207 - val_root_mean_squared_error: 0.0289\n",
      "Epoch 7/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0572 - val_loss: 0.0205 - val_mae: 0.0205 - val_root_mean_squared_error: 0.0282\n",
      "Epoch 8/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0415 - mae: 0.0415 - root_mean_squared_error: 0.0558 - val_loss: 0.0213 - val_mae: 0.0213 - val_root_mean_squared_error: 0.0302\n",
      "Epoch 9/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0397 - mae: 0.0397 - root_mean_squared_error: 0.0546 - val_loss: 0.0266 - val_mae: 0.0266 - val_root_mean_squared_error: 0.0344\n",
      "Epoch 10/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0368 - mae: 0.0368 - root_mean_squared_error: 0.0500 - val_loss: 0.0179 - val_mae: 0.0179 - val_root_mean_squared_error: 0.0243\n",
      "Epoch 11/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0495 - val_loss: 0.0196 - val_mae: 0.0196 - val_root_mean_squared_error: 0.0276\n",
      "Epoch 12/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0500 - val_loss: 0.0221 - val_mae: 0.0221 - val_root_mean_squared_error: 0.0304\n",
      "Epoch 13/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0505 - val_loss: 0.0189 - val_mae: 0.0189 - val_root_mean_squared_error: 0.0259\n",
      "Epoch 14/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0473 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0308\n",
      "Epoch 15/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0333 - mae: 0.0333 - root_mean_squared_error: 0.0452 - val_loss: 0.0187 - val_mae: 0.0187 - val_root_mean_squared_error: 0.0260\n",
      "Epoch 16/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0335 - mae: 0.0335 - root_mean_squared_error: 0.0460 - val_loss: 0.0182 - val_mae: 0.0182 - val_root_mean_squared_error: 0.0250\n",
      "Epoch 17/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0323 - mae: 0.0323 - root_mean_squared_error: 0.0447 - val_loss: 0.0190 - val_mae: 0.0190 - val_root_mean_squared_error: 0.0270\n",
      "Epoch 18/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0314 - mae: 0.0314 - root_mean_squared_error: 0.0437 - val_loss: 0.0196 - val_mae: 0.0196 - val_root_mean_squared_error: 0.0271\n",
      "Epoch 19/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0299 - mae: 0.0299 - root_mean_squared_error: 0.0415 - val_loss: 0.0170 - val_mae: 0.0170 - val_root_mean_squared_error: 0.0237\n",
      "Epoch 20/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0390 - val_loss: 0.0138 - val_mae: 0.0138 - val_root_mean_squared_error: 0.0183\n",
      "Epoch 21/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0273 - mae: 0.0273 - root_mean_squared_error: 0.0382 - val_loss: 0.0168 - val_mae: 0.0168 - val_root_mean_squared_error: 0.0225\n",
      "Epoch 22/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0274 - mae: 0.0274 - root_mean_squared_error: 0.0380 - val_loss: 0.0156 - val_mae: 0.0156 - val_root_mean_squared_error: 0.0206\n",
      "Epoch 23/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0252 - mae: 0.0252 - root_mean_squared_error: 0.0354 - val_loss: 0.0153 - val_mae: 0.0153 - val_root_mean_squared_error: 0.0212\n",
      "Epoch 24/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0240 - mae: 0.0240 - root_mean_squared_error: 0.0342 - val_loss: 0.0144 - val_mae: 0.0144 - val_root_mean_squared_error: 0.0195\n",
      "Epoch 25/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0229 - mae: 0.0229 - root_mean_squared_error: 0.0322 - val_loss: 0.0127 - val_mae: 0.0127 - val_root_mean_squared_error: 0.0161\n",
      "Epoch 26/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0209 - mae: 0.0209 - root_mean_squared_error: 0.0294 - val_loss: 0.0108 - val_mae: 0.0108 - val_root_mean_squared_error: 0.0149\n",
      "Epoch 27/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0202 - mae: 0.0202 - root_mean_squared_error: 0.0286 - val_loss: 0.0115 - val_mae: 0.0115 - val_root_mean_squared_error: 0.0158\n",
      "Epoch 28/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0189 - mae: 0.0189 - root_mean_squared_error: 0.0273 - val_loss: 0.0113 - val_mae: 0.0113 - val_root_mean_squared_error: 0.0156\n",
      "Epoch 29/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177 - mae: 0.0177 - root_mean_squared_error: 0.0261 - val_loss: 0.0136 - val_mae: 0.0136 - val_root_mean_squared_error: 0.0176\n",
      "Epoch 30/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0169 - mae: 0.0169 - root_mean_squared_error: 0.0253 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0108\n",
      "Epoch 31/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0142 - mae: 0.0142 - root_mean_squared_error: 0.0223 - val_loss: 0.0058 - val_mae: 0.0058 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 32/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0134 - root_mean_squared_error: 0.0212 - val_loss: 0.0052 - val_mae: 0.0052 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 33/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0130 - mae: 0.0130 - root_mean_squared_error: 0.0211 - val_loss: 0.0050 - val_mae: 0.0050 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 34/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0123 - mae: 0.0123 - root_mean_squared_error: 0.0206 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 35/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0126 - mae: 0.0126 - root_mean_squared_error: 0.0207 - val_loss: 0.0056 - val_mae: 0.0056 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 36/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0114 - mae: 0.0114 - root_mean_squared_error: 0.0194 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 37/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0125 - mae: 0.0125 - root_mean_squared_error: 0.0201 - val_loss: 0.0076 - val_mae: 0.0076 - val_root_mean_squared_error: 0.0102\n",
      "Epoch 38/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0105 - mae: 0.0105 - root_mean_squared_error: 0.0186 - val_loss: 0.0049 - val_mae: 0.0049 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 39/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0107 - mae: 0.0107 - root_mean_squared_error: 0.0186 - val_loss: 0.0075 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0099\n",
      "Epoch 40/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0125 - mae: 0.0125 - root_mean_squared_error: 0.0208 - val_loss: 0.0095 - val_mae: 0.0095 - val_root_mean_squared_error: 0.0130\n",
      "Epoch 41/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0194 - val_loss: 0.0066 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 42/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0101 - mae: 0.0101 - root_mean_squared_error: 0.0181 - val_loss: 0.0088 - val_mae: 0.0088 - val_root_mean_squared_error: 0.0103\n",
      "Epoch 43/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0090 - mae: 0.0090 - root_mean_squared_error: 0.0171 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 44/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0157 - val_loss: 0.0050 - val_mae: 0.0050 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 45/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0093 - mae: 0.0093 - root_mean_squared_error: 0.0161 - val_loss: 0.0111 - val_mae: 0.0111 - val_root_mean_squared_error: 0.0123\n",
      "Epoch 46/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0085 - mae: 0.0085 - root_mean_squared_error: 0.0155 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0056\n",
      "Epoch 47/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0086 - root_mean_squared_error: 0.0158 - val_loss: 0.0068 - val_mae: 0.0068 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 48/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0080 - mae: 0.0080 - root_mean_squared_error: 0.0149 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0066\n",
      "Epoch 49/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0086 - root_mean_squared_error: 0.0155 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 50/50\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0086 - root_mean_squared_error: 0.0156 - val_loss: 0.0060 - val_mae: 0.0060 - val_root_mean_squared_error: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:32:52 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:33:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:33:01 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:33:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: input_width = 96 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0823 - mae: 0.0823 - root_mean_squared_error: 0.1094 - val_loss: 0.0287 - val_mae: 0.0287 - val_root_mean_squared_error: 0.0394\n",
      "Epoch 2/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0614 - mae: 0.0614 - root_mean_squared_error: 0.0811 - val_loss: 0.0269 - val_mae: 0.0269 - val_root_mean_squared_error: 0.0378\n",
      "Epoch 3/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0551 - mae: 0.0551 - root_mean_squared_error: 0.0734 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 4/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0497 - mae: 0.0497 - root_mean_squared_error: 0.0675 - val_loss: 0.0270 - val_mae: 0.0270 - val_root_mean_squared_error: 0.0377\n",
      "Epoch 5/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0484 - mae: 0.0484 - root_mean_squared_error: 0.0665 - val_loss: 0.0259 - val_mae: 0.0259 - val_root_mean_squared_error: 0.0369\n",
      "Epoch 6/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0463 - mae: 0.0463 - root_mean_squared_error: 0.0643 - val_loss: 0.0243 - val_mae: 0.0243 - val_root_mean_squared_error: 0.0347\n",
      "Epoch 7/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0445 - mae: 0.0445 - root_mean_squared_error: 0.0630 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 8/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0441 - mae: 0.0441 - root_mean_squared_error: 0.0613 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0358\n",
      "Epoch 9/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0419 - mae: 0.0419 - root_mean_squared_error: 0.0594 - val_loss: 0.0253 - val_mae: 0.0253 - val_root_mean_squared_error: 0.0364\n",
      "Epoch 10/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.0405 - root_mean_squared_error: 0.0584 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 11/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0410 - mae: 0.0410 - root_mean_squared_error: 0.0587 - val_loss: 0.0240 - val_mae: 0.0240 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 12/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0392 - mae: 0.0392 - root_mean_squared_error: 0.0568 - val_loss: 0.0250 - val_mae: 0.0250 - val_root_mean_squared_error: 0.0360\n",
      "Epoch 13/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0566 - val_loss: 0.0241 - val_mae: 0.0241 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 14/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0381 - mae: 0.0381 - root_mean_squared_error: 0.0559 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 15/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0558 - val_loss: 0.0242 - val_mae: 0.0242 - val_root_mean_squared_error: 0.0353\n",
      "Epoch 16/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0555 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0349\n",
      "Epoch 17/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0373 - mae: 0.0373 - root_mean_squared_error: 0.0554 - val_loss: 0.0245 - val_mae: 0.0245 - val_root_mean_squared_error: 0.0356\n",
      "Epoch 18/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0365 - mae: 0.0365 - root_mean_squared_error: 0.0546 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 19/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0363 - mae: 0.0363 - root_mean_squared_error: 0.0546 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 20/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0362 - mae: 0.0362 - root_mean_squared_error: 0.0543 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 21/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0355 - mae: 0.0355 - root_mean_squared_error: 0.0538 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 22/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0538 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 23/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0533 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n",
      "Epoch 24/50\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0351 - mae: 0.0351 - root_mean_squared_error: 0.0537 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:34:19 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:34:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:34:29 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:34:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 22:35:09 INFO mlflow.tracking.fluent: Experiment with name 'log_return_simplernn_batch_size_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: batch_size = 16 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0607 - mae: 0.0607 - root_mean_squared_error: 0.0825 - val_loss: 0.0227 - val_mae: 0.0227 - val_root_mean_squared_error: 0.0271\n",
      "Epoch 2/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0416 - mae: 0.0416 - root_mean_squared_error: 0.0542 - val_loss: 0.0100 - val_mae: 0.0100 - val_root_mean_squared_error: 0.0138\n",
      "Epoch 3/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0358 - mae: 0.0358 - root_mean_squared_error: 0.0458 - val_loss: 0.0177 - val_mae: 0.0177 - val_root_mean_squared_error: 0.0207\n",
      "Epoch 4/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0318 - mae: 0.0318 - root_mean_squared_error: 0.0405 - val_loss: 0.0154 - val_mae: 0.0154 - val_root_mean_squared_error: 0.0187\n",
      "Epoch 5/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0306 - mae: 0.0306 - root_mean_squared_error: 0.0388 - val_loss: 0.0119 - val_mae: 0.0119 - val_root_mean_squared_error: 0.0147\n",
      "Epoch 6/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0267 - mae: 0.0267 - root_mean_squared_error: 0.0344 - val_loss: 0.0145 - val_mae: 0.0145 - val_root_mean_squared_error: 0.0166\n",
      "Epoch 7/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0237 - mae: 0.0237 - root_mean_squared_error: 0.0306 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 8/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0222 - mae: 0.0222 - root_mean_squared_error: 0.0288 - val_loss: 0.0060 - val_mae: 0.0060 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 9/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196 - mae: 0.0196 - root_mean_squared_error: 0.0252 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 10/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0185 - root_mean_squared_error: 0.0240 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 11/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168 - mae: 0.0168 - root_mean_squared_error: 0.0221 - val_loss: 0.0098 - val_mae: 0.0098 - val_root_mean_squared_error: 0.0108\n",
      "Epoch 12/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0155 - mae: 0.0155 - root_mean_squared_error: 0.0201 - val_loss: 0.0055 - val_mae: 0.0055 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 13/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0143 - root_mean_squared_error: 0.0189 - val_loss: 0.0070 - val_mae: 0.0070 - val_root_mean_squared_error: 0.0096\n",
      "Epoch 14/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0133 - root_mean_squared_error: 0.0177 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 15/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0117 - root_mean_squared_error: 0.0161 - val_loss: 0.0078 - val_mae: 0.0078 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 16/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0105 - root_mean_squared_error: 0.0146 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0056\n",
      "Epoch 17/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0102 - mae: 0.0102 - root_mean_squared_error: 0.0140 - val_loss: 0.0056 - val_mae: 0.0056 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 18/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0094 - root_mean_squared_error: 0.0137 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 19/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0131 - val_loss: 0.0026 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 20/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0084 - root_mean_squared_error: 0.0120 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 21/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0084 - root_mean_squared_error: 0.0121 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0055\n",
      "Epoch 22/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - mae: 0.0081 - root_mean_squared_error: 0.0119 - val_loss: 0.0039 - val_mae: 0.0039 - val_root_mean_squared_error: 0.0056\n",
      "Epoch 23/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0107 - val_loss: 0.0031 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 24/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0071 - mae: 0.0071 - root_mean_squared_error: 0.0111 - val_loss: 0.0032 - val_mae: 0.0032 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 25/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0070 - mae: 0.0070 - root_mean_squared_error: 0.0109 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 26/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0067 - mae: 0.0067 - root_mean_squared_error: 0.0109 - val_loss: 0.0026 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 27/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0069 - mae: 0.0069 - root_mean_squared_error: 0.0105 - val_loss: 0.0034 - val_mae: 0.0034 - val_root_mean_squared_error: 0.0042\n",
      "Epoch 28/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0069 - mae: 0.0069 - root_mean_squared_error: 0.0107 - val_loss: 0.0031 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 29/50\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0070 - mae: 0.0070 - root_mean_squared_error: 0.0107 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:35:48 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:35:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:35:58 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:36:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: batch_size = 32 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0664 - mae: 0.0664 - root_mean_squared_error: 0.0907 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0233\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0449 - mae: 0.0449 - root_mean_squared_error: 0.0587 - val_loss: 0.0125 - val_mae: 0.0125 - val_root_mean_squared_error: 0.0173\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0505 - val_loss: 0.0210 - val_mae: 0.0210 - val_root_mean_squared_error: 0.0239\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0449 - val_loss: 0.0295 - val_mae: 0.0295 - val_root_mean_squared_error: 0.0312\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0331 - mae: 0.0331 - root_mean_squared_error: 0.0424 - val_loss: 0.0139 - val_mae: 0.0139 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.0303 - root_mean_squared_error: 0.0393 - val_loss: 0.0075 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0373 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0357 - val_loss: 0.0159 - val_mae: 0.0159 - val_root_mean_squared_error: 0.0183\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0339 - val_loss: 0.0106 - val_mae: 0.0106 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0248 - mae: 0.0248 - root_mean_squared_error: 0.0318 - val_loss: 0.0177 - val_mae: 0.0177 - val_root_mean_squared_error: 0.0193\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0227 - mae: 0.0227 - root_mean_squared_error: 0.0293 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0219 - mae: 0.0219 - root_mean_squared_error: 0.0280 - val_loss: 0.0150 - val_mae: 0.0150 - val_root_mean_squared_error: 0.0168\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0205 - mae: 0.0205 - root_mean_squared_error: 0.0265 - val_loss: 0.0046 - val_mae: 0.0046 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0206 - mae: 0.0206 - root_mean_squared_error: 0.0266 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191 - mae: 0.0191 - root_mean_squared_error: 0.0247 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0063\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173 - mae: 0.0173 - root_mean_squared_error: 0.0225 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171 - mae: 0.0171 - root_mean_squared_error: 0.0220 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0058\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0154 - mae: 0.0154 - root_mean_squared_error: 0.0202 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0152 - mae: 0.0152 - root_mean_squared_error: 0.0199 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0141 - root_mean_squared_error: 0.0187 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0135 - root_mean_squared_error: 0.0182 - val_loss: 0.0053 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - root_mean_squared_error: 0.0161 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - root_mean_squared_error: 0.0159 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0150 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0053\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0108 - mae: 0.0108 - root_mean_squared_error: 0.0143 - val_loss: 0.0084 - val_mae: 0.0084 - val_root_mean_squared_error: 0.0097\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0104 - root_mean_squared_error: 0.0141 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - root_mean_squared_error: 0.0127 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0126 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0116 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - mae: 0.0080 - root_mean_squared_error: 0.0114 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0073 - mae: 0.0073 - root_mean_squared_error: 0.0101 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0108 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0024\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0094 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0067 - mae: 0.0067 - root_mean_squared_error: 0.0098 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0097 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0099 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0061 - mae: 0.0061 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0059 - mae: 0.0059 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0089 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0088 - val_loss: 0.0012 - val_mae: 0.0012 - val_root_mean_squared_error: 0.0019\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0051 - mae: 0.0051 - root_mean_squared_error: 0.0081 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0090 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0099 - val_loss: 0.0016 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0088 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0089 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0033\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0052 - mae: 0.0052 - root_mean_squared_error: 0.0085 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:37:31 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:37:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:37:41 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:37:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: batch_size = 64 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0805 - mae: 0.0805 - root_mean_squared_error: 0.1104 - val_loss: 0.0237 - val_mae: 0.0237 - val_root_mean_squared_error: 0.0306\n",
      "Epoch 2/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0489 - mae: 0.0489 - root_mean_squared_error: 0.0639 - val_loss: 0.0206 - val_mae: 0.0206 - val_root_mean_squared_error: 0.0259\n",
      "Epoch 3/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0436 - mae: 0.0436 - root_mean_squared_error: 0.0562 - val_loss: 0.0131 - val_mae: 0.0131 - val_root_mean_squared_error: 0.0173\n",
      "Epoch 4/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0520 - val_loss: 0.0120 - val_mae: 0.0120 - val_root_mean_squared_error: 0.0156\n",
      "Epoch 5/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0380 - mae: 0.0380 - root_mean_squared_error: 0.0485 - val_loss: 0.0094 - val_mae: 0.0094 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 6/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0346 - mae: 0.0346 - root_mean_squared_error: 0.0447 - val_loss: 0.0222 - val_mae: 0.0222 - val_root_mean_squared_error: 0.0244\n",
      "Epoch 7/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0339 - mae: 0.0339 - root_mean_squared_error: 0.0431 - val_loss: 0.0087 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0115\n",
      "Epoch 8/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0319 - mae: 0.0319 - root_mean_squared_error: 0.0408 - val_loss: 0.0224 - val_mae: 0.0224 - val_root_mean_squared_error: 0.0239\n",
      "Epoch 9/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0311 - mae: 0.0311 - root_mean_squared_error: 0.0402 - val_loss: 0.0100 - val_mae: 0.0100 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 10/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0289 - mae: 0.0289 - root_mean_squared_error: 0.0374 - val_loss: 0.0196 - val_mae: 0.0196 - val_root_mean_squared_error: 0.0206\n",
      "Epoch 11/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0290 - mae: 0.0290 - root_mean_squared_error: 0.0370 - val_loss: 0.0269 - val_mae: 0.0269 - val_root_mean_squared_error: 0.0279\n",
      "Epoch 12/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0279 - mae: 0.0279 - root_mean_squared_error: 0.0358 - val_loss: 0.0098 - val_mae: 0.0098 - val_root_mean_squared_error: 0.0121\n",
      "Epoch 13/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0263 - mae: 0.0263 - root_mean_squared_error: 0.0338 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0056\n",
      "Epoch 14/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0268 - mae: 0.0268 - root_mean_squared_error: 0.0344 - val_loss: 0.0076 - val_mae: 0.0076 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 15/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0254 - mae: 0.0254 - root_mean_squared_error: 0.0326 - val_loss: 0.0158 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0169\n",
      "Epoch 16/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0237 - mae: 0.0237 - root_mean_squared_error: 0.0307 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0063\n",
      "Epoch 17/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0236 - mae: 0.0236 - root_mean_squared_error: 0.0302 - val_loss: 0.0063 - val_mae: 0.0063 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 18/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0247 - mae: 0.0247 - root_mean_squared_error: 0.0316 - val_loss: 0.0194 - val_mae: 0.0194 - val_root_mean_squared_error: 0.0207\n",
      "Epoch 19/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0217 - mae: 0.0217 - root_mean_squared_error: 0.0278 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 20/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0210 - mae: 0.0210 - root_mean_squared_error: 0.0268 - val_loss: 0.0089 - val_mae: 0.0089 - val_root_mean_squared_error: 0.0096\n",
      "Epoch 21/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0214 - mae: 0.0214 - root_mean_squared_error: 0.0270 - val_loss: 0.0181 - val_mae: 0.0181 - val_root_mean_squared_error: 0.0192\n",
      "Epoch 22/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0202 - mae: 0.0202 - root_mean_squared_error: 0.0260 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 23/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0191 - mae: 0.0191 - root_mean_squared_error: 0.0246 - val_loss: 0.0078 - val_mae: 0.0078 - val_root_mean_squared_error: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:38:46 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:38:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:38:55 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:38:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: batch_size = 128 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0954 - mae: 0.0954 - root_mean_squared_error: 0.1296 - val_loss: 0.0279 - val_mae: 0.0279 - val_root_mean_squared_error: 0.0372\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0541 - mae: 0.0541 - root_mean_squared_error: 0.0713 - val_loss: 0.0198 - val_mae: 0.0198 - val_root_mean_squared_error: 0.0268\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0658 - val_loss: 0.0347 - val_mae: 0.0347 - val_root_mean_squared_error: 0.0398\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0454 - mae: 0.0454 - root_mean_squared_error: 0.0592 - val_loss: 0.0145 - val_mae: 0.0145 - val_root_mean_squared_error: 0.0199\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0435 - mae: 0.0435 - root_mean_squared_error: 0.0561 - val_loss: 0.0146 - val_mae: 0.0146 - val_root_mean_squared_error: 0.0193\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0421 - mae: 0.0421 - root_mean_squared_error: 0.0548 - val_loss: 0.0131 - val_mae: 0.0131 - val_root_mean_squared_error: 0.0173\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0404 - mae: 0.0404 - root_mean_squared_error: 0.0519 - val_loss: 0.0183 - val_mae: 0.0183 - val_root_mean_squared_error: 0.0210\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0481 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0282\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0357 - mae: 0.0357 - root_mean_squared_error: 0.0461 - val_loss: 0.0119 - val_mae: 0.0119 - val_root_mean_squared_error: 0.0148\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0342 - mae: 0.0342 - root_mean_squared_error: 0.0439 - val_loss: 0.0209 - val_mae: 0.0209 - val_root_mean_squared_error: 0.0229\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0439 - val_loss: 0.0252 - val_mae: 0.0252 - val_root_mean_squared_error: 0.0269\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0328 - mae: 0.0328 - root_mean_squared_error: 0.0426 - val_loss: 0.0112 - val_mae: 0.0112 - val_root_mean_squared_error: 0.0138\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0321 - mae: 0.0321 - root_mean_squared_error: 0.0411 - val_loss: 0.0060 - val_mae: 0.0060 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0302 - mae: 0.0302 - root_mean_squared_error: 0.0388 - val_loss: 0.0165 - val_mae: 0.0165 - val_root_mean_squared_error: 0.0182\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0312 - mae: 0.0312 - root_mean_squared_error: 0.0403 - val_loss: 0.0069 - val_mae: 0.0069 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0304 - mae: 0.0304 - root_mean_squared_error: 0.0388 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0286 - mae: 0.0286 - root_mean_squared_error: 0.0366 - val_loss: 0.0174 - val_mae: 0.0174 - val_root_mean_squared_error: 0.0187\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0286 - mae: 0.0286 - root_mean_squared_error: 0.0366 - val_loss: 0.0063 - val_mae: 0.0063 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0298 - mae: 0.0298 - root_mean_squared_error: 0.0378 - val_loss: 0.0159 - val_mae: 0.0159 - val_root_mean_squared_error: 0.0177\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0276 - mae: 0.0276 - root_mean_squared_error: 0.0355 - val_loss: 0.0132 - val_mae: 0.0132 - val_root_mean_squared_error: 0.0149\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0360 - val_loss: 0.0154 - val_mae: 0.0154 - val_root_mean_squared_error: 0.0169\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0261 - mae: 0.0261 - root_mean_squared_error: 0.0333 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0267 - mae: 0.0267 - root_mean_squared_error: 0.0341 - val_loss: 0.0186 - val_mae: 0.0186 - val_root_mean_squared_error: 0.0198\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0256 - mae: 0.0256 - root_mean_squared_error: 0.0327 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 25/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0252 - mae: 0.0252 - root_mean_squared_error: 0.0325 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0063\n",
      "Epoch 26/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0243 - mae: 0.0243 - root_mean_squared_error: 0.0309 - val_loss: 0.0079 - val_mae: 0.0079 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 27/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0239 - mae: 0.0239 - root_mean_squared_error: 0.0303 - val_loss: 0.0069 - val_mae: 0.0069 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 28/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0239 - mae: 0.0239 - root_mean_squared_error: 0.0307 - val_loss: 0.0186 - val_mae: 0.0186 - val_root_mean_squared_error: 0.0193\n",
      "Epoch 29/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0254 - mae: 0.0254 - root_mean_squared_error: 0.0323 - val_loss: 0.0187 - val_mae: 0.0187 - val_root_mean_squared_error: 0.0202\n",
      "Epoch 30/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0254 - mae: 0.0254 - root_mean_squared_error: 0.0323 - val_loss: 0.0073 - val_mae: 0.0073 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 31/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0236 - mae: 0.0236 - root_mean_squared_error: 0.0305 - val_loss: 0.0079 - val_mae: 0.0079 - val_root_mean_squared_error: 0.0098\n",
      "Epoch 32/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.0222 - root_mean_squared_error: 0.0285 - val_loss: 0.0041 - val_mae: 0.0041 - val_root_mean_squared_error: 0.0057\n",
      "Epoch 33/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0216 - mae: 0.0216 - root_mean_squared_error: 0.0279 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 34/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0215 - mae: 0.0215 - root_mean_squared_error: 0.0279 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0056\n",
      "Epoch 35/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0214 - mae: 0.0214 - root_mean_squared_error: 0.0274 - val_loss: 0.0080 - val_mae: 0.0080 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 36/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0208 - mae: 0.0208 - root_mean_squared_error: 0.0267 - val_loss: 0.0088 - val_mae: 0.0088 - val_root_mean_squared_error: 0.0096\n",
      "Epoch 37/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0198 - mae: 0.0198 - root_mean_squared_error: 0.0254 - val_loss: 0.0068 - val_mae: 0.0068 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 38/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0204 - mae: 0.0204 - root_mean_squared_error: 0.0265 - val_loss: 0.0034 - val_mae: 0.0034 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 39/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0192 - mae: 0.0192 - root_mean_squared_error: 0.0245 - val_loss: 0.0070 - val_mae: 0.0070 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 40/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0189 - mae: 0.0189 - root_mean_squared_error: 0.0244 - val_loss: 0.0068 - val_mae: 0.0068 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 41/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0185 - mae: 0.0185 - root_mean_squared_error: 0.0236 - val_loss: 0.0074 - val_mae: 0.0074 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 42/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0183 - mae: 0.0183 - root_mean_squared_error: 0.0237 - val_loss: 0.0049 - val_mae: 0.0049 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 43/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0173 - mae: 0.0173 - root_mean_squared_error: 0.0224 - val_loss: 0.0044 - val_mae: 0.0044 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 44/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0172 - mae: 0.0172 - root_mean_squared_error: 0.0223 - val_loss: 0.0065 - val_mae: 0.0065 - val_root_mean_squared_error: 0.0072\n",
      "Epoch 45/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0177 - mae: 0.0177 - root_mean_squared_error: 0.0231 - val_loss: 0.0106 - val_mae: 0.0106 - val_root_mean_squared_error: 0.0112\n",
      "Epoch 46/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0180 - mae: 0.0180 - root_mean_squared_error: 0.0230 - val_loss: 0.0099 - val_mae: 0.0099 - val_root_mean_squared_error: 0.0108\n",
      "Epoch 47/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0163 - mae: 0.0163 - root_mean_squared_error: 0.0212 - val_loss: 0.0080 - val_mae: 0.0080 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 48/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0167 - mae: 0.0167 - root_mean_squared_error: 0.0218 - val_loss: 0.0133 - val_mae: 0.0133 - val_root_mean_squared_error: 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:40:12 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:40:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:40:21 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:40:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 22:41:10 INFO mlflow.tracking.fluent: Experiment with name 'log_return_simplernn_learning_rate_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: learning_rate = 0.0001 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0932 - mae: 0.0932 - root_mean_squared_error: 0.1227 - val_loss: 0.0314 - val_mae: 0.0314 - val_root_mean_squared_error: 0.0427\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0652 - mae: 0.0652 - root_mean_squared_error: 0.0867 - val_loss: 0.0257 - val_mae: 0.0257 - val_root_mean_squared_error: 0.0346\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0581 - mae: 0.0581 - root_mean_squared_error: 0.0767 - val_loss: 0.0256 - val_mae: 0.0256 - val_root_mean_squared_error: 0.0337\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0532 - mae: 0.0532 - root_mean_squared_error: 0.0703 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0303\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0509 - mae: 0.0509 - root_mean_squared_error: 0.0660 - val_loss: 0.0181 - val_mae: 0.0181 - val_root_mean_squared_error: 0.0245\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0479 - mae: 0.0479 - root_mean_squared_error: 0.0629 - val_loss: 0.0184 - val_mae: 0.0184 - val_root_mean_squared_error: 0.0246\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0462 - mae: 0.0462 - root_mean_squared_error: 0.0602 - val_loss: 0.0152 - val_mae: 0.0152 - val_root_mean_squared_error: 0.0207\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0446 - mae: 0.0446 - root_mean_squared_error: 0.0581 - val_loss: 0.0165 - val_mae: 0.0165 - val_root_mean_squared_error: 0.0214\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0431 - mae: 0.0431 - root_mean_squared_error: 0.0560 - val_loss: 0.0139 - val_mae: 0.0139 - val_root_mean_squared_error: 0.0186\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0550 - val_loss: 0.0175 - val_mae: 0.0175 - val_root_mean_squared_error: 0.0222\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0401 - mae: 0.0401 - root_mean_squared_error: 0.0524 - val_loss: 0.0158 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0203\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0399 - mae: 0.0399 - root_mean_squared_error: 0.0516 - val_loss: 0.0148 - val_mae: 0.0148 - val_root_mean_squared_error: 0.0191\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0385 - mae: 0.0385 - root_mean_squared_error: 0.0498 - val_loss: 0.0136 - val_mae: 0.0136 - val_root_mean_squared_error: 0.0177\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0374 - mae: 0.0374 - root_mean_squared_error: 0.0490 - val_loss: 0.0098 - val_mae: 0.0098 - val_root_mean_squared_error: 0.0135\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0370 - mae: 0.0370 - root_mean_squared_error: 0.0481 - val_loss: 0.0098 - val_mae: 0.0098 - val_root_mean_squared_error: 0.0135\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0372 - mae: 0.0372 - root_mean_squared_error: 0.0478 - val_loss: 0.0141 - val_mae: 0.0141 - val_root_mean_squared_error: 0.0175\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0368 - mae: 0.0368 - root_mean_squared_error: 0.0473 - val_loss: 0.0200 - val_mae: 0.0200 - val_root_mean_squared_error: 0.0227\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0454 - val_loss: 0.0103 - val_mae: 0.0103 - val_root_mean_squared_error: 0.0135\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0343 - mae: 0.0343 - root_mean_squared_error: 0.0443 - val_loss: 0.0099 - val_mae: 0.0099 - val_root_mean_squared_error: 0.0131\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0450 - val_loss: 0.0141 - val_mae: 0.0141 - val_root_mean_squared_error: 0.0168\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0436 - val_loss: 0.0111 - val_mae: 0.0111 - val_root_mean_squared_error: 0.0139\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0326 - mae: 0.0326 - root_mean_squared_error: 0.0423 - val_loss: 0.0084 - val_mae: 0.0084 - val_root_mean_squared_error: 0.0111\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0333 - mae: 0.0333 - root_mean_squared_error: 0.0430 - val_loss: 0.0134 - val_mae: 0.0134 - val_root_mean_squared_error: 0.0157\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0321 - mae: 0.0321 - root_mean_squared_error: 0.0418 - val_loss: 0.0112 - val_mae: 0.0112 - val_root_mean_squared_error: 0.0136\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0323 - mae: 0.0323 - root_mean_squared_error: 0.0415 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0314 - mae: 0.0314 - root_mean_squared_error: 0.0406 - val_loss: 0.0103 - val_mae: 0.0103 - val_root_mean_squared_error: 0.0125\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0312 - mae: 0.0312 - root_mean_squared_error: 0.0399 - val_loss: 0.0121 - val_mae: 0.0121 - val_root_mean_squared_error: 0.0142\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0317 - mae: 0.0317 - root_mean_squared_error: 0.0409 - val_loss: 0.0092 - val_mae: 0.0092 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0306 - mae: 0.0306 - root_mean_squared_error: 0.0395 - val_loss: 0.0088 - val_mae: 0.0088 - val_root_mean_squared_error: 0.0109\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.0303 - root_mean_squared_error: 0.0391 - val_loss: 0.0145 - val_mae: 0.0145 - val_root_mean_squared_error: 0.0160\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0298 - mae: 0.0298 - root_mean_squared_error: 0.0385 - val_loss: 0.0130 - val_mae: 0.0130 - val_root_mean_squared_error: 0.0145\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0298 - mae: 0.0298 - root_mean_squared_error: 0.0382 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0298 - mae: 0.0298 - root_mean_squared_error: 0.0381 - val_loss: 0.0130 - val_mae: 0.0130 - val_root_mean_squared_error: 0.0145\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0291 - mae: 0.0291 - root_mean_squared_error: 0.0373 - val_loss: 0.0202 - val_mae: 0.0202 - val_root_mean_squared_error: 0.0212\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0294 - mae: 0.0294 - root_mean_squared_error: 0.0381 - val_loss: 0.0055 - val_mae: 0.0055 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0290 - mae: 0.0290 - root_mean_squared_error: 0.0372 - val_loss: 0.0149 - val_mae: 0.0149 - val_root_mean_squared_error: 0.0161\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0280 - mae: 0.0280 - root_mean_squared_error: 0.0362 - val_loss: 0.0099 - val_mae: 0.0099 - val_root_mean_squared_error: 0.0113\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0280 - mae: 0.0280 - root_mean_squared_error: 0.0357 - val_loss: 0.0085 - val_mae: 0.0085 - val_root_mean_squared_error: 0.0095\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0358 - val_loss: 0.0126 - val_mae: 0.0126 - val_root_mean_squared_error: 0.0137\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0279 - mae: 0.0279 - root_mean_squared_error: 0.0356 - val_loss: 0.0075 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0269 - mae: 0.0269 - root_mean_squared_error: 0.0345 - val_loss: 0.0076 - val_mae: 0.0076 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0276 - mae: 0.0276 - root_mean_squared_error: 0.0351 - val_loss: 0.0137 - val_mae: 0.0137 - val_root_mean_squared_error: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:41:47 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:41:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:41:57 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:42:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: learning_rate = 0.001 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0664 - mae: 0.0664 - root_mean_squared_error: 0.0907 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0233\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0449 - mae: 0.0449 - root_mean_squared_error: 0.0587 - val_loss: 0.0125 - val_mae: 0.0125 - val_root_mean_squared_error: 0.0173\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0505 - val_loss: 0.0210 - val_mae: 0.0210 - val_root_mean_squared_error: 0.0239\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0449 - val_loss: 0.0295 - val_mae: 0.0295 - val_root_mean_squared_error: 0.0312\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0331 - mae: 0.0331 - root_mean_squared_error: 0.0424 - val_loss: 0.0139 - val_mae: 0.0139 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.0303 - root_mean_squared_error: 0.0393 - val_loss: 0.0075 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0373 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0357 - val_loss: 0.0159 - val_mae: 0.0159 - val_root_mean_squared_error: 0.0183\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0339 - val_loss: 0.0106 - val_mae: 0.0106 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0248 - mae: 0.0248 - root_mean_squared_error: 0.0318 - val_loss: 0.0177 - val_mae: 0.0177 - val_root_mean_squared_error: 0.0193\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0227 - mae: 0.0227 - root_mean_squared_error: 0.0293 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0219 - mae: 0.0219 - root_mean_squared_error: 0.0280 - val_loss: 0.0150 - val_mae: 0.0150 - val_root_mean_squared_error: 0.0168\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0205 - mae: 0.0205 - root_mean_squared_error: 0.0265 - val_loss: 0.0046 - val_mae: 0.0046 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0206 - mae: 0.0206 - root_mean_squared_error: 0.0266 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191 - mae: 0.0191 - root_mean_squared_error: 0.0247 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0063\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173 - mae: 0.0173 - root_mean_squared_error: 0.0225 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171 - mae: 0.0171 - root_mean_squared_error: 0.0220 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0058\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0154 - mae: 0.0154 - root_mean_squared_error: 0.0202 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0152 - mae: 0.0152 - root_mean_squared_error: 0.0199 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0141 - root_mean_squared_error: 0.0187 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0135 - root_mean_squared_error: 0.0182 - val_loss: 0.0053 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - root_mean_squared_error: 0.0161 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - root_mean_squared_error: 0.0159 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0150 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0053\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108 - root_mean_squared_error: 0.0143 - val_loss: 0.0084 - val_mae: 0.0084 - val_root_mean_squared_error: 0.0097\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0104 - mae: 0.0104 - root_mean_squared_error: 0.0141 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - root_mean_squared_error: 0.0127 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0126 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0116 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - mae: 0.0080 - root_mean_squared_error: 0.0114 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0073 - mae: 0.0073 - root_mean_squared_error: 0.0101 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0108 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0024\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0094 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0067 - mae: 0.0067 - root_mean_squared_error: 0.0098 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0097 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0099 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0061 - mae: 0.0061 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0059 - mae: 0.0059 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0089 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0088 - val_loss: 0.0012 - val_mae: 0.0012 - val_root_mean_squared_error: 0.0019\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0051 - mae: 0.0051 - root_mean_squared_error: 0.0081 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0090 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0099 - val_loss: 0.0016 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0088 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0089 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0033\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0052 - mae: 0.0052 - root_mean_squared_error: 0.0085 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:43:28 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:43:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:43:37 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:43:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: learning_rate = 0.01 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0678 - mae: 0.0678 - root_mean_squared_error: 0.1149 - val_loss: 0.0265 - val_mae: 0.0265 - val_root_mean_squared_error: 0.0321\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0465 - val_loss: 0.0155 - val_mae: 0.0155 - val_root_mean_squared_error: 0.0209\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - mae: 0.0256 - root_mean_squared_error: 0.0360 - val_loss: 0.0087 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0114\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.0208 - root_mean_squared_error: 0.0295 - val_loss: 0.0098 - val_mae: 0.0098 - val_root_mean_squared_error: 0.0134\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - root_mean_squared_error: 0.0277 - val_loss: 0.0120 - val_mae: 0.0120 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0206 - mae: 0.0206 - root_mean_squared_error: 0.0290 - val_loss: 0.0154 - val_mae: 0.0154 - val_root_mean_squared_error: 0.0212\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175 - mae: 0.0175 - root_mean_squared_error: 0.0250 - val_loss: 0.0140 - val_mae: 0.0140 - val_root_mean_squared_error: 0.0188\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0188 - root_mean_squared_error: 0.0263 - val_loss: 0.0115 - val_mae: 0.0115 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0237 - mae: 0.0237 - root_mean_squared_error: 0.0338 - val_loss: 0.0203 - val_mae: 0.0203 - val_root_mean_squared_error: 0.0283\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.0303 - root_mean_squared_error: 0.0459 - val_loss: 0.0227 - val_mae: 0.0227 - val_root_mean_squared_error: 0.0337\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0319 - mae: 0.0319 - root_mean_squared_error: 0.0490 - val_loss: 0.0207 - val_mae: 0.0207 - val_root_mean_squared_error: 0.0300\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0295 - mae: 0.0295 - root_mean_squared_error: 0.0441 - val_loss: 0.0238 - val_mae: 0.0238 - val_root_mean_squared_error: 0.0340\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0323 - mae: 0.0323 - root_mean_squared_error: 0.0483 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:44:37 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:44:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:44:45 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:44:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: learning_rate = 0.1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.7134 - mae: 0.7134 - root_mean_squared_error: 1.1684 - val_loss: 0.2779 - val_mae: 0.2779 - val_root_mean_squared_error: 0.2800\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3876 - mae: 0.3876 - root_mean_squared_error: 0.5297 - val_loss: 0.9483 - val_mae: 0.9483 - val_root_mean_squared_error: 0.9489\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5362 - mae: 0.5362 - root_mean_squared_error: 0.6749 - val_loss: 0.2183 - val_mae: 0.2183 - val_root_mean_squared_error: 0.2210\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3896 - mae: 0.3896 - root_mean_squared_error: 0.5359 - val_loss: 0.0579 - val_mae: 0.0579 - val_root_mean_squared_error: 0.0653\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4114 - mae: 0.4114 - root_mean_squared_error: 0.5403 - val_loss: 0.2844 - val_mae: 0.2844 - val_root_mean_squared_error: 0.2865\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2821 - mae: 0.2821 - root_mean_squared_error: 0.3508 - val_loss: 0.4655 - val_mae: 0.4655 - val_root_mean_squared_error: 0.4668\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3071 - mae: 0.3071 - root_mean_squared_error: 0.4220 - val_loss: 0.1553 - val_mae: 0.1553 - val_root_mean_squared_error: 0.1587\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4253 - mae: 0.4253 - root_mean_squared_error: 0.5116 - val_loss: 0.2179 - val_mae: 0.2179 - val_root_mean_squared_error: 0.2205\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3008 - mae: 0.3008 - root_mean_squared_error: 0.3641 - val_loss: 0.1964 - val_mae: 0.1964 - val_root_mean_squared_error: 0.1992\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2687 - mae: 0.2687 - root_mean_squared_error: 0.3684 - val_loss: 0.1372 - val_mae: 0.1372 - val_root_mean_squared_error: 0.1410\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2809 - mae: 0.2809 - root_mean_squared_error: 0.3464 - val_loss: 0.2574 - val_mae: 0.2574 - val_root_mean_squared_error: 0.2598\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3455 - mae: 0.3455 - root_mean_squared_error: 0.4626 - val_loss: 0.4398 - val_mae: 0.4398 - val_root_mean_squared_error: 0.4411\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3750 - mae: 0.3750 - root_mean_squared_error: 0.4926 - val_loss: 0.2346 - val_mae: 0.2346 - val_root_mean_squared_error: 0.2372\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3876 - mae: 0.3876 - root_mean_squared_error: 0.4536 - val_loss: 0.1163 - val_mae: 0.1163 - val_root_mean_squared_error: 0.1209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:45:51 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:45:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:46:00 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:46:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 22:46:47 INFO mlflow.tracking.fluent: Experiment with name 'log_return_simplernn_model_units_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: model_units = 10 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1444 - mae: 0.1444 - root_mean_squared_error: 0.2005 - val_loss: 0.0450 - val_mae: 0.0450 - val_root_mean_squared_error: 0.0594\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0876 - mae: 0.0876 - root_mean_squared_error: 0.1168 - val_loss: 0.0374 - val_mae: 0.0374 - val_root_mean_squared_error: 0.0483\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0742 - mae: 0.0742 - root_mean_squared_error: 0.0995 - val_loss: 0.0281 - val_mae: 0.0281 - val_root_mean_squared_error: 0.0385\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0637 - mae: 0.0637 - root_mean_squared_error: 0.0853 - val_loss: 0.0283 - val_mae: 0.0283 - val_root_mean_squared_error: 0.0381\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0551 - mae: 0.0551 - root_mean_squared_error: 0.0756 - val_loss: 0.0249 - val_mae: 0.0249 - val_root_mean_squared_error: 0.0348\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0502 - mae: 0.0502 - root_mean_squared_error: 0.0689 - val_loss: 0.0236 - val_mae: 0.0236 - val_root_mean_squared_error: 0.0334\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0454 - mae: 0.0454 - root_mean_squared_error: 0.0653 - val_loss: 0.0226 - val_mae: 0.0226 - val_root_mean_squared_error: 0.0324\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0424 - mae: 0.0424 - root_mean_squared_error: 0.0607 - val_loss: 0.0230 - val_mae: 0.0230 - val_root_mean_squared_error: 0.0327\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0392 - mae: 0.0392 - root_mean_squared_error: 0.0569 - val_loss: 0.0221 - val_mae: 0.0221 - val_root_mean_squared_error: 0.0316\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0367 - mae: 0.0367 - root_mean_squared_error: 0.0534 - val_loss: 0.0216 - val_mae: 0.0216 - val_root_mean_squared_error: 0.0305\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0350 - mae: 0.0350 - root_mean_squared_error: 0.0516 - val_loss: 0.0202 - val_mae: 0.0202 - val_root_mean_squared_error: 0.0285\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0334 - mae: 0.0334 - root_mean_squared_error: 0.0482 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0315\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0320 - mae: 0.0320 - root_mean_squared_error: 0.0473 - val_loss: 0.0195 - val_mae: 0.0195 - val_root_mean_squared_error: 0.0271\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0310 - mae: 0.0310 - root_mean_squared_error: 0.0456 - val_loss: 0.0197 - val_mae: 0.0197 - val_root_mean_squared_error: 0.0272\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0306 - mae: 0.0306 - root_mean_squared_error: 0.0449 - val_loss: 0.0183 - val_mae: 0.0183 - val_root_mean_squared_error: 0.0257\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0293 - mae: 0.0293 - root_mean_squared_error: 0.0432 - val_loss: 0.0193 - val_mae: 0.0193 - val_root_mean_squared_error: 0.0266\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0289 - mae: 0.0289 - root_mean_squared_error: 0.0424 - val_loss: 0.0177 - val_mae: 0.0177 - val_root_mean_squared_error: 0.0249\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0286 - mae: 0.0286 - root_mean_squared_error: 0.0412 - val_loss: 0.0192 - val_mae: 0.0192 - val_root_mean_squared_error: 0.0269\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0276 - mae: 0.0276 - root_mean_squared_error: 0.0405 - val_loss: 0.0169 - val_mae: 0.0169 - val_root_mean_squared_error: 0.0237\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0265 - mae: 0.0265 - root_mean_squared_error: 0.0393 - val_loss: 0.0167 - val_mae: 0.0167 - val_root_mean_squared_error: 0.0234\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0253 - mae: 0.0253 - root_mean_squared_error: 0.0375 - val_loss: 0.0156 - val_mae: 0.0156 - val_root_mean_squared_error: 0.0219\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0241 - mae: 0.0241 - root_mean_squared_error: 0.0353 - val_loss: 0.0158 - val_mae: 0.0158 - val_root_mean_squared_error: 0.0215\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0235 - mae: 0.0235 - root_mean_squared_error: 0.0348 - val_loss: 0.0138 - val_mae: 0.0138 - val_root_mean_squared_error: 0.0195\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0231 - mae: 0.0231 - root_mean_squared_error: 0.0352 - val_loss: 0.0146 - val_mae: 0.0146 - val_root_mean_squared_error: 0.0201\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0215 - mae: 0.0215 - root_mean_squared_error: 0.0332 - val_loss: 0.0134 - val_mae: 0.0134 - val_root_mean_squared_error: 0.0184\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0210 - mae: 0.0210 - root_mean_squared_error: 0.0334 - val_loss: 0.0143 - val_mae: 0.0143 - val_root_mean_squared_error: 0.0192\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0207 - mae: 0.0207 - root_mean_squared_error: 0.0323 - val_loss: 0.0113 - val_mae: 0.0113 - val_root_mean_squared_error: 0.0165\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193 - root_mean_squared_error: 0.0303 - val_loss: 0.0103 - val_mae: 0.0103 - val_root_mean_squared_error: 0.0154\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0189 - root_mean_squared_error: 0.0299 - val_loss: 0.0097 - val_mae: 0.0097 - val_root_mean_squared_error: 0.0145\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.0187 - root_mean_squared_error: 0.0291 - val_loss: 0.0113 - val_mae: 0.0113 - val_root_mean_squared_error: 0.0161\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0188 - mae: 0.0188 - root_mean_squared_error: 0.0299 - val_loss: 0.0094 - val_mae: 0.0094 - val_root_mean_squared_error: 0.0138\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172 - mae: 0.0172 - root_mean_squared_error: 0.0270 - val_loss: 0.0102 - val_mae: 0.0102 - val_root_mean_squared_error: 0.0142\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0170 - mae: 0.0170 - root_mean_squared_error: 0.0279 - val_loss: 0.0082 - val_mae: 0.0082 - val_root_mean_squared_error: 0.0123\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0164 - mae: 0.0164 - root_mean_squared_error: 0.0266 - val_loss: 0.0079 - val_mae: 0.0079 - val_root_mean_squared_error: 0.0118\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0162 - mae: 0.0162 - root_mean_squared_error: 0.0268 - val_loss: 0.0084 - val_mae: 0.0084 - val_root_mean_squared_error: 0.0125\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0160 - mae: 0.0160 - root_mean_squared_error: 0.0264 - val_loss: 0.0102 - val_mae: 0.0102 - val_root_mean_squared_error: 0.0142\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0157 - mae: 0.0157 - root_mean_squared_error: 0.0258 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0108\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0155 - root_mean_squared_error: 0.0255 - val_loss: 0.0080 - val_mae: 0.0080 - val_root_mean_squared_error: 0.0118\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0150 - mae: 0.0150 - root_mean_squared_error: 0.0254 - val_loss: 0.0070 - val_mae: 0.0070 - val_root_mean_squared_error: 0.0107\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0151 - mae: 0.0151 - root_mean_squared_error: 0.0255 - val_loss: 0.0095 - val_mae: 0.0095 - val_root_mean_squared_error: 0.0128\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0144 - mae: 0.0144 - root_mean_squared_error: 0.0249 - val_loss: 0.0075 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0115\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0144 - mae: 0.0144 - root_mean_squared_error: 0.0251 - val_loss: 0.0122 - val_mae: 0.0122 - val_root_mean_squared_error: 0.0152\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0161 - mae: 0.0161 - root_mean_squared_error: 0.0257 - val_loss: 0.0083 - val_mae: 0.0083 - val_root_mean_squared_error: 0.0118\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0146 - mae: 0.0146 - root_mean_squared_error: 0.0247 - val_loss: 0.0115 - val_mae: 0.0115 - val_root_mean_squared_error: 0.0148\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0144 - mae: 0.0144 - root_mean_squared_error: 0.0246 - val_loss: 0.0078 - val_mae: 0.0078 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0143 - root_mean_squared_error: 0.0245 - val_loss: 0.0069 - val_mae: 0.0069 - val_root_mean_squared_error: 0.0105\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0140 - mae: 0.0140 - root_mean_squared_error: 0.0253 - val_loss: 0.0069 - val_mae: 0.0069 - val_root_mean_squared_error: 0.0104\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0145 - mae: 0.0145 - root_mean_squared_error: 0.0245 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0103\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0138 - root_mean_squared_error: 0.0232 - val_loss: 0.0084 - val_mae: 0.0084 - val_root_mean_squared_error: 0.0118\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0142 - mae: 0.0142 - root_mean_squared_error: 0.0248 - val_loss: 0.0068 - val_mae: 0.0068 - val_root_mean_squared_error: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:47:32 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:47:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:47:41 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:47:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: model_units = 50 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0664 - mae: 0.0664 - root_mean_squared_error: 0.0907 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0233\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0449 - mae: 0.0449 - root_mean_squared_error: 0.0587 - val_loss: 0.0125 - val_mae: 0.0125 - val_root_mean_squared_error: 0.0173\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0505 - val_loss: 0.0210 - val_mae: 0.0210 - val_root_mean_squared_error: 0.0239\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0449 - val_loss: 0.0295 - val_mae: 0.0295 - val_root_mean_squared_error: 0.0312\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0331 - mae: 0.0331 - root_mean_squared_error: 0.0424 - val_loss: 0.0139 - val_mae: 0.0139 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.0303 - root_mean_squared_error: 0.0393 - val_loss: 0.0075 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0373 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0357 - val_loss: 0.0159 - val_mae: 0.0159 - val_root_mean_squared_error: 0.0183\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0339 - val_loss: 0.0106 - val_mae: 0.0106 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - mae: 0.0248 - root_mean_squared_error: 0.0318 - val_loss: 0.0177 - val_mae: 0.0177 - val_root_mean_squared_error: 0.0193\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0227 - mae: 0.0227 - root_mean_squared_error: 0.0293 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0219 - mae: 0.0219 - root_mean_squared_error: 0.0280 - val_loss: 0.0150 - val_mae: 0.0150 - val_root_mean_squared_error: 0.0168\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0205 - mae: 0.0205 - root_mean_squared_error: 0.0265 - val_loss: 0.0046 - val_mae: 0.0046 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0206 - mae: 0.0206 - root_mean_squared_error: 0.0266 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - root_mean_squared_error: 0.0247 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0063\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173 - mae: 0.0173 - root_mean_squared_error: 0.0225 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171 - mae: 0.0171 - root_mean_squared_error: 0.0220 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0058\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0154 - mae: 0.0154 - root_mean_squared_error: 0.0202 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0152 - mae: 0.0152 - root_mean_squared_error: 0.0199 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0141 - root_mean_squared_error: 0.0187 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0135 - root_mean_squared_error: 0.0182 - val_loss: 0.0053 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - root_mean_squared_error: 0.0161 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - root_mean_squared_error: 0.0159 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0150 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0053\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108 - root_mean_squared_error: 0.0143 - val_loss: 0.0084 - val_mae: 0.0084 - val_root_mean_squared_error: 0.0097\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0104 - root_mean_squared_error: 0.0141 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0093 - root_mean_squared_error: 0.0127 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0126 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0116 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - mae: 0.0080 - root_mean_squared_error: 0.0114 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0073 - mae: 0.0073 - root_mean_squared_error: 0.0101 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0108 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0024\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0094 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0067 - mae: 0.0067 - root_mean_squared_error: 0.0098 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0097 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0099 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0061 - mae: 0.0061 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0059 - mae: 0.0059 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0089 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0088 - val_loss: 0.0012 - val_mae: 0.0012 - val_root_mean_squared_error: 0.0019\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0051 - mae: 0.0051 - root_mean_squared_error: 0.0081 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0090 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0099 - val_loss: 0.0016 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0088 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0089 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0033\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0052 - mae: 0.0052 - root_mean_squared_error: 0.0085 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:49:09 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:49:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:49:19 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:49:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: model_units = 100 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0601 - mae: 0.0601 - root_mean_squared_error: 0.0967 - val_loss: 0.0073 - val_mae: 0.0073 - val_root_mean_squared_error: 0.0098\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0354 - mae: 0.0354 - root_mean_squared_error: 0.0450 - val_loss: 0.0174 - val_mae: 0.0174 - val_root_mean_squared_error: 0.0191\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0308 - mae: 0.0308 - root_mean_squared_error: 0.0392 - val_loss: 0.0173 - val_mae: 0.0173 - val_root_mean_squared_error: 0.0187\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.0303 - root_mean_squared_error: 0.0381 - val_loss: 0.0247 - val_mae: 0.0247 - val_root_mean_squared_error: 0.0265\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0271 - mae: 0.0271 - root_mean_squared_error: 0.0347 - val_loss: 0.0063 - val_mae: 0.0063 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0255 - mae: 0.0255 - root_mean_squared_error: 0.0327 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0243 - mae: 0.0243 - root_mean_squared_error: 0.0310 - val_loss: 0.0117 - val_mae: 0.0117 - val_root_mean_squared_error: 0.0131\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0231 - mae: 0.0231 - root_mean_squared_error: 0.0294 - val_loss: 0.0120 - val_mae: 0.0120 - val_root_mean_squared_error: 0.0139\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0228 - mae: 0.0228 - root_mean_squared_error: 0.0289 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0210 - mae: 0.0210 - root_mean_squared_error: 0.0267 - val_loss: 0.0123 - val_mae: 0.0123 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0207 - mae: 0.0207 - root_mean_squared_error: 0.0266 - val_loss: 0.0136 - val_mae: 0.0136 - val_root_mean_squared_error: 0.0147\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0198 - mae: 0.0198 - root_mean_squared_error: 0.0252 - val_loss: 0.0140 - val_mae: 0.0140 - val_root_mean_squared_error: 0.0164\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0201 - mae: 0.0201 - root_mean_squared_error: 0.0256 - val_loss: 0.0120 - val_mae: 0.0120 - val_root_mean_squared_error: 0.0137\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194 - mae: 0.0194 - root_mean_squared_error: 0.0250 - val_loss: 0.0129 - val_mae: 0.0129 - val_root_mean_squared_error: 0.0145\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189 - mae: 0.0189 - root_mean_squared_error: 0.0240 - val_loss: 0.0148 - val_mae: 0.0148 - val_root_mean_squared_error: 0.0158\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169 - mae: 0.0169 - root_mean_squared_error: 0.0217 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0170 - mae: 0.0170 - root_mean_squared_error: 0.0216 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0059\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167 - mae: 0.0167 - root_mean_squared_error: 0.0214 - val_loss: 0.0056 - val_mae: 0.0056 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0159 - mae: 0.0159 - root_mean_squared_error: 0.0206 - val_loss: 0.0039 - val_mae: 0.0039 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0147 - mae: 0.0147 - root_mean_squared_error: 0.0190 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0144 - mae: 0.0144 - root_mean_squared_error: 0.0186 - val_loss: 0.0044 - val_mae: 0.0044 - val_root_mean_squared_error: 0.0058\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0143 - mae: 0.0143 - root_mean_squared_error: 0.0188 - val_loss: 0.0083 - val_mae: 0.0083 - val_root_mean_squared_error: 0.0095\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0132 - root_mean_squared_error: 0.0176 - val_loss: 0.0023 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0126 - mae: 0.0126 - root_mean_squared_error: 0.0162 - val_loss: 0.0039 - val_mae: 0.0039 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0127 - root_mean_squared_error: 0.0167 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0133 - root_mean_squared_error: 0.0177 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0056\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0122 - mae: 0.0122 - root_mean_squared_error: 0.0162 - val_loss: 0.0062 - val_mae: 0.0062 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0117 - root_mean_squared_error: 0.0155 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0106 - mae: 0.0106 - root_mean_squared_error: 0.0140 - val_loss: 0.0031 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0105 - mae: 0.0105 - root_mean_squared_error: 0.0137 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0057\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0098 - root_mean_squared_error: 0.0131 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0039\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - root_mean_squared_error: 0.0126 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0099 - mae: 0.0099 - root_mean_squared_error: 0.0133 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:50:41 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:50:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:50:50 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:50:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: model_units = 200 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0550 - mae: 0.0550 - root_mean_squared_error: 0.1064 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0290 - mae: 0.0290 - root_mean_squared_error: 0.0369 - val_loss: 0.0308 - val_mae: 0.0308 - val_root_mean_squared_error: 0.0327\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0272 - mae: 0.0272 - root_mean_squared_error: 0.0344 - val_loss: 0.0174 - val_mae: 0.0174 - val_root_mean_squared_error: 0.0202\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0273 - mae: 0.0273 - root_mean_squared_error: 0.0346 - val_loss: 0.0192 - val_mae: 0.0192 - val_root_mean_squared_error: 0.0209\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0226 - mae: 0.0226 - root_mean_squared_error: 0.0287 - val_loss: 0.0193 - val_mae: 0.0193 - val_root_mean_squared_error: 0.0209\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0226 - mae: 0.0226 - root_mean_squared_error: 0.0291 - val_loss: 0.0081 - val_mae: 0.0081 - val_root_mean_squared_error: 0.0110\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0216 - mae: 0.0216 - root_mean_squared_error: 0.0278 - val_loss: 0.0204 - val_mae: 0.0204 - val_root_mean_squared_error: 0.0220\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0217 - mae: 0.0217 - root_mean_squared_error: 0.0277 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0192 - mae: 0.0192 - root_mean_squared_error: 0.0247 - val_loss: 0.0051 - val_mae: 0.0051 - val_root_mean_squared_error: 0.0070\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0200 - mae: 0.0200 - root_mean_squared_error: 0.0257 - val_loss: 0.0210 - val_mae: 0.0210 - val_root_mean_squared_error: 0.0218\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0179 - mae: 0.0179 - root_mean_squared_error: 0.0229 - val_loss: 0.0050 - val_mae: 0.0050 - val_root_mean_squared_error: 0.0067\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193 - mae: 0.0193 - root_mean_squared_error: 0.0247 - val_loss: 0.0208 - val_mae: 0.0208 - val_root_mean_squared_error: 0.0229\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0186 - mae: 0.0186 - root_mean_squared_error: 0.0240 - val_loss: 0.0044 - val_mae: 0.0044 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0187 - mae: 0.0187 - root_mean_squared_error: 0.0240 - val_loss: 0.0070 - val_mae: 0.0070 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0171 - mae: 0.0171 - root_mean_squared_error: 0.0222 - val_loss: 0.0114 - val_mae: 0.0114 - val_root_mean_squared_error: 0.0137\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0173 - mae: 0.0173 - root_mean_squared_error: 0.0225 - val_loss: 0.0073 - val_mae: 0.0073 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182 - mae: 0.0182 - root_mean_squared_error: 0.0234 - val_loss: 0.0134 - val_mae: 0.0134 - val_root_mean_squared_error: 0.0149\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0170 - mae: 0.0170 - root_mean_squared_error: 0.0220 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0095\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0164 - mae: 0.0164 - root_mean_squared_error: 0.0213 - val_loss: 0.0066 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0162 - mae: 0.0162 - root_mean_squared_error: 0.0210 - val_loss: 0.0114 - val_mae: 0.0114 - val_root_mean_squared_error: 0.0137\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0168 - mae: 0.0168 - root_mean_squared_error: 0.0216 - val_loss: 0.0058 - val_mae: 0.0058 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0150 - mae: 0.0150 - root_mean_squared_error: 0.0195 - val_loss: 0.0076 - val_mae: 0.0076 - val_root_mean_squared_error: 0.0099\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0149 - mae: 0.0149 - root_mean_squared_error: 0.0196 - val_loss: 0.0065 - val_mae: 0.0065 - val_root_mean_squared_error: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:52:13 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:52:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:52:23 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:52:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 22:53:12 INFO mlflow.tracking.fluent: Experiment with name 'log_return_simplernn_dropout_rate_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: dropout_rate = 0 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0467 - mae: 0.0467 - root_mean_squared_error: 0.1008 - val_loss: 0.0094 - val_mae: 0.0094 - val_root_mean_squared_error: 0.0130\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0167 - mae: 0.0167 - root_mean_squared_error: 0.0225 - val_loss: 0.0060 - val_mae: 0.0060 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0140 - mae: 0.0140 - root_mean_squared_error: 0.0188 - val_loss: 0.0119 - val_mae: 0.0119 - val_root_mean_squared_error: 0.0131\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0151 - mae: 0.0151 - root_mean_squared_error: 0.0197 - val_loss: 0.0293 - val_mae: 0.0293 - val_root_mean_squared_error: 0.0304\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - root_mean_squared_error: 0.0163 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0113 - root_mean_squared_error: 0.0149 - val_loss: 0.0193 - val_mae: 0.0193 - val_root_mean_squared_error: 0.0200\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108 - root_mean_squared_error: 0.0143 - val_loss: 0.0113 - val_mae: 0.0113 - val_root_mean_squared_error: 0.0119\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0100 - mae: 0.0100 - root_mean_squared_error: 0.0137 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0069\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0112 - val_loss: 0.0035 - val_mae: 0.0035 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - mae: 0.0079 - root_mean_squared_error: 0.0113 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - mae: 0.0076 - root_mean_squared_error: 0.0106 - val_loss: 0.0049 - val_mae: 0.0049 - val_root_mean_squared_error: 0.0057\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0085 - mae: 0.0085 - root_mean_squared_error: 0.0112 - val_loss: 0.0076 - val_mae: 0.0076 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - mae: 0.0079 - root_mean_squared_error: 0.0105 - val_loss: 0.0066 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0070\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0090 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - mae: 0.0081 - root_mean_squared_error: 0.0105 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0062 - mae: 0.0062 - root_mean_squared_error: 0.0084 - val_loss: 0.0149 - val_mae: 0.0149 - val_root_mean_squared_error: 0.0155\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0080 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0055 - mae: 0.0055 - root_mean_squared_error: 0.0075 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0049 - mae: 0.0049 - root_mean_squared_error: 0.0071 - val_loss: 0.0069 - val_mae: 0.0069 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0058 - mae: 0.0058 - root_mean_squared_error: 0.0077 - val_loss: 0.0053 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0063 - mae: 0.0063 - root_mean_squared_error: 0.0086 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0056\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0048 - mae: 0.0048 - root_mean_squared_error: 0.0066 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0024\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0075 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0045 - mae: 0.0045 - root_mean_squared_error: 0.0061 - val_loss: 0.0070 - val_mae: 0.0070 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0076 - val_loss: 0.0049 - val_mae: 0.0049 - val_root_mean_squared_error: 0.0052\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0046 - mae: 0.0046 - root_mean_squared_error: 0.0063 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0037 - mae: 0.0037 - root_mean_squared_error: 0.0053 - val_loss: 0.0012 - val_mae: 0.0012 - val_root_mean_squared_error: 0.0018\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0048 - mae: 0.0048 - root_mean_squared_error: 0.0069 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0037 - root_mean_squared_error: 0.0055 - val_loss: 0.0088 - val_mae: 0.0088 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - mae: 0.0037 - root_mean_squared_error: 0.0053 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0040 - mae: 0.0040 - root_mean_squared_error: 0.0055 - val_loss: 0.0025 - val_mae: 0.0025 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0039 - mae: 0.0039 - root_mean_squared_error: 0.0054 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0042 - mae: 0.0042 - root_mean_squared_error: 0.0060 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0032\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0042 - root_mean_squared_error: 0.0056 - val_loss: 0.0055 - val_mae: 0.0055 - val_root_mean_squared_error: 0.0059\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0044 - mae: 0.0044 - root_mean_squared_error: 0.0060 - val_loss: 0.0017 - val_mae: 0.0017 - val_root_mean_squared_error: 0.0021\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0043 - mae: 0.0043 - root_mean_squared_error: 0.0063 - val_loss: 0.0016 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0022\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0041 - mae: 0.0041 - root_mean_squared_error: 0.0057 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:53:46 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:53:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:53:55 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:53:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: dropout_rate = 0.2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0664 - mae: 0.0664 - root_mean_squared_error: 0.0907 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0233\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0449 - mae: 0.0449 - root_mean_squared_error: 0.0587 - val_loss: 0.0125 - val_mae: 0.0125 - val_root_mean_squared_error: 0.0173\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0505 - val_loss: 0.0210 - val_mae: 0.0210 - val_root_mean_squared_error: 0.0239\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0449 - val_loss: 0.0295 - val_mae: 0.0295 - val_root_mean_squared_error: 0.0312\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0331 - mae: 0.0331 - root_mean_squared_error: 0.0424 - val_loss: 0.0139 - val_mae: 0.0139 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.0303 - root_mean_squared_error: 0.0393 - val_loss: 0.0075 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0373 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0357 - val_loss: 0.0159 - val_mae: 0.0159 - val_root_mean_squared_error: 0.0183\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0339 - val_loss: 0.0106 - val_mae: 0.0106 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - mae: 0.0248 - root_mean_squared_error: 0.0318 - val_loss: 0.0177 - val_mae: 0.0177 - val_root_mean_squared_error: 0.0193\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0227 - mae: 0.0227 - root_mean_squared_error: 0.0293 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0219 - mae: 0.0219 - root_mean_squared_error: 0.0280 - val_loss: 0.0150 - val_mae: 0.0150 - val_root_mean_squared_error: 0.0168\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0205 - mae: 0.0205 - root_mean_squared_error: 0.0265 - val_loss: 0.0046 - val_mae: 0.0046 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0206 - mae: 0.0206 - root_mean_squared_error: 0.0266 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0191 - root_mean_squared_error: 0.0247 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0063\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173 - mae: 0.0173 - root_mean_squared_error: 0.0225 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171 - mae: 0.0171 - root_mean_squared_error: 0.0220 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0058\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0154 - mae: 0.0154 - root_mean_squared_error: 0.0202 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0152 - mae: 0.0152 - root_mean_squared_error: 0.0199 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0141 - root_mean_squared_error: 0.0187 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0135 - root_mean_squared_error: 0.0182 - val_loss: 0.0053 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0121 - root_mean_squared_error: 0.0161 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - root_mean_squared_error: 0.0159 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0150 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0053\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0108 - mae: 0.0108 - root_mean_squared_error: 0.0143 - val_loss: 0.0084 - val_mae: 0.0084 - val_root_mean_squared_error: 0.0097\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0104 - root_mean_squared_error: 0.0141 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - root_mean_squared_error: 0.0127 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0126 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0116 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - mae: 0.0080 - root_mean_squared_error: 0.0114 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0073 - mae: 0.0073 - root_mean_squared_error: 0.0101 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0108 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0024\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0094 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0067 - mae: 0.0067 - root_mean_squared_error: 0.0098 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0097 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0099 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0061 - mae: 0.0061 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0059 - mae: 0.0059 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0089 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0088 - val_loss: 0.0012 - val_mae: 0.0012 - val_root_mean_squared_error: 0.0019\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0051 - mae: 0.0051 - root_mean_squared_error: 0.0081 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0090 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0099 - val_loss: 0.0016 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0088 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0089 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0033\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0052 - mae: 0.0052 - root_mean_squared_error: 0.0085 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:55:27 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:55:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:55:36 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:55:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: dropout_rate = 0.5 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1042 - mae: 0.1042 - root_mean_squared_error: 0.1397 - val_loss: 0.0231 - val_mae: 0.0231 - val_root_mean_squared_error: 0.0302\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0735 - mae: 0.0735 - root_mean_squared_error: 0.0945 - val_loss: 0.0193 - val_mae: 0.0193 - val_root_mean_squared_error: 0.0257\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0623 - mae: 0.0623 - root_mean_squared_error: 0.0792 - val_loss: 0.0232 - val_mae: 0.0232 - val_root_mean_squared_error: 0.0284\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0542 - mae: 0.0542 - root_mean_squared_error: 0.0698 - val_loss: 0.0212 - val_mae: 0.0212 - val_root_mean_squared_error: 0.0263\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0480 - mae: 0.0480 - root_mean_squared_error: 0.0618 - val_loss: 0.0124 - val_mae: 0.0124 - val_root_mean_squared_error: 0.0165\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0414 - mae: 0.0414 - root_mean_squared_error: 0.0536 - val_loss: 0.0175 - val_mae: 0.0175 - val_root_mean_squared_error: 0.0214\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0369 - mae: 0.0369 - root_mean_squared_error: 0.0474 - val_loss: 0.0162 - val_mae: 0.0162 - val_root_mean_squared_error: 0.0204\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0320 - mae: 0.0320 - root_mean_squared_error: 0.0418 - val_loss: 0.0100 - val_mae: 0.0100 - val_root_mean_squared_error: 0.0137\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0272 - mae: 0.0272 - root_mean_squared_error: 0.0360 - val_loss: 0.0136 - val_mae: 0.0136 - val_root_mean_squared_error: 0.0167\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - mae: 0.0247 - root_mean_squared_error: 0.0329 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0212 - mae: 0.0212 - root_mean_squared_error: 0.0285 - val_loss: 0.0123 - val_mae: 0.0123 - val_root_mean_squared_error: 0.0143\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183 - mae: 0.0183 - root_mean_squared_error: 0.0245 - val_loss: 0.0051 - val_mae: 0.0051 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168 - mae: 0.0168 - root_mean_squared_error: 0.0230 - val_loss: 0.0103 - val_mae: 0.0103 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0160 - mae: 0.0160 - root_mean_squared_error: 0.0220 - val_loss: 0.0058 - val_mae: 0.0058 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0143 - root_mean_squared_error: 0.0201 - val_loss: 0.0077 - val_mae: 0.0077 - val_root_mean_squared_error: 0.0104\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0138 - root_mean_squared_error: 0.0194 - val_loss: 0.0075 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0125 - mae: 0.0125 - root_mean_squared_error: 0.0177 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0122 - root_mean_squared_error: 0.0179 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0067\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118 - root_mean_squared_error: 0.0169 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0106 - root_mean_squared_error: 0.0156 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0069\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0162 - val_loss: 0.0041 - val_mae: 0.0041 - val_root_mean_squared_error: 0.0055\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0105 - mae: 0.0105 - root_mean_squared_error: 0.0158 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0102 - mae: 0.0102 - root_mean_squared_error: 0.0150 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0039\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - root_mean_squared_error: 0.0146 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0143 - val_loss: 0.0051 - val_mae: 0.0051 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - root_mean_squared_error: 0.0155 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0042\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0095 - root_mean_squared_error: 0.0149 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0088 - root_mean_squared_error: 0.0138 - val_loss: 0.0049 - val_mae: 0.0049 - val_root_mean_squared_error: 0.0058\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0091 - root_mean_squared_error: 0.0139 - val_loss: 0.0034 - val_mae: 0.0034 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0094 - root_mean_squared_error: 0.0148 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087 - root_mean_squared_error: 0.0142 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0056\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0136 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0089 - root_mean_squared_error: 0.0135 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0062\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0087 - root_mean_squared_error: 0.0135 - val_loss: 0.0041 - val_mae: 0.0041 - val_root_mean_squared_error: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:56:57 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:57:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:57:07 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:57:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: dropout_rate = 0.8 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1707 - mae: 0.1707 - root_mean_squared_error: 0.2263 - val_loss: 0.0518 - val_mae: 0.0518 - val_root_mean_squared_error: 0.0589\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1126 - mae: 0.1126 - root_mean_squared_error: 0.1436 - val_loss: 0.0208 - val_mae: 0.0208 - val_root_mean_squared_error: 0.0280\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0858 - mae: 0.0858 - root_mean_squared_error: 0.1092 - val_loss: 0.0420 - val_mae: 0.0420 - val_root_mean_squared_error: 0.0486\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0636 - mae: 0.0636 - root_mean_squared_error: 0.0834 - val_loss: 0.0179 - val_mae: 0.0179 - val_root_mean_squared_error: 0.0261\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0496 - mae: 0.0496 - root_mean_squared_error: 0.0660 - val_loss: 0.0175 - val_mae: 0.0175 - val_root_mean_squared_error: 0.0255\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0376 - mae: 0.0376 - root_mean_squared_error: 0.0524 - val_loss: 0.0175 - val_mae: 0.0175 - val_root_mean_squared_error: 0.0254\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0319 - mae: 0.0319 - root_mean_squared_error: 0.0465 - val_loss: 0.0152 - val_mae: 0.0152 - val_root_mean_squared_error: 0.0221\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0409 - val_loss: 0.0153 - val_mae: 0.0153 - val_root_mean_squared_error: 0.0216\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0258 - mae: 0.0258 - root_mean_squared_error: 0.0374 - val_loss: 0.0123 - val_mae: 0.0123 - val_root_mean_squared_error: 0.0177\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - mae: 0.0244 - root_mean_squared_error: 0.0352 - val_loss: 0.0126 - val_mae: 0.0126 - val_root_mean_squared_error: 0.0175\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - mae: 0.0226 - root_mean_squared_error: 0.0338 - val_loss: 0.0117 - val_mae: 0.0117 - val_root_mean_squared_error: 0.0160\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0203 - mae: 0.0203 - root_mean_squared_error: 0.0294 - val_loss: 0.0076 - val_mae: 0.0076 - val_root_mean_squared_error: 0.0108\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0201 - mae: 0.0201 - root_mean_squared_error: 0.0301 - val_loss: 0.0082 - val_mae: 0.0082 - val_root_mean_squared_error: 0.0118\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0190 - root_mean_squared_error: 0.0291 - val_loss: 0.0075 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0108\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0179 - root_mean_squared_error: 0.0276 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0176 - root_mean_squared_error: 0.0269 - val_loss: 0.0091 - val_mae: 0.0091 - val_root_mean_squared_error: 0.0123\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0167 - mae: 0.0167 - root_mean_squared_error: 0.0255 - val_loss: 0.0070 - val_mae: 0.0070 - val_root_mean_squared_error: 0.0102\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0166 - mae: 0.0166 - root_mean_squared_error: 0.0250 - val_loss: 0.0063 - val_mae: 0.0063 - val_root_mean_squared_error: 0.0093\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0150 - mae: 0.0150 - root_mean_squared_error: 0.0223 - val_loss: 0.0084 - val_mae: 0.0084 - val_root_mean_squared_error: 0.0110\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0155 - root_mean_squared_error: 0.0240 - val_loss: 0.0072 - val_mae: 0.0072 - val_root_mean_squared_error: 0.0105\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0143 - root_mean_squared_error: 0.0228 - val_loss: 0.0049 - val_mae: 0.0049 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0153 - mae: 0.0153 - root_mean_squared_error: 0.0242 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0147 - root_mean_squared_error: 0.0235 - val_loss: 0.0084 - val_mae: 0.0084 - val_root_mean_squared_error: 0.0114\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0151 - mae: 0.0151 - root_mean_squared_error: 0.0243 - val_loss: 0.0041 - val_mae: 0.0041 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0145 - mae: 0.0145 - root_mean_squared_error: 0.0228 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0079\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0136 - mae: 0.0136 - root_mean_squared_error: 0.0218 - val_loss: 0.0049 - val_mae: 0.0049 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0139 - mae: 0.0139 - root_mean_squared_error: 0.0222 - val_loss: 0.0035 - val_mae: 0.0035 - val_root_mean_squared_error: 0.0055\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0137 - mae: 0.0137 - root_mean_squared_error: 0.0227 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0138 - root_mean_squared_error: 0.0216 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0134 - mae: 0.0134 - root_mean_squared_error: 0.0209 - val_loss: 0.0065 - val_mae: 0.0065 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0134 - mae: 0.0134 - root_mean_squared_error: 0.0216 - val_loss: 0.0049 - val_mae: 0.0049 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0131 - root_mean_squared_error: 0.0215 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0055\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0134 - mae: 0.0134 - root_mean_squared_error: 0.0217 - val_loss: 0.0044 - val_mae: 0.0044 - val_root_mean_squared_error: 0.0066\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0130 - root_mean_squared_error: 0.0204 - val_loss: 0.0065 - val_mae: 0.0065 - val_root_mean_squared_error: 0.0099\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0127 - mae: 0.0127 - root_mean_squared_error: 0.0209 - val_loss: 0.0057 - val_mae: 0.0057 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0134 - mae: 0.0134 - root_mean_squared_error: 0.0213 - val_loss: 0.0063 - val_mae: 0.0063 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0130 - root_mean_squared_error: 0.0207 - val_loss: 0.0039 - val_mae: 0.0039 - val_root_mean_squared_error: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 22:58:28 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 22:58:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 22:58:37 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 22:58:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 22:59:28 INFO mlflow.tracking.fluent: Experiment with name 'log_return_simplernn_number_of_layer_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: number_of_layer = 1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0664 - mae: 0.0664 - root_mean_squared_error: 0.0907 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0233\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0449 - mae: 0.0449 - root_mean_squared_error: 0.0587 - val_loss: 0.0125 - val_mae: 0.0125 - val_root_mean_squared_error: 0.0173\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0505 - val_loss: 0.0210 - val_mae: 0.0210 - val_root_mean_squared_error: 0.0239\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0449 - val_loss: 0.0295 - val_mae: 0.0295 - val_root_mean_squared_error: 0.0312\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0331 - mae: 0.0331 - root_mean_squared_error: 0.0424 - val_loss: 0.0139 - val_mae: 0.0139 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.0303 - root_mean_squared_error: 0.0393 - val_loss: 0.0075 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0373 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0357 - val_loss: 0.0159 - val_mae: 0.0159 - val_root_mean_squared_error: 0.0183\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0339 - val_loss: 0.0106 - val_mae: 0.0106 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0248 - mae: 0.0248 - root_mean_squared_error: 0.0318 - val_loss: 0.0177 - val_mae: 0.0177 - val_root_mean_squared_error: 0.0193\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0227 - mae: 0.0227 - root_mean_squared_error: 0.0293 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0219 - mae: 0.0219 - root_mean_squared_error: 0.0280 - val_loss: 0.0150 - val_mae: 0.0150 - val_root_mean_squared_error: 0.0168\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0205 - mae: 0.0205 - root_mean_squared_error: 0.0265 - val_loss: 0.0046 - val_mae: 0.0046 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0206 - mae: 0.0206 - root_mean_squared_error: 0.0266 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - root_mean_squared_error: 0.0247 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0063\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173 - mae: 0.0173 - root_mean_squared_error: 0.0225 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171 - mae: 0.0171 - root_mean_squared_error: 0.0220 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0058\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0154 - mae: 0.0154 - root_mean_squared_error: 0.0202 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0152 - mae: 0.0152 - root_mean_squared_error: 0.0199 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0141 - root_mean_squared_error: 0.0187 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0135 - root_mean_squared_error: 0.0182 - val_loss: 0.0053 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0121 - root_mean_squared_error: 0.0161 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0120 - root_mean_squared_error: 0.0159 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0150 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0053\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108 - root_mean_squared_error: 0.0143 - val_loss: 0.0084 - val_mae: 0.0084 - val_root_mean_squared_error: 0.0097\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0104 - root_mean_squared_error: 0.0141 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - root_mean_squared_error: 0.0127 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0126 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0116 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - mae: 0.0080 - root_mean_squared_error: 0.0114 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0073 - mae: 0.0073 - root_mean_squared_error: 0.0101 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0108 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0024\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0094 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0067 - mae: 0.0067 - root_mean_squared_error: 0.0098 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0097 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0099 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0061 - mae: 0.0061 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0059 - mae: 0.0059 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0089 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0088 - val_loss: 0.0012 - val_mae: 0.0012 - val_root_mean_squared_error: 0.0019\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0051 - mae: 0.0051 - root_mean_squared_error: 0.0081 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0090 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0099 - val_loss: 0.0016 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0088 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0089 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0033\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0052 - mae: 0.0052 - root_mean_squared_error: 0.0085 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 23:00:10 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 23:00:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 23:00:19 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 23:00:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: number_of_layer = 2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1588 - mae: 0.1588 - root_mean_squared_error: 0.2218 - val_loss: 0.0148 - val_mae: 0.0148 - val_root_mean_squared_error: 0.0207\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0766 - mae: 0.0766 - root_mean_squared_error: 0.0991 - val_loss: 0.0286 - val_mae: 0.0286 - val_root_mean_squared_error: 0.0316\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0612 - mae: 0.0612 - root_mean_squared_error: 0.0791 - val_loss: 0.0239 - val_mae: 0.0239 - val_root_mean_squared_error: 0.0270\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0489 - mae: 0.0489 - root_mean_squared_error: 0.0621 - val_loss: 0.0195 - val_mae: 0.0195 - val_root_mean_squared_error: 0.0233\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0427 - mae: 0.0427 - root_mean_squared_error: 0.0548 - val_loss: 0.0088 - val_mae: 0.0088 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0389 - mae: 0.0389 - root_mean_squared_error: 0.0498 - val_loss: 0.0142 - val_mae: 0.0142 - val_root_mean_squared_error: 0.0169\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0347 - mae: 0.0347 - root_mean_squared_error: 0.0443 - val_loss: 0.0144 - val_mae: 0.0144 - val_root_mean_squared_error: 0.0167\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0314 - mae: 0.0314 - root_mean_squared_error: 0.0403 - val_loss: 0.0090 - val_mae: 0.0090 - val_root_mean_squared_error: 0.0119\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0294 - mae: 0.0294 - root_mean_squared_error: 0.0380 - val_loss: 0.0184 - val_mae: 0.0184 - val_root_mean_squared_error: 0.0202\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0270 - mae: 0.0270 - root_mean_squared_error: 0.0351 - val_loss: 0.0128 - val_mae: 0.0128 - val_root_mean_squared_error: 0.0140\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0247 - mae: 0.0247 - root_mean_squared_error: 0.0317 - val_loss: 0.0089 - val_mae: 0.0089 - val_root_mean_squared_error: 0.0104\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0223 - mae: 0.0223 - root_mean_squared_error: 0.0285 - val_loss: 0.0060 - val_mae: 0.0060 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0219 - mae: 0.0219 - root_mean_squared_error: 0.0281 - val_loss: 0.0066 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0199 - mae: 0.0199 - root_mean_squared_error: 0.0261 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0183 - mae: 0.0183 - root_mean_squared_error: 0.0235 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0086\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178 - mae: 0.0178 - root_mean_squared_error: 0.0233 - val_loss: 0.0066 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0159 - mae: 0.0159 - root_mean_squared_error: 0.0210 - val_loss: 0.0049 - val_mae: 0.0049 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0141 - mae: 0.0141 - root_mean_squared_error: 0.0186 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0138 - mae: 0.0138 - root_mean_squared_error: 0.0186 - val_loss: 0.0041 - val_mae: 0.0041 - val_root_mean_squared_error: 0.0055\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0124 - mae: 0.0124 - root_mean_squared_error: 0.0166 - val_loss: 0.0035 - val_mae: 0.0035 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0113 - mae: 0.0113 - root_mean_squared_error: 0.0152 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0108 - root_mean_squared_error: 0.0148 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0055\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0102 - mae: 0.0102 - root_mean_squared_error: 0.0140 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0053\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0094 - mae: 0.0094 - root_mean_squared_error: 0.0130 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0039\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0089 - mae: 0.0089 - root_mean_squared_error: 0.0124 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0053\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - mae: 0.0080 - root_mean_squared_error: 0.0112 - val_loss: 0.0044 - val_mae: 0.0044 - val_root_mean_squared_error: 0.0054\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0077 - mae: 0.0077 - root_mean_squared_error: 0.0112 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0077 - mae: 0.0077 - root_mean_squared_error: 0.0115 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0111 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0042\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0068 - mae: 0.0068 - root_mean_squared_error: 0.0106 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0103 - val_loss: 0.0066 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0068 - mae: 0.0068 - root_mean_squared_error: 0.0107 - val_loss: 0.0023 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0107 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0062 - mae: 0.0062 - root_mean_squared_error: 0.0100 - val_loss: 0.0017 - val_mae: 0.0017 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0067 - mae: 0.0067 - root_mean_squared_error: 0.0106 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0061 - root_mean_squared_error: 0.0100 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0062 - mae: 0.0062 - root_mean_squared_error: 0.0104 - val_loss: 0.0034 - val_mae: 0.0034 - val_root_mean_squared_error: 0.0052\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0061 - root_mean_squared_error: 0.0105 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0039\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0107 - val_loss: 0.0023 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0106 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0063 - mae: 0.0063 - root_mean_squared_error: 0.0100 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0097 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0066\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0061 - mae: 0.0061 - root_mean_squared_error: 0.0103 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0059 - root_mean_squared_error: 0.0106 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 23:02:07 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 23:02:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 23:02:16 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 23:02:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: number_of_layer = 3 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.3296 - mae: 0.3296 - root_mean_squared_error: 0.4325 - val_loss: 0.0711 - val_mae: 0.0711 - val_root_mean_squared_error: 0.0770\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1504 - mae: 0.1504 - root_mean_squared_error: 0.1929 - val_loss: 0.0730 - val_mae: 0.0730 - val_root_mean_squared_error: 0.0765\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0973 - mae: 0.0973 - root_mean_squared_error: 0.1249 - val_loss: 0.0261 - val_mae: 0.0261 - val_root_mean_squared_error: 0.0332\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0721 - mae: 0.0721 - root_mean_squared_error: 0.0929 - val_loss: 0.0189 - val_mae: 0.0189 - val_root_mean_squared_error: 0.0266\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0582 - mae: 0.0582 - root_mean_squared_error: 0.0747 - val_loss: 0.0154 - val_mae: 0.0154 - val_root_mean_squared_error: 0.0223\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0494 - mae: 0.0494 - root_mean_squared_error: 0.0648 - val_loss: 0.0133 - val_mae: 0.0133 - val_root_mean_squared_error: 0.0190\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0437 - mae: 0.0437 - root_mean_squared_error: 0.0557 - val_loss: 0.0304 - val_mae: 0.0304 - val_root_mean_squared_error: 0.0337\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0400 - mae: 0.0400 - root_mean_squared_error: 0.0516 - val_loss: 0.0131 - val_mae: 0.0131 - val_root_mean_squared_error: 0.0173\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0336 - mae: 0.0336 - root_mean_squared_error: 0.0437 - val_loss: 0.0087 - val_mae: 0.0087 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0318 - mae: 0.0318 - root_mean_squared_error: 0.0410 - val_loss: 0.0079 - val_mae: 0.0079 - val_root_mean_squared_error: 0.0105\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0276 - mae: 0.0276 - root_mean_squared_error: 0.0359 - val_loss: 0.0092 - val_mae: 0.0092 - val_root_mean_squared_error: 0.0123\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0260 - mae: 0.0260 - root_mean_squared_error: 0.0336 - val_loss: 0.0065 - val_mae: 0.0065 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0252 - mae: 0.0252 - root_mean_squared_error: 0.0326 - val_loss: 0.0152 - val_mae: 0.0152 - val_root_mean_squared_error: 0.0166\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0214 - mae: 0.0214 - root_mean_squared_error: 0.0280 - val_loss: 0.0055 - val_mae: 0.0055 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0202 - mae: 0.0202 - root_mean_squared_error: 0.0263 - val_loss: 0.0056 - val_mae: 0.0056 - val_root_mean_squared_error: 0.0075\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0185 - mae: 0.0185 - root_mean_squared_error: 0.0241 - val_loss: 0.0075 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0096\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0175 - mae: 0.0175 - root_mean_squared_error: 0.0231 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0055\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0160 - mae: 0.0160 - root_mean_squared_error: 0.0214 - val_loss: 0.0052 - val_mae: 0.0052 - val_root_mean_squared_error: 0.0070\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0145 - mae: 0.0145 - root_mean_squared_error: 0.0198 - val_loss: 0.0056 - val_mae: 0.0056 - val_root_mean_squared_error: 0.0077\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0130 - mae: 0.0130 - root_mean_squared_error: 0.0176 - val_loss: 0.0097 - val_mae: 0.0097 - val_root_mean_squared_error: 0.0105\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0122 - mae: 0.0122 - root_mean_squared_error: 0.0168 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0117 - mae: 0.0117 - root_mean_squared_error: 0.0161 - val_loss: 0.0049 - val_mae: 0.0049 - val_root_mean_squared_error: 0.0067\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0106 - mae: 0.0106 - root_mean_squared_error: 0.0149 - val_loss: 0.0032 - val_mae: 0.0032 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0100 - mae: 0.0100 - root_mean_squared_error: 0.0144 - val_loss: 0.0034 - val_mae: 0.0034 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0096 - mae: 0.0096 - root_mean_squared_error: 0.0140 - val_loss: 0.0054 - val_mae: 0.0054 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0084 - mae: 0.0084 - root_mean_squared_error: 0.0123 - val_loss: 0.0034 - val_mae: 0.0034 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0084 - mae: 0.0084 - root_mean_squared_error: 0.0130 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0078 - mae: 0.0078 - root_mean_squared_error: 0.0126 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0039\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0077 - mae: 0.0077 - root_mean_squared_error: 0.0122 - val_loss: 0.0041 - val_mae: 0.0041 - val_root_mean_squared_error: 0.0062\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0073 - mae: 0.0073 - root_mean_squared_error: 0.0121 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0078 - mae: 0.0078 - root_mean_squared_error: 0.0126 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0058\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0080 - mae: 0.0080 - root_mean_squared_error: 0.0126 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0073 - mae: 0.0073 - root_mean_squared_error: 0.0122 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0053\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0073 - mae: 0.0073 - root_mean_squared_error: 0.0128 - val_loss: 0.0035 - val_mae: 0.0035 - val_root_mean_squared_error: 0.0052\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0078 - mae: 0.0078 - root_mean_squared_error: 0.0131 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0072 - mae: 0.0072 - root_mean_squared_error: 0.0123 - val_loss: 0.0044 - val_mae: 0.0044 - val_root_mean_squared_error: 0.0070\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0075 - mae: 0.0075 - root_mean_squared_error: 0.0127 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0073 - mae: 0.0073 - root_mean_squared_error: 0.0123 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0071 - mae: 0.0071 - root_mean_squared_error: 0.0124 - val_loss: 0.0036 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0055\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0068 - mae: 0.0068 - root_mean_squared_error: 0.0114 - val_loss: 0.0023 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 23:04:13 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 23:04:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 23:04:23 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 23:04:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: number_of_layer = 4 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.3848 - mae: 0.3848 - root_mean_squared_error: 0.4932 - val_loss: 0.1363 - val_mae: 0.1363 - val_root_mean_squared_error: 0.1418\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.2163 - mae: 0.2163 - root_mean_squared_error: 0.2753 - val_loss: 0.0733 - val_mae: 0.0733 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.1353 - mae: 0.1353 - root_mean_squared_error: 0.1733 - val_loss: 0.1160 - val_mae: 0.1160 - val_root_mean_squared_error: 0.1193\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0911 - mae: 0.0911 - root_mean_squared_error: 0.1168 - val_loss: 0.0440 - val_mae: 0.0440 - val_root_mean_squared_error: 0.0493\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0690 - mae: 0.0690 - root_mean_squared_error: 0.0887 - val_loss: 0.0477 - val_mae: 0.0477 - val_root_mean_squared_error: 0.0529\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0563 - mae: 0.0563 - root_mean_squared_error: 0.0735 - val_loss: 0.0218 - val_mae: 0.0218 - val_root_mean_squared_error: 0.0289\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0483 - mae: 0.0483 - root_mean_squared_error: 0.0628 - val_loss: 0.0294 - val_mae: 0.0294 - val_root_mean_squared_error: 0.0352\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0425 - mae: 0.0425 - root_mean_squared_error: 0.0560 - val_loss: 0.0173 - val_mae: 0.0173 - val_root_mean_squared_error: 0.0225\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0378 - mae: 0.0378 - root_mean_squared_error: 0.0497 - val_loss: 0.0182 - val_mae: 0.0182 - val_root_mean_squared_error: 0.0216\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0340 - mae: 0.0340 - root_mean_squared_error: 0.0451 - val_loss: 0.0107 - val_mae: 0.0107 - val_root_mean_squared_error: 0.0158\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0317 - mae: 0.0317 - root_mean_squared_error: 0.0428 - val_loss: 0.0100 - val_mae: 0.0100 - val_root_mean_squared_error: 0.0142\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0318 - mae: 0.0318 - root_mean_squared_error: 0.0426 - val_loss: 0.0104 - val_mae: 0.0104 - val_root_mean_squared_error: 0.0152\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0284 - mae: 0.0284 - root_mean_squared_error: 0.0382 - val_loss: 0.0136 - val_mae: 0.0136 - val_root_mean_squared_error: 0.0162\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0358 - val_loss: 0.0074 - val_mae: 0.0074 - val_root_mean_squared_error: 0.0116\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0251 - mae: 0.0251 - root_mean_squared_error: 0.0345 - val_loss: 0.0144 - val_mae: 0.0144 - val_root_mean_squared_error: 0.0184\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0236 - mae: 0.0236 - root_mean_squared_error: 0.0330 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0218 - mae: 0.0218 - root_mean_squared_error: 0.0300 - val_loss: 0.0175 - val_mae: 0.0175 - val_root_mean_squared_error: 0.0204\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0219 - mae: 0.0219 - root_mean_squared_error: 0.0309 - val_loss: 0.0152 - val_mae: 0.0152 - val_root_mean_squared_error: 0.0171\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0194 - mae: 0.0194 - root_mean_squared_error: 0.0281 - val_loss: 0.0063 - val_mae: 0.0063 - val_root_mean_squared_error: 0.0092\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0184 - mae: 0.0184 - root_mean_squared_error: 0.0269 - val_loss: 0.0057 - val_mae: 0.0057 - val_root_mean_squared_error: 0.0100\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0169 - mae: 0.0169 - root_mean_squared_error: 0.0248 - val_loss: 0.0078 - val_mae: 0.0078 - val_root_mean_squared_error: 0.0105\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0167 - mae: 0.0167 - root_mean_squared_error: 0.0240 - val_loss: 0.0139 - val_mae: 0.0139 - val_root_mean_squared_error: 0.0166\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0152 - mae: 0.0152 - root_mean_squared_error: 0.0232 - val_loss: 0.0100 - val_mae: 0.0100 - val_root_mean_squared_error: 0.0125\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0152 - mae: 0.0152 - root_mean_squared_error: 0.0227 - val_loss: 0.0080 - val_mae: 0.0080 - val_root_mean_squared_error: 0.0105\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0146 - mae: 0.0146 - root_mean_squared_error: 0.0228 - val_loss: 0.0098 - val_mae: 0.0098 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0134 - mae: 0.0134 - root_mean_squared_error: 0.0213 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0072\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0130 - mae: 0.0130 - root_mean_squared_error: 0.0204 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0130 - mae: 0.0130 - root_mean_squared_error: 0.0211 - val_loss: 0.0058 - val_mae: 0.0058 - val_root_mean_squared_error: 0.0091\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0122 - mae: 0.0122 - root_mean_squared_error: 0.0197 - val_loss: 0.0064 - val_mae: 0.0064 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0111 - mae: 0.0111 - root_mean_squared_error: 0.0184 - val_loss: 0.0062 - val_mae: 0.0062 - val_root_mean_squared_error: 0.0097\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0115 - mae: 0.0115 - root_mean_squared_error: 0.0191 - val_loss: 0.0050 - val_mae: 0.0050 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0107 - mae: 0.0107 - root_mean_squared_error: 0.0186 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0103 - mae: 0.0103 - root_mean_squared_error: 0.0179 - val_loss: 0.0046 - val_mae: 0.0046 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0101 - mae: 0.0101 - root_mean_squared_error: 0.0176 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0096 - mae: 0.0096 - root_mean_squared_error: 0.0169 - val_loss: 0.0034 - val_mae: 0.0034 - val_root_mean_squared_error: 0.0066\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0097 - mae: 0.0097 - root_mean_squared_error: 0.0172 - val_loss: 0.0038 - val_mae: 0.0038 - val_root_mean_squared_error: 0.0067\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0096 - mae: 0.0096 - root_mean_squared_error: 0.0170 - val_loss: 0.0034 - val_mae: 0.0034 - val_root_mean_squared_error: 0.0062\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0087 - mae: 0.0087 - root_mean_squared_error: 0.0161 - val_loss: 0.0025 - val_mae: 0.0025 - val_root_mean_squared_error: 0.0053\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0096 - mae: 0.0096 - root_mean_squared_error: 0.0164 - val_loss: 0.0034 - val_mae: 0.0034 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0088 - mae: 0.0088 - root_mean_squared_error: 0.0155 - val_loss: 0.0038 - val_mae: 0.0038 - val_root_mean_squared_error: 0.0069\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0087 - mae: 0.0087 - root_mean_squared_error: 0.0156 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0059\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0089 - mae: 0.0089 - root_mean_squared_error: 0.0156 - val_loss: 0.0035 - val_mae: 0.0035 - val_root_mean_squared_error: 0.0055\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0149 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0053\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0086 - mae: 0.0086 - root_mean_squared_error: 0.0150 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0075 - mae: 0.0075 - root_mean_squared_error: 0.0141 - val_loss: 0.0026 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0084 - mae: 0.0084 - root_mean_squared_error: 0.0149 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0055\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0145 - val_loss: 0.0046 - val_mae: 0.0046 - val_root_mean_squared_error: 0.0067\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0076 - mae: 0.0076 - root_mean_squared_error: 0.0141 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0145 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0069\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0080 - mae: 0.0080 - root_mean_squared_error: 0.0144 - val_loss: 0.0038 - val_mae: 0.0038 - val_root_mean_squared_error: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 23:06:52 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 23:07:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 23:07:02 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 23:07:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n",
      "2026/01/15 23:07:55 INFO mlflow.tracking.fluent: Experiment with name 'log_return_simplernn_loss_function_2026_01_15' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: loss_function = mae ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0664 - mae: 0.0664 - root_mean_squared_error: 0.0907 - val_loss: 0.0172 - val_mae: 0.0172 - val_root_mean_squared_error: 0.0233\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0449 - mae: 0.0449 - root_mean_squared_error: 0.0587 - val_loss: 0.0125 - val_mae: 0.0125 - val_root_mean_squared_error: 0.0173\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0388 - mae: 0.0388 - root_mean_squared_error: 0.0505 - val_loss: 0.0210 - val_mae: 0.0210 - val_root_mean_squared_error: 0.0239\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0352 - mae: 0.0352 - root_mean_squared_error: 0.0449 - val_loss: 0.0295 - val_mae: 0.0295 - val_root_mean_squared_error: 0.0312\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0331 - mae: 0.0331 - root_mean_squared_error: 0.0424 - val_loss: 0.0139 - val_mae: 0.0139 - val_root_mean_squared_error: 0.0159\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.0303 - root_mean_squared_error: 0.0393 - val_loss: 0.0075 - val_mae: 0.0075 - val_root_mean_squared_error: 0.0101\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0288 - mae: 0.0288 - root_mean_squared_error: 0.0373 - val_loss: 0.0067 - val_mae: 0.0067 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0278 - mae: 0.0278 - root_mean_squared_error: 0.0357 - val_loss: 0.0159 - val_mae: 0.0159 - val_root_mean_squared_error: 0.0183\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0264 - mae: 0.0264 - root_mean_squared_error: 0.0339 - val_loss: 0.0106 - val_mae: 0.0106 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - mae: 0.0248 - root_mean_squared_error: 0.0318 - val_loss: 0.0177 - val_mae: 0.0177 - val_root_mean_squared_error: 0.0193\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0227 - mae: 0.0227 - root_mean_squared_error: 0.0293 - val_loss: 0.0061 - val_mae: 0.0061 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0219 - mae: 0.0219 - root_mean_squared_error: 0.0280 - val_loss: 0.0150 - val_mae: 0.0150 - val_root_mean_squared_error: 0.0168\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0205 - mae: 0.0205 - root_mean_squared_error: 0.0265 - val_loss: 0.0046 - val_mae: 0.0046 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0206 - mae: 0.0206 - root_mean_squared_error: 0.0266 - val_loss: 0.0045 - val_mae: 0.0045 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0191 - root_mean_squared_error: 0.0247 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0063\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173 - mae: 0.0173 - root_mean_squared_error: 0.0225 - val_loss: 0.0071 - val_mae: 0.0071 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171 - mae: 0.0171 - root_mean_squared_error: 0.0220 - val_loss: 0.0043 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0058\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0154 - mae: 0.0154 - root_mean_squared_error: 0.0202 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0073\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0152 - mae: 0.0152 - root_mean_squared_error: 0.0199 - val_loss: 0.0048 - val_mae: 0.0048 - val_root_mean_squared_error: 0.0061\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0141 - root_mean_squared_error: 0.0187 - val_loss: 0.0047 - val_mae: 0.0047 - val_root_mean_squared_error: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0135 - mae: 0.0135 - root_mean_squared_error: 0.0182 - val_loss: 0.0053 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0121 - root_mean_squared_error: 0.0161 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0120 - root_mean_squared_error: 0.0159 - val_loss: 0.0033 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0112 - root_mean_squared_error: 0.0150 - val_loss: 0.0042 - val_mae: 0.0042 - val_root_mean_squared_error: 0.0053\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0108 - mae: 0.0108 - root_mean_squared_error: 0.0143 - val_loss: 0.0084 - val_mae: 0.0084 - val_root_mean_squared_error: 0.0097\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0104 - mae: 0.0104 - root_mean_squared_error: 0.0141 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0093 - root_mean_squared_error: 0.0127 - val_loss: 0.0028 - val_mae: 0.0028 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0092 - root_mean_squared_error: 0.0126 - val_loss: 0.0029 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0083 - mae: 0.0083 - root_mean_squared_error: 0.0116 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - mae: 0.0082 - root_mean_squared_error: 0.0116 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - mae: 0.0080 - root_mean_squared_error: 0.0114 - val_loss: 0.0040 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0073 - mae: 0.0073 - root_mean_squared_error: 0.0101 - val_loss: 0.0059 - val_mae: 0.0059 - val_root_mean_squared_error: 0.0065\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0074 - mae: 0.0074 - root_mean_squared_error: 0.0108 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0024\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0065 - mae: 0.0065 - root_mean_squared_error: 0.0094 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0067 - mae: 0.0067 - root_mean_squared_error: 0.0098 - val_loss: 0.0027 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0097 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0066 - mae: 0.0066 - root_mean_squared_error: 0.0099 - val_loss: 0.0037 - val_mae: 0.0037 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0061 - mae: 0.0061 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0059 - mae: 0.0059 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0057 - mae: 0.0057 - root_mean_squared_error: 0.0089 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0092 - val_loss: 0.0018 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0056 - mae: 0.0056 - root_mean_squared_error: 0.0088 - val_loss: 0.0012 - val_mae: 0.0012 - val_root_mean_squared_error: 0.0019\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0051 - mae: 0.0051 - root_mean_squared_error: 0.0081 - val_loss: 0.0019 - val_mae: 0.0019 - val_root_mean_squared_error: 0.0027\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0090 - val_loss: 0.0022 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0020 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0060 - mae: 0.0060 - root_mean_squared_error: 0.0099 - val_loss: 0.0016 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0054 - mae: 0.0054 - root_mean_squared_error: 0.0088 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0030\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0089 - val_loss: 0.0024 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0033\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0053 - mae: 0.0053 - root_mean_squared_error: 0.0091 - val_loss: 0.0030 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0038\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0052 - mae: 0.0052 - root_mean_squared_error: 0.0085 - val_loss: 0.0021 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 23:08:42 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 23:08:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 23:08:51 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 23:08:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: loss_function = mse ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0078 - mae: 0.0646 - root_mean_squared_error: 0.0882 - val_loss: 7.4913e-04 - val_mae: 0.0212 - val_root_mean_squared_error: 0.0274\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0035 - mae: 0.0452 - root_mean_squared_error: 0.0592 - val_loss: 2.9454e-04 - val_mae: 0.0125 - val_root_mean_squared_error: 0.0172\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0391 - root_mean_squared_error: 0.0510 - val_loss: 3.1131e-04 - val_mae: 0.0147 - val_root_mean_squared_error: 0.0176\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0022 - mae: 0.0365 - root_mean_squared_error: 0.0465 - val_loss: 2.1281e-04 - val_mae: 0.0118 - val_root_mean_squared_error: 0.0146\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0019 - mae: 0.0341 - root_mean_squared_error: 0.0437 - val_loss: 4.2765e-04 - val_mae: 0.0194 - val_root_mean_squared_error: 0.0207\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0017 - mae: 0.0321 - root_mean_squared_error: 0.0417 - val_loss: 2.9086e-04 - val_mae: 0.0153 - val_root_mean_squared_error: 0.0171\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0298 - root_mean_squared_error: 0.0383 - val_loss: 5.0067e-05 - val_mae: 0.0051 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0014 - mae: 0.0289 - root_mean_squared_error: 0.0370 - val_loss: 1.2460e-04 - val_mae: 0.0091 - val_root_mean_squared_error: 0.0112\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0012 - mae: 0.0272 - root_mean_squared_error: 0.0346 - val_loss: 1.3142e-04 - val_mae: 0.0095 - val_root_mean_squared_error: 0.0115\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0012 - mae: 0.0271 - root_mean_squared_error: 0.0347 - val_loss: 7.8978e-05 - val_mae: 0.0069 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9.6525e-04 - mae: 0.0244 - root_mean_squared_error: 0.0311 - val_loss: 7.7106e-05 - val_mae: 0.0074 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.8322e-04 - mae: 0.0232 - root_mean_squared_error: 0.0297 - val_loss: 1.9608e-04 - val_mae: 0.0126 - val_root_mean_squared_error: 0.0140\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.3235e-04 - mae: 0.0225 - root_mean_squared_error: 0.0289 - val_loss: 4.6236e-05 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.1816e-04 - mae: 0.0223 - root_mean_squared_error: 0.0286 - val_loss: 3.4420e-05 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0059\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.3662e-04 - mae: 0.0213 - root_mean_squared_error: 0.0271 - val_loss: 3.1343e-05 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0056\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.3855e-04 - mae: 0.0196 - root_mean_squared_error: 0.0253 - val_loss: 6.4078e-05 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6.2810e-04 - mae: 0.0195 - root_mean_squared_error: 0.0251 - val_loss: 3.8628e-05 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0062\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.4505e-04 - mae: 0.0180 - root_mean_squared_error: 0.0233 - val_loss: 2.6273e-05 - val_mae: 0.0039 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.5587e-04 - mae: 0.0182 - root_mean_squared_error: 0.0236 - val_loss: 1.6664e-05 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.2225e-04 - mae: 0.0175 - root_mean_squared_error: 0.0229 - val_loss: 4.1119e-05 - val_mae: 0.0055 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4.2635e-04 - mae: 0.0158 - root_mean_squared_error: 0.0206 - val_loss: 5.7875e-05 - val_mae: 0.0068 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.2075e-04 - mae: 0.0159 - root_mean_squared_error: 0.0205 - val_loss: 1.8251e-05 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.5216e-04 - mae: 0.0143 - root_mean_squared_error: 0.0188 - val_loss: 1.1911e-05 - val_mae: 0.0025 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.5199e-04 - mae: 0.0144 - root_mean_squared_error: 0.0188 - val_loss: 9.6821e-06 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.3608e-04 - mae: 0.0141 - root_mean_squared_error: 0.0183 - val_loss: 2.4594e-05 - val_mae: 0.0035 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.0100e-04 - mae: 0.0133 - root_mean_squared_error: 0.0173 - val_loss: 1.2765e-05 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.7002e-04 - mae: 0.0125 - root_mean_squared_error: 0.0164 - val_loss: 9.9635e-06 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0032\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.5906e-04 - mae: 0.0122 - root_mean_squared_error: 0.0161 - val_loss: 8.3866e-06 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.5464e-04 - mae: 0.0119 - root_mean_squared_error: 0.0160 - val_loss: 1.9098e-05 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.3165e-04 - mae: 0.0113 - root_mean_squared_error: 0.0152 - val_loss: 1.6072e-05 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.0575e-04 - mae: 0.0107 - root_mean_squared_error: 0.0143 - val_loss: 1.2903e-05 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.8864e-04 - mae: 0.0103 - root_mean_squared_error: 0.0137 - val_loss: 9.4994e-06 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.9271e-04 - mae: 0.0102 - root_mean_squared_error: 0.0139 - val_loss: 1.0534e-05 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0032\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.4656e-04 - mae: 0.0090 - root_mean_squared_error: 0.0121 - val_loss: 1.3217e-05 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.4754e-04 - mae: 0.0091 - root_mean_squared_error: 0.0121 - val_loss: 7.6389e-06 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.7163e-04 - mae: 0.0097 - root_mean_squared_error: 0.0131 - val_loss: 1.1284e-05 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.4918e-04 - mae: 0.0089 - root_mean_squared_error: 0.0122 - val_loss: 9.9256e-06 - val_mae: 0.0025 - val_root_mean_squared_error: 0.0032\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.6311e-04 - mae: 0.0094 - root_mean_squared_error: 0.0128 - val_loss: 1.5098e-05 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0039\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2967e-04 - mae: 0.0081 - root_mean_squared_error: 0.0114 - val_loss: 1.2890e-05 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1595e-04 - mae: 0.0080 - root_mean_squared_error: 0.0108 - val_loss: 5.2316e-06 - val_mae: 0.0017 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1684e-04 - mae: 0.0076 - root_mean_squared_error: 0.0108 - val_loss: 4.7412e-06 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0022\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0674e-04 - mae: 0.0074 - root_mean_squared_error: 0.0103 - val_loss: 5.8361e-06 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0024\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.3444e-05 - mae: 0.0069 - root_mean_squared_error: 0.0097 - val_loss: 7.8869e-06 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1668e-04 - mae: 0.0076 - root_mean_squared_error: 0.0108 - val_loss: 1.8480e-05 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.0236e-04 - mae: 0.0071 - root_mean_squared_error: 0.0101 - val_loss: 6.0045e-06 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2653e-04 - mae: 0.0078 - root_mean_squared_error: 0.0112 - val_loss: 6.9399e-06 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.0839e-04 - mae: 0.0072 - root_mean_squared_error: 0.0104 - val_loss: 5.9164e-06 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0024\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.0299e-05 - mae: 0.0066 - root_mean_squared_error: 0.0095 - val_loss: 3.6430e-06 - val_mae: 0.0014 - val_root_mean_squared_error: 0.0019\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.4471e-05 - mae: 0.0068 - root_mean_squared_error: 0.0097 - val_loss: 3.5890e-06 - val_mae: 0.0014 - val_root_mean_squared_error: 0.0019\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.8498e-05 - mae: 0.0058 - root_mean_squared_error: 0.0083 - val_loss: 8.4054e-06 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 23:10:21 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 23:10:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 23:10:31 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 23:10:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: simplernn | Param: loss_function = huber ---\n",
      "Epoch 1/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0646 - root_mean_squared_error: 0.0882 - val_loss: 3.7459e-04 - val_mae: 0.0212 - val_root_mean_squared_error: 0.0274\n",
      "Epoch 2/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0018 - mae: 0.0452 - root_mean_squared_error: 0.0592 - val_loss: 1.4728e-04 - val_mae: 0.0125 - val_root_mean_squared_error: 0.0172\n",
      "Epoch 3/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0391 - root_mean_squared_error: 0.0510 - val_loss: 1.5567e-04 - val_mae: 0.0147 - val_root_mean_squared_error: 0.0176\n",
      "Epoch 4/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0365 - root_mean_squared_error: 0.0465 - val_loss: 1.0639e-04 - val_mae: 0.0118 - val_root_mean_squared_error: 0.0146\n",
      "Epoch 5/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 9.5660e-04 - mae: 0.0341 - root_mean_squared_error: 0.0437 - val_loss: 2.1385e-04 - val_mae: 0.0194 - val_root_mean_squared_error: 0.0207\n",
      "Epoch 6/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.6755e-04 - mae: 0.0321 - root_mean_squared_error: 0.0417 - val_loss: 1.4543e-04 - val_mae: 0.0153 - val_root_mean_squared_error: 0.0171\n",
      "Epoch 7/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7.3409e-04 - mae: 0.0298 - root_mean_squared_error: 0.0383 - val_loss: 2.5034e-05 - val_mae: 0.0051 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 8/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.8602e-04 - mae: 0.0289 - root_mean_squared_error: 0.0370 - val_loss: 6.2303e-05 - val_mae: 0.0091 - val_root_mean_squared_error: 0.0112\n",
      "Epoch 9/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.9918e-04 - mae: 0.0272 - root_mean_squared_error: 0.0346 - val_loss: 6.5705e-05 - val_mae: 0.0095 - val_root_mean_squared_error: 0.0115\n",
      "Epoch 10/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.0135e-04 - mae: 0.0271 - root_mean_squared_error: 0.0347 - val_loss: 3.9486e-05 - val_mae: 0.0069 - val_root_mean_squared_error: 0.0089\n",
      "Epoch 11/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.8263e-04 - mae: 0.0244 - root_mean_squared_error: 0.0311 - val_loss: 3.8553e-05 - val_mae: 0.0074 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 12/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.4161e-04 - mae: 0.0232 - root_mean_squared_error: 0.0297 - val_loss: 9.8043e-05 - val_mae: 0.0126 - val_root_mean_squared_error: 0.0140\n",
      "Epoch 13/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.1618e-04 - mae: 0.0225 - root_mean_squared_error: 0.0289 - val_loss: 2.3119e-05 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 14/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.0908e-04 - mae: 0.0223 - root_mean_squared_error: 0.0286 - val_loss: 1.7209e-05 - val_mae: 0.0043 - val_root_mean_squared_error: 0.0059\n",
      "Epoch 15/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.6831e-04 - mae: 0.0213 - root_mean_squared_error: 0.0271 - val_loss: 1.5671e-05 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0056\n",
      "Epoch 16/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.1928e-04 - mae: 0.0196 - root_mean_squared_error: 0.0253 - val_loss: 3.2033e-05 - val_mae: 0.0066 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 17/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.1405e-04 - mae: 0.0195 - root_mean_squared_error: 0.0251 - val_loss: 1.9311e-05 - val_mae: 0.0053 - val_root_mean_squared_error: 0.0062\n",
      "Epoch 18/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.7252e-04 - mae: 0.0180 - root_mean_squared_error: 0.0233 - val_loss: 1.3136e-05 - val_mae: 0.0039 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 19/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.7794e-04 - mae: 0.0182 - root_mean_squared_error: 0.0236 - val_loss: 8.3317e-06 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0041\n",
      "Epoch 20/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.6112e-04 - mae: 0.0175 - root_mean_squared_error: 0.0229 - val_loss: 2.0556e-05 - val_mae: 0.0055 - val_root_mean_squared_error: 0.0064\n",
      "Epoch 21/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.1318e-04 - mae: 0.0158 - root_mean_squared_error: 0.0206 - val_loss: 2.8938e-05 - val_mae: 0.0068 - val_root_mean_squared_error: 0.0076\n",
      "Epoch 22/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.1038e-04 - mae: 0.0159 - root_mean_squared_error: 0.0205 - val_loss: 9.1245e-06 - val_mae: 0.0031 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 23/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.7608e-04 - mae: 0.0143 - root_mean_squared_error: 0.0188 - val_loss: 5.9556e-06 - val_mae: 0.0025 - val_root_mean_squared_error: 0.0035\n",
      "Epoch 24/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.7600e-04 - mae: 0.0144 - root_mean_squared_error: 0.0188 - val_loss: 4.8412e-06 - val_mae: 0.0022 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 25/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.6804e-04 - mae: 0.0141 - root_mean_squared_error: 0.0183 - val_loss: 1.2296e-05 - val_mae: 0.0035 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 26/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.5050e-04 - mae: 0.0133 - root_mean_squared_error: 0.0173 - val_loss: 6.3822e-06 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 27/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.3501e-04 - mae: 0.0125 - root_mean_squared_error: 0.0164 - val_loss: 4.9812e-06 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0032\n",
      "Epoch 28/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.2953e-04 - mae: 0.0122 - root_mean_squared_error: 0.0161 - val_loss: 4.1931e-06 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0029\n",
      "Epoch 29/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.2732e-04 - mae: 0.0119 - root_mean_squared_error: 0.0160 - val_loss: 9.5484e-06 - val_mae: 0.0036 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 30/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1583e-04 - mae: 0.0113 - root_mean_squared_error: 0.0152 - val_loss: 8.0362e-06 - val_mae: 0.0033 - val_root_mean_squared_error: 0.0040\n",
      "Epoch 31/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.0288e-04 - mae: 0.0107 - root_mean_squared_error: 0.0143 - val_loss: 6.4511e-06 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 32/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.4320e-05 - mae: 0.0103 - root_mean_squared_error: 0.0137 - val_loss: 4.7497e-06 - val_mae: 0.0024 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 33/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.6350e-05 - mae: 0.0102 - root_mean_squared_error: 0.0139 - val_loss: 5.2666e-06 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0032\n",
      "Epoch 34/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.3278e-05 - mae: 0.0090 - root_mean_squared_error: 0.0121 - val_loss: 6.6078e-06 - val_mae: 0.0030 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 35/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.3770e-05 - mae: 0.0091 - root_mean_squared_error: 0.0121 - val_loss: 3.8178e-06 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 36/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.5812e-05 - mae: 0.0097 - root_mean_squared_error: 0.0131 - val_loss: 5.6467e-06 - val_mae: 0.0027 - val_root_mean_squared_error: 0.0034\n",
      "Epoch 37/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.4591e-05 - mae: 0.0089 - root_mean_squared_error: 0.0122 - val_loss: 4.9600e-06 - val_mae: 0.0025 - val_root_mean_squared_error: 0.0031\n",
      "Epoch 38/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.1554e-05 - mae: 0.0094 - root_mean_squared_error: 0.0128 - val_loss: 7.5495e-06 - val_mae: 0.0029 - val_root_mean_squared_error: 0.0039\n",
      "Epoch 39/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.4838e-05 - mae: 0.0081 - root_mean_squared_error: 0.0114 - val_loss: 6.4438e-06 - val_mae: 0.0026 - val_root_mean_squared_error: 0.0036\n",
      "Epoch 40/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.7973e-05 - mae: 0.0080 - root_mean_squared_error: 0.0108 - val_loss: 2.6144e-06 - val_mae: 0.0017 - val_root_mean_squared_error: 0.0023\n",
      "Epoch 41/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.8424e-05 - mae: 0.0076 - root_mean_squared_error: 0.0108 - val_loss: 2.3699e-06 - val_mae: 0.0016 - val_root_mean_squared_error: 0.0022\n",
      "Epoch 42/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.3370e-05 - mae: 0.0074 - root_mean_squared_error: 0.0103 - val_loss: 2.9181e-06 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0024\n",
      "Epoch 43/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.6721e-05 - mae: 0.0069 - root_mean_squared_error: 0.0097 - val_loss: 3.9439e-06 - val_mae: 0.0023 - val_root_mean_squared_error: 0.0028\n",
      "Epoch 44/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.8335e-05 - mae: 0.0076 - root_mean_squared_error: 0.0108 - val_loss: 9.2414e-06 - val_mae: 0.0040 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 45/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.1177e-05 - mae: 0.0071 - root_mean_squared_error: 0.0101 - val_loss: 3.0013e-06 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0025\n",
      "Epoch 46/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.3254e-05 - mae: 0.0078 - root_mean_squared_error: 0.0112 - val_loss: 3.4701e-06 - val_mae: 0.0020 - val_root_mean_squared_error: 0.0026\n",
      "Epoch 47/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.4193e-05 - mae: 0.0072 - root_mean_squared_error: 0.0104 - val_loss: 2.9578e-06 - val_mae: 0.0018 - val_root_mean_squared_error: 0.0024\n",
      "Epoch 48/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.5145e-05 - mae: 0.0066 - root_mean_squared_error: 0.0095 - val_loss: 1.8217e-06 - val_mae: 0.0014 - val_root_mean_squared_error: 0.0019\n",
      "Epoch 49/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.7231e-05 - mae: 0.0068 - root_mean_squared_error: 0.0097 - val_loss: 1.7946e-06 - val_mae: 0.0014 - val_root_mean_squared_error: 0.0019\n",
      "Epoch 50/50\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.4249e-05 - mae: 0.0058 - root_mean_squared_error: 0.0083 - val_loss: 4.2014e-06 - val_mae: 0.0021 - val_root_mean_squared_error: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 23:12:02 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2026/01/15 23:12:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2026/01/15 23:12:11 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2026/01/15 23:12:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "f:\\Programming\\Projects\\crypto_price_predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow training cycle complete.\n"
     ]
    }
   ],
   "source": [
    "# Log-Return Grid Search Experimentation Script.\n",
    "# --- Configuration & Search Space ---\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
    "model_list = [\"lstm\", \"gru\", \"simplernn\"]\n",
    "\n",
    "search_space = {\n",
    "    \"input_width\": [12, 24, 48, 72, 96],\n",
    "    \"batch_size\": [16, 32, 64, 128],\n",
    "    \"learning_rate\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"model_units\": [10, 50, 100, 200],\n",
    "    \"dropout_rate\": [0, 0.2, 0.5, 0.8],\n",
    "    \"number_of_layer\": [1, 2, 3, 4],\n",
    "    \"loss_function\": ['mae', 'mse', 'huber'],\n",
    "}\n",
    "\n",
    "base_config = {\n",
    "    \"input_width\": 24,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 50,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"model_units\": 50,\n",
    "    \"dense_units\": 1,\n",
    "    \"dropout_rate\": 0.2,\n",
    "    \"number_of_layer\": 1,\n",
    "    \"loss_function\": 'mae',\n",
    "    \"train_ratio\": 0.7,\n",
    "    \"val_ratio\": 0.25,\n",
    "    'optimizer_name': 'adam',\n",
    "}\n",
    "\n",
    "# --- Experiment Loop ---\n",
    "\n",
    "for model_type in model_list:\n",
    "    for param_name, values in search_space.items():\n",
    "        # Set experiment scope per model/parameter combination\n",
    "        experiment_name = f\"log_return_{model_type}_{param_name}_{date}\"\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "\n",
    "        for value in values:\n",
    "            print(f\"--- Model: {model_type} | Param: {param_name} = {value} ---\")\n",
    "            \n",
    "            # Memoriy cleanup and seed reset for reproducibility\n",
    "            tf.keras.backend.clear_session()\n",
    "            set_seed(42)\n",
    "            \n",
    "            # Generate configuration for this specific run         \n",
    "            run_config = base_config.copy() \n",
    "            run_config[param_name] = value\n",
    "            run_name = f\"{param_name}_{value}\"\n",
    "\n",
    "            with mlflow.start_run(run_name=run_name):\n",
    "                # 1. Logging Metadata\n",
    "                mlflow.log_params(run_config)\n",
    "                mlflow.log_param(\"model_name\", model_type)\n",
    "                mlflow.log_param(\"studied_parameter\", param_name)\n",
    "\n",
    "                # 2. Data Preparation\n",
    "                df_raw = pd.read_csv('../data/dataset/BTCUSDT_1h.csv')\n",
    "                df_raw['timestamp'] = pd.to_datetime(df_raw['timestamp'], unit='ms')\n",
    "                df_raw.set_index('timestamp', inplace=True)\n",
    "                df_2025= df_raw[df_raw.index.year == 2025][['close']].sort_index()\n",
    "                \n",
    "                # Filter and transform to Log Returns (Stationarity)\n",
    "                df_2025['close'] = np.log(df['close']).diff()\n",
    "                df_2025 = df_2025.dropna()\n",
    "\n",
    "                df_train, df_val, df_test, train_gen, val_gen, test_gen, scaler = (\n",
    "                    split_and_generate_dataset(\n",
    "                        df_2025,\n",
    "                        input_width=run_config['input_width'],\n",
    "                        batch_size=run_config['batch_size'],\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # 3. Model Architecture Construction\n",
    "                input_shape = (run_config['input_width'], 1)\n",
    "                layer_config = []\n",
    "                \n",
    "                for i in range(run_config['number_of_layer']):\n",
    "                    layer_config.append({\n",
    "                        'type' : model_type,\n",
    "                        'units': run_config['model_units'],\n",
    "                        'return_sequences': True if i < run_config['number_of_layer'] - 1 else False\n",
    "                    })\n",
    "                    layer_config.append({\n",
    "                        'type' : 'dropout',\n",
    "                        'rate': run_config['dropout_rate']\n",
    "                    })\n",
    "                \n",
    "                layer_config.append({\n",
    "                    'type' : 'dense',\n",
    "                    'units': run_config['dense_units']\n",
    "                    })\n",
    "                    \n",
    "                mg = ModelGenerator(input_shape=input_shape)\n",
    "                model = mg.build_model(\n",
    "                    layers_config=layer_config,\n",
    "                    optimizer_name=run_config['optimizer_name'],\n",
    "                    optimizer_config={'learning_rate': run_config['learning_rate']},\n",
    "                    loss=run_config['loss_function'],\n",
    "                    metrics=['mae', RootMeanSquaredError()]\n",
    "                )\n",
    "                \n",
    "                # 4. Training with Early Stopping\n",
    "                early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "                history = mg.train(train_gen, val_gen, epochs=run_config['epochs'], callbacks=[early_stop])\n",
    "\n",
    "                # 5. Log Training Metrics\n",
    "                mlflow.log_metrics({\n",
    "                    \"final_train_loss\": history.history['loss'][-1],\n",
    "                    \"final_val_loss\": history.history['val_loss'][-1],\n",
    "                    \"final_val_mae\": history.history['val_mae'][-1],\n",
    "                    \"final_val_rmse\": history.history['val_root_mean_squared_error'][-1],\n",
    "                })\n",
    "\n",
    "                mlflow.keras.log_model(mg.model, name=\"model\")\n",
    "                mlflow.sklearn.log_model(scaler, name=\"scaler\")\n",
    "\n",
    "                # 6. Walk-Forward Prediction & Plotting\n",
    "                predictions_wf, y_true_wf, df_init, future_index = run_walkforward_prediction(\n",
    "                    df_test=df_test,\n",
    "                    model=mg.model,\n",
    "                    scaler=scaler,\n",
    "                    input_width=run_config['input_width']\n",
    "                )\n",
    "\n",
    "                if predictions_wf is not None:\n",
    "                    # Data consolidation for visualization\n",
    "                    plot_df = pd.DataFrame({\n",
    "                        'Date': future_index,\n",
    "                        'Real values': y_true_wf,\n",
    "                        'Predictions': predictions_wf\n",
    "                    }).melt(id_vars='Date', var_name='Type', value_name='Valeur')\n",
    "\n",
    "                    initial_df = pd.DataFrame({\n",
    "                        'Date': df_init.index,\n",
    "                        'Valeur': df_init['close'].values, \n",
    "                        'Type': 'Initial sequence'\n",
    "                    })\n",
    "\n",
    "                    full_plot_df = pd.concat([initial_df, plot_df], ignore_index=True)\n",
    "                    \n",
    "                    # Export data and log artifacts\n",
    "                    dir_path = f\"data/{date}/log_return/{model_type}\"\n",
    "                    os.makedirs(dir_path, exist_ok=True)\n",
    "                    full_plot_df.to_csv(f\"{dir_path}/{run_name}.csv\", index=False)\n",
    "                    \n",
    "                    fig2 = px.line(\n",
    "                        full_plot_df, x='Date', y='Valeur', color='Type',\n",
    "                        title=f'WF Pred: {model_type.upper()} | {param_name}={value}',\n",
    "                        template='simple_white', color_discrete_map=custom_colors\n",
    "                    )\n",
    "\n",
    "                    plot_path = f\"plot_{model_type}_{run_name}.html\"\n",
    "                    plot(fig2, filename=plot_path, auto_open=False)\n",
    "                    mlflow.log_artifact(plot_path)\n",
    "                    if os.path.exists(plot_path): os.remove(plot_path)\n",
    "\n",
    "print(\"MLflow grid search cycle complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d6ef0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 170\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fig\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8050\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m#The page can be accessed at http://127.0.0.1:8050/\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Programming\\Projects\\bitcoin_price_analysis\\.venv\\Lib\\site-packages\\dash\\dash.py:2481\u001b[39m, in \u001b[36mDash.run\u001b[39m\u001b[34m(self, host, port, proxy, debug, jupyter_mode, jupyter_width, jupyter_height, jupyter_server_url, dev_tools_ui, dev_tools_props_check, dev_tools_serve_dev_bundles, dev_tools_hot_reload, dev_tools_hot_reload_interval, dev_tools_hot_reload_watch_interval, dev_tools_hot_reload_max_retry, dev_tools_silence_routes_logging, dev_tools_disable_version_check, dev_tools_prune_errors, **flask_run_options)\u001b[39m\n\u001b[32m   2478\u001b[39m             extra_files.append(path)\n\u001b[32m   2480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m jupyter_dash.active:\n\u001b[32m-> \u001b[39m\u001b[32m2481\u001b[39m     \u001b[43mjupyter_dash\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_app\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2482\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjupyter_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjupyter_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjupyter_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjupyter_server_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2489\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2490\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2491\u001b[39m     \u001b[38;5;28mself\u001b[39m.server.run(host=host, port=port, debug=debug, **flask_run_options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Programming\\Projects\\bitcoin_price_analysis\\.venv\\Lib\\site-packages\\dash\\_jupyter.py:461\u001b[39m, in \u001b[36mJupyterDash.run_app\u001b[39m\u001b[34m(self, app, mode, width, height, host, port, server_url)\u001b[39m\n\u001b[32m    458\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m     \u001b[43mwait_for_app\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.in_colab:\n\u001b[32m    464\u001b[39m         JupyterDash._display_in_colab(dashboard_url, port, mode, width, height)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Programming\\Projects\\bitcoin_price_analysis\\.venv\\Lib\\site-packages\\retrying.py:55\u001b[39m, in \u001b[36mretry.<locals>.wrap.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_f\u001b[39m(*args, **kw):\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRetrying\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Programming\\Projects\\bitcoin_price_analysis\\.venv\\Lib\\site-packages\\retrying.py:298\u001b[39m, in \u001b[36mRetrying.call\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    296\u001b[39m         sleep = sleep + \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, jitter)\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m._logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetrying in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msleep\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[32m1000.0\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m attempt_number += \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Crypto Predictor Analysis Dashboard.\n",
    "\n",
    "This Dash app aggregates results from the MLflow-driven experiments,\n",
    "allowing for side-by-side comparison of different hyperparameters and \n",
    "model architectures across Log-Return and Normal Value datasets.\n",
    "\"\"\"\n",
    "\n",
    "# --- 1. Data Aggregation ---\n",
    "\n",
    "date = \"2026_01_15\" # or datetime.datetime.now().strftime(\"%Y_%m_%d\") \n",
    "base_path = os.path.join(\"..\", \"data\", date)\n",
    "all_results = []\n",
    "\n",
    "# Walk through the directory structure to collect experiment CSVs\n",
    "for data_type in ['normal_value', 'log_return']:\n",
    "    for model_name in ['lstm', 'gru', 'simplernn']:\n",
    "        folder_path = os.path.join(base_path, data_type, model_name)\n",
    "        \n",
    "        if not os.path.exists(folder_path):\n",
    "            continue\n",
    "            \n",
    "        for file in os.listdir(folder_path):\n",
    "            if not file.endswith('.csv'):\n",
    "                continue\n",
    "                \n",
    "            csv_path = os.path.join(folder_path, file)\n",
    "            df = pd.read_csv(csv_path)\n",
    "            \n",
    "            # Enrich the dataframe with metadata extracted from path/filename\n",
    "            df['analysis_type'] = data_type\n",
    "            df['model_name'] = model_name\n",
    "            \n",
    "            # Split 'param_value' from filename (e.g., 'learning_rate_0.01.csv')\n",
    "            param_string = file.replace('.csv', '')\n",
    "            try:\n",
    "                name, val = param_string.rsplit('_', 1)\n",
    "                df['param_name'] = name\n",
    "                df['param_value'] = val\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "            all_results.append(df)\n",
    "\n",
    "# Combine all experiment data into a single master DataFrame\n",
    "if all_results:\n",
    "    df_results = pd.concat(all_results, ignore_index=True)\n",
    "else:\n",
    "    print(\"Warning: No results found in the specified path.\")\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "# --- 2. Dash Application Layout ---\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Crypto Predictor Analysis Dashboard\", style={'textAlign': 'center', 'padding': '20px'}),\n",
    "    \n",
    "    # Navigation & Filter Bar\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Label(\"Analysis Type\", style={'fontWeight': 'bold'}),\n",
    "            dcc.Dropdown(\n",
    "                id='dropdown-analysis', \n",
    "                options=[{'label': i.replace('_', ' ').title(), 'value': i} \n",
    "                         for i in sorted(df_results['analysis_type'].unique())],\n",
    "                value=df_results['analysis_type'].unique()[0] if not df_results.empty else None\n",
    "            )\n",
    "        ], style={'width': '30%', 'display': 'inline-block'}),\n",
    "        \n",
    "        html.Div([\n",
    "            html.Label(\"Model Architecture\", style={'fontWeight': 'bold'}),\n",
    "            dcc.Dropdown(\n",
    "                id='dropdown-model', \n",
    "                options=[{'label': i.upper(), 'value': i} \n",
    "                         for i in sorted(df_results['model_name'].unique())],\n",
    "                value=df_results['model_name'].unique()[0] if not df_results.empty else None\n",
    "            )\n",
    "        ], style={'width': '30%', 'display': 'inline-block', 'marginLeft': '5%'}),\n",
    "        \n",
    "        html.Div([\n",
    "            html.Label(\"Hyperparameter Tested\", style={'fontWeight': 'bold'}),\n",
    "            dcc.Dropdown(id='dropdown-param')\n",
    "        ], style={'width': '30%', 'display': 'inline-block', 'marginLeft': '5%'})\n",
    "    ], style={'padding': '20px', 'backgroundColor': '#f9f9f9', 'borderRadius': '10px', 'margin': '20px'}),\n",
    "\n",
    "    # Primary Visualization Area\n",
    "    dcc.Loading(\n",
    "        id=\"loading-graph\",\n",
    "        type=\"circle\",\n",
    "        children=dcc.Graph(id='main-graph', style={'height': '85vh'})\n",
    "    )\n",
    "])\n",
    "\n",
    "# --- 3. Callbacks ---\n",
    "\n",
    "@app.callback(\n",
    "    Output('dropdown-param', 'options'),\n",
    "    Output('dropdown-param', 'value'),\n",
    "    [DashInput('dropdown-analysis', 'value'),\n",
    "     DashInput('dropdown-model', 'value')]\n",
    ")\n",
    "def update_param_list(analysis_type, model_name):\n",
    "    \"\"\"Updates the parameter list based on selected analysis type and model.\"\"\"\n",
    "    mask = (df_results['analysis_type'] == analysis_type) & (df_results['model_name'] == model_name)\n",
    "    params = sorted(df_results[mask]['param_name'].unique())\n",
    "    options = [{'label': p.replace('_', ' ').title(), 'value': p} for p in params]\n",
    "    default_val = params[0] if params else None\n",
    "    return options, default_val\n",
    "\n",
    "@app.callback(\n",
    "    Output('main-graph', 'figure'),\n",
    "    [DashInput('dropdown-analysis', 'value'),\n",
    "     DashInput('dropdown-model', 'value'),\n",
    "     DashInput('dropdown-param', 'value')]\n",
    ")\n",
    "def update_graph(a_type, m_name, p_name):\n",
    "    \"\"\"Generates a grid of plots for each value tested within a parameter group.\"\"\"\n",
    "    if not p_name: \n",
    "        return go.Figure()\n",
    "\n",
    "    # Filter data for specific grid view\n",
    "    sub_df = df_results[\n",
    "        (df_results['analysis_type'] == a_type) & \n",
    "        (df_results['model_name'] == m_name) & \n",
    "        (df_results['param_name'] == p_name)\n",
    "    ]\n",
    "    \n",
    "    # Sort parameter values numerically if possible\n",
    "    p_values = sorted(\n",
    "        sub_df['param_value'].unique(), \n",
    "        key=lambda x: (float(x) if str(x).replace('.', '', 1).isdigit() else x)\n",
    "    )\n",
    "    \n",
    "    cols = 2\n",
    "    rows = int(np.ceil(len(p_values) / cols))\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=rows, cols=cols,\n",
    "        subplot_titles=[f\"<b>{p_name}: {v}</b>\" for v in p_values],\n",
    "        vertical_spacing=0.1, \n",
    "        horizontal_spacing=0.08\n",
    "    )\n",
    "\n",
    "    for i, val in enumerate(p_values):\n",
    "        v_df = sub_df[sub_df['param_value'] == val]\n",
    "        r, c = (i // cols) + 1, (i % cols) + 1\n",
    "        \n",
    "        for t_type in ['Initial sequence', 'Real values', 'Predictions']:\n",
    "            t_data = v_df[v_df['Type'] == t_type]\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=t_data['Date'], \n",
    "                y=t_data['Valeur'],\n",
    "                name=t_type, \n",
    "                line=dict(color=custom_colors[t_type]),\n",
    "                legendgroup=t_type,\n",
    "                showlegend=(i == 0)\n",
    "            ), row=r, col=c)\n",
    "\n",
    "    fig.update_layout(\n",
    "        template='simple_white',\n",
    "        margin=dict(t=100, b=50, l=50, r=50),\n",
    "        hovermode='x unified',\n",
    "        title=f\"Grid Analysis: {m_name.upper()} | Dataset: {a_type} | Parameter: {p_name}\"\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=8050)\n",
    "    #The page can be accessed at http://127.0.0.1:8050/\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
